\documentclass[10pt]{mypackage}

% sans serif font:
%\usepackage{cmbright,sfmath,bbold}
%\renewcommand{\mathcal}{\mathtt}

%Euler:
\usepackage{newpxtext,eulerpx,eucal,eufrak}
\renewcommand*{\mathbb}[1]{\varmathbb{#1}}
\renewcommand*{\hbar}{\hslash}

%kp fonts:
%\usepackage{kpfonts}
%\renewcommand{\mathbb}{\mathds}

\pagestyle{fancy} %better headers
\fancyhf{}
\rhead{Avinash Iyer}
\lhead{Partial Differential Equations: Class Notes}

\setcounter{secnumdepth}{0}

\begin{document}
\renewcommand{\arraystretch}{1.5}
\RaggedRight
\section{Introduction}%
Consider the equations
\begin{align*}
  \frac{d^2y}{dx^2} + y(x) &= e^x\tag*{(1)}\\
  \diff{^{17}y}{x^{17}}(x) + \sin\left(y(x)\right) &= \left(x^{x}\right)^{x}\tag*{(2)}
\end{align*}
Before we want to solve these equations, we need to understand what these equations \textit{are}. 
\begin{enumerate}[(1)]
  \item This is a second order, inhomogeneous, linear ordinary differential equation.
  \item This is a 17th order, inhomogeneous, nonlinear ordinary differential equation.
\end{enumerate}
Generally, when we have a nonlinear equation, we convert it (using the Jacobian) to the ``nearest'' corresponding linear equation using Taylor approximations. In this case, converting equation (2), we have
\begin{align*}
  \diff{^{17}y}{x^{1y}}(x) + y(x) &= \left(x^{x}\right)^{x}.\tag*{(2')}
\end{align*}
Now, equation (2') is linear, so it is able to be solved. It may not be pretty,\footnote{Citation needed.} but it can be solved, using Laplace Transforms or other methods.
\section{Ordinary Differential Equations}%
Returning to our equation (1), 
\begin{align*}
  \frac{d^2y}{dx^2} + y(x) &= e^x,\tag*{(1)}
\end{align*}
there is one more fact that we can see --- this is an equation with constant coefficients. The most general form of a $n$th order linear ordinary differential equation is of the form
\begin{align*}
  a_n(x)\diff{^ny}{x^n}(x) + a_{n-1}(x)\diff{^{n-1}y}{x^{n-1}}(x) + \cdots + a_1(x)\frac{dy}{dx} + a_0(x)y(x) = g(x).\label{eq:general_linear_ode}\tag{\textdagger}
\end{align*}
Specifically, we also require $a_k(x)\in C(I)$, where $I$ is some interval (specifics will be detailed later).
\begin{theorem}[Existence and Uniqueness Theorem]
  Any ordinary differential equation of the form (\textdagger) has unique solutions in the interval $I$.\newline

  There are $n$ linearly independent solutions for $g(x) = 0$.
\end{theorem}
The corresponding homogeneous equation for (1) is
\begin{align*}
  \frac{d^2y}{dx^2} + y(x) &= 0.\tag*{(1')}
\end{align*}
The equations (1) and (1') are related by the linearity principle. In particular, if $y_0(x)$ is a solution to (1'), then we can add $\alpha y_0(x)$ to any solution $y_p(x)$ of (1), then we have all the solutions for (1). In particular, the solutions to (1') are
\begin{align*}
  y_1(x) &= \sin(x)\\
  y_2(x) &= \cos(x).
\end{align*}
To evaluate that these solutions are linearly independent, we consider the differential operator $L$ from (\textdagger) defined by
\begin{align*}
  L\left[y\right] &= \sum_{k=0}^{n}a_k(x)\diff{^{k}y}{x^{k}}.
\end{align*}
We rewrite (\textdagger) as
\begin{align*}
  L\left[y\right] &= g(x).
\end{align*}
The operator $L$ is linear, so $L$ has the following properties:
\begin{itemize}
  \item $L\left[y_1 + y_2\right]$;
  \item $L\left[cy\right] = cL\left[y\right]$.
\end{itemize}
Now, in (1) and (1'), if we set $L\left[y\right] = \frac{d^2y}{dx^2} + y(x)$, then evaluating our solutions $y_1$ and $y_2$ to (1'), we get
\begin{align*}
  L\left[c_1y_1 + c_2y_2\right] &= c_1L\left[y_1\right] + c_2L\left[y_2\right]\\
                                &= 0.
\end{align*}
Now, we get
\begin{align*}
  y_0(x) &= c_1\sin(x) + c_2\sin(x)
\end{align*}
as our general solution to (1'). By the linearity principle, all we need is one solution to $L\left[y\right] = e^x$ to find all solutions to (1).\newline

Evaluating \eqref{eq:general_linear_ode} in the most general form, we have the general solution
\begin{align*}
  y(x) &= \underbrace{c_1y_1(x) + c_2y_2(x) + \cdots + c_ny_n(x)}_{\text{homogeneous solution}} + y_p(x),
\end{align*}
where $y_p(x)$ is the particular solution. In other words, our general solution is
\begin{align*}
  y(x) &= \Span\left(y_1(x),y_2(x),\dots,y_n(x)\right) + y_p(x).
\end{align*}
For this to work, we need the set $\set{y_1,\dots,y_n}$ to be linearly independent. To do this, we evaluate the Wronskian:
{
  \begin{align*}
    W(x) &= \det \begin{pmatrix}y_1(x) & y_2(x) & \cdots & y_n(x) \\ \diff{y_1}{x}& \diff{y_2}{x} & \cdots & \diff{y_n}{x} \\ \vdots & \vdots & \ddots & \vdots \\ \diff{^{n-1}y_1}{x^{n-1}} & \diff{^{n-1}y_2}{x^{n-1}} & \cdots & \diff{^{n-1}y_n}{x^{n-1}}\end{pmatrix}.
\end{align*}
}
Specifically, the set $\set{y_1,\dots,y_n}$ is linearly independent if $W(x)\neq 0$ for all $x\in I$.
\begin{example}
  Consider the equation
  \begin{align*}
    \frac{d^2y}{dx^2} - y(x) &= e^{x}\tag{1}
  \end{align*}
  We want to find the general solution to this constant coefficient equation.\newline

  We start by finding two linearly independent homogeneous solutions to the equation, take their span, then add a particular solution.\newline

  The characteristic equation of the homogeneous equation for (1) is
  \begin{align*}
    r^2 - 1 &= 0
  \end{align*}
  We get $r=\pm 1$, which by the definition of the characteristic equation yields $y_1(x) = e^{x}$ and $y_2(x) = e^{-x}$. To verify that this this solution set is linearly independent
  {\renewcommand{\arraystretch}{1.25}
    \begin{align*}
      W(x) &= \det \begin{pmatrix}e^{x} & e^{-x} \\ e^{x} & -e^{-x}\end{pmatrix}\\
           &= -2\\
           &\neq 0.
  \end{align*}
  }
  Thus, our solutions are linearly independent. We get the general form of
  \begin{align*}
    y(x) &= c_1e^{x} + c_2e^{-x} + y_p(x).
  \end{align*}
  Now, we only have to find a particular solution. This is, unfortunately, the hard part.\newline

  We begin by guessing. But, in a way that doesn't suck. Specifically, we let $y_p(x) = Axe^{x}$. Evaluating, we get
  \begin{align*}
    \diff{y_p}{x} &= A\left(x+1\right)e^{x}\\
    \diff{^2y_p}{x^2} &= A\left(x+2\right)e^{x}\\
     \diff{^2y_p}{x^2}- y_p(x) &= A\left(x+2\right)e^{x} - Axe^{x}\\
                        &= 2Ae^{x},
  \end{align*}
  so $2A = 1$, and $A = \frac{1}{2}$. Thus, we have the end result of
  \begin{align*}
    y(x) &= c_1e^{x} + c_2e^{x} + \frac{1}{2}xe^{x}.
  \end{align*}
  Evaluating in Mathematica, we take
  \begin{lstlisting}[style=mathematicastyle]
    DSolve[y''[x] - y[x] == Exp[x], y[x], x]
  \end{lstlisting}
  and we get
  \begin{align*}
    y(x) &= c_1e^{x} + c_2e^{-x} + \frac{1}{4}\left(2x-1\right)e^{x},
  \end{align*}
  corroborating our solution.\footnote{Only slightly different, but they're the same solution.}
\end{example}
\begin{example}
  Consider the equation
  \begin{align*}
    \diff{^3y}{x^3} - y(x) &= 0.
  \end{align*}
  The particular solution to this equation is $y(x) = 0$. The characteristic equation for this equation is
  \begin{align*}
    r^3 - 1 &= 0.
  \end{align*}
  Factoring, we get
  \begin{align*}
    \left(r-1\right)\left(r^2 + r + 1\right) &=0\\
    \left(r-1\right)\left(r-\zeta_3\right)\left(r-\zeta_3^2\right) &= 0.
  \end{align*}
  Thus, we get
  \begin{align*}
    r &= \set{1, e^{\frac{2\pi i}{3}}, e^{\frac{4\pi i}{3}}}.
  \end{align*}
  Thus, our solutions are of the form
  \begin{align*}
    y(x) &= c_1e^{x} + c_2e^{-\frac{1}{2}x}\cos\left(\frac{\sqrt{3}}{2}x\right) + c_3e^{-\frac{1}{2}x}\sin\left(\frac{\sqrt{3}}{2}x\right).
  \end{align*}
\end{example}
Recall that the most general second order constant-coefficient linear differential equation is 
\begin{align*}
  y'' + ay' + by &= 0,
\end{align*}
with characteristic equation 
\begin{align*}
  r^2 + ar + b &=0.
\end{align*}
The solutions to the characteristic equation are
\begin{align*}
  r &= -\frac{a}{2} \pm \frac{\sqrt{a^2 - 4b}}{2}.
\end{align*}
There are a few cases:
\begin{enumerate}[(1)]
  \item $r_1\neq r_2$ with $r_1,r_2\in \R$;
  \item $r_1 = r_2$ with $r_1,r_2\in \R$;
  \item $r_1 = c + id$, $r_2 = c - id$, where $c,d\in \R$.
\end{enumerate}
The solutions are $y_1 = c_1e^{r_1 x}$ and $y_2 = c_2e^{r_2 x}$.
\begin{example}[Solving Second-Order Equations]\hfill
  \begin{enumerate}[(1)]
    \item Let
      \begin{align*}
        y'' - 3y' + 2y &= 0.
      \end{align*}
      The characteristic equation is $r^2 - 3r + 2 = 0$, whose solutions are $r=1,r=2$. The general solution is, thus,
      \begin{align*}
        y(x) &= c_1 e^x + c_2e^{2x}\tag{\textdagger}
      \end{align*}
      The Wronskian is
      \begin{align*}
        W(x) &= \det \begin{pmatrix}e^x & e^{2x} \\ e^x & 2e^{2x}\end{pmatrix}\\
             &= 2e^{3x} - e^{3x}\\
             &= e^{3x}\\
             &\neq 0.
      \end{align*}
      Thus, the solution is indeed (\textdagger).
    \item Let
      \begin{align*}
        y'' + 6y' + 9y &=0.
      \end{align*}
      The characteristic equation is $r^2 + 6r + 9 =0$, with solution $r = -3,-3$. Currently, we only have the solution $y_1(x) = c_1e^{-3x}$.\newline

      Note that in an $n$th order linear ordinary differential equation, we always have $n$ linearly independent solutions. Let's guess. Consider the equation $y_2(x) = c_2xe^{-3x}$.\newline

      We can see that $y_2(x)$ is also a solution to this equation,\footnote{Exercise left for the reader.} but we need to verify linear independence. Taking the Wronskian, we get
      \begin{align*}
        W(x) &= \det \begin{pmatrix}e^{-3x} & xe^{-3x} \\ -3e^{-3x} & -3xe^{-3x} + e^{-3x}\end{pmatrix}\\
             &= e^{-6x} \begin{pmatrix}1 & x \\ -3 & -3x + 1\end{pmatrix}\\
             &= e^{-6x}\left(-3x + 1 + 3x\right)\\
             &= e^{-6x}\\
             &\neq 0.
      \end{align*}
      Thus, we have two linearly independent solutions, with the general solution of
      \begin{align*}
        y(x) &= c_1e^{-3x} + c_2xe^{-3x}.
      \end{align*}
    \item Let
      \begin{align*}
        y'' + 4y' + 5 &= 0.
      \end{align*}
      The characteristic equation is $r^2 + 4r + 5 = 0$, with solutions of $r = -2 \pm i$. We then have the solutions
      \begin{align*}
        y_1(x) &= e^{\left(-2 + i\right)x}\\
        y_2(x) &= e^{\left(-2-i\right)x}.
      \end{align*}
      Unfortunately, we cannot just let these equations stand on their own, because we want \textit{real} solutions. Let's use Euler's theorem, $e^{ix} = \cos x + i\sin x$. Then, we get
      \begin{align*}
        y(x) &= c_1e^{\left(-2+i\right)x} + c_2e^{\left(-2-i\right)x}\\
             &= e^{-2x}\left(c_1e^{ix} + c_2e^{-ix}\right).
      \end{align*}
      Let $f(x) = c_1e^{ix} + c_2e^{-ix}$. Using the even/odd decomposition, we get
      \begin{align*}
        f(x) &= \frac{1}{2}\left(f(x) + f\left(-x\right)\right) + \frac{1}{2}\left(f(x) - f\left(-x\right)\right)\\
             &= \left(c_1 + c_2\right)\cos\left(x\right) + i\left(c_1 - c_2\right)\sin\left(x\right).
      \end{align*}
      We ``real''-ize our solution by just dropping the value of $i$ in $f(x)$. Thus, we get the full general solution
      \begin{align*}
        y(x) &= e^{-2x}\left(d_1\cos\left(x\right) + d_2\sin\left(x\right)\right).
      \end{align*}
    \item If we have the equation
      \begin{align*}
        y^{(4)} - 25y'',
      \end{align*}
      then using a similar process, we get the solution
      \begin{align*}
        y(x) = c_1 + c_2 x + c_3e^{5x} + c_4e^{-5x}.
      \end{align*}
    \item Considering the equation
      \begin{align*}
        y^{(5)} + 4y''' + 4y' = 0,
      \end{align*}
      we take the characteristic equation $r^{5}+ 4r^3 + 4r = 0$. Factoring, we get solutions of $r=0,r=\pm i\sqrt{2}$. Thus, we get the solution of
      \begin{align*}
        y(x) = c_1 + c_2\cos\left(\sqrt{2}x\right) + c_3\sin\left(\sqrt{2}x\right) + c_4x\cos\left(\sqrt{2}x\right) + c_5x\sin\left(\sqrt{2}x\right).
      \end{align*}
  \end{enumerate}
\end{example}
\subsection{Reducing our Orders}%
Let
\begin{align*}
  \frac{d^2y}{dx^2} + p(x)\frac{dy}{dx} + q(x)y(x) &= 0.
\end{align*}
Suppose we know $y_1(x)$. Can we find $y_2(x)$? The answer is yes. We presume
\begin{align*}
  y_2(x) &= v(x)y_1(x).
\end{align*}
Now, we have
\begin{align*}
  y_2 &= vy_1\\
  y_2' &= v'y_1 + vy_1'\\
  y_2'' &= v''y_1 + 2v'y_1' + vy_1'',
\end{align*}
and inserting into the equation, we get
\begin{align*}
  0 &= v''y_1 + 2v'y_1' + vy_1'' + pv'y_1 + pvy_1' + qvy_1\\
    &= v''y_1 + 2v'y_1' + pv'y_1 + v\underbrace{\left(y_1'' + py_1' + qy_1\right)}_{=0}\\
    &= v''y_1 + 2v'y_1' + pv'y_1
\end{align*}
Now, we have
\begin{align*}
  \frac{v''}{v'} &= -2\frac{y_1'}{y_1} - p.\tag{\textasteriskcentered}
\end{align*}
Integrating, we get
\begin{align*}
  \ln\left(v'\right) &= -2\ln\left(y_1\right) - \int_{}^{} p(x)\:dx.
\end{align*}
Taking powers, we get
\begin{align*}
  v' &= e^{-2\ln\left(y_1\right) - \int_{}^{} p(x)\:dx}\\
     &= y_1^{-2} e^{-\int_{}^{} p(x)\:dx}\\
     &= \frac{e^{-\int_{}^{} p(x)\:dx}}{y_1(x)^2}\\
  v &= \int_{}^{} \frac{e^{-\int_{}^{} p(x)\:dx}}{y_1(x)^2}\:dx
\end{align*}
\begin{example}
  Consider the equation
  \begin{align*}
    \cos^2\left(x\right)\frac{d^2y}{dx^2} - \sin(x)\cos(x)y' - y(x) = 0.
  \end{align*}
  Putting our equation into standard form, we may be able to find another solution.
  \begin{align*}
    y'' - \tan(x)y' - \sec^2\left(x\right)y &= 0.
  \end{align*}
  Guessing $y(x) = \tan(x)$, we get $y' = \sec^2\left(x\right)$ and $y'' = 2\sec^2\left(x\right)\tan(x)$. This is also another solution, $y_2(x) = \tan(x)$.\newline

  We don't want to guess anymore. Let $y_2(x) = v(x)y_1(x)$. We get
  \begin{align*}
    v(x) &= \int_{}^{} \frac{e^{-\int_{}^{} p(x)\:dx}}{y_1^2\left(x\right)}\:dx.
  \end{align*}
  We have $-p(x) = \tan(x)$, so $-\int_{}^{} p(x)\:dx = \ln\left(\sec(x)\right)$. Thus, $e^{-\int_{}^{} p(x)\:dx} = \sec(x)$. Thus, we get
  \begin{align*}
    v(x) &= \int_{}^{} \frac{\sec(x)}{\tan^2\left(x\right)}\:dx\\
         &= \int_{}^{} \frac{\cos(x)}{\sin^2\left(x\right)}\:dx\\
         &= \int_{}^{} \frac{1}{u^2}\:du\tag*{$u = \sin(x)$}\\
         &= -\frac{1}{u}\\
         &= -\csc(x).
  \end{align*}
  Thus, we have $y_2(x) = -\csc(x)\tan(x) = -\sec(x)$. 
\end{example}
\begin{example}
  Consider the equation
  \begin{align*}
    x^2\left(\ln(x)-1\right)\frac{d^2y}{dx^2} -x\frac{dy}{dx} + \frac{dy}{dx} = 0.
  \end{align*}
  We can use the power of inspection to find one solution, $y_1(x) = x$. Dividing out, we have
  \begin{align*}
    y'' - \frac{1}{x\left(\ln(x) - 1\right)} y' + \frac{1}{x^2\left(\ln(x) - 1\right)}y &= 0.
  \end{align*}
  Using the reduction of order, we guess $y_2(x) = v(x)y_1(x)$, and have
  \begin{align*}
    v(x) &= \int_{}^{} \frac{e^{-\int_{}^{} p(x)\:dx}}{y_1^2}\:dx.
  \end{align*}
  Noting that $-p(x) = \frac{1}{x\left(\ln(x)-1\right)}$, we have $\int_{}^{} \frac{1}{x\left(\ln(x)-1\right)}\:dx = \ln\left(\ln(x)-1\right)$.\newline

  Now, we have
  \begin{align*}
    v(x) &= \int_{}^{} \frac{\ln(x)-1}{x^2}\:dx\\
         &= \frac{1-\ln(x)}{x} - \int_{}^{} -\frac{1}{x^2}\:dx\tag*{$u=\ln(x)-1,dv=x^{-2}$}\\
         &= \frac{-\ln(x)}{x} - \frac{1}{x}\\
         &= -\frac{\ln(x)}{x}.
  \end{align*}
  Thus, we get $y_2(x) = -\ln(x)$, and the general solution of $y(x) = c_1 x + c_2\ln(x)$.
\end{example}
\begin{example}[Cauchy--Euler Equation]
  A second-order Cauchy--Euler equation is of the form
  \begin{align*}
    ax^2\frac{d^2y}{dx^2} + bx\frac{dy}{dx} + cy(x) &= 0.
  \end{align*}
  More generally,
  \begin{align*}
    \sum_{k=0}^{n}c_kx^ky^{(k)}(x) &= 0.
  \end{align*}
  We guess $y(x) = x^r$. Then, $\frac{dy}{dx} = rx^{r-1}$ and $\frac{d^2y}{dx^2} = r(r-1)x^{r-2}$. This yields
  \begin{align*}
    a(r)(r-1)x^r + brx^{r} + cx^r &=x^r \left(a\left(r^2 - r\right) + br + c\right)\\
                                  &= 0.
  \end{align*}
\end{example}
\begin{example}[Solving a Cauchy--Euler Equation]
  Consider the equation
  \begin{align*}
    x^2y'' + xy' - y &= 0.
  \end{align*}
  Substituting the characteristic equation, we get
  \begin{align*}
    r^2 - 1 &= 0,
  \end{align*}
  so our general solution is $y(x) = c_1x + c_2/x$.
\end{example}
\begin{example}[Solving another Cauchy--Euler Equation]
  Consider the equation
  \begin{align*}
    x^2y'' - 3xy' + 4y &= 0.
  \end{align*}
  Substituting the characteristic equation, we get
  \begin{align*}
    r^2 - 4r + 4 &= 0,
  \end{align*}
  so our solutions are $x^2$ and $x^2$. This is not good enough, we need another solution.\newline

  Now, we place our equation into standard form.
  \begin{align*}
    y'' - \frac{3}{x}y' + \frac{4}{x^2}y' &= 0.
  \end{align*}
  Thus, we get $p(x) = -\frac{3}{x}$. Using reduction of order, we get $y_2(x) = v(x)y_1(x)$,
  \begin{align*}
    v(x) &= \int_{}^{} \frac{e^{-\int_{}^{} -3/x\:dx}}{x^4}\:dx\\
         &= \int_{}^{} \frac{e^{3\ln(x)}}{x^4}\:dx\\
         &= \int_{}^{} \frac{x^3}{x^4}\:dx\\
         &= \ln(x).
  \end{align*}
  Thus, we have the solution $y_2(x) = \ln(x)x^2$, and the general solution of $y(x) = c_1x^2 + c_2\ln(x)x^2$.
\end{example}
\begin{example}
  Consider the equation
  \begin{align*}
    x^2y'' + 3xy' + 5y &= 0.
  \end{align*}
  We get the characteristic equation of
  \begin{align*}
    0 &= r^2 - 4r + 5\\
    r &= 2\pm i.
  \end{align*}
  Now, we need to figure out what $x^{2\pm i}$ means.\newline

  To solve this part, we keep the positive exponent, so we only need to try to understand $y = x^{2 + i}$. Now, we get $y = x^2 x^i$. To evaluate $x^{i}$, we take $x = \left(e^{\ln x}\right)^{i} = e^{i\ln x}$. Using Euler's identity, we get
  \begin{align*}
    y &= x^2\left(\cos\left(\ln x\right) + i\sin\left(\ln x\right)\right).
  \end{align*}
  Since our solutions are real, get
  \begin{align*}
    y &= c_1x^2\cos\left(\ln x\right) + c_2x^2\sin\left(\ln x\right).
  \end{align*}
\end{example}
\begin{example}
  Consider the equation
  \begin{align*}
    x^4y^{(4)} - 2x^2y'' + y &= 2.
  \end{align*}
  We have the particular solution $y_p(x) = 2$. Substituting into our method for the Cauchy--Euler equation, we have
  \begin{align*}
    r\left(r-1\right)\left(r-2\right)\left(r-3\right) - 2r\left(r-1\right) + 1 &= 0.
  \end{align*}
  Factoring, we have
  \begin{align*}
    r\left(r-1\right)^2\left(r-4\right) + 1 &= 0.
  \end{align*}
  Unfortunately, to go forward from here we need Mathematica.\newline

  This has the solution set of of
  \begin{align*}
    r_1 &=\frac{3}{2}-\frac{1}{2} \sqrt{3+\frac{1}{3} \sqrt[3]{135-6 \sqrt{249}}+\frac{\sqrt[3]{45+2
   \sqrt{249}}}{3^{2/3}}}\\
      &-\frac{1}{2} \sqrt{6-\frac{1}{3} \sqrt[3]{135-6 \sqrt{249}}-\frac{\sqrt[3]{45+2
   \sqrt{249}}}{3^{2/3}}-\frac{8}{\sqrt{3+\frac{1}{3} \sqrt[3]{135-6 \sqrt{249}}+\frac{\sqrt[3]{45+2
   \sqrt{249}}}{3^{2/3}}}}}\\
          r_2 &=\frac{3}{2}-\frac{1}{2} \sqrt{3+\frac{1}{3} \sqrt[3]{135-6 \sqrt{249}}+\frac{\sqrt[3]{45+2
   \sqrt{249}}}{3^{2/3}}}\\
            &+\frac{1}{2} \sqrt{6-\frac{1}{3} \sqrt[3]{135-6 \sqrt{249}}-\frac{\sqrt[3]{45+2
   \sqrt{249}}}{3^{2/3}}-\frac{8}{\sqrt{3+\frac{1}{3} \sqrt[3]{135-6 \sqrt{249}}+\frac{\sqrt[3]{45+2
   \sqrt{249}}}{3^{2/3}}}}}\\
                r_3 &=\frac{3}{2}+\frac{1}{2} \sqrt{3+\frac{1}{3} \sqrt[3]{135-6 \sqrt{249}}+\frac{\sqrt[3]{45+2
   \sqrt{249}}}{3^{2/3}}}\\
                  &-\frac{1}{2} \sqrt{6-\frac{1}{3} \sqrt[3]{135-6 \sqrt{249}}-\frac{\sqrt[3]{45+2
   \sqrt{249}}}{3^{2/3}}+\frac{8}{\sqrt{3+\frac{1}{3} \sqrt[3]{135-6 \sqrt{249}}+\frac{\sqrt[3]{45+2
   \sqrt{249}}}{3^{2/3}}}}}\\
                      r_4&=\frac{3}{2}+\frac{1}{2} \sqrt{3+\frac{1}{3} \sqrt[3]{135-6 \sqrt{249}}+\frac{\sqrt[3]{45+2
   \sqrt{249}}}{3^{2/3}}}\\
                       &+\frac{1}{2} \sqrt{6-\frac{1}{3} \sqrt[3]{135-6 \sqrt{249}}-\frac{\sqrt[3]{45+2
   \sqrt{249}}}{3^{2/3}}+\frac{8}{\sqrt{3+\frac{1}{3} \sqrt[3]{135-6 \sqrt{249}}+\frac{\sqrt[3]{45+2
   \sqrt{249}}}{3^{2/3}}}}}
  \end{align*}
  
\end{example}
\subsection{Varying our Parameters}%
Given a set of $n$ linearly independent homogeneous solutions, we want to find a particular solution.\newline

To find this, we start with the general second-order inhomogeneous equation in standard form:
\begin{align*}
  \frac{d^2y}{dx^2} + p(x)\frac{dy}{dx} + q(x)y(x) = g(x).
\end{align*}
Given $y_1,y_2$, we find $y_p(x)$ by taking
\begin{align*}
  y_p &= v_1y_1 + v_2y_2.
\end{align*}
Finding the derivatives, we have
\begin{align*}
  y_p' &= v_1y_1' + v_1'y_1 + v_2y_2' + v_2'y_2\\
  y_p'' &= v_1y_1'' + 2v_1'y_1' + v_1''y_1 + v_2y_2'' + 2v_2'y_2' + v_2''y_2.
\end{align*}
Substituting, we have
\begin{align*}
  y_p'' &= v_1y_1'' + 2v_1'y_1' + v_1''y_1 + v_2y_2'' + 2v_2'y_2' + v_2''y_2\\
  py_p' &= pv_1y_1' + pv_1'y_1 + pv_2y_2' + pv_2'y_2\\
  qy_p &= qv_1y_1 + qv_2y_2\\
  \\
  g(x) &= v_1\overbrace{\left(y_1'' + py_1' + qy_1\right)}^{=0} + v_2\overbrace{\left(y_2'' + py_2' + qy_2\right)}^{=0} + v_1'\left(2y_1'+py_1\right) + v_1''y_1 + v_2\left(2y_2' + py_2\right) + v_2''y_2\\
       \\
  g(x) &= v_1'\left(2y_1' + py_1\right) + v_1''y_1 + v_2\left(2y_2' + py_2\right) + v_2''y_2.
\end{align*}
We suppose that $v_1'y_1 + v_2'y_2 = 0$. Then,
\begin{align*}
  \diff{}{x}\left(v_1'y_1 + v_2'y_2\right) &= 0\\
  v_1''y_1 + v_1'y_1' + v_2''y_2 + v_2'y_2 &= 0.
\end{align*}
Plugging into our earlier expression, we get the expression of
\begin{align*}
  v_1'y_1 + v_2'y_2 &= 0\\
  v_2'y2' + v_2'y_2' &= g(x).
\end{align*}
Plugging into matrix form, we have
\begin{align*}
  \begin{pmatrix}y_1 & y_2 \\ y_1' & y_2'\end{pmatrix} \begin{pmatrix}v_1'\\v_2'\end{pmatrix} &= \begin{pmatrix}0\\g(x)\end{pmatrix}.
\end{align*}
Since the Wronskian is nonzero, we have
\begin{align*}
  \begin{pmatrix}\diff{v_1}{x} \\ \diff{v_2}{x}\end{pmatrix} &= \begin{pmatrix}y_1 & y_2\\y_1' & y_2'\end{pmatrix}^{-1} \begin{pmatrix}0\\g(x)\end{pmatrix}\\
                                                 &= \frac{1}{y_1(x)\diff{y_2}{x} - y_2(x)\diff{y_1}{x}} \begin{pmatrix}-y_2(x)g(x) \\ y_1(x)g(x)\end{pmatrix}\label{eq:variation_parameters}\tag{\textdaggerdbl}
\end{align*}
\begin{example}
  Let
  \begin{align*}
    y'' - 2y' + y &= e^x.
  \end{align*}
  Solving the homogeneous solution, we have the characteristic equation of $r^2 - 2r + 1 = 0$. Thus, $y_1(x) = e^x$ and $y_2(x) = xe^x$.\newline

  To find $y_p(x)$, we guess $y_p(x) = x^2 e^x$. Using the power of computation in Sage, we get the answer of
  \begin{lstlisting}[style=pythonstyle,title=Avoiding Variation of Parameters]
  de = diff(y,x,2) - 2*diff(y,x) + y - e^(x)
  g = desolve(de,y)
  latex(expand(g))
  \end{lstlisting}
  
  \begin{align*}
    y_p(x) &= K_{2} x e^{x}+ K_{1} e^{x} + \frac{1}{2} x^{2} e^{x}.
  \end{align*}
  However, this is a very unsatisfying method.\newline

  Using \eqref{eq:variation_parameters}, we can find a different solution. We find
  \begin{align*}
    \diff{v_1}{x} &= \frac{1}{e^{2x}}\left( \left( -1 \right)\left( xe^{x} \right)\left( e^x \right) \right)\\
            &= -x,
  \end{align*}
  yielding
  \begin{align*}
    v_1(x) &= -\frac{x^2}{2} + c_2.
  \end{align*}
  Similarly, we get
  \begin{align*}
    \diff{v_2}{x} &= \frac{1}{e^{2x}}\left( e^x \right)\left( e^x \right)\\
    v_2(x) &= x + c_2.
  \end{align*}
  This gives
  \begin{align*}
    y_p(x) &= \frac{1}{2}x^2e^x.
  \end{align*}
\end{example}
\begin{example}
  Let
  \begin{align*}
    \diff{^3y}{x^3} - \frac{dy}{dx} &= x + e^{x}.
  \end{align*}
  Using the characteristic equation, we have $y_1(x) = 1$, $y_2(x) = e^x$, and $y_3(x) = e^{-x}$.\newline

  Now, using the Wronskian, we get
  \begin{align*}
    \begin{pmatrix}v_1' \\ v_2' \\ v_3'\end{pmatrix} &= \begin{pmatrix}1 & e^x & e^{-x} \\ 0 & e^x & -e^{-x} \\ 0 & e^{x} & e^{-x}\end{pmatrix}^{-1} \begin{pmatrix}0\\0\\x + e^{x}\end{pmatrix}.
  \end{align*}
  This would suck, but we would be able to find a solution nonetheless.
\end{example}
In the general form, with linearly independent homogeneous solutions $y_1,\dots,y_n$, we have the solution of
\begin{align*}
  \begin{pmatrix}v_1' \\ \vdots \\ v_n'\end{pmatrix} &= \begin{pmatrix}y_1 & \cdots & y_n \\ \vdots & \ddots & \vdots \\ y_1^{(n-1)} & \cdots & y_n^{(n-1)}\end{pmatrix}^{-1} \begin{pmatrix}0 \\ \vdots \\ g(x)\end{pmatrix}\\
  y(x) &= \sum_{i=1}^{n}c_iy_i(x) + \sum_{i=1}^{n}v_i(x)y_i(x).
\end{align*}
\begin{example}[Solving a Coupled System]
  Before we can start using variation of parameters for systems, we need to recall how to solve constant-coefficient systems.
  \begin{align*}
    x'(t) &= 3x(t) + y(t)\\
    y'(t) &= x(t) + 3y(t).
  \end{align*}
  Here, setting
  \begin{align*}
    \mathbf{x} &= \begin{pmatrix}x(t)\\y(t)\end{pmatrix},
  \end{align*}
  we get system of linear equations
  \begin{align*}
    \mathbf{x}'(t) &= \begin{pmatrix}3 & 1 \\ 1 & 3\end{pmatrix} \mathbf{x}\\
    \begin{pmatrix}x'(t) \\y'(t)\end{pmatrix} &= \begin{pmatrix}3& 1\\1&3\end{pmatrix} \begin{pmatrix}x(t)\\y(t)\end{pmatrix}.
  \end{align*}

\end{example}
\begin{remark}
In the matrix
\begin{align*}
  A &= \begin{pmatrix}a & b \\ b & a\end{pmatrix},
\end{align*}
the eigenvalues are 
\begin{align*}
  \lambda_1 &= a + b\\
  \lambda_2 &= a-b\\
  \end{align*}
  with eigenvectors of
  \begin{align*}
  \mathbf{v}_1 &= \begin{pmatrix}1\\1\end{pmatrix}\\
  \mathbf{v}_2 &= \begin{pmatrix}1\\-1\end{pmatrix}.
\end{align*}
\end{remark}
\begin{example}[General $n$-dimensional System of Differential Equations]
  Consider the system of equations defined by
  \begin{align*}
    x_1'(t) &= g_1\left( t,x_1(t),\dots,x_n(t) \right)\\
            &\vdots\\
    x_n'(t) &= g_n\left( t,x_1(t),\dots,x_n(t) \right).
  \end{align*}
  We will refine this slightly so as to be a system of \textit{linear} equations. Let
  \begin{align*}
    \mathbf{x} &= \begin{pmatrix}x_1(t)\\\vdots\\x_n(t)\end{pmatrix}\\
    \diff{\mathbf{x}}{t} &= \begin{pmatrix}x_1'(t)\\\vdots\\x_n'(t)\end{pmatrix}\\
    \mathbf{F} &= \begin{pmatrix}f_1(t) \\ \vdots \\ f_n(t)\end{pmatrix}\\
    \mathbf{x}_{t_0} &= \begin{pmatrix}x_1\left(t_0\right)\\\vdots\\x_n\left(t_0\right)\end{pmatrix}.
  \end{align*}
  Now, we have
  \begin{align*}
    \diff{\mathbf{x}}{t} &= A\mathbf{x},
  \end{align*}
  where $\mathbf{x}\left(t_0\right) = \mathbf{x}_{t_0}$ and $A$ is some matrix that represents some linear transformation.\newline

  Furthermore, we may make an inhomogeneous equation by
  \begin{align*}
    \diff{\mathbf{x}}{t} &= A\mathbf{x} + \mathbf{F}.
  \end{align*}
\end{example}
\begin{example}
  Going back to our example of
  \begin{align*}
    \diff{\mathbf{x}}{t} &= \underbrace{\begin{pmatrix}3 & 1 \\ 1 & 3\end{pmatrix}}_{A}\mathbf{x}.
  \end{align*}
  We find eigenvalues of $\lambda_1 = 4,\lambda_2 = 2$ and eigenvectors $\mathbf{v}_1 = \begin{pmatrix}1\\1\end{pmatrix}$ and $\mathbf{v}_2 = \begin{pmatrix}1\\-1\end{pmatrix}$. This gives
  \begin{align*}
    \mathbf{x}_1 &= e^{4t} \begin{pmatrix}1\\1\end{pmatrix}\\
    \mathbf{x}_2 &= e^{2t} \begin{pmatrix}1\\-1\end{pmatrix}.
  \end{align*}
  In general, if we have two distinct eigenvalues, then our solutions are
  \begin{align*}
    \mathbf{x} &= e^{\lambda t} \mathbf{v}
  \end{align*}
  Define
  \begin{align*}
    \Phi_A(t) &= \begin{pmatrix}\mathbf{x}_1 & \mathbf{x}_2\end{pmatrix}\\
                       &= \begin{pmatrix}e^{4t} & e^{2t} \\ e^{4t} & -e^{2t}\end{pmatrix}.
  \end{align*}
  We call $\Phi_A$ a fundamental matrix for $A$.\newline

  The general solution to the system is given by
  \begin{align*}
    \mathbf{x}(t) &= c_1\mathbf{x}_1(t) + c_2\mathbf{x}_2(t)\\
                  &= c_1 \begin{pmatrix}e^{4t}\\e^{4t}\end{pmatrix} + c_2 \begin{pmatrix}e^{2t} \\ -e^{2t}\end{pmatrix}\\
                  &= \begin{pmatrix}e^{4t} & e^{2t} \\ e^{4t} & -e^{2t}\end{pmatrix} \begin{pmatrix}c_1\\c_2\end{pmatrix}.
  \end{align*}
\end{example}
\begin{example}
  Consider the equation
  \begin{align*}
    \diff{\mathbf{x}}{t} &= A\mathbf{x},
  \end{align*}
  where
  \begin{align*}
    A &= \begin{pmatrix}4 & 2 & 1 \\ 0 & 4 & 2 \\ 0 & 0 & 4\end{pmatrix} \label{eq:generalized_eigenvalues_example}\tag{$A$}
  \end{align*}
  Notice that we have a triple-repeated eigenvalue,
  \begin{align*}
    \lambda_1 &= 4\\
    \lambda_2 &= 4\\
    \lambda_3 &= 4.
  \end{align*}
  Unfortunately, to find the eigenvectors, this will be a bit harder.
  \begin{align*}
    \left( A - 4I \right)\mathbf{v} &= 0\\
    \begin{pmatrix}0 & 2 & 1 \\ 0 & 0 & 2 \\ 0 & 0 & 0\end{pmatrix} \begin{pmatrix}a\\b\\c\end{pmatrix} &= \begin{pmatrix}0\\0\\0\end{pmatrix}.
  \end{align*}
  This gives
  \begin{align*}
    \begin{pmatrix}2b + c \\ 2c \\ 0 \end{pmatrix} &= \begin{pmatrix}0\\0\\0\end{pmatrix},
  \end{align*}
  so $b = c = 0$, and our eigenvector is
  \begin{align*}
    \mathbf{v}_1 &= \begin{pmatrix}1\\0\\0\end{pmatrix}.
  \end{align*}
  We may need some more eigenvectors. Currently, our solution is
  \begin{align*}
    \mathbf{x}_1(t) &= e^{4t} \begin{pmatrix}1\\0\\0\end{pmatrix}.
  \end{align*}
  We need to go into the realm of generalized eigenvectors. If $\lambda$ is repeated, we need to do the following.
  \begin{enumerate}[(1)]
    \item Find all the eigenvectors for which $\left( A - \lambda I \right)\mathbf{v} = 0$. If we come up short, then we have a defective system.
    \item For the remaining eigenvectors, we solve the system
      \begin{align*}
        \left( A - \lambda I \right)\mathbf{v}_j &= \mathbf{v}_k,
      \end{align*}
      where $\mathbf{v}_k$ is known, and we desire $\mathbf{v}_j$. The $\mathbf{v}_j$ are known as generalized eigenvectors.
    \item Continue this process until we are done. 
  \end{enumerate}
  Now, in this case, we get
  \begin{align*}
    \begin{pmatrix}0 & 2 & 1 \\ 0 & 0 & 2 \\ 0 & 0 & 0\end{pmatrix} \begin{pmatrix}a\\b\\c\end{pmatrix} &= \begin{pmatrix}1\\0\\0\end{pmatrix}.
  \end{align*}
  This gives
  \begin{align*}
    \begin{pmatrix}2b + c \\ 2c \\ 0\end{pmatrix} &= \begin{pmatrix}1\\0\\0\end{pmatrix},
  \end{align*}
  and a generalized eigenvector of
  \begin{align*}
    \mathbf{v}_2 &= \begin{pmatrix}0\\1/2\\0\end{pmatrix}.
  \end{align*}
  Going at it again, we have
  \begin{align*}
    \begin{pmatrix}0 & 2 & 1 \\ 0 & 0 & 2 \\ 0 & 0 & 0\end{pmatrix} \begin{pmatrix}a\\b\\c\end{pmatrix} &= \begin{pmatrix}0\\1/2\\0\end{pmatrix},
  \end{align*}
  giving the equation
  \begin{align*}
    \begin{pmatrix}2b + c\\2c\\0\end{pmatrix} &= \begin{pmatrix}0\\1/2\\0\end{pmatrix},
  \end{align*}
  giving
  \begin{align*}
    \mathbf{v}_3 &= \begin{pmatrix}0\\-1/8\\1/4\end{pmatrix}.
  \end{align*}
  Note that when we take generalized eigenvectors, we ``integrate'' with respect to $t$ before adding. For instance
  \begin{align*}
    \mathbf{x}_1 &= e^{\lambda t} \mathbf{v}_1\\
    \mathbf{x}_2 &= e^{\lambda t} \left( t \mathbf{v}_1 + \mathbf{v}_2 \right)\\
    \mathbf{x}_3 &= e^{\lambda t} \left( \frac{t^2}{t}\mathbf{v}_1 + t\mathbf{v}_2 + \mathbf{v}_3 \right).
  \end{align*}
  Now, our linearly independent solutions to the system in \eqref{eq:generalized_eigenvalues_example} is of the form
  \begin{align*}
    \mathbf{x}_1(t) &= e^{4t} \begin{pmatrix}1\\0\\0\end{pmatrix}\\
    \mathbf{x}_2(t) &= e^{4t} \left( t\begin{pmatrix}1\\0\\0\end{pmatrix} + \begin{pmatrix}0\\1/2\\0\end{pmatrix} \right)\\
    \mathbf{x}_3 (t) &= e^{4t} \left( \frac{t^2}{2} \begin{pmatrix}1\\0\\0\end{pmatrix} + t \begin{pmatrix}0\\1/2\\0\end{pmatrix} + \begin{pmatrix}0\\-1/8\\1/4\end{pmatrix} \right).
  \end{align*}
  This gives the fundamental matrix
  \begin{align*}
    \Phi(t) &= \begin{pmatrix}e^{4t} & te^{4t} & \frac{t^2}{2}e^{4t} \\ 0 & \frac{1}{2}e^{4t} & e^{4t}\left( \frac{t}{2} - \frac{1}{8} \right) \\ 0 & 0 & \frac{1}{4}e^{4t}\end{pmatrix}.
  \end{align*}
  The general solution is
  \begin{align*}
    \mathbf{x}(t) &= \Phi(t) \mathbf{c}.
  \end{align*}
  The general solution is, then,
  \begin{align*}
    \mathbf{x}(t) &= e^{At}\mathbf{c},
  \end{align*}
  where $\mathbf{c}$ is a constant vector, and $e^{At}$ is the matrix exponential of $A$.
\end{example}
\begin{example}
  Consider $A$ as the matrix with eigenvalue $\lambda$ and eigenvector $\mathbf{v}_1$ and generalized eigenvectors $\mathbf{v}_2$ and $\mathbf{v}_3$. Then, the solution set
  \begin{align*}
    \mathbf{x}_1(t) &= e^{\lambda t}\mathbf{v}_1\\
    \mathbf{x}_2(t) &= e^{\lambda t}\left( t\mathbf{v}_1 + \mathbf{v}_2 \right)\\
    \mathbf{x}_3(t) &= e^{\lambda t}\left( \frac{t^2}{2}\mathbf{v}_1 + t\mathbf{v}_2 + \mathbf{v}_3 \right).
  \end{align*}
  Thus, we have
  \begin{align*}
    \diff{\mathbf{x}}{t} &= \lambda e^{\lambda t} \mathbf{v}_1\\
    A\mathbf{x}_1(t) &= Ae^{\lambda t} \mathbf{v}_1\\
                     &= e^{\lambda t} A\mathbf{v}_1\\
                     &= \lambda e^{\lambda t}\mathbf{v}_1.
  \end{align*}
  Now, recalling that $A\mathbf{v}_1 = \lambda \mathbf{v}_1$ and $A\mathbf{v}_2 = \lambda \mathbf{v}_2 + \mathbf{v}_1$, we have
  \begin{align*}
    \diff{\mathbf{x}_2}{t} &= \lambda e^{\lambda t}\left( t\mathbf{v}_1 + \mathbf{v}_2 \right) + e^{\lambda t}\mathbf{v}_1\\
    A\mathbf{x}_2(t) &= Ae^{\lambda t}\left( t\mathbf{v}_1 + \mathbf{v}_2 \right)\\
                     &= e^{\lambda t}\left( tA\mathbf{v}_1 +  A\mathbf{v}_2\right)\\
                     &= e^{\lambda t}\left( t\lambda \mathbf{v}_1 + \lambda \mathbf{v}_2 + \mathbf{v}_1 \right)\\
                     &= \lambda e^{\lambda t}\left( t\mathbf{v}_1 + \mathbf{v}_2 \right) + e^{\lambda t}\mathbf{v}_1.
  \end{align*}
  Finally, we have $A\mathbf{v}_3 = \lambda \mathbf{v}_3 + \mathbf{v}_2 $.
\end{example}
\begin{example}
  We assume $A$ is a $n\times n$ real matrix. Then, all complex eigenvalues of $A$ come in conjugate pairs, $\lambda_1 = a + ib$ and $\lambda_2 = a - ib$.\newline

  Then, our eigenvectors are of the form $\mathbf{v}_1 = \mathbf{u} + i\mathbf{w}$ and $\mathbf{v}_2 = \mathbf{u} - i\mathbf{w}$.\newline

  Note that if we find the solution for $\lambda_1$ and $\mathbf{v}_2$. This gives
  \begin{align*}
    e^{\lambda t}\mathbf{v} &= e^{\left( a + ib \right)} \left( \mathbf{u} + i\mathbf{w} \right)\\
                            &= e^{at}\left( \cos\left( bt \right) + i\sin\left( bt \right) \right) \left( \mathbf{u} + i\mathbf{w} \right)\\
                            &= e^{at}\left( \left( \cos\left( bt \right) \mathbf{u} - \sin\left( bt \right)\mathbf{w} \right) + i\left( \cos\left( bt \right)\mathbf{w} + \sin\left( bt \right)\mathbf{u} \right) \right).
  \end{align*}
\end{example}
\begin{example}
  Consider the matrix
  \begin{align*}
    A &= \begin{pmatrix}1 & 0 & -4 \\ 0 & 3 & 0 \\ 2 & 0 & 5\end{pmatrix}
  \end{align*}
  for the system of equations
  \begin{align*}
    \diff{\mathbf{x}}{t} &= A\mathbf{x}.
  \end{align*}
  Using the power of computation, we have
  \begin{align*}
    \lambda_1 &= 3\\
    \lambda_2 &= 3+2i\\
    \lambda_3 &= 3-2i,
  \end{align*}
  and eigenvectors of
  \begin{align*}
    \mathbf{v}_1 &= \begin{pmatrix}0\\1\\0\end{pmatrix}\\
    \mathbf{v}_2 &= \begin{pmatrix}-4\\0\\2+2i\end{pmatrix}\\
    \mathbf{v}_3 &= \begin{pmatrix}-4\\0\\2-2i\end{pmatrix}.
  \end{align*}
  Now, we see that
  \begin{align*}
    \mathbf{x}_1(t) &= e^{\lambda_1 t}\mathbf{v}_1\\
                    &= \begin{pmatrix}0\\e^{3t}\\0\end{pmatrix},
  \end{align*}
  and
  \begin{align*}
    \mathbf{x}_2(t) &= e^{3t}\left( \cos\left( 2t \right) \begin{pmatrix}-4\\0\\2\end{pmatrix} - \sin\left( 2t \right) \begin{pmatrix}0\\0\\2\end{pmatrix} \right)\\
    \mathbf{x}_3(t) &= e^{3t} \left( \cos\left( 2t \right) \begin{pmatrix}0\\0\\2\end{pmatrix} + \sin\left( 2t \right) \begin{pmatrix}-4\\0\\2\end{pmatrix} \right).
  \end{align*}
  This gives the matrix
  \begin{align*}
    \Phi(t) &= \begin{pmatrix}0 & -4e^{3t}\cos\left( 2t \right) & -4e^{3t}\sin\left( 2t \right) \\ e^{3t} & 0 & 0 \\ 0 & 2e^{3t}\left( \cos\left( 2t \right) - \sin\left( 2t \right) \right) & 2e^{3t}\left( \sin\left( 2t \right) + \cos\left( 2t \right) \right)\end{pmatrix}\\
    W(t) &= \det\left( \Phi(t) \right)\\
         &= -e^{3t}\left( -8e^{6t}\left( \cos\left( 2t \right)\sin\left( 2t \right) + \cos^2\left( 2t \right) \right) + 8e^{6t}\left( \sin\left( 2t \right)\cos\left( 2t \right) - \sin^2\left( 2t \right) \right) \right)\\
         &= 8e^{9t}\\
         &\neq 0.
  \end{align*}
\end{example}
\begin{example}
  We wish to solve $\diff{\mathbf{x}}{t} = A\mathbf{x}$, where
  \begin{align*}
    A &= \begin{pmatrix}2 & 0 & 1 & 0 & 0 \\ 0 & 1 & 0 & 5 & 0 \\ 0 & 0 & 2 & 0 & 0 \\ 0 & -2 & 0 & -1 & 0 \\ 0 & 0 & 0 & 0 & 2\end{pmatrix}.
  \end{align*}
  To find our eigenvalues and eigenvectors, we begin by finding
  \begin{align*}
    \det\left( A - \lambda I \right) &= \left( 2-\lambda \right)^2 \det \begin{pmatrix}2-\lambda & 0 & 0 \\ 0 & 1-\lambda & 5 \\ 0 & -2 & -1-\lambda\end{pmatrix}\\
                                     &= \left( 2-\lambda \right)^3 \det \begin{pmatrix}1-\lambda & 5 \\ -2 & -1-\lambda\end{pmatrix}\\
                                     &= \left( 2-\lambda \right)^3 \left( \left( 1-\lambda \right)\left( -1-\lambda \right) + 10 \right).
  \end{align*}
  We have five eigenvalues,
  \begin{align*}
    \lambda &= \pm 3i,2,2,2.
  \end{align*}
  For $\lambda_{1,2} = \pm3i$, then
  \begin{align*}
    \mathbf{v}_{1,2} &= \begin{pmatrix}0\\1\\0\\-2\\0\end{pmatrix} \pm i \:\begin{pmatrix}0\\3\\0\\0\\0\end{pmatrix}.
  \end{align*}
  Now for $\lambda_3 = 2$, we have
  \begin{align*}
    \mathbf{v}_3 &= \begin{pmatrix}0\\0\\0\\0\\1\end{pmatrix}.
  \end{align*}
  Now, we have
  \begin{align*}
    \left( A - 2I \right)\mathbf{v}_3 &= 0\\
    \begin{pmatrix}0 & 0 & 1 & 0 & 0 \\ 0 & -1 & 0 & 5 & 0 \\ 0 & 0 & 0 & 0 & 0 \\  0 & -2 & 0 & -3 & 0 \\ 0 & 0 & 0 & 0 & 0 \end{pmatrix} \:\begin{pmatrix}a\\b\\c\\d\\3\end{pmatrix} &= 0.
  \end{align*}
  From this equation, we have
  \begin{align*}
    c &= 0\\
    -b + 5d &= 0\\
    -2b-3d &= 0.
  \end{align*}
  Now, we have independent $a$ and $e$. This gives
  \begin{align*}
    \mathbf{v}_4 &= \begin{pmatrix}1\\0\\0\\0\\0\end{pmatrix}.
  \end{align*}
  Note that both $\mathbf{v}_3$ and $\mathbf{v}_4$ are regular eigenvectors. Now, we wish to find one generalized eigenvector. We find this generalized eigenvector, $\mathbf{w}$, by observing that the $1$ in entry $A_{1,3}$ effectively ties our vector $\mathbf{v}_4$ to vector $\mathbf{v}_{1,2}$. Thus, we get
  \begin{align*}
    \left( A - 2I \right)\mathbf{w} &= \mathbf{v}_4\\
    \begin{pmatrix}0 & 0 & 1 & 0 & 0 \\ 0 & -1 & 0 & 5 & 0 \\ 0 & 0 & 0 & 0 & 0 \\ 0 & -2 & 0 & -3 & 0 \\ 0 & 0 & 0 & 0 & 0\end{pmatrix} \begin{pmatrix}a\\b\\c\\d\\e\end{pmatrix} &= \begin{pmatrix}1\\0\\0\\0\\0\end{pmatrix}.
  \end{align*}
  Now, solving this, we get $c = 1$, giving the generalized eigenvector of
  \begin{align*}
    \mathbf{w} &= \begin{pmatrix}0\\0\\1\\0\\0\end{pmatrix}.
  \end{align*}
  Now, we have
  \begin{align*}
    \mathbf{v}_{1} &= \begin{pmatrix}0\\1\\0\\-2\\0\end{pmatrix} + i \:\begin{pmatrix}0\\3\\0\\0\\0\end{pmatrix}\\
    \mathbf{v}_{2} &= \begin{pmatrix}0\\1\\0\\-2\\0\end{pmatrix} - i \:\begin{pmatrix}0\\3\\0\\0\\0\end{pmatrix}\\
    \mathbf{v}_3 &= \begin{pmatrix}0\\0\\0\\0\\1\end{pmatrix}\\
    \mathbf{v}_4 &= \begin{pmatrix}1\\0\\0\\0\\0\end{pmatrix}\\
    \mathbf{w} &= \begin{pmatrix}0\\0\\1\\0\\0\end{pmatrix},
  \end{align*}
  where $\mathbf{v}_4\rightarrow \mathbf{w}$ is a chain of length $2$. This gives the JCF of
  \begin{align*}
    A &= \begin{pmatrix}0 & 0 & 0 & 1 & 0 \\ 1+3i & 1-3i & 0 & 0 & 0 \\ 0 & 0 & 0 & 0 & 1 \\ -2 & -2 & 0 & 0 & 0 \\ 0 & 0 & 1 & 0 & 0\end{pmatrix} \begin{pmatrix}3i & 0 & 0 & 0 & 0 \\ 0 & -3i & 0 & 0 & 0 \\ 0 & 0 & 2 & 0 & 0 \\ 0 & 0 & 0 & 2 & 1 \\ 0 & 0 & 0 & 0 & 2\end{pmatrix} \begin{pmatrix}0 & 0 & 0 & 1 & 0 \\ 1+3i & 1-3i & 0 & 0 & 0 \\ 0 & 0 & 0 & 0 & 1 \\ -2 & -2 & 0 & 0 & 0 \\ 0 & 0 & 1 & 0 & 0\end{pmatrix}^{-1}.
  \end{align*}
  We get the solutions
  \begin{align*}
    \mathbf{x}_1(t) &= \begin{pmatrix}0 \\ -\cos\left( 3t \right) - 3\sin\left( 3t \right)\\0\\2\cos\left( 3t \right)\\0\end{pmatrix}\\
    \mathbf{x}_2(t) &= \begin{pmatrix}0\\3\cos\left( 3t \right)-\sin\left( 3t \right) \\ 0 \\ 2\sin\left( 3t \right)\\0\end{pmatrix}\\
    \mathbf{x}_3(t) &= \begin{pmatrix}0\\0\\0\\0\\e^{2t}\end{pmatrix}\\
    \mathbf{x}_4(t) &= \begin{pmatrix}e^{2t}\\0\\0\\0\\0\end{pmatrix}\\
    \mathbf{x}_5(t) &= \begin{pmatrix}te^{2t}\\0\\e^{2t}\\0\\0\end{pmatrix},
  \end{align*}
  where $\mathbf{x}_5(t) = e^{2t}\left( t\mathbf{v}_4 + \mathbf{v}_5 \right)$.\newline

  The fundamental solution matrix is
  \begin{align*}
    \Phi(t) &= \begin{pmatrix}0 & 0 & 0 & e^{2t} & te^{2t} \\ -\cos\left( 3t \right) + 3\sin\left( 3t \right) & 3\cos\left( 3t \right) - \sin\left( 3t \right) & 0 & 0 & 0 \\ 0 & 0 & 0 & 0 & e^{2t} \\ 2\cos\left( 3t \right) & 2\sin\left( 3t \right) & 0 & 0 & 0 \\ 0 & 0 & e^{2t} & 0 & 0\end{pmatrix}.
  \end{align*}
  Now, we want to find $\Phi(0)$, or $\Phi\left( t_0 \right)$. Furthermore, we need to find $\Phi^{-1}(0)$, or $\Phi^{-1}\left( t_0 \right)$.
\end{example}

\end{document}
