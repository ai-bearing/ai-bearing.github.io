\documentclass[10pt]{mypackage}

% sans serif font:
%\usepackage{cmbright}
%\usepackage{sfmath}
%\usepackage{bbold} %better blackboard bold

%serif font + different blackboard bold for serif font
\usepackage{newpxtext,eulerpx}
\usepackage{eucal}
\renewcommand*{\mathbb}[1]{\varmathbb{#1}}
\renewcommand*{\hbar}{\hslash}
\DeclareMathOperator{\hdim}{hdim}
\DeclareMathOperator{\hDim}{hdim}
\DeclareMathOperator{\Hdim}{hdim}
\newcommand{\sa}{\text{s.a.}}
%\newcommand{\M}{\mathbb{M}}
\newcommand{\K}{\mathbb{K}}
\newcommand{\B}{\mathbb{B}}

\pagestyle{fancy} %better headers
\fancyhf{}
\rhead{Avinash Iyer}
\lhead{Functional Analysis: Hilbert Spaces and Operators}

\setcounter{secnumdepth}{0}

\begin{document}
\RaggedRight
\tableofcontents
\section{Introduction}%
This is going to be part of my notes for my Honors Thesis independent study, focused on Amenability and $C^{\ast}$-algebras. This set of notes will be focused on the theory of Hilbert spaces and bounded linear operators on Hilbert spaces. The primary source for this section of notes will be Timothy Rainone's \textit{Functional Analysis: En Route to Operator Algebras}.\newline

I do not claim any of this work to be original.
\section{Hilbert Spaces}%
In quantum mechanics, the state of a non-relativistic particle is given by a vector in some Hilbert space, which evolves by moving around that space. Specifically, the state of such a particle is determined entirely by the wave function $\xi = \xi\left(x,t\right)$, where $x\in \R$ is position and $t$ is time. The wave function is a probability distribution satisfying
\begin{align*}
  \int_{\R}^{} \left\vert \xi\left(x,t\right) \right\vert^2\:d\lambda &= 1.
\end{align*}
In particular, $\xi$ is an element of the space $L_{2}\left(\R,\lambda\right)$. The observables on $\xi$ are modeled as operators on $L_{2}\left(\R,\lambda\right)$.
\subsection{Theory of Hilbert Spaces}%
In undergraduate linear algebra, the dot product of vectors in $\R^n$, $v\cdot w$, is intimately tied to the geometry of $\R^n$ through the equations
\begin{align*}
  v\cdot v &= \norm{v}^2\\
  v\cdot w &= \norm{v}\norm{w}\cos\theta.
\end{align*}
Inner product spaces help generalize these properties.
\begin{definition}
  Let $X$ be a vector space over a field $\F$.
  \begin{enumerate}[(1)]
    \item An inner product on $X$ is a map 
      \begin{align*}
        \iprod{\cdot}{\cdot}: X\times X &\rightarrow \F\\
        \left(x,y\right) &\mapsto \iprod{x}{y}
      \end{align*}
      which satisfies the following conditions for all $x,y,z\in X$ and $\lambda,\mu\in \F$.
    \begin{enumerate}[(i)]
      \item $ \iprod{\lambda x + \mu y}{z} = \lambda \iprod{x}{z} + \mu \iprod{y}{z} $;
      \item $ \iprod{x}{y} = \overline{ \iprod{y}{x} } $;
      \item $ \iprod{x}{x} \geq 0 $;
      \item $ \iprod{x}{x} = 0 \Rightarrow x = 0_{X} $.
    \end{enumerate}
    If $ \iprod{\cdot}{\cdot} $ satisfies (i)--(iii), but not necessarily (iv), then it is called a semi-inner product.
  \item If $ \iprod{\cdot}{\cdot} $ is an inner product on $X$, the pair $\left(X, \iprod{\cdot}{\cdot}\right)$ is called an inner product space.
  \end{enumerate}
\end{definition}
\begin{remark}
  A semi inner product also satisfies, for all $x,y,z\in X$ and $\lambda,\mu \in \F$,
  \begin{align*}
    \iprod{x}{\lambda y + \mu z} &= \overline{\lambda} \iprod{x}{z} + \overline{\mu} \iprod{y}{z}.
  \end{align*}
  A semi-inner product is linear in the first variable and conjugate linear in the second variable.
\end{remark}
\begin{definition}
  Let $X$ be a complex vector space. A map
  \begin{align*}
    F: X\times X \rightarrow \C
  \end{align*}
  which is linear in the first variable and conjugate linear in the second variable is called a sesquilinear form on $X$.
\end{definition}
A fundamental fact about sesquilinear forms is that for any given sesquilinear form, we are able to pass it into a form that only consists of the same elements in both inputs.
\begin{lemma}[Polarization Identity]
Let $F: X\times X \rightarrow \C$ be a sesquilinear form on $X$. For all $x,y\in X$, we have
\begin{align*}
  4 F\left(x,y\right) &=  F\left(x+y,x+y\right) + iF\left(x+iy,x+iy\right) - F\left(x-y,x-y\right) + iF\left(x-iy,x-iy\right)\\
                      &= \sum_{k=0}^{3}i^{k}F\left(x + i^{k}y,x + i^{k}y\right).
\end{align*}
\end{lemma}
\begin{proof}
  Taking each expression
  \begin{align*}
    F\left(x+y,x+y\right) &= F\left(x,x\right) + F\left(x,y\right) + F\left(y,x\right) + F\left(y,y\right)\\
    iF\left(x + iy,x + iy\right) &= iF\left(x,x\right) - F\left(y,x\right) + F\left(x,y\right) + iF\left(y,y\right)\\
    -F\left(x-y,x-y\right) &= -F\left(x,x\right) + F\left(x,y\right) + F\left(y,x\right) - F\left(y,y\right)\\
    -iF\left(x-iy,x-iy\right) &= -iF\left(x,x\right) -F\left(y,x\right) + F\left(x,y\right) - iF\left(y,y\right).
  \end{align*}
  Adding these expressions up, we get the polarization identity.
\end{proof}
The following fact follows from the polarization identity.
\begin{fact}
  If $F$ and $G$ are two sesquilinear forms that agree on the diagonal --- i.e., $F(x,x) = G(x,x)$ --- then $F$ and $G$ agree everywhere.
\end{fact}

\begin{fact}
  Let $X$ be an inner product space, and suppose $z_1,z_2\in X$ are such that $ \iprod{x}{z_1} = \iprod{x}{z_2} $ for all $x\in X$. Then, $z_1 = z_2$.
\end{fact}
\begin{proof}
  We have $ \iprod{x}{z_1} = \iprod{x}{z_2} $. Then, $ \iprod{x}{z_1 - z_2} = 0 $ for all $x\in X$, so $ \iprod{z_1 - z_1}{z_1 - z_2} = 0 $, so $z_1 - z_2 = 0$.
\end{proof}
Let's see some inner product spaces.
\begin{example}[Finite-Dimensional Space]
  The finite dimensional space $\C^n$ admits an inner product space given by
  \begin{align*}
    \iprod{\xi}{\eta} &= \sum_{j=1}^{n}\xi_j \overline{\eta_j},
  \end{align*}
  where $\xi$ and $\eta$ are $n$ dimensional vectors over $\C$.
\end{example}
\begin{example}[Sequence Space]
  The space of square-summable sequences,
  \begin{align*}
    \ell_2 &= \set{\left(\lambda_k\right)_k | \sum_{n=1}^{\infty}\left\vert \lambda_n \right\vert^2 := \norm{\lambda}^2 < \infty}
  \end{align*}
  is an inner product space with the inner product
  \begin{align*}
    \iprod{\lambda}{\mu} &= \sum_{n=1}^{\infty}\lambda_n \overline{\mu_n}.
  \end{align*}
  The Cauchy--Schwarz inequality provides for this to be a well-defined inner product.
  \begin{align*}
    \sum_{n=1}^{N}\left\vert \lambda_n \overline{\mu_n} \right\vert &\leq \left(\sum_{n=1}^{N}\left\vert \lambda_n \right\vert^2\right)^{1/2}\left(\sum_{n=1}^{N}\left\vert \mu_n \right\vert^2\right)^{1/2}\\
                                                                    &\leq \norm{\lambda}_2\norm{\mu}_2\\
                                                                    &< \infty.
  \end{align*}
\end{example}
\begin{example}[Continuous Functions]
  The space $X = C\left([0,1]\right)$ admits an inner product given by
  \begin{align*}
    \iprod{f}{g} &= \int_{0}^{1} f(t)\overline{g(t)}\:dt.
  \end{align*}
\end{example}
\begin{example}[Sesquilinear Form on Continuous Function Space]
  Let $\Omega$ be a locally compact Hausdorff space and suppose $\varphi: C_0\left(\Omega\right)\rightarrow \F$ is a positive linear functional. We know that $\varphi = \varphi_{\mu}$ for some positive regular finite measure $\mu$ on $\left(\Omega,\B_{\Omega}\right)$, and
  \begin{align*}
    \varphi_{\mu}\left(f\right) &= \int_{\Omega}^{} f\:d\mu.
  \end{align*}
  We get a semi inner product on $C_{0}\left(\Omega\right)$ by
  \begin{align*}
    \iprod{\cdot}{\cdot}_{\varphi}: C_0\left(\Omega\right)\times C_0\left(\Omega\right) &\rightarrow \F\\
    \left(f,g\right) &\mapsto \int_{\Omega}^{} f\overline{g}\:d\mu.
  \end{align*}
  We claim that, when $\mu$ has full support, $ \iprod{\cdot}{\cdot}_{\varphi} $ is an inner product.\newline

  Suppose $g\in C_0\left(\Omega\right)$ with $g\geq 0$ and $g \neq 0$. Then, there is a nonempty open subset $U\subseteq \Omega$ and $\delta > 0$ such that $g(x) \geq \delta$ for all $x\in U$. Since $\mu$ has full support, it must be the case that $\mu\left(U\right) > 0$, so
  \begin{align*}
    \varphi\left(g\right) &= \int_{\Omega}^{} g\:d\mu\\
                          &\geq \int_{\Omega}^{} \delta \1_{U}\:d\mu\\
                          &= \delta \mu\left(U\right)\\
                          &> 0.
  \end{align*}
  Thus, if $ \iprod{f}{f}_{\varphi} = 0 $, then $\varphi\left(\left\vert f \right\vert^2\right) = 0$, so $f = 0$.
\end{example}
\begin{example}[Hilbert--Schmidt Operators]
  Let $\mathbb{M}_{n}$ be the $\ast$-algebra of $n\times n$ matrices over the complex numbers. Let $\tr: \mathbb{M}_{n}\rightarrow \C$ denote the trace. The trace is a linear, positive, faithful functional satisfying $\tr\left(a^{\ast}\right) = \overline{\tr\left(a\right)}$ for all $a\in \mathbb{M}_{n}$. The trace induces an inner product
  \begin{align*}
    \iprod{a}{b}_{\text{HS}} = \tr\left(b^{\ast}a\right),
  \end{align*}
  where the subscript HS stands for Hilbert--Schmidt.
\end{example}
\begin{definition}
  Let $X$ be an inner product space.
  \begin{enumerate}[(1)]
    \item We say two vectors $x,y\in X$ are orthogonal if $ \iprod{x}{y} = 0 $. We write $x\perp y$.
    \item Let $z\neq 0$ be a fixed vector in $X$. We define the one dimensional projection
      \begin{align*}
        P_{z}\left(x\right) &= \frac{ \iprod{x}{z} }{ \iprod{z}{z} } z.
      \end{align*}
      Note that $P_{z}$ is linear and its range is the one-dimensional subspace $\Span(z)$.
  \end{enumerate}
\end{definition}
\begin{note}
There are a lot of propositions, lemmas, and exercises in this section of my professor's textbook, but I'm not going to be going through all of them since we learn a lot of this in Real Analysis II.
\end{note}
We can turn any semi-inner product space into a seminormed vector space using the semi-inner product. If the semi-inner product is a true inner product, then we can use the inner product to define a norm.
\begin{definition}
  Let $X$ be a semi-inner product space. For each $x\in X$, we set
  \begin{align*}
    \norm{x} &= \iprod{x}{x}^{1/2}.
  \end{align*}
\end{definition}
\begin{theorem}[Pythagoras]
  Let $X$ be a semi-inner product space, and suppose $x_1,x_2,\dots,x_n$ are pairwise orthogonal. Then,
  \begin{align*}
    \norm{\sum_{j=1}^{n}x_j}^2 &= \sum_{j=1}^{n}\norm{x_j}^2
  \end{align*}
\end{theorem}
\begin{corollary}
  Let $X$ be an inner product space, and fix $z\neq 0$ in $X$. Then, for all $x,y\in X$, we have
  \begin{enumerate}[(1)]
    \item $\norm{x}^2 = \norm{x-P_z(x)}^2 + \norm{P_z(x)}^2$;
    \item $\norm{P_z(x)} \leq \norm{x}$;
    \item $\left\vert \iprod{x}{z} \right\vert \leq \norm{x}\norm{y}$, with equality if and only if $x$ and $y$ are linearly independent (the Cauchy--Schwarz inequality);
    \item $\norm{x + y} \leq \norm{x} + \norm{y}$;
    \item $\norm{\cdot}$ is a norm on $X$.
  \end{enumerate}
\end{corollary}
\begin{proposition}
  If $X$ is an inner product space, then the inner product
  \begin{align*}
    \iprod{\cdot}{\cdot}:X\times X \rightarrow \F
  \end{align*}
  is continuous.
\end{proposition}
We often start with a semi-inner product, then construct an inner product by quotient out by the null space.
\begin{proposition}
  Let $ \iprod{\cdot}{\cdot} $ be a semi-inner product on $X$.
  \begin{enumerate}[(1)]
    \item The set
      \begin{align*}
        N = \set{x\in X | \iprod{x}{x} = 0}
      \end{align*}
      is a subspace of $X$.
    \item The map
      \begin{align*}
        \iprod{x+N}{y+N}_{X/N} &= \iprod{x}{y}
      \end{align*}
      is an inner product on the quotient space $X/N$.
  \end{enumerate}
\end{proposition}
\begin{proposition}[Parallelogram Law]
Let $X$ be an inner product space. Then,
\begin{align*}
  \norm{x+y}^2 + \norm{x-y}^2 &= 2\norm{x}^2 + 2\norm{y}^2.
\end{align*}
\end{proposition}
Recall that Banach spaces include ideas regarding isometric isomorphisms --- however, we cannot immediately assume this extends to inner product spaces since they include an inherent geometric structure as well. As it turns out, this automatically appears from the definition of an isometry.
\begin{proposition}
  Let $X$ and $Y$ be inner product spaces. Suppose $V: X\rightarrow Y$ is a linear transformation. The following are equivalent.
  \begin{enumerate}[(i)]
    \item $V$ is an isometry;
    \item for each $x,x'\in X$, we have $ \iprod{V\left(x\right)}{V\left(x'\right)}_{Y} = \iprod{x}{x'}_{X} $.
  \end{enumerate}
\end{proposition}
\begin{proof}
  To show that (ii) implies (i), we see that for $x\in X$, 
  \begin{align*}
    \norm{V\left(x\right)}^2 &= \iprod{V\left(x\right)}{V\left(x\right)}\\
                &= \iprod{x}{x}\\
                &= \norm{x}^2.
  \end{align*}
  We define the sesquilinear forms
  \begin{align*}
    F\left(x,x'\right) &= \iprod{V\left(x\right)}{V\left(x'\right)}_{Y}\\
    G\left(x,x'\right) &= \iprod{x}{x'}.
  \end{align*}
  Since $V$ is norm-preserving, we have
  \begin{align*}
    F\left(x,x\right) &= \norm{V\left(x\right)}^2\\
                      &= \norm{x}^2\\
                      &= G\left(x,x\right),
  \end{align*}
  so by the polarization identity, $F$ and $G$ agree everywhere.
\end{proof}
\begin{definition}
  Let $X$ and $Y$ be inner product spaces. A surjective linear isometry $U: X\rightarrow Y$ is called a unitary operator.\newline

  Equivalently, a unitary operator is a linear isomorphism $U: X\rightarrow Y$ that preserves the inner product. We say $X$ and $Y$ are unitarily isomorphic.
\end{definition}
\begin{example}[A Nonunitary Isometry]
  Consider the right shift on $\ell_2$, defined by
  \begin{align*}
    R\left(\xi_1,\xi_2,\dots,\right) &= \left(0,\xi_1,\xi_2,\dots\right).
  \end{align*}
  Then, $R$ is not onto, but for each $\xi,\eta\in \ell_2$, we have $ \iprod{R\left(\xi\right)}{R\left(\eta\right)} = \iprod{\xi}{\eta} $. Thus, $R$ is isometric but not unitary.
\end{example}
\begin{definition}[Hilbert Space]
  A Hilbert space is an inner product space $\mathcal{H}$ over $\C$ such that the norm $\norm{x}^2 = \iprod{x}{x}$ is complete.
\end{definition}
\begin{example}
  The space $\ell_2$ of all square-summable sequences is a Hilbert space.
\end{example}
\begin{example}
  If $\left(\Omega,\mathcal{M},\mu\right)$ is any measure space, then $L_{2}\left(\Omega,\mu\right)$ is a Hilbert space with inner product
  \begin{align*}
    \iprod{f}{g} &= \int_{\Omega}^{} f\overline{g}\:d\mu.
  \end{align*}
  
\end{example}
\subsection{Orthogonal Projections}%
Recall that closed subspaces of Banach spaces may not always admit a topological complement (for instance, $c_0\subseteq \ell_{\infty}$). However, in a Hilbert space, a closed subspace always admits an orthogonal projection operator (hence a topological complement).
\begin{theorem}[Hilbert Projection Theorem]
  Let $\mathcal{H}$ be a Hilbert space. Suppose $C\subseteq \mathcal{H}$ is a closed and convex set. Given $x\in \mathcal{H}$, there is a unique $y_x\in C$ such that $\dist_{C}\left(x\right) = d\left(x,y_x\right)$. We say $y_x$ is the point in $C$ closest to $x$
\end{theorem}
\begin{proof}
  Set $d = \dist_{C}(x)$. If $x\in C$, we take $y=x$, so we assume $x\notin C$.\newline

  We find a sequence $\left(y_n\right)_{n\geq 1}$ with $d\left(x,y_n\right)\rightarrow d$ decreasing. Set $z_n = y_n - x$. We have $\norm{z_n}\rightarrow d$ decreasing, meaning $\norm{z_n}^2 \rightarrow d^2$ decreasing. Given $\ve > 0$, there is $N\in \N$ such that for $n\geq N$,
  \begin{align*}
    \norm{z_n}^2 < d^2 + \ve.
  \end{align*}
  We claim that $\left(y_n\right)_{n}$ is a Cauchy sequence in $C$. If $p,q\in \N$, we see that
  \begin{align*}
    y_p - y_q &= z_p - z_q\\
    \norm{\frac{1}{2}\left(z_p + z_q\right)} &= \norm{\frac{1}{2}\left(y_p + y_q\right) - x}\\
                                             &\geq d,
  \end{align*}
  as $\frac{1}{2}\left(y_p + y_q\right)$ belongs to $C$. Thus, for $p,q \geq N$, we have
  \begin{align*}
    \norm{y_p - y_q}^2 &= \norm{z_p - z_q}^2\\
                       &= 2\norm{z_p}^2 + 2\norm{z_q}^2 - \norm{z_p + z_q}^2\\
                       &= 2\norm{z_p}^2 + 2\norm{z_q}^2 - 4\norm{\frac{1}{2}\left(z_p + z_q\right)}^2\\
                       &\leq 2d^2 + 2\ve + 2d^2 + 2\ve - 4d^2\\
                       &= 4\ve.
  \end{align*}
  Since $C$ is closed, we thus have $d = \lim_{n\rightarrow\infty}d\left(x,y_n\right) = d\left(x,y\right)$ for $\left(y_n\right)_n \rightarrow y$ for some $y\in C$.\newline

  To see uniqueness, suppose $y_1,y_2\in C$ with $d\left(x,y_i\right) = d$. Set $z = y_j - x$ for each $j$. We have
  \begin{align*}
    0 &\leq \norm{z_1 - z_2}^2\\
      &= 2\norm{z_1}^2 + 2\norm{z_2}^2 - 4\norm{\frac{1}{2}\left(z_1 + z_2\right)}^2,
  \end{align*}
  meaning
  \begin{align*}
    0 &\leq \norm{y_1 - y_2}^2\\
      &= 2\norm{y_1 - x}^2 + 2\norm{y_2 - x}^2 - 4\norm{\frac{1}{2}\left(y_1 + y_2\right) - x}^2\\
      &\leq 2d^2 + 2d^2 - 4d^2\\
      &= 0.
  \end{align*}
  Thus, $y_1 = y_2$.
\end{proof}
\begin{definition}
  Let $\mathcal{H}$ be a Hilbert space, and let $M\subseteq \mathcal{H}$ be a closed subspace. We define
  \begin{align*}
    P_M: \mathcal{H}\rightarrow \mathcal{H}
  \end{align*}
  by $P_M\left(x\right) = y_x$, where $y_x$ is the unique point from the Hilbert projection theorem.\newline

  We call $P_M$ the orthogonal projection of $\mathcal{H}$ onto $M$.
\end{definition}
\begin{fact}
  There are some facts about the orthogonal projection that are useful for us to know.
  \begin{itemize}
    \item $P_M(x) = x \Leftrightarrow x\in M$;
    \item $\Ran\left(P_M\right) = M$;
    \item $P_M \circ P_M = P_M$ (i.e., that $P_M$ is idempotent).
  \end{itemize}
\end{fact}
\begin{definition}
  Let $X$ be an inner product space, and suppose $S\subseteq X$ is an arbitrary subset. We define the perp of $S$, $S^{\perp}$, to be
  \begin{align*}
    S^{\perp} &= \set{x\in X | \iprod{x}{y} = 0\text{ for all $y\in S$}}.
  \end{align*}
  
\end{definition}
\begin{exercise}
  Let $S\subseteq \mathcal{H}$ be an arbitrary subset. Prove the following.
  \begin{enumerate}[(1)]
    \item $S^{\perp}$ is always a closed subspace of $\mathcal{H}$.
    \item $S\subseteq \left(S^{\perp}\right)^{\perp}$.
    \item $S\cap S^{\perp} = \set{0}$.
  \end{enumerate}
\end{exercise}
\begin{solution}\hfill
  \begin{enumerate}[(1)]
    \item For $x,x'\in S^{\perp}$ and $\alpha \in \C$, we have for all $y\in S$,
      \begin{align*}
        \iprod{x + \alpha x'}{y} &= \iprod{x}{y} + \alpha \iprod{x'}{y}\\
                                 &= 0,
      \end{align*}
      so $S^{\perp}$ is a subspace. Additionally, for any sequence $\left(x_n\right)_n\subseteq S^{\perp}$ with $\left(x_n\right)_n\rightarrow x$ in $X$, the continuity of the inner product gives
      \begin{align*}
        \iprod{x_n}{y} &\rightarrow \iprod{x}{y}\\
                       &= 0.
      \end{align*}
    \item For $t\in S$, we have, for all $x\in S^{\perp}$,
      \begin{align*}
        \iprod{x}{t} &= 0\\
                     &= \iprod{t}{x},
      \end{align*}
      meaning $t \in \left(S^{\perp}\right)^{\perp}$.
    \item If $t\in S\cap S^{\perp}$, then $t\in S$ and $t\in S^{\perp}$, so
      \begin{align*}
        \iprod{t}{t} &= 0,
      \end{align*}
      so $t = 0$.
  \end{enumerate}
\end{solution}
One of the features of Hilbert spaces is that closed subspaces are always complemented. 
\begin{theorem}
  Let $M\subseteq \mathcal{H}$ be a closed subspace of a Hilbert space $\mathcal{H}$. Then, the following are true.
  \begin{enumerate}[(1)]
    \item $x-P_M\left(x\right)\in M^{\perp}$ for all $x\in \mathcal{H}$.
    \item $\mathcal{H} = M\oplus M^{\perp}$.
    \item $\left(M^{\perp}\right)^{\perp} = M$.
    \item Let $P$ and $Q$ denote the projection operators onto $M$ and $M^{\perp}$ according to the decomposition $\mathcal{H} = M\oplus M^{\perp}$. Then, $P = P_M$ and $Q = P_{M^{\perp}}$.
    \item $P_M$ is linear, $P_M^2 = P_M$, $\Ran\left(P_M\right) = M$, $\norm{P_M} = 1$, and $\ker\left(P_M\right) = M^{\perp}$.
    \item $\mathcal{H}/M \cong M^{\perp}$ are isometrically isomorphic.
  \end{enumerate}
\end{theorem}
\begin{proof}\hfill
  \begin{enumerate}[(1)]
    \item Let $y = P_M(x)$, and set $z = x-y$. We know that $\norm{z} = \dist_{M}(x) = d$. Let $0\neq \xi\in M$. Set $\zeta = P_{\xi}(z) = \frac{ \iprod{z}{\xi} }{ \iprod{\xi}{\xi} }\xi$.\newline

      We claim that $\zeta = 0$. Note that
      \begin{align*}
        \norm{z - \zeta}&= \norm{x - y-\zeta}\\
                        &= \norm{x - \left(y + \zeta\right)}\\
                        &\geq d,
      \end{align*}
      as $y + \zeta \in M$.\newline

      On the other hand, we have
      \begin{align*}
        \norm{z - \zeta}^2 + \norm{\zeta}^2 &= \norm{z}^2\\
                                            &= d^2.
      \end{align*}
      Thus, $\norm{ z - \zeta } \leq d$. With $\norm{z - \zeta} = d$, we have $\norm{x - y - \zeta} = d$. Thus, we must have $y + \zeta = y$, so $\zeta = 0$.
    \item If $x\in \mathcal{H}$, we have
      \begin{align*}
        x &= P_M\left(x\right) + x - P_M\left(x\right),
      \end{align*}
      and since $M\cap M^{\perp} = \set{0}$, we have $\mathcal{H} = M\oplus M^{\perp}$.
    \item It is the case that $M\subseteq \left(M^{\perp}\right)^{\perp}$. Let $x\in \left(M^{\perp}\right)^{\perp}$. Write $x = y + z$ according to the decomposition $\mathcal{H} = M\oplus M^{\perp}$. Then, $z = x - y \in \left(M^{\perp}\right)^{\perp}\cap \left(M^{\perp}\right) = \set{0}$, so $x = y\in M$, so $M = \left(M^{\perp}\right)^{\perp}$.
    \item By the way we have defined $P$ and $Q$, we must have $P(x)  = P_M(x)$ for every $x\in \mathcal{H}$. Let $\widetilde{P}$ and $\widetilde{Q}$ be the bounded linear projections according to the decomposition $\mathcal{H} = M^{\perp}\oplus \left(M^{\perp}\right)^{\perp}$. Since $M = \left(M^{\perp}\right)^{\perp}$, we have $\widetilde{Q} = P$. Additionally, we must have $\widetilde{P} = P_{M^{\perp}}$. Thus,
      \begin{align*}
        Q &= I - P\\
          &= I - \widetilde{Q}\\
          &= \widetilde{P}\\
          &= P_{M^{\perp}}.
      \end{align*}
    \item By the Pythagorean theorem, we have
      \begin{align*}
        \norm{x}^2 &= \norm{P_M(x)}^2 + \norm{x-P_M(x)}^2
      \end{align*}
      for every $x\in \mathcal{H}$, so $\norm{P_M(x)}\leq \norm{x}$, meaning $\norm{P_M} \leq 1$. Since $P_{M}^2 = P_{M}$, we also have $\norm{P_M} \geq 1$.
    \item Notice that $P_{M^{\perp}}:\mathcal{H}\rightarrow M^{\perp}$ is a $1$-quotient map with the kernel $\ker\left(P_{M^{\perp}}\right) = M$. Thus, we have $\mathcal{H}/M \cong M^{\perp}$.
  \end{enumerate}
\end{proof}
\begin{corollary}
  The following are true.
  \begin{enumerate}[(1)]
    \item The quotient of a Hilbert space is a Hilbert space.
    \item If $M\subsetneq \mathcal{H}$, then $M^{\perp}\neq \set{0}$. Additionally, if $M^{\perp} = \mathcal{H}$, then $M = \set{0}$.
    \item For any subset $S\subseteq \mathcal{H}$, we have $\left(S^{\perp}\right)^{\perp} = \overline{\Span}\left(S\right)$.
  \end{enumerate}
\end{corollary}
\begin{exercise}
  Let $\left(\Omega,\mathcal{M},\mu\right)$ be a measure space, and let $E\subseteq \mathcal{M}$ be measurable. We look at the set of essentially $E$-supported square-integrable functions:
  \begin{align*}
  M_{E} &= \set{\xi\in L_{2}\left(\Omega,\mu\right) | \xi|_{E^{c}} = 0 \text{ $\mu$-a.e.}}.
  \end{align*}
  \begin{enumerate}[(1)]
    \item Show that $M_{E}$ is a closed subspace of $L_{2}\left(\Omega,\mu\right)$, and prove that the orthogonal projection onto $M_{E}$ is given by
      \begin{align*}
        P_{M_E}\left(\xi\right) &= \xi \1_{E}.
      \end{align*}
    \item Note that the restriction $\left(E,\mathcal{M}|_{E},\mu_{E}\right)$ is a measure space, where
      \begin{align*}
        \mathcal{M}_E &= \set{F\cap E | F\in \mathcal{M}}\\
        \mu_{E} &= \mu|_{\mathcal{M}_E}.
      \end{align*}
      Prove that $L_{2}\left(E,\mu_E\right)$ and $M_{E}$ are unitarily isomorphic.
  \end{enumerate}
\end{exercise}
\begin{solution}\hfill
  \begin{enumerate}[(1)]
    \item If $\xi$ and $\eta$ are two functions that are essentially $E$-supported, then the sum $\xi + \alpha \eta$, where $\alpha\in \C$, is also essentially $E$-supported. Similarly, if $\left(\xi_n\right)_n\rightarrow \xi$ is a sequence of essentially $E$-supported functions converging in norm to $\xi$, then we have $\left(\xi_m - \xi_{n}\right)|_{E^{c}} = 0$ for each $\xi_{m},\xi_{n}$, so $\xi$ is also essentially $E$-supported.\newline

      To show that $P_{M_E}$ defined by $P_{M_E}\left(\xi\right) = \xi \1_{E}$ is the orthogonal projection onto $M_{E}$, we show that $P_{M_E}$ is idempotent and maps all members of $M_{E}$ to themselves. For $\xi\in L_{2}\left(\Omega,\mu\right)$, we see that
      \begin{align*}
        P_{M_E}^2\left(\xi\right) &= P_{M_E}\left(\xi \1_{E}\right)\\
                                  &= \xi\left(\1_{E}\right)\left(\1_{E}\right)\\
                                  &= \xi \1_{E}\\
                                  &= P_{M_E}\left(\xi\right).
      \end{align*}
      Additionally, for any $\xi\in M_{E}$, we have that $\xi \1_{E} \equiv \xi$ since $\xi|_{E^c} = 0$ $\mu$-a.e. Thus, $P_{M_E}$ is an idempotent operator that preserves the closed subspace $M_{E}$, so by the Hilbert projection theorem, it is necessarily the only (up to $\mu$-a.e. equivalence) orthogonal projection onto $M_{E}$.
    \item 
  \end{enumerate}
\end{solution}
\begin{proposition}
  Let $\mathcal{H}$ be a Hilbert space, and suppose $\set{M_i}_{i=1}^{n}$ is a finite family of mutually orthogonal closed subspaces. Write $M = \sum_{i=1}^{n}M_i$ for the internal sum.
  \begin{enumerate}[(1)]
    \item $M\subseteq \mathcal{H}$ is a closed subspace, and $M = \bigoplus_{i=1}^{n}M_i$ is the internal direct sum.
    \item $P_{M} = \sum_{i=1}^{n}P_{M_i}$.
  \end{enumerate}
\end{proposition}
\begin{proof}
  To see (1), we know that since $M_i\perp M_j$ for each $i\neq j$, it is the case that $M_i\cap M_j = \set{0}$ for each $i\neq j$, so it is indeed a direct sum.\newline

  To see (2), let $x\in \mathcal{H}$, and write $x = y + z$ according to the decomposition $\mathcal{H} = M\oplus M^{\perp}$. Since $M_j\subseteq M$, we have $\ker\left(P_{M_j}\right) \supseteq M^{\perp}$ for each $j$. Thus, $P_{M_j}(z) = 0$ for every $j$.\newline

  Since $M = \bigoplus_{i=1}^{n}M_i$, we write $y = \sum_{i=1}^{n}y_i$, with $y_i\in M_i$ uniquely. Since $M_i$ are mutually orthogonal, we know that $M_i\subseteq M_{j}^{\perp} = \ker\left(P_{M_j}\right)$ for each $i\neq j$. We compute
  \begin{align*}
    P_{M_j}\left(x\right) &= P_{M_j}\left(y + z\right)\\
                          &= P_{M_j}\left(y\right)\\
                          &= P_{M_j}\left(\sum_{i=1}^{n}y_i\right)\\
                          &= \sum_{i=1}^{n}P_{M_j}\left(y_i\right)\\
                          &= y_j.
  \end{align*}
  Thus, we get
  \begin{align*}
    \left(\sum_{i=1}^{n}P_{M_i}\right)\left(x\right) &= \sum_{i=1}^{n}P_{M_i}\left(x\right)\\
                                                     &= \sum_{i=1}^{n}y_i\\
                                                     &= y\\
                                                     &= P_{M}\left(x\right).
  \end{align*}
  
\end{proof}
We can now turn our attention to understanding the continuous dual of Hilbert spaces.
\begin{definition}
  Let $X$ be an inner product space, and fix $z\in X\setminus \set{0}$. We define $\varphi_z: X\rightarrow \F$ by $\varphi_z\left(x\right) = \iprod{x}{z}$.
\end{definition}
\begin{proposition}
  Let $X$ be an inner product space. Each $\varphi_z\in X^{\ast}$, and the map $X\rightarrow X^{\ast}$ defined by $z\mapsto \varphi_z$ is a conjugate linear isometry.
\end{proposition}
\begin{proof}
  We see that $\varphi_z$ is linear. We have
  \begin{align*}
    \left\vert \varphi_z\left(x\right) \right\vert &= \left\vert \iprod{x}{z} \right\vert\\
                                                   &\leq \norm{x}\norm{z},
  \end{align*}
  with
  \begin{align*}
    \varphi_z\left(\frac{z}{\norm{z}}\right) &= \frac{1}{\norm{z}} \iprod{z}{z}\\
                                             &= \norm{z},
  \end{align*}
  so $\norm{\varphi_z}_{\text{op}} = \norm{z}$. For every $x\in X$, we also have
  \begin{align*}
    \varphi_{z_1 + \alpha z_2} \left(x\right) &= \iprod{x}{z_1 + \alpha z_2}\\
                                              &= \iprod{x}{z_1} + \overline{\alpha} \iprod{x}{z_2}\\
                                              &= \left(\varphi_{z_1} + \overline{\alpha}\varphi_{z_2}\right) \left(x\right).
  \end{align*}
\end{proof}
If $\mathcal{H}$ is a Hilbert space, then the map $\mathcal{H}\rightarrow \mathcal{H}^{\ast}$ given by $z\mapsto \varphi_z$ is a bijection. This is known as the Riesz Representation Theorem (not to be confused for the Riesz representation Theorem for measures on $C_c\left(\Omega\right)$).
\begin{theorem}[Riesz Representation Theorem]
  Let $\mathcal{H}$ be a Hilbert space. If $\varphi\in H^{\ast}$, then there exists a unique $z\in \mathcal{H}$ such that $\varphi = \varphi_z$.
\end{theorem}
\begin{proof}
  We assume $\varphi\neq 0$. We have $M = \ker\left(\varphi\right)\subseteq \mathcal{H}$ is a proper closed subspace, so we can choose $w\in M^{\perp}$ such that $w\neq 0$.\newline

  We see that $\ker\left(\varphi\right)\subseteq \ker\left(\varphi_w\right)$, meaning that $\varphi = \lambda \varphi_w$ for some $\lambda\in \F$. We compute
  \begin{align*}
    \varphi(x) &= \lambda\varphi_w\left(x\right)\\
               &= \lambda \iprod{x}{w}\\
               &= \iprod{x}{\overline{\lambda}w}.
  \end{align*}
  Set $z = \overline{\lambda}w$.\newline

  To show uniqueness, if $\varphi = \varphi_{z_1} = \varphi_{z_2}$, then $ \iprod{x}{z_1 - z_2} = 0 $ for all $x\in \mathcal{H}$, so $z_1 - z_2 \in \mathcal{H}^{\perp} = \set{0}$, so $z_1 = z_2$.
\end{proof}
\begin{theorem}
  Every Hilbert space is reflexive.
\end{theorem}
\begin{proof}
  Let $\iota: \mathcal{H}\rightarrow \mathcal{H}^{\ast\ast}$ be the canonical embedding. Let $f\in \mathcal{H}^{\ast\ast}$, and define $\psi: \mathcal{H}\rightarrow \C$ by $\psi(x) = \overline{f\left(\varphi_x\right)}$. For all $x_1,x_2\in \mathcal{H}$ and $\lambda\in \C$, we have
  \begin{align*}
    \psi\left(x_1 + \lambda x_2\right) &= \overline{f\left(\varphi_{x_1 + \lambda x_2}\right)}\\
                                       &= \overline{f\left(\varphi_{x_1} + \overline{\lambda}\varphi_{x_2}\right)}\\
                                       &= \overline{f\left(\varphi_{x_1}\right) + \overline{\lambda}f\left(\varphi_{x_2}\right)}\\
                                       &= \overline{f\left(\varphi_{x_1}\right)} + \lambda \overline{f\left(\varphi_{x_2}\right)}\\
                                       &= \psi\left(x_1\right) + \lambda \psi\left(x_2\right).
  \end{align*}
  Moreover,
  \begin{align*}
    \left\vert \psi\left(x\right) \right\vert &= \left\vert \overline{f\left(\varphi_{x}\right)} \right\vert\\
                                              &= \left\vert f\left(\varphi_x\right) \right\vert\\
                                              &\leq \norm{f}\norm{\varphi_x}\\
                                              &= \norm{f}\norm{x}.
  \end{align*}
  Thus, $\psi\in \mathcal{H}^{\ast}$, so we know that $\psi = \varphi_{z}$ for some $z\in H$. Thus,
  \begin{align*}
    \overline{f\left(\varphi_x\right)} &= \psi\left(x\right)\\
                                       &= \varphi_z\left(x\right)\\
                                       &= \iprod{x}{z}\\
                                       &= \overline{ \iprod{z}{x} },
  \end{align*}
  so $f\left(\varphi_x\right) = \iprod{z}{x} = \varphi_x\left(z\right) = \hat{z}\left(\varphi_x\right)$, so $f = \hat{z}$, so $\iota$ is surjective.
\end{proof}
\subsection{Orthonormal Sets and Orthonormal Bases}%
\begin{definition}
  Let $X$ be an inner product space, and let $A$ be an indexing set.
  \begin{enumerate}[(1)]
    \item A subset $\set{x_{\alpha}}_{\alpha\in A}$ is called orthogonal if $ \iprod{x_{\alpha}}{x_{\beta}} = 0 $ for $\alpha \neq \beta$.
    \item An orthonormal set is an orthogonal set consisting of unit vectors. The set $\set{e_{\alpha}}_{\alpha \in A}$ is orthonormal if
      \begin{align*}
        \iprod{e_{\alpha}}{e_{\beta}} &= \begin{cases}
          1 & \alpha = \beta\\
          0 = \alpha \neq \beta
        \end{cases}.
      \end{align*}
  \end{enumerate}
\end{definition}
\begin{exercise}
  Show every orthogonal set is linearly independent.
\end{exercise}
\begin{solution}
  Let $\set{x_{\alpha}}_{\alpha\in A}$ be an orthogonal set. Then, for
  \begin{align*}
    \sum_{i=1}^{n}a_ix_{\alpha_i} &= 0,
  \end{align*}
  we take
  \begin{align*}
    \iprod{x_{\alpha_j}}{\sum_{i=1}^{n}a_ix_{\alpha_i}} &= a_j\norm{x_{\alpha_j}}^2\\
                                                        &= 0,
  \end{align*}
  so $a_i = 0$ for all $i$.
\end{solution}
\begin{remark}
  Given an inner product space $X$ and a finite linearly independent subset $F = \set{x_1,\dots,x_n}$, we can always use the Gram--Schmidt process to generate an orthonormal subset $G = \set{u_1,\dots,u_n}\subseteq X$ with $\Span(G) = \Span(F)$. Inductively, we take
  \begin{align*}
    v_1 &= x_1\\
    v_{k} &= x_k - \sum_{j=1}^{k-1}\frac{ \iprod{x_k}{v_j} }{ \iprod{v_j}{v_j} }v_j\\
    u_k &= \frac{1}{\norm{v_k}}v_k.
  \end{align*}
\end{remark}
\begin{exercise}
  Let $A$ be an arbitrary set, and consider the Hilbert space $\ell_{2}\left(A\right)$. Show that $\set{e_{\alpha}}_{\alpha \in A}\subseteq \ell_{2}\left(A\right)$ is an orthonormal set.
\end{exercise}
\begin{example}
  The family of continuous functions $\left(e_n\colon \mathbb{T}\rightarrow \C\right)_{n\in \Z}$ is an orthonormal basis for the arc length measure space $\left(\mathbb{T},\mathcal{L}_{\mathbb{T}},\nu\right)$.
  \begin{align*}
    \iprod{e_n}{e_m} &= \int_{\mathbb{T}}^{} e_{n}\overline{e_{m}}\:d\nu\\
                     &= \int_{\mathbb{T}}^{} e_{n}e_{-m}\:d\nu\\
                     &= \int_{\mathbb{T}}^{} e_{n-m}\:d\nu\\
                     &= \delta_{mn}.
  \end{align*}
\end{example}
\begin{theorem}
  Let $\mathcal{H}$ be a Hilbert space, and suppose $\left(e_{\alpha}\right)_{\alpha \in A}$ is an orthonormal family in $\mathcal{H}$.
  \begin{enumerate}[(1)]
    \item If $\left(c_{\alpha}\right)_{\alpha\in A}\in \ell_{2}\left(A\right)$, then $\sum_{\alpha \in A}c_{\alpha}e_{\alpha}$ is summable in $\mathcal{H}$, and
      \begin{align*}
        \norm{\sum_{a\in A}c_{\alpha}e_{\alpha}} &= \norm{\left(c_{\alpha}\right)_{\alpha}}.
      \end{align*}
    \item The map $T: \ell_{2}\left(A\right)\rightarrow \mathcal{H}$ defined by $T\left(\xi\right) = \sum_{\alpha \in A}\xi\left(\alpha\right)e_{\alpha}$ is a linear isometry.
    \item If $x\in \mathcal{H}$, then $\sum_{\alpha \in A}\left\vert \iprod{x}{e_{\alpha}} \right\vert^{2}\leq \norm{x}^2$. This is known as Bessel's inequality.
    \item If $M = \overline{\Span}\left(\set{e_{\alpha}}_{\alpha \in A}\right)$, then $P_{M}\left(x\right) = \sum_{\alpha \in A} \iprod{x}{e_{\alpha}}e_{\alpha}$ is the orthogonal projection onto $M$.
  \end{enumerate}
\end{theorem}
\begin{proof}\hfill
  \begin{enumerate}[(1)]
    \item We let $\mathcal{F}$ be the collection of finite subsets of $A$ directed by inclusion. For $F\in \mathcal{F}$, we define
      \begin{align*}
        s_F &= \sum_{\alpha \in F}c_{\alpha}e_{\alpha}\\
        c_{F} &= \sum_{\alpha \in F}\left\vert c_{\alpha} \right\vert^2.
      \end{align*}
      By the Pythagorean theorem, we have
      \begin{align*}
        \norm{s_F}^2 &= \norm{\sum_{\alpha \in F}c_{\alpha}e_{\alpha}}^2\\
                     &= \sum_{\alpha \in F}\norm{c_{\alpha}e_{\alpha}}^2\\
                     &= \sum_{\alpha \in F}\left\vert c_{\alpha} \right\vert^2\\
                     &= c_F.
      \end{align*}
      We claim the net $\left(s_{F}\right)_{F\in \mathcal{F}}$ is Cauchy in $\mathcal{H}$. For $F$ and $G$ in $\mathcal{F}$, we set
      \begin{align*}
        d_{\alpha} &= \begin{cases}
          c_{\alpha} & \alpha\in F\\
          -c_{\alpha} & \alpha \in G
        \end{cases}.
      \end{align*}
      Then,
      \begin{align*}
        \norm{s_{F} - s_{G}}^2 &= \norm{\sum_{\alpha \in F}c_{\alpha}e_{\alpha} - \sum_{\alpha \in G}c_{\alpha}e_{\alpha}}^2\\
                               &= \norm{\sum_{\alpha \in F\triangle G}d_{\alpha}e_{\alpha}}\\
                               &= \sum_{\alpha \in F\triangle G}\left\vert d_{\alpha} \right\vert^2\\
                               &= c_{F\triangle G}.
      \end{align*}
      Let $\ve > 0$. Since $\sum_{\alpha \in A}\left\vert c_{\alpha} \right\vert^2$ is summable, there is a finite $F_0\subseteq A$ such that for all $F\in \mathcal{F}$ with $F\cap F_0 = \emptyset$, we have $c_F\leq \ve^2$.\newline

      If $F$ and $G$ are finite subsets of $A$ with $F\supseteq F_0$ and $G\supseteq F_0$, then $F_0\subseteq F\cap G$, so $\left(F\triangle G\right)\cap F_0 = \emptyset$, so
      \begin{align*}
        \norm{s_F - s_G}^2 &= c_{F\triangle G}\\
                           &< \ve^2.
      \end{align*}
      We define $s = \sum_{\alpha \in A}c_{\alpha}e_{\alpha}$. This limit exists since $\mathcal{H}$ is complete and Cauchy nets converge. The norm of $s$ is computed as
      \begin{align*}
        \norm{s}^2 &= \sum_{\alpha \in A}\left\vert c_{\alpha} \right\vert^2.
      \end{align*}
    \item This follows directly from (1).
    \item Let $F\subseteq A$ be finite, and set $M_F = \Span\set{e_{\alpha} | \alpha \in F}$. Since $M_F$ is finite-dimensional, $M_F$ is closed. For $x\in \mathcal{H}$ and $\beta \in A\setminus F$, the orthogonality of $\left(e_{\alpha}\right)_{\alpha \in A}$ provides
      \begin{align*}
        \iprod{x - \sum_{\alpha \in F} \iprod{x}{e_{\alpha}}e_{\alpha}}{e_{\beta}} &= 0.
      \end{align*}
      Thus, we write
      \begin{align*}
        x &= x -\sum_{\alpha \in F} \iprod{x}{e_{\alpha}}e_{\alpha} + \sum_{\alpha \in F} \iprod{x}{e_{\alpha}}e_{\alpha},
      \end{align*}
      which gives $P_{M_F} = \sum_{\alpha \in F} \iprod{x}{e_{\alpha}}e_{\alpha}$. Using the Pythagorean theorem, we get
      \begin{align*}
        \sum_{\alpha \in F} \left\vert \iprod{x}{e_{\alpha}} \right\vert^2 &= \norm{P_{M_F}\left(x\right)}^2\\
                                                                           &\leq \norm{x}^2.
      \end{align*}
      The inequality follows by taking the supremum,
      \begin{align*}
        \sum_{\alpha \in A} \left\vert \iprod{x}{e_{\alpha}} \right\vert^2 &= \sup_{F\subseteq A}\left(\sum_{\alpha \in F}\left\vert \iprod{x}{e_{\alpha}} \right\vert^2\right)\\
                                                                           &\leq \norm{x}^2.
      \end{align*}
    \item Fix $x\in \mathcal{H}$, and for each $\alpha \in A$, we set $c_{\alpha} = \iprod{x}{e_{\alpha}}$. We have $\left(c_{\alpha}\right)_{\alpha \in A}\in \ell_2\left(A\right)$, so $\sum_{\alpha \in A}c_{\alpha}e_{\alpha}$ is norm-summable in $\mathcal{H}$. Continuity of the inner product yields
      \begin{align*}
        \iprod{x - \sum_{\alpha \in A} \iprod{x}{e_{\alpha}}e_{\alpha}}{e_{\beta}} &= 0,
      \end{align*}
      so $x - \sum_{\alpha \in A} \iprod{x}{e_{\alpha}}e_{\alpha} \in M^{\perp}$, meaning $P_{M}(x) = \sum_{\alpha \in A} \iprod{x}{e_{\alpha}}e_{\alpha}$.
  \end{enumerate}
\end{proof}
\begin{corollary}
  If $\mathcal{H}$ is a Hilbert space, and $\set{x_{\alpha}}_{\alpha\in A}$ is an orthogonal set such that $\sum_{\alpha \in A}\norm{x_{\alpha}}^2$ is summable, then $\sum_{\alpha \in A}x_\alpha$ is summable and
  \begin{align*}
    \norm{\sum_{\alpha \in A}x_{\alpha}}^2 &= \sum_{\alpha \in A}\norm{x_{\alpha}}^2.
  \end{align*}
\end{corollary}
\begin{proof}
  Set $e_{\alpha} = \frac{1}{\norm{x_{\alpha}}}x_{\alpha}$, and $c_{\alpha} = \norm{x_{\alpha}}$ in the proof of the theorem above.
\end{proof}
\begin{example}
  If $\left(e_n\right)_{n\geq 1}$ is the set of standard coordinate vectors in $\ell_2$, then $\sum_{n\in \N}\frac{1}{n}e_n$ is summable, but the series does not converge absolutely.
\end{example}
\begin{definition}
  Let $\mathcal{H}$ be a Hilbert space. An orthonormal basis in $\mathcal{H}$ is a maximal orthonormal set $E$. That is, if $E\subsetneq E'$, then $E'$ is not an orthonormal basis.
\end{definition}
\begin{lemma}
  Let $\mathcal{H}$ be a Hilbert space. Every orthonormal set in $\mathcal{H}$ is contained in an orthonormal basis.
\end{lemma}
\begin{proof}
  Let $F\subseteq \mathcal{H}$ be an orthonormal set. Let
  \begin{align*}
    \mathcal{E} &= \set{E\subseteq \mathcal{H} | F\subseteq E,~E \text{ orthonormal}},
  \end{align*}
  and order $\mathcal{E}$ by inclusion. For any chain $\mathcal{C}$ in $\mathcal{E}$, then $U = \bigcup_{C\in \mathcal{C}}C$ is an upper bound for $\mathcal{C}$, as for any two vectors $e_{\alpha},e_{\beta}\in U$, both $e_{\alpha}$ and $e_{\beta}$ are contained in some $C\in \mathcal{C}$, so $ \iprod{e_{\alpha}}{e_{\beta}} = \delta_{\alpha \beta}$. Applying Zorn's lemma, we get the desired result.
\end{proof}
Orthonormal bases, like Schauder bases, have dense linear span in a Hilbert space.
\begin{theorem}
  Let $\mathcal{H}$ be a Hilbert space, and $E = \left(e_{\alpha}\right)_{\alpha \in A}$ be an orthonormal set. Let $M = \overline{\Span}\set{e_{\alpha} | \alpha \in A}$. The following are equivalent:
  \begin{enumerate}[(i)]
    \item $E$ is an orthonormal basis;
    \item $M^{\perp} = \set{0}$;
    \item $M = \mathcal{H}$;
    \item for each $x\in \mathcal{H}$, we have $x = \sum_{\alpha \in A} \iprod{x}{e_{\alpha}}e_{\alpha}$;
    \item for each $x\in \mathcal{H}$, we have $\norm{x}^2 = \sum_{\alpha \in A} \left\vert \iprod{x}{e_{\alpha}} \right\vert^2$ (known as Parseval's identity);
    \item for each $x,y\in \mathcal{H}$, we have $ \iprod{x}{y} = \sum_{\alpha \in A} \iprod{x}{e_{\alpha}} \overline{ \iprod{y}{e_{\alpha}} }$.
  \end{enumerate}
\end{theorem}
\begin{proof}
  To see (i) implies (ii), we suppose there is $v\in M^{\perp}$ with $\norm{v} = 1$. Then, $\set{v}\cup E$ is an orthonormal set containing $E$, which contradicts the maximality of $E$.\newline

  The equivalence of (ii) and (iii) follows from the fact that $\mathcal{H}^{\perp} = \set{0}$ and $\set{0}^{\perp} = \mathcal{H}$.\newline

  To see that (iii) implies (i), we suppose there is $v\in \mathcal{H}$ such that $v\notin E$ and $\set{v}\cup E$ is an orthonormal set. THen, for each $\alpha \in A$, we have $ \iprod{v}{e_{\alpha}} = 0 $, so $ \iprod{v}{x} = 0 $ for each $x\in \Span\set{e_{\alpha} | \alpha \in A}$. Since the inner product is continuous, we have $ \iprod{v}{x} = 0 $ for each $x\in \overline{\Span}\set{e_{\alpha} | \alpha \in A} = M = \mathcal{H}$, implying that $\norm{v} =0$.\newline

  To see that (iii) implies (iv), recall that we proved that $P_M(x) = \sum_{\alpha \in A} \iprod{x}{e_{\alpha}}e_{\alpha}$, but since $M = \mathcal{H}$, we have $P_M(x) = x$.\newline

  We see that (v) follows from (iv) by the previous theorem.\newline

  To see that (v) implies (i), if $ \iprod{v}{e_{\alpha}} = 0 $ for each $\alpha \in A$, we must have $\norm{v} = 0$, so $E $ is a maximal orthonormal set.\newline

  To see that (vi) implies (v), we let $x = y$ in the hypothesis of (vi).\newline

  To see that (iv) implies (vi), we let $x,y\in \mathcal{H}$. We let $x = \sum_{\alpha \in A} \iprod{x}{e_{\alpha}}e_{\alpha}$, and $y = \sum_{\beta\in A} \iprod{y}{e_{\beta}} e_{\beta}$. By the continuity of the inner product and the orthonormality of $E$, we have
  \begin{align*}
    \iprod{x}{y} &= \iprod{\sum_{\alpha \in A} \iprod{x}{e_{\alpha}}e_{\alpha}}{ \sum_{\beta\in A} \iprod{y}{e_{\beta}}e_{\beta} }\\
                 &= \sum_{\alpha,\beta \in A} \iprod{x}{e_{\alpha}} \overline{\iprod{y}{e_{\beta}}} \iprod{e_{\alpha}}{e_{\beta}}\\
                 &= \sum_{\alpha \in A} \iprod{x}{e_{\alpha}} \overline{ \iprod{y}{e_{\beta}} }.
  \end{align*}
  
\end{proof}
For an orthonormal basis $\set{e_{\alpha}}_{\alpha \in A}$ and a given $x\in \mathcal{H}$, we often refer to the terms $ \iprod{x}{e_{\alpha}} $ as the Fourier coefficients of $x$ with respect to the basis $\set{e_{\alpha}}_{\alpha \in A}$.\newline

Recall that any two vector spaces $X$ and $Y$ are isomorphic if and only if $\Dim(X) = \Dim(Y)$. A similar idea holds for Hilbert spaces.
\begin{proposition}
Let $\mathcal{H}$ be a Hilbert space. Any two orthonormal bases for $\mathcal{H}$ have the same cardinality.
\end{proposition}
\begin{proof}
  Let $E = \set{e_{\alpha}}_{\alpha \in A}$ and $F = \set{f_{\beta}}_{\beta \in B}$ be two orthonormal bases for $\mathcal{H}$. If $E$ is finite, then it must be a Hamel basis as orthogonal sets are independent and finite orthonormal bases are spanning by Parseval's identity. Thus, $\Dim(\mathcal{H}) < \infty$, and since $F$ is independent, $F$ is finite, so it must be a Hamel basis, with $\Card(E) = \Card(F)$.\newline

  Suppose $A$ and $B$ are both infinite. For each $\beta \in B$, consider
  \begin{align*}
    A_{\beta} \coloneq \set{\alpha | \iprod{f_{\beta}}{e_{\alpha}} \neq 0}.
  \end{align*}
  Since
  \begin{align*}
    \norm{f_{\beta}}^2 &= \sum_{\alpha \in A} \left\vert \iprod{f_{\beta}}{e_{\alpha}} \right\vert^2\\
                       &= 1
  \end{align*}
  is summable, $A_{\beta}$ must be countable. Additionally, $A\subseteq \bigcup_{\beta \in B}A_{\beta}$, since
  \begin{align*}
    \norm{e_{\alpha}}^2 &= \sum_{\beta \in B}\left\vert \iprod{e_{\alpha}}{f_{\beta}} \right\vert^2.
  \end{align*}
  Since $\Card\left(A_{\beta}\right) \leq \aleph_0\leq \Card(B)$, we get
  \begin{align*}
    \Card(A) \leq \Card\left(\bigcup_{\beta \in B}A_{\beta}\right)\leq \Card(B).
  \end{align*}
  Similarly, $\Card(B) \leq \Card(A)$, so $\Card(A) = \Card(B)$ by Cantor--SchrÃ¶der--Bernstein.
\end{proof}
\begin{definition}
  Let $\mathcal{H}$ be a Hilbert space. The Hilbert dimension of $\mathcal{H}$, written $\hdim(\mathcal{H})$, is the cardinality of $E$ for any orthonormal basis $E$ of $\mathcal{H}$.
\end{definition}
We can characterize all Hilbert spaces with countable Hilbert dimension.
\begin{proposition}
  Let $\mathcal{H}$ be a Hamel basis with $\dim(H) = n < \infty$. Then, $\mathcal{H} \cong \ell_2^{n}$ are unitarily isomorphic.
\end{proposition}
\begin{proof}
  Let $\set{v_1,\dots,v_n}$ be a Hamel basis for $\mathcal{H}$. Applying the Gram--Schmidt process, we obtain an orthonormal set $\set{u_1,\dots,u_n}$ with the same span as $\set{v_1,\dots,v_n}$. The map $T\colon \ell_{2}^{n}\rightarrow \mathcal{H}$ given by $T\left(e_j\right) = u_j$ is a surjective isometry.
\end{proof}
\begin{proposition}
  Let $\mathcal{H}$ be an infinite-dimensional Hilbert space. The following are equivalent.
  \begin{enumerate}[(i)]
    \item $\mathcal{H}$ is separable;
    \item $\hdim\left(\mathcal{H}\right) = \aleph_0$;
    \item $\mathcal{H}\cong \ell_2$.
  \end{enumerate}
\end{proposition}
\begin{proof}
  Let $\set{x_k}_{k=1}^{\infty}\subseteq \mathcal{H}$ be norm-dense, and let $\left(e_{\alpha}\right)_{\alpha}$ be an orthonormal basis. Note that for $\alpha \neq \beta$, we have
  \begin{align*}
    \norm{e_{\alpha} - e_{\beta}}^2 &= \iprod{e_{\alpha} - e_{\beta}}{e_{\alpha} - e_{\beta}}\\
                                    &= 2,
  \end{align*}
  so $\norm{e_{\alpha} - e_{\beta}} = \sqrt{2}$. For each $\alpha \in A$, the density of $\set{x_k}_{k=1}^{\infty}$ allows us to find $J\left(\alpha\right)\in \N$ such that
  \begin{align*}
    \norm{e_{\alpha} - x_{J_{\alpha}}} < \frac{1}{2}.
  \end{align*}
  We have a map $J: A\rightarrow \N$. We claim that $J$ is injective. If not, then there are $\alpha,\beta \in A$ with $\alpha\neq \beta$, $J\left(\alpha\right) = J\left(\beta\right)$. We then have
  \begin{align*}
    \sqrt{2} &= \norm{e_{\alpha} - e_{\beta}}\\
             &\leq \norm{e_{\alpha} - x_{J\left(\alpha\right)}} + \norm{x_{J\left(\alpha\right)} - e_{\beta}}\\
             &= \norm{e_{\alpha} - x_{J\left(\alpha\right)}} + \norm{x_{J\left(\beta\right)} - e_{\beta}}\\
             &< 1.
  \end{align*}
  Thus, $J$ is injective, so $A$ is countable.\newline

  If $\left(f_n\right)_{n\in \N}$ is an orthonormal basis for $\mathcal{H}$, then we have $\mathcal{H} \cong \ell_2\left(\N\right) = \ell_2$.\newline

  If $\left(e_n\right)_{n\geq 1}$ is the canonical orthonormal basis for $\ell_2$, then we know that $\Span\left(E\right)$ is dense in $\ell_2$, so $E$ is a countable total subset of $\ell_2$, so $\mathcal{H}$ is separable.
\end{proof}
\subsection{Tensor Products and Direct Sums of Hilbert Spaces}%
We have shown that closed subspaces and quotient spaces of Hilbert spaces are Hilbert spaces. Now, we turn our attention to external direct sums and tensor products.
\subsubsection{Direct Sums}%
In linear algebra, we learn that, for a normal $n\times n$ matrix, we can decompose $\ell_2^{n}$ into orthogonal pieces that the matrix acts on by scalar multiplication. In order to understand the spectral theorem for normal operators on Hilbert spaces, we need to understand such a decomposition.
\begin{proposition}
  Let $\set{\mathcal{H}_i}_{i\in I}$ be a family of Hilbert spaces. The set
  \begin{align*}
    \bigoplus_{i\in I}\mathcal{H}_i = \set{\left(x_i\right)_{i\in I} | x_i\in \mathcal{H}_i\text{ and } \sum_{i\in I}\norm{x_i}^2\text{ is summable}}
  \end{align*}
  equipped with pointwise operations is a vector space, with inner product
  \begin{align*}
    \iprod{x}{y} &\coloneq \sum_{i\in I} \iprod{x_i}{y_i}
  \end{align*}
  for $\left(x_i\right)_{i\in I},\left(y_i\right)_{i\in I}\in \bigoplus_{i\in I}\mathcal{H}_i$ that induces the complete norm
  \begin{align*}
    \norm{\left(x_i\right)_i} &\coloneq \left(\sum_{i\in I}\norm{x_i}^2\right)^{1/2}.
  \end{align*}
    The Hilbert space $\bigoplus_{i\in I}\mathcal{H}_i$ is known as the external direct sum of the family $\set{\mathcal{H}_i}_{i\in I}$.
\end{proposition}
\begin{example}
  If $I$ is a set, and for each $i\in I$, we have $\mathcal{H}_{i} = \C$, then $\bigoplus_{i\in I}\mathcal{H}_{i} = \ell_2\left(I\right)$.
\end{example}
\begin{example}
  If we fix a Hilbert space $\mathcal{H}$, the external direct sum $\bigoplus_{n\geq 1}\mathcal{H}$ is often denoted by $\mathcal{H}^{\infty}$ or $\ell_2\left(\mathcal{H}\right)$.
\end{example}
\begin{example}
  Let $\set{\left(\Omega_n,\mathcal{M}_n,\mu_n\right)}_{n}$ be a countable family of measure spaces, and let $\left(\Sigma,\mathcal{M},\mu\right)$ be the coproduct of these spaces, defined by
  \begin{align*}
    \Sigma &\coloneq \coprod_{n=1}^{\infty}\Omega_n\\
    \mathcal{M}&\coloneq \set{E\subseteq \Sigma | \iota_n^{-1}\left(E\right)\in \mathcal{M}_n\text{ for all $n$}}\\
    \mu\left(E\right) &= \sum_{n=1}^{\infty}\mu_n\left(\iota_n^{-1}\left(E\right)\right).
  \end{align*}
  Then, the map
  \begin{align*}
    V: L_{2}\left(\Sigma,\mu\right) \rightarrow \bigoplus_{n\geq 1}L_2\left(\Omega_n,\mu_n\right),
  \end{align*}
  defined by
  \begin{align*}
    V\left(\xi\right) &= \left(\xi\circ \iota_n\right)_n
  \end{align*}
  is a well-defined unitary isomorphism.\newline

  Let $\xi \in L_{2}\left(\Sigma,\mu\right)$. Since each $\iota_n: \Omega_n\rightarrow \Sigma$ is measurable, $\xi\circ \iota_n: \Omega_n\rightarrow \C$ is also measurable. Additionally, if $\xi$ is $0$ $\mu$-a.e., then so is $\xi\circ \iota_n$. Moreover, we have
  \begin{align*}
    \norm{V\left(\xi\right)}^2 &= \norm{\left(\xi\circ \iota_n\right)_n}^2\\
                               &= \sum_{n\geq 1}\norm{\xi\circ \iota_n}^2\\
                               &= \sum_{n\geq 1}\int_{\Omega_n}^{} \left\vert \xi\circ \iota_n(x) \right\vert^2\:d\mu_n\\
                               &= \sum_{n\geq 1}\int_{\Omega_n}^{} \left\vert \xi \right\vert^2\circ \iota_n(x)\:d\mu_n\\
                               &= \int_{\Sigma}^{} \left\vert \xi \right\vert^2\:d\mu\\
                               &= \norm{\xi}^2.
  \end{align*}
  This shows $V$ is a well-defined linear map. Our calculation shows that $V$ is an isometry.\newline

  We only need to write an inverse, for which which we define
  \begin{align*}
    W: \bigoplus_{n\geq 2}L_{2}\left(\Omega_n,\mu_n\right)\rightarrow L_2\left(\Sigma,\mu\right),
  \end{align*}
  defined by
  \begin{align*}
    W\left(\left(\xi_n\right)_n\right) &= \xi,
  \end{align*}
  where
  \begin{align*}
    \xi &\coloneq \coprod_{n\geq 1}\left(\xi_n: \Omega\rightarrow \C\right)\\
    \xi\left(x,n\right) &= \xi_n\left(x\right).
  \end{align*}
\end{example}
\begin{lemma}
  Let $\set{\mathcal{H}_{i}}_{i\in I}$ be a family of Hilbert spaces. For each $k\in I$, the maps
  \begin{align*}
    \pi_k\colon \bigoplus_{i\in I}\mathcal{H}_i \rightarrow \mathcal{H}_k\\
    \iota_k\colon \bigoplus_{i\in I}\mathcal{H}_i,
  \end{align*}
  given by
  \begin{align*}
    \pi_k\left(\left(x_i\right)_i\right) &= x_k\\
    \iota_k\left(x\right) &= \left(x_i\right)_i\text{ where $x_{i\neq k} = 0$, $x_k = x$}
  \end{align*}
  are bounded linear operators, with
  \begin{align*}
    \iprod{\pi_k\left(\left(x_i\right)_i\right)}{y} &= \iprod{\left(x_i\right)_i}{\iota_k\left(y\right)}.
  \end{align*}
\end{lemma}
Breaking apart an operator into smaller parts is often useful, such as in the spectral theorem.
\begin{proposition}
  Let $\mathcal{H}$ be a Hilbert space, and let $\set{M_i}_{i\in I}$ be a collection of pairwise orthogonal closed subspaces of $\mathcal{H}$. The following are equivalent
  \begin{enumerate}[(i)]
    \item The internal sum $\sum_{i\in I}M_i$ is dense in $\mathcal{H}$.
    \item Given $x\in \mathcal{H}$, there are unique $x_i\in M_i$ such that
      \begin{align*}
        x &= \sum_{i\in I}x_i
      \end{align*}
      is a norm convergent sum. We have $x_i = P_{M_i}\left(x\right)$.
  \end{enumerate}
\end{proposition}
\begin{proof}
  We see that (ii) implies (i) by the definition of the internal sum and summability.\newline

  To see that (i) implies (ii), let $x\in \mathcal{H}$, and we set $x_i = P_{M_i}\left(x\right)$. Since $M_i$ are mutually orthogonal, it follows that $\left(x_i\right)_i$ are mutually orthogonal vectors.\newline

  Let $F\subseteq I$ be finite, and set $P = \sum_{i\in F}P_{M_i}$. We know that $P$ is the orthogonal projection onto $\sum_{i\in F}M_{i}$. By the Pythagorean theorem, we have that
  \begin{align*}
    \sum_{i\in F}\norm{x_i}^2 &= \norm{\sum_{i\in F}x_i}^2\\
                              &= \norm{\sum_{i\in F}P_{M_i}(x)}^2\\
                              &= \norm{P(x)}^2\\
                              &\leq \norm{x}^2.
  \end{align*}
  Taking the supremum across finite subsets, we have $\sum_{i\in I}\norm{x_i}^2 \leq \norm{x}^2$. Thus, $\sum_{i\in I}x_i$ is summable in $\mathcal{H}$ to $z$, and that $\norm{z}^2 = \sum_{i\in I}\norm{x_i}^2$.\newline

  We claim that $x = z$. Let $y\in M_i$ be arbitrary, and note that $ \iprod{z}{y} = \iprod{x_i}{y} $. Thus, we have
  \begin{align*}
    \iprod{x-z}{y} &= \iprod{x}{y} - \iprod{z}{y} \\
                   &= \iprod{x}{P_{M_i}(y)} - \iprod{x_i}{y}\\
                   &= \iprod{P_{M_i}(x)}{y} - \iprod{x_i}{y}\\
                   &= \iprod{x_i}{y} - \iprod{x_i}{y}\\
                   &= 0.
  \end{align*}
  Since $y$ is arbitrary, we have $x - z\in M_i^{\perp}$. Since $i$ is arbitrary, we see that $x-z$ is orthogonal to $\sum_{i\in I}M_i$. Since the latter is dense in $\mathcal{H}$, continuity of the inner product shows that $x - z\in \mathcal{H}^{\perp} = \set{0}$.\newline

  For uniqueness, suppose $x = \sum_{i\in I}x_i'$ is an norm-convergent sum with $x_i'\in M_i$ for all $i\in I$. For $j\in I$, we have
  \begin{align*}
    x_j' &= P_j\left(x\right)\\
         &= P_j\left(\sum_{i\in I}x_i'\right)\\
                      &= \sum_{i\in I}P_j\left(x_i'\right)\\
                      &= x_j'
  \end{align*}
\end{proof}
\begin{definition}
  Let $\mathcal{H}$ be a Hilbert space, and suppose $\mathcal{M} = \set{M_i}_{i\in I}$ is a collection of mutually orthogonal closed subspaces that satisfy the conditions above. Then, we say $\mathcal{H}$ is the internal direct sum of the family $\mathcal{M}$, and write
  \begin{align*}
    \mathcal{H} &= \bigoplus_{i\in I}M_i.
  \end{align*}
\end{definition}
\begin{exercise}
  Let $\mathcal{H} = \bigoplus_{i\in I}M_i$ be an internal direct sum. Viewing each $M_i$ as a Hilbert space, prove that
  \begin{align*}
    U\colon \bigoplus_{i\in I}M_i \rightarrow H\\
    \left(x_i\right)_{i\in I} \xmapsto{U} \sum_{i\in I}x_i
  \end{align*}
  is unitary. In other words, the external direct sum of the spaces $M_i$ is unitarily isomorphic to $\mathcal{H}$.
\end{exercise}
\begin{solution}
  To see that $U$ is an isometry, we can see that for $x = \sum_{i\in I}x_i$,
  \begin{align*} 
    \norm{U\left(\left(x_i\right)_i\right)}^2 &= \norm{\sum_{i\in I}x_i}^2\\
                                              &= \sum_{i\in I} \norm{x_i}^2\\
                                              &= \norm{\left(x_i\right)_i}^2.
  \end{align*}
  Additionally, for any $x\in \mathcal{H}$, we can find an indexed family $\left(x_i\right)_i$ such that $\sum_{i\in I}x_i = x$. Thus, we can select the indexed family $\left(x_i\right)_i$ in $\bigoplus_{i\in I}M_i$ such that $U\left(\left(x_i\right)_i\right) = x$.\newline

  Thus, $U$ is a surjective isometry, so $U$ is unitary.
\end{solution}
\begin{exercise}
  Let $\mathcal{H} = \bigoplus_{i\in I}M_i$ be an internal direct sum, and let $j\in I$ be fixed, $x\in M_j^{\perp}$. Prove that $x$ has the form
  \begin{align*}
    x &= \sum_{\substack{i\in I\\i\neq j}}x_i,
  \end{align*}
  a norm-convergent sum, where $x_i \in M_i$.
\end{exercise}
\begin{solution}
  Note that we have proved $x_i = P_{M_i}\left(x\right)$. Thus, $x_j = P_{M_j}\left(x\right) = 0$, so we have
  \begin{align*}
    x &= \sum_{i\in I}P_{M_i}\left(x\right)\\
      &= \sum_{\substack{i\in I\\i\neq j}}P_{M_i}\left(x\right)\\
      &= \sum_{\substack{i\in I\\i\neq j}}x_i.
  \end{align*}
\end{solution}
\begin{corollary}
  Suppose $\mathcal{H}=\bigoplus_{i\in I}M_i$ is an internal direct sum, and let $P_i = P_{M_i}$ be the orthogonal projections onto each $M_i$. Then,
  \begin{align*}
    I_{\mathcal{H}} &= \sum_{i\in I}P_{i}
  \end{align*}
  in the strong operator topology. That is,
  \begin{align*}
    x &= \sum_{i\in I}P_i\left(x\right)\\
    \norm{x}^2 &= \sum_{i\in I}\norm{P_i\left(x\right)}^2.
  \end{align*}
\end{corollary}
\begin{exercise}
  Let $\left(\Omega,\mathcal{L},\mu\right)$ be a measure space, and let $\bigsqcup_{n\geq 1}E_n = \Omega$ be a measurable partition. Show that there is an internal sum
  \begin{align*}
    L_2\left(\Omega,\mu\right) &= \bigoplus_{n\geq 1}M_{E_n}\\
                               &\cong \bigoplus_{n\geq 1}L_{2}\left(E_n,\mu_{E_n}\right).
  \end{align*}
\end{exercise}

\section{Bounded Operators on Hilbert Spaces}%
Hilbert spaces are, according to John Conway, anyway, ``boring,'' so we are interested in understanding the effects of operators on Hilbert spaces.\newline

In the case of quantum mechanics, a particle with wave function $\xi$ moving along the $x$ axis has position equivalent to its expected value,
\begin{align*}
  \int_{\R}^{} x \left\vert \xi\left(x\right) \right\vert^2\:d\lambda &= \iprod{\id_{\R} \xi}{\xi},
\end{align*}
where the $x$ coordinate is now an observable of an operator $\xi\xmapsto{Q} \id_{R}\xi$, which is known as position. This operator is only defined on its domain, as it is not bounded.\newline

Similarly, linear momentum is the map $\xi\xmapsto{P} \xi'$ (on the domain that it is defined), yielding
\begin{align*}
  \iprod{P\left(\xi\right)}{\xi} &= \int_{\R}^{} \diff{\xi}{x}\overline{\xi(x)}\:d\lambda,
\end{align*}
from which we get the uncertainty principle
\begin{align*}
  PQ\left(\xi\right) &= I\left(\xi\right) + QP\left(\xi\right).
\end{align*}
\subsection{Structure of $\B\left(\mathcal{H}\right)$}%
If $X$ is a Banach space, then $\B\left(X\right)$, the space of bounded linear operators on $X$, is a unital Banach algebra. We will study the structure of $\B\left(\mathcal{H}\right)$, which is the space of bounded linear operators on a Hilbert space.
\subsubsection{Algebraic-Analytic Structure}%
\begin{fact}
  Let $T,S\colon \mathcal{H}\rightarrow \mathcal{K}$ be linear maps between Hilbert spaces.
  \begin{enumerate}[(1)]
    \item We have $T=S$ if and only if $ \iprod{T(x)}{y} = \iprod{S(x)}{y} $ for all $x\in \mathcal{H}, y\in \mathcal{K}$.
    \item If $\mathcal{H} = \mathcal{K}$, then $T = S$ if and only if $ \iprod{T(x)}{x} = \iprod{S(x)}{x} $ for all $x\in \mathcal{H}$.
  \end{enumerate}
\end{fact}
\begin{proof}\hfill
  \begin{enumerate}[(1)]
    \item This follows from the fact that $ \iprod{x}{z_1} = \iprod{x}{z_2} $ for all $x$ if and only if $z_1 = z_2$.
    \item We define the sesquilinear forms $F\colon \mathcal{H}\times \mathcal{H}\rightarrow \C$, $G\colon \mathcal{H}\times \mathcal{H}\rightarrow \C$ by
      \begin{align*}
        F\left(x,y\right) &= \iprod{T(x)}{y}\\
        G\left(x,y\right) &= \iprod{S(x)}{y}.
      \end{align*}
      We see that $T = S$ if and only if $F = G$, if and only if $F$ and $G$ agree on the diagonal, meaning $ \iprod{T(x)}{x} = \iprod{S(x)}{x} $ for all $x\in \mathcal{H}$.
  \end{enumerate}
\end{proof}
\begin{fact}
  If $T\colon \mathcal{H}\rightarrow \mathcal{K}$ is a linear map, then
  \begin{align*}
    \norm{T}_{\text{op}} &= \sup\set{\left\vert \iprod{T(x)}{y} \right\vert | x\in B_{\mathcal{H}},y\in B_{\mathcal{K}}}.
  \end{align*}
\end{fact}
\begin{proof}
  By the Riesz Representation theorem, we have that $B_{K^{\ast}} = \set{ \iprod{\cdot}{y} | y\in B_{\mathcal{K}} }$, meaning we have
  \begin{align*}
    \norm{T(x)} &= \sup_{y\in B_{\mathcal{K}}}\left\vert \iprod{T(x)}{y} \right\vert.
  \end{align*}
  Taking the supremum over $x\in B_{\mathcal{Y}}$ yields
  \begin{align*}
    \norm{T}_{\text{op}} &= \sup_{x\in B_{\mathcal{H}}} \norm{T(x)}\\
                         &= \sup\set{ \left\vert \iprod{T(x)}{y} \right\vert | x\in B_{\mathcal{H}},y\in B_{\mathcal{K}} }.
  \end{align*}
\end{proof}
\begin{definition}
  Let $F: \mathcal{H}\times \mathcal{K}\rightarrow \C$ be a sesquilinear form. We define the norm
  \begin{align*}
    \norm{F} &\coloneq \sup\set{\left\vert F(x,y) \right\vert | x\in B_{\mathcal{H}},y\in B_{\mathcal{K}}}.
  \end{align*}
  We say $F$ is bounded if $\norm{F} < \infty $.
\end{definition}
\begin{proposition}
  If $F: \mathcal{H}\times \mathcal{K}\rightarrow \C$ is a bounded sesquilinear form, then there exists a unique $S\in B\left(\mathcal{K},\mathcal{H}\right)$ such that
  \begin{align*}
    F\left(x,y\right) &= \iprod{x}{S(y)}.
  \end{align*}
\end{proposition}
\begin{proof}
Fix $y\in \mathcal{K}$, and consider the linear functional $\varphi: \mathcal{H}\rightarrow \C$ given by $\varphi(x) = F\left(x,y\right)$. Since $\varphi$ is linear, we have
\begin{align*}
  \left\vert \varphi(x) \right\vert &= \left\vert F\left(x,y\right) \right\vert\\
                                    &\leq \norm{F}\norm{y}
\end{align*}
for all $x\in B_{\mathcal{H}}$, meaning $\varphi\in \mathcal{H}^{\ast}$. Thus, there is a unique $z\in \mathcal{H}$ such that $\varphi = \varphi_z$. We define $S(y) \coloneq z$. Doing this for each $y\in \mathcal{K}$, we get a map $S: \mathcal{K}\rightarrow \mathcal{H}$ such that
\begin{align*}
  F\left(x,y\right) &= \iprod{x}{S(y)}.
\end{align*}
We show that $S$ is linear and bounded. Let $y_1,y_2\in \mathcal{K}$ and $\alpha \in \mathcal{C}$. For all $x\in \mathcal{H}$, we have
\begin{align*}
  \iprod{x}{S\left(y_1 + \alpha y_2\right)} &= F\left(x,y_1 + \alpha y_2\right)\\
                                            &= F\left(x,y_1\right) + \overline{\alpha}F\left(x,y_2\right)\\
                                            &= \iprod{x}{S\left(y_1\right)} + \overline{\alpha} \iprod{x}{S\left(y_2\right)}\\
                                            &= \iprod{x}{S\left(y_1\right) + \alpha S\left(y_2\right)}.
\end{align*}
Thus, $S$ is linear. We also have
\begin{align*}
  \norm{S}_{\text{op}} &= \sup\set{\left\vert \iprod{x}{S(y)} \right\vert | x\in B_{\mathcal{H}},y\in B_{\mathcal{K}}}\\
                       &= \sup\set{\left\vert F(x,y) \right\vert | x\in B_{\mathcal{H}},y\in B_{\mathcal{K}}}\\
                       &= \norm{F}.
\end{align*}
For uniqueness, we see that if $ \iprod{x}{S_1(y)} = F(x,y) = \iprod{x}{S_2(y)} $, then $S_1 = S_2$ necessarily.
\end{proof}
\begin{theorem}
  Let $\mathcal{H}, \mathcal{K},\mathcal{L}$ be Hilbert spaces. If $T\in \B\left(\mathcal{H},\mathcal{K}\right)$, then there is a unique bounded operator $T^{\ast}\in \B\left(\mathcal{K},\mathcal{H}\right)$ such that 
  \begin{align*}
    \iprod{T(x)}{y} &= \iprod{x}{T^{\ast}\left(y\right)}
  \end{align*}
  for all $x\in \mathcal{H}$ and $y\in \mathcal{K}$. We call $T^{\ast}$ the Hilbert space adjoint of $T$. Moreover, the following are true for $T,S\in \B\left(\mathcal{H},\mathcal{K}\right)$, $R\in \B\left(\mathcal{K},\mathcal{L}\right)$, and $\lambda \in \C$:
  \begin{enumerate}[(1)]
    \item $\left(T + \lambda S\right)^{\ast} = T^{\ast} + \overline{\lambda}S^{\ast}$;
    \item $T^{\ast\ast} = T$;
    \item $\left(R\circ T\right)^{\ast} = T^{\ast}\circ R^{\ast}$;
    \item if $T$ is invertible, then $\left(T^{-1}\right)^{\ast} = \left(T^{\ast}\right)^{-1}$;
    \item $\norm{T^{\ast}} = \norm{T}$;
    \item $\norm{T^{\ast}T} = \norm{T}^2$ (known as the $C^{\ast}$-property).
  \end{enumerate}
\end{theorem}
\begin{proof}
  We define $F: \mathcal{H}\times \mathcal{K}\rightarrow \C$ by $F\left(x,y\right) = \iprod{T(x)}{y}$. We have $F$ is a sesquilinear form, and
  \begin{align*}
    \norm{F} &= \sup\set{\left\vert F(x,y) \right\vert | x\in B_{\mathcal{H}},y\in B_{\mathcal{K}}}\\
             &= \sup\set{\left\vert \iprod{T(x)}{y} \right\vert | x\in B_{\mathcal{H}},y\in B_{\mathcal{K}}}\\
             &= \norm{T}_{\text{op}}.
  \end{align*}
  Thus, there is a unique operator $S_T\in \B\left(\mathcal{K},\mathcal{H}\right)$ such that $ \iprod{T(x)}{y} = \iprod{x}{S_T(y)} $, with $\norm{S_T} = \norm{T}$. We define $T^{\ast} = S_T$.\newline

  We will show (6).
  \begin{align*}
    \norm{T^{\ast}T} &= \sup_{\substack{x\in B_{\mathcal{H}}\\y\in B_{\mathcal{K}}}} \left\vert \iprod{T^{\ast} T (x)}{y} \right\vert\\
                     &\geq \sup_{x\in B_{\mathcal{H}}} \left\vert \iprod{T^{\ast}T\left(x\right)}{x} \right\vert\\
                     &= \sup_{x\in B_{\mathcal{H}}}\left\vert \iprod{T(x)}{T(x)} \right\vert\\
                     &= \sup_{x\in B_{\mathcal{H}}} \norm{T(x)}^2\\
                     &= \left(\sup_{x\in B_{\mathcal{H}}}\norm{T(x)}\right)^2\\
                     &= \norm{T}^2\\
                     &= \norm{T}\norm{T}\\
                     &= \norm{T^{\ast}}\norm{T}\\
                     &\geq \norm{T^{\ast}T}.
  \end{align*}
\end{proof}
\begin{exercise}
  Let $\mathcal{H}$ and $\mathcal{K}$ be Hilbert spaces, and suppose $T\in \B\left(\mathcal{H},\mathcal{K}\right)$. Write $T^{\ast}\in \B\left(\mathcal{K},\mathcal{H}\right)$ to be the (Hilbert space) adjoint, and $T^{\dagger}: K^{\ast}\rightarrow H^{\ast}$ to be the Banach space adjoint. Let $\rho_{\mathcal{H}}:\mathcal{H}\rightarrow \mathcal{H}^{\ast}$ be the conjugate linear isometry $x\mapsto \varphi_x$, and let $\rho_{\mathcal{K}}: \mathcal{K}\rightarrow \mathcal{K}^{\ast}$ to be the conjugate linear isometry $y \mapsto \varphi_{y}$. Show that the following diagram commutes.
  \begin{center}
    % https://tikzcd.yichuanshen.de/#N4Igdg9gJgpgziAXAbVABwnAlgFyxMJZABgBoBGAXVJADcBDAGwFcYkQAdDgW3pwAsAxk2ABpAL4hxpdJlz5CKchWp0mrdl14DhjYAAlJ02djwEiZYqoYs2iTjz5CREgHrAu9ODiMyQGUwUiZSsaGw17LSddA3F3T28jVRgoAHN4IlAAMwAnCG4kMhAcCCRlEEZ6ACMYRgAFOTNFEBysVP4cEDD1OxAAFXiOLx8pP1z8wpoSpAAmbttNDhz+CAB9D0cdF3FfbLyCxHLpxABmGkqa+sag+1b2zvmIh2W1je1nPUNdkHGDueLSqdHr0BhsoPRUukcklxEA
\begin{tikzcd}
\mathcal{K}^{\ast} \arrow[r, "T^{\dagger}"]                        & \mathcal{H}^{\ast}                           \\
\mathcal{K} \arrow[r, "T^{\ast}"'] \arrow[u, "\rho_{\mathcal{K}}"] & \mathcal{H} \arrow[u, "\rho_{\mathcal{H}}"']
\end{tikzcd}
  \end{center}
\end{exercise}
\begin{proof}
  Let $x\in \mathcal{H}$, $y\in \mathcal{K}$. By the Riesz representation theorem, we have $\varphi_{x} = \iprod{\cdot}{x}$ and $\varphi_{y} = \iprod{\cdot}{y}$. Thus, we have
  \begin{align*}
    T^{\dagger}\left(\varphi_y\right)\left(\left(x\right)\right) &= \varphi_{y}\left(T\left(x\right)\right)\\
                                                                 &= \iprod{T(x)}{y}\\
                                                                 &= \iprod{x}{T^{\ast}(y)}\\
                                                                 &= \varphi_{x}\left(T^{\ast}\left(y\right)\right).
  \end{align*}
  
\end{proof}
\begin{corollary}
  The adjoint map $\ast: \B\left(\mathcal{H}\right)\rightarrow \B\left(\mathcal{H}\right)$ defined by $T\mapsto T^{\ast}$ is an involution, meaning $\B\left(\mathcal{H}\right)$ is a unital $\ast$-algebra. If $\Dim\left(\mathcal{H}\right) > 1$, then $\B\left(\mathcal{H}\right)$ is noncommutative.
\end{corollary}
\begin{definition}
  A Banach $\ast$-algebra is a Banach algebra $A$ with an involution satisfying
  \begin{align*}
    \norm{a^{\ast}} = \norm{a}
  \end{align*}
  for all $a\in A$. If $A$ is a Banach $\ast$-algebra that satisfies the $C^{\ast}$-property, then $A$ is called a $C^{\ast}$-algebra.
\end{definition}
We can now look at some examples of operators and adjoints.
\begin{example}
  Let $a = \left(a_{ij}\right)_{i,j}\in \Mat_{m,n}\left(\C\right)$, with the linear operator
  \begin{align*}
    T_{a}\colon \ell_{2}^{n}\rightarrow \ell_{2}^{m}
  \end{align*}
  defined by $T_a\left(\xi\right) = a\xi$. Since $\ell_2^{n}$ is finite-dimensional, $T_a$ is bounded. The conjugate transpose $a^{\ast} = \left(\overline{a_{ji}}\right)_{i,j}$ is an $n\times m$ matrix satisfying
  \begin{align*}
    \iprod{T_{a}\left(\xi\right)}{\eta} &= \iprod{a\eta}{\xi}\\
                                        &= \left(a\xi\right)^{\ast}\eta\\
                                        &= \xi^{\ast}a^{\ast}\eta\\
                                        &= \iprod{\xi}{a^{\ast}\eta}\\
                                        &= \iprod{\xi}{T_{a^{\ast}}\left(\eta\right)},
  \end{align*}
  meaning $T_{a}^{\ast} = T_{a^{\ast}}$.
\end{example}
\begin{example}
  The canonical projection
  \begin{align*}
    \pi_k\colon \bigoplus_{i\in I}\mathcal{H}_i \rightarrow \mathcal{H}_k
  \end{align*}
  and canonical injection
  \begin{align*}
    \iota_k\colon \mathcal{H}_k \rightarrow \bigoplus_{i\in I}\mathcal{H}_i,
  \end{align*}
  defined by
  \begin{align*}
    \pi_k\left(\left(x_i\right)_i\right) &= x_k\\
    \iota_k\left(x_k\right) &= \begin{cases}
      x_k & i=k\\
      0 & i\neq k
    \end{cases}
  \end{align*}
  are adjoints.
\end{example}
\begin{example}
  Let $\mathcal{H}$ and $\mathcal{K}$ be Hilbert spaces. For every pair of nonzero vectors $x\in \mathcal{H}$ and $y\in \mathcal{K}$, we define the rank-one bounded operator $\theta_{x,y}: \mathcal{K}\rightarrow \mathcal{H}$ by $\theta_{x,y}\left(z\right) = \iprod{z}{y}x$.\newline

  In physics, $\theta_{x,y} = \ket{x}\bra{y}$.\newline

  By the Cauchy--Schwarz inequality, we have
  \begin{align*}
    \norm{\theta_{x,y}\left(z\right)} &= \norm{\iprod{z}{y}x}\\
                                      &= \left\vert \iprod{z}{y} \right\vert \norm{x}\\
                                      &\leq \norm{z}\norm{y}\norm{x},
  \end{align*}
  meaning $\norm{\theta_{x,y}}_{\text{op}} \leq \norm{x}\norm{y}$. Alternatively, we also know that
  \begin{align*}
    \theta_{x,y}\left(\frac{y}{\norm{y}}\right) &= \norm{x}\norm{y},
  \end{align*}
  meaning that $\norm{\theta_{x,y}}_{\text{op}} = \norm{x}\norm{y}$.\newline

  The adjoint of $\theta_{x,y}$ is $\theta_{y,x}$. We can see this by taking, for $z\in \mathcal{K}$ and $u\in \mathcal{H}$,
  \begin{align*}
    \iprod{\theta_{x,y}\left(z\right)}{u} &= \iprod{ \iprod{z}{y}x }{u}\\
                                          &= \iprod{z}{y} \iprod{x}{u}\\
                                          &= \iprod{z}{y} \overline{\iprod{u}{x}}\\
                                          &= \iprod{z}{ \iprod{u}{x}y }\\
                                          &= \iprod{z}{ \theta_{y,x}\left(u\right) }.
  \end{align*}
\end{example}

\subsubsection{Topologies on $\B\left(\mathcal{H}\right)$}%
Given a Banach space $X$, we can introduce two locally convex topologies on $\B\left(X\right)$ --- namely, the weak operator topology and the strong operator topology, both of which are weaker than the norm topology.
\begin{lemma}
  Let $\mathcal{H}$ be a Hilbert space, and let $\left(T_{\alpha}\right)_{\alpha}$ be a net in $\B\left(\mathcal{H}\right)$. The following are equivalent:
  \begin{enumerate}[(i)]
    \item $\left(T_{\alpha}\right)_{\alpha}\xrightarrow{\text{WOT}}T$;
    \item for all $\xi,\eta\in \mathcal{H}$, $ \iprod{T_{\alpha}\left(\xi\right)}{\eta}\rightarrow \iprod{T\left(\xi\right)}{\eta} $;
    \item for all $\xi,\eta\in B_{\mathcal{H}}$, $ \iprod{T_{\alpha}\left(\xi\right)}{\eta}\rightarrow \iprod{T\left(\xi\right)}{\eta} $;
    \item for all $\xi\in \mathcal{H}$, $ \iprod{T_{\alpha}\left(\xi\right)}{\xi} \rightarrow \iprod{T\left(\xi\right)}{\xi} $;
    \item for all $\xi\in B_{\mathcal{H}}$, $ \iprod{T_{\alpha}\left(\xi\right)}{\xi} \rightarrow \iprod{T\left(\xi\right)}{\xi} $.
  \end{enumerate}
\end{lemma}
\begin{proof}
  We only need to prove the equivalence between (i) and (ii). The rest follow from scaling or the polarization identity.\newline

  We know that $\left(T_{\alpha}\right)_{\alpha}\xrightarrow{\text{WOT}}T$ in $\B\left(\mathcal{H}\right)$ if and only if $\varphi\left(T_{\alpha}\left(\xi\right)\right)\rightarrow \varphi\left(T\left(\xi\right)\right)$ for each $\xi\in \mathcal{H}$ and $\varphi\in \mathcal{H}^{\ast}$. By the Riesz representation theorem, each $\varphi\in \mathcal{H}^{\ast}$ is of the form $\varphi\left(\cdot\right) = \iprod{\cdot}{\eta}$.
\end{proof}
\begin{example}
  Let $\left(\Omega,\mathcal{M},\mu\right)$ be a semi-finite\footnote{A measure space where, for any $E\in \mathcal{M}$ with $\mu(E) = \infty$, there is $F\subseteq E$ and $0 < \mu(F) < \infty$.} measure space. We consider the multiplication operators $M_{f}\in \B\left(L_{2}\left(\Omega,\mu\right)\right)$, where $f\in L_{\infty}\left(\Omega,\mu\right)$. If $f\in L_{\infty}\left(\Omega,\mu\right)$ and $\left(f_{\alpha}\right)_{\alpha}$ is a net in $L_{\infty}\left(\Omega,\mu\right)$, we claim that $\left(f_{\alpha}\right)_{\alpha}\xrightarrow{w^{\ast}}f$ if and only if $M_{f_{\alpha}}\xrightarrow{\text{WOT}}M_{f}$. Here, the $w^{\ast}$ topology on $L_{\infty}\left(\Omega,\mu\right)$ is given by the duality $\left(L_{1}\left(\Omega,\mu\right)\right)^{\ast}\cong L_{\infty}\left(\Omega,\mu\right)$.\newline

  If $\left(f_{\alpha}\right)_{\alpha}\xrightarrow{w^{\ast}}f$, then $\int_{\Omega}^{} f_{\alpha}g\:d\mu\rightarrow \int_{\Omega}^{} fg\:d\mu$ for every $g\in L_{1}\left(\Omega,\mu\right)$. For $\xi\in L_{2}\left(\Omega,\mu\right)$, we have $\left\vert \xi \right\vert^2\in L_{1}\left(\Omega,\mu\right)$, so
  \begin{align*}
    \iprod{M_{f_{\alpha}}\left(\xi\right)}{\xi} &= \int_{\Omega}^{} f_{\alpha}\overline{\xi}\xi\:d\mu\\
                                                &= \int_{\Omega}^{} f_{\alpha}\left\vert \xi \right\vert^2\:d\mu\\
                                                &\rightarrow \int_{\Omega}^{} f\left\vert \xi \right\vert^2\:d\mu\\
                                                &= \iprod{M_{f}\left(\xi\right)}{\xi}.
  \end{align*}
  Thus, $M_{f_{\alpha}}\xrightarrow{\text{WOT}} M_{f}$.\newline

  Suppose $M_{f_{\alpha}}\xrightarrow{\text{WOT}}M_{f}$. Given $g\in L_{1}\left(\Omega,\mu\right)$, we can write $g = \xi \overline{\eta}$ for $\xi,\eta \in L_{2}\left(\Omega,\mu\right)$. Thus, we have
  \begin{align*}
    \int_{\Omega}^{} f_{\alpha}g\:d\mu &= \int_{\Omega}^{} f_{\alpha}\xi \overline{\eta}\:d\mu\\
                                       &= \iprod{M_{f_{\alpha}}\xi}{\eta}\\
                                       &\rightarrow \iprod{M_{f}\xi}{\eta}\\
                                       &= \int_{\Omega}^{} f \xi \overline{\eta}\:d\mu\\
                                       &= \int_{\Omega}^{} fg\:d\mu,
  \end{align*}
  so $\left(f_{\alpha}\right)_{\alpha}\xrightarrow{w^{\ast}}f$ in $L_{\infty}\left(\Omega,\mu\right)$.\newline

  We can define
  \begin{align*}
    \mathcal{L}_{\infty}\left(\Omega,\mu\right) &= \set{M_{f} | f\in L_{\infty}\left(\Omega,\mu\right)},
  \end{align*}
  and we see that $M: L_{\infty}\left(\Omega,\mu\right) \rightarrow \mathcal{L}_{\infty}\left(\Omega,\mu\right)$ is an isometric $\ast$-isomorphism and a $w^{\ast}$-WOT-homeomorphism.
\end{example}
\begin{proposition}
  Let $\mathcal{H}$ be a Hilbert space.
  \begin{enumerate}[(1)]
    \item Left and right multiplication defined by a fixed operator is SOT-continuous. If $S\in \B\left(\mathcal{H}\right)$, the maps $L_{S}\colon \B\left(\mathcal{H}\right)\rightarrow \B\left(\mathcal{H}\right)$ and $R_{S}\colon \B\left(\mathcal{H}\right)\rightarrow \B\left(\mathcal{H}\right)$ defined by
      \begin{align*}
        L_S\left(T\right) &= ST\\
        R_{S}\left(T\right) &= TS
      \end{align*}
      are SOT-SOT-continuous.
    \item The maps $L_S$ and $R_S$ are WOT-WOT-continuous.
    \item The adjoint map $\ast\colon \B\left(\mathcal{H}\right)\rightarrow \B\left(\mathcal{H}\right)$, defined by $T\mapsto T^{\ast}$, is WOT-WOT-continuous. If $\Dim(\mathcal{H}) = \infty$, the adjoint map is not SOT-SOT-continuous.
    \item If $\Dim\left(\mathcal{H}\right) = \infty$, joint multiplication, $\B\left(\mathcal{H}\right)\times \B\left(\mathcal{H}\right)\rightarrow \B\left(\mathcal{H}\right)$, defined by $\left(T,S\right)\mapsto TS$, is neither WOT-WOT-continuous nor SOT-SOT-continuous.
  \end{enumerate}
\end{proposition}
\begin{proof}\hfill
  \begin{enumerate}[(1)]
    \item Let $\left(T_{\alpha}\right)_{\alpha}\xrightarrow{\text{SOT}}T$ in $\B\left(\mathcal{H}\right)$. For $\xi\in \mathcal{H}$, we have
      \begin{align*}
        \norm{ST_{\alpha}\left(\xi\right) - ST\left(\xi\right)} &= \norm{S\left(T_{\alpha}\left(\xi\right) - T\left(\xi\right)\right)}\\
                                                                &\leq \norm{S}_{\text{op}}\norm{T_{\alpha}\left(\xi\right) - T\left(\xi\right)}\\
                                                                &\rightarrow 0,
      \end{align*}
      meaning $\left(ST_{\alpha}\right)_{\alpha}\xrightarrow{\text{SOT}}ST$, meaning $L_S$ is SOT-SOT-continuous.\newline

      Similarly, we have
      \begin{align*}
        \norm{T_{\alpha}S\left(\xi\right) - TS\left(\xi\right)} &= \norm{T_{\alpha}\left(\xi\right) - T\left(S\left(\xi\right)\right)}\\
                                                                &\rightarrow 0,
      \end{align*}
      so $\left(T_{\alpha}S\right)_{\alpha}\xrightarrow{\text{SOT}}TS$, meaning $R_{S}$ is SOT-SOT-continuous.
    \item Let $\left(T_{\alpha}\right)_{\alpha}\xrightarrow{\text{WOT}}T$. For $\xi,\eta\in \mathcal{H}$, we have
      \begin{align*}
        \iprod{ST_{\alpha}\left(\xi\right)}{\eta} &= \iprod{T_{\alpha}\left(\xi\right)}{S^{\ast}\left(\eta\right)}\\
                                                  &\rightarrow \iprod{T\left(\xi\right)}{S^{\ast}\left(\eta\right)}\\
                                                  &= \iprod{ST\left(\xi\right)}{\eta},
      \end{align*}
      meaning $\left(ST_{\alpha}\right)_{\alpha}\xrightarrow{\text{WOT}}ST$, so $L_{S}$ is WOT-WOT-continuous. Additionally, by definition, we must have $ \iprod{T_{\alpha}\left(S\left(\xi\right)\right)}{\eta}\rightarrow \iprod{T\left(S\left(\xi\right)\right)}{\eta} $, so $\left(T_{\alpha}S\right)_{\alpha}\xrightarrow{\text{WOT}}TS$, so $R_{S}$ is also WOT-WOT-continuous.
    \item If $\left(T_{\alpha}\right)_{\alpha}\xrightarrow{\text{WOT}}T$, then we have
      \begin{align*}
        \iprod{T^{\ast}_{\alpha}\left(\xi\right)}{\eta} &= \iprod{\xi}{T_{\alpha}\left(\eta\right)}\\
                                                        &\rightarrow \iprod{\xi}{T\left(\eta\right)}\\
                                                        &= \iprod{T^{\ast}\left(\xi\right)}{\eta},
      \end{align*}
      so $\left(T_{\alpha}^{\ast}\right)_{\alpha}\xrightarrow{\text{WOT}} T^{\ast}$.\newline

      To see that the adjoint map is not SOT-SOT-continuous, we consider $\ell_2$ with the orthonormal basis of canonical coordinate vectors, $\left(e_n\right)_{n\geq 1}$. Then, the outer product operators
      \begin{align*}
        T_n &= \theta_{e_1,e_n}\\
        T_n\left(\xi\right) &= \iprod{\xi}{e_n}e_1
      \end{align*}
      give
      \begin{align*}
        \norm{T_n\left(\xi\right)} &= \norm{ \iprod{\xi}{e_n}e_1 }\\
                                   &= \left\vert \iprod{\xi}{e_n} \right\vert\\
                                   &\rightarrow 0,
      \end{align*}
      since, by Bessel's inequality, the sum of the squares of $\left\vert \iprod{\xi}{e_n} \right\vert$ converges. Thus, $\left(T_n\right)_n\xrightarrow{\text{SOT}} 0$. However, since $T^{\ast}_{n} = \theta_{e_n,e_1}$, we have
      \begin{align*}
        \norm{T^{\ast}_{n}\left(e_1\right)} &= \norm{ \iprod{e_1}{e_1}e_n }\\
                                            &= \left\vert \iprod{e_1}{e_1} \right\vert\\
                                            &= 1.
      \end{align*}
      Thus, $\left(T_n^{\ast}\right)_{n}\not\rightarrow 0$ in SOT.
    \item Consider $\left(T_n\right)_n$ as above. Since $\left(T_n\right)_n\xrightarrow{\text{SOT}} 0$, we know that $\left(T_n\right)_n\xrightarrow{\text{WOT}}T$. However, though $\left(T_n^{\ast}\right)_n\not\rightarrow0$ in SOT, we do have $\left(T_n^{\ast}\right)_n\xrightarrow{\text{WOT}}0$ . We have
      \begin{align*}
        T_nT_n^{\ast} &= \theta_{e_1,e_n}\circ \theta_{e_n,e_1}\\
                      &= \theta_{e_1,e_1},
      \end{align*}
      which does not converge in WOT to $0$, since $ \iprod{\theta_{e_1,e_1}\left(e_1\right)}{e_1} = 1 $.
  \end{enumerate}
\end{proof}
\begin{exercise}
  Let $X$ be a Banach space, and suppose $\left(T_n\right)_n\xrightarrow{\text{SOT}}T$ and $\left(S_n\right)_n\xrightarrow{\text{SOT}}S$ in $\B\left(\mathcal{X}\right)$. Show that $\left(T_nS_n\right)_n\xrightarrow{\text{SOT}}TS$.
\end{exercise}
\begin{solution}
  Let $x\in X$. We have that $\norm{T_n\left(x\right)-T(x)}\xrightarrow{n\rightarrow\infty}0$, so we see that the $\left(T_n\right)_n$ are a pointwise bounded family. Similarly, we see that $\norm{S_n(x) - S(x)}\xrightarrow{n\rightarrow\infty}0$, so the $\left(S_n\right)_n$ are a pointwise bounded family.\newline

  Thus, we see that
  \begin{align*}
    \norm{T_nS_n(x) - TS(x)} &\leq \norm{T_nS_n(x) - T_nS(x)} + \norm{T_nS(x) - TS(x)}\\
                             &\leq \sup_{n\in \N}\norm{T_n}_{\text{op}}\norm{S_n(x) - S(x)} + \norm{T_n\left(S(x)\right) - T\left(S(x)\right)}\\
                             &\rightarrow 0.
  \end{align*}
  
\end{solution}
\begin{theorem}
  Let $B$ be the closed unit ball of $\B\left(\mathcal{H}\right)$, where $\mathcal{H}$ is a Hilbert space. Then, $B$ is compact in WOT.
\end{theorem}
\begin{proof}
  Let $K$ be defined by
  \begin{align*}
    K &= \prod_{\xi,\eta\in B_{\mathcal{H}}}\overline{\mathbb{D}},
  \end{align*}
  where $\overline{\mathbb{D}}$ is the closed unit disk in the complex plane. Then, $K$ is compact in the product topology.\newline

  Consider the map $\phi\colon B\rightarrow K$ defined by
  \begin{align*}
    \phi(T) &= \left( \iprod{T\left(\xi\right)}{\eta}\right)_{\xi,\eta\in B_{\mathcal{H}}}.
  \end{align*}
  Since, by Cauchy--Schwarz, we have that
  \begin{align*}
    \left\vert \iprod{T\left(\xi\right)}{\eta} \right\vert &\leq \norm{T}_{\text{op}}\norm{\xi}\norm{\eta}\\
                                                           &\leq 1,
  \end{align*}
  for all $\xi,\eta\in B_{\mathcal{H}}$, it is the case that $\phi$ is well-defined. Additionally, $\phi$ is injective since $T = S$ if and only if $ \iprod{T\left(\xi\right)}{\eta} = \iprod{S\left(\xi\right)}{\eta} $ for all $\xi,\eta\in B_{\mathcal{H}}$, and $\phi$ is an embedding by the definition of the weak operator topology.\newline

  We wish to show that the range of $\phi$ is closed. Let
  \begin{align*}
    \left( \iprod{T_{\alpha}\left(\xi\right)}{\eta}\right)_{\xi,\eta} \rightarrow \left(z_{\xi,\eta}\right)_{\xi,\eta}\in K
  \end{align*}
  be a net in $K$. Scaling, we see that $\left( \iprod{T_{\alpha}\left(\xi\right)}{\eta}\right)_{\xi,\eta}$ converges in $\C$ for all $\xi,\eta\in \mathcal{H}$, so we have a bounded sesquilinear form defined by
  \begin{align*}
    F\left(\xi,\eta\right) &= \lim_{\alpha \in A} \iprod{T_{\alpha}\left(\xi\right)}{\eta},
  \end{align*}
  with $\norm{F} \leq 1$. Thus, there is $T\in \B\left(\mathcal{H}\right)$ with $\norm{T}_{\text{op}} = \norm{F} \leq 1$ and $ \iprod{T\left(\xi\right)}{\eta} = F\left(\xi,\eta\right) $, meaning $\phi(T) = \left(z_{\xi,\eta}\right)_{\xi,\eta}$.
\end{proof}
\begin{proposition}
  Let $\mathcal{H}$ be a Hilbert space, and let $\varphi: \B\left(\mathcal{H}\right)\rightarrow \C$ be a linear functional. The following are equivalent.
  \begin{enumerate}[(i)]
    \item There exist $\xi_1,\dots,\xi_n$ and $\eta_1,\dots,\eta_n$ in $\mathcal{H}$ such that
      \begin{align*}
        \varphi\left(T\right) &= \sum_{j=1}^{n} \iprod{T\left(\xi_j\right)}{\eta_j}.
      \end{align*}
    \item $\varphi$ is WOT-continuous.
    \item $\varphi$ is SOT-continuous.
  \end{enumerate}
\end{proposition}
\begin{proof}
  The implication (i) to (ii) follows from the definition of $\varphi$ as a finite sum of inner products. The implication (ii) to (iii) follows from the fact that left and right multiplication is WOT-continuous.\newline

  We only need to show that (iii) implies (i). Let $\varphi$ be SOT continuous. There exists $K > 0$ and $\xi_1,\dots,\xi_n\in \mathcal{H}$ with
  \begin{align*}
    \left\vert \varphi(T) \right\vert &\leq K\max_{j=1}^{n}\norm{T\left(\xi_j\right)}\\
                                      &\leq K \left(\sum_{j=1}^{n}\norm{T\left(\xi_j\right)}\right)^{1/2}
  \end{align*}
  Consider the subspace $\mathcal{K}_0\subseteq \bigoplus_{j=1}^{n}\mathcal{H}$ given by
  \begin{align*}
    \mathcal{K}_0 &= \set{\left(T\left(\xi_1\right),\dots,T\left(\xi_n\right)\right) | T\in \B\left(\mathcal{H}\right)}.
  \end{align*}
  Let $\mathcal{K} = \overline{\mathcal{K}_0}$. By the above inequality, the linear functional
  \begin{align*}
    \psi_0\left(\left(T\left(\xi_1\right),\dots,T\left(\xi_n\right)\right)\right) &\coloneq \varphi(T)
  \end{align*}
  is continuous, meaning it extends continuously to a bounded linear functional on $\mathcal{K}$. There exists a vector $\eta = \left(\eta_1,\dots,\eta_n\right)\in \mathcal{K}$ such that $\psi\left(\xi\right) = \iprod{\xi}{\eta}$ for all $\xi\in \mathcal{K}$. Thus, we get
  \begin{align*}
    \varphi\left(T\right) &= \psi\left(\left(T\left(\xi_1\right),\dots,T\left(\xi_n\right)\right)\right)\\
                          &= \iprod{\left(T\left(\xi_1\right),\dots,T\left(\xi_n\right)\right)}{\left(\eta_1,\dots,\eta_n\right)}\\
                          &= \sum_{j=1}^{n} \iprod{T\left(\xi_j\right)}{\eta_j}.
  \end{align*}
\end{proof}
\begin{remark}
  The above result implies that $\left(\B\left(\mathcal{H}\right),\text{WOT}\right)^{\ast} = \left(\B\left(\mathcal{H}\right),\text{SOT}\right)^{\ast}$.
\end{remark}

\begin{corollary}
  Let $\mathcal{H}$ be a Hilbert space, and suppose $C\subseteq \B\left(\mathcal{H}\right)$ is a convex subset. Then, $\overline{C}^{\text{WOT}} = \overline{C}^{\text{SOT}}$.
\end{corollary}
\begin{proof}
  Since WOT is weaker than SOT, and we have shown $\left(\B\left(\mathcal{H}\right),\text{WOT}\right)^{\ast} = \left(\B\left(\mathcal{H}\right),\text{SOT}\right)^{\ast}$, the result follows from the analogous result on locally convex topological vector spaces.
\end{proof}
Particular WOT-closed self-adjoint subalgebras of $\B\left(\mathcal{H}\right)$ are one of the central subjects of the study of operator algebras. 
\begin{definition}
  Let $\mathcal{H}$ be a Hilbert space. A von Neumann algebra acting on $\mathcal{H}$ is a WOT-closed unital $\ast$-subalgebra $N\subseteq \B\left(\mathcal{H}\right)$.
\end{definition}
\begin{exercise}
  Let $\set{N_i}_{i\in I}$ be a family of von Neumann algebras acting on $\mathcal{H}$. Prove that $\bigcap_{i\in I}N_i$ is a von Neumann algebra.
\end{exercise}
\begin{solution}
  Since $\set{N_i}_{i\in I}$ is a family of WOT-closed unital $\ast$-subalgebras, each $N_i$ is WOT-closed, so the intersection $N \coloneq \bigcap_{i\in I}N_i$ is WOT-closed. Additionally, since the identity map is in each $N_i$, it is also in $N$, and for any $A\in N$, we must have $A\in N_i$ for all $i\in I$, so $A^{\ast}\in N_i$ for all $N_i$, so $A^{\ast}\in N$. Finally, since the intersection of subrings is a subring, it is the case that $N$ is a WOT-closed unital $\ast$-subalgebra.
\end{solution}
\begin{example}
  Let $\mathcal{S} \subseteq \B\left(\mathcal{H}\right)$ be a family of bounded operators. We define the von Neumann algebra generated by $\mathcal{S}$ to be the smallest von Neumann algebra containing $\mathcal{S}$.
  \begin{align*}
    W^{\ast}\left(\mathcal{S}\right) &= \bigcap\set{N\subseteq \B\left(\mathcal{H}\right) | N\text{ is a von Neumann algebra and }N\supseteq \mathcal{S}}.
  \end{align*}
\end{example}
\begin{definition}
  Let $\mathcal{H}$ be a Hilbert space, and suppose $\mathcal{S}\subseteq \B\left(\mathcal{H}\right)$ is a nonempty collection of bounded operators. The commutant of $\mathcal{S}$ is
  \begin{align*}
    \mathcal{S}' &= \set{T\in \B\left(\mathcal{H}\right) | TS = ST\text{ for all }S\in \mathcal{S}}.
  \end{align*}
  The double commutant of $\mathcal{S}$ is $\mathcal{S}'' = \left(\mathcal{S}'\right)'$.
\end{definition}
\begin{exercise}
  Let $\mathcal{H}$ be a Hilbert space, and suppose $\emptyset\neq \mathcal{S},\mathcal{T}\subseteq \B\left(\mathcal{H}\right)$ are subsets.
  \begin{enumerate}[(1)]
    \item The commutant $\mathcal{S}'$ is a unital subalgebra of $\B\left(\mathcal{H}\right)$.
    \item If $\mathcal{S}$ is self-adjoint, then $\mathcal{S}'$ is a unital $\ast$-subalgebra of $\B\left(\mathcal{H}\right)$.
    \item If $\mathcal{S}\subseteq \mathcal{T}$, then $\mathcal{T}' \subseteq \mathcal{S}'$.
    \item $\mathcal{S}\subseteq \mathcal{S}''$.
    \item $\mathcal{S}''' = \mathcal{S}'$.
  \end{enumerate}
\end{exercise}
\begin{solution}\hfill
  \begin{enumerate}[(1)]
    \item If $Q,S\in \mathcal{S}$ and $\alpha \in \C$, we have, for $T\in \mathcal{S}'$,
      \begin{align*}
        \left(Q + \alpha S\right)T &= QT + \alpha ST\\
                                   &= TQ + \alpha TS\\
                                   &= T\left(Q + \alpha S\right),
      \end{align*}
      and
      \begin{align*}
        \left(SQ\right)T &= S\left(QT\right)\\
                         &= S\left(TQ\right)\\
                         &= \left(ST\right)Q\\
                         &= \left(TS\right)Q\\
                         &= T\left(SQ\right).
      \end{align*}
      Finally, since $TI = IT$ for $I = \id$, $\mathcal{S}$ is a unital subalgebra of $\B\left(\mathcal{H}\right)$.
    \item If $\mathcal{S}$ is $\ast$-closed, we have, for $T\in \mathcal{S}$ and $S\in \mathcal{S}'$, we have
      \begin{align*}
        S^{\ast}T^{\ast} &= \left(TS\right)^{\ast}\\
                         &= \left(ST\right)^{\ast}\\
                         &= T^{\ast}S^{\ast},
      \end{align*}
      so $S^{\ast}\in \mathcal{S}$.
    \item Let $\mathcal{S}\subseteq \mathcal{T}$. Then, for $Q\in \mathcal{T}'$, we must have, for all $T\in \mathcal{S}$, $TQ = QT$, so $Q\in \mathcal{S}'$.
    \item Let $T\in \mathcal{S}$. Then, for any $Q\in \mathcal{S}'$, we have $TQ = QT$, so $T\in \left(\mathcal{S}'\right)'= \mathcal{S}''$.
    \item Consult Rainone
  \end{enumerate}
\end{solution}
\begin{lemma}
  Let $\mathcal{H}$ be a Hilbert space, and suppose $\mathcal{S}\subseteq \B\left(\mathcal{H}\right)$ is a subset. Then, $\mathcal{S}'$ is WOT-closed, so it is SOT-closed.
\end{lemma}
\begin{proof}
  Let $\left(T_{\alpha}\right)_{\alpha}$ be a net in $\mathcal{S}'$ converging in WOT to an operator $T\in \B\left(\mathcal{H}\right)$. For $S\in \mathcal{S}$, we have
  \begin{align*}
    TS &= \lim_{\alpha}T_{\alpha}S\\
       &= \lim_{\alpha}ST_{\alpha}\\
       &= ST,
  \end{align*}
  where the limits are taken in the weak operator topology. Thus, $T\in \mathcal{S}'$.
\end{proof}
\begin{corollary}
  If $\mathcal{H}$ is a Hilbert space, and $\mathcal{S}\subseteq \B\left(\mathcal{H}\right)$ is a self-adjoint subset of operators, then $\mathcal{S}'$ is a von Neumann algebra acting on $\mathcal{H}$. Also, $\mathcal{S}''$ is a von Neumann algebra containing $\mathcal{S}$.
\end{corollary}
There are also various locally convex topologies on $\B\left(\mathcal{H}\right)$.
\begin{definition}
  Let $\mathcal{H}$ be a Hilbert space. The locally convex topology on $\B\left(\mathcal{H}\right)$ generated by the family of seminorms $\set{q_{\xi} | \xi\in \mathcal{H}}$, defined by
  \begin{align*}
    q_{\xi}\left(T\right) &= \norm{T\left(\xi\right)} + \norm{T^{\ast}\left(\xi\right)},
  \end{align*}
  is known as the strong* operator topology, or S*OT.
\end{definition}
\begin{proposition}
  Let $\mathcal{H}$ be a Hilbert space. The identity maps
  \begin{align*}
    \left(\B\left(\mathcal{H}\right),\norm{\cdot}_{\text{op}}\right) \xrightarrow{\id}\left(\B\left(\mathcal{H}\right),\text{S*OT}\right)\xrightarrow{\id}\left(\B\left(\mathcal{H}\right),\text{SOT}\right)\xrightarrow{\id}\left(\B\left(\mathcal{H}\right),\text{WOT}\right)
  \end{align*}
  are continuous. If $\Dim\left(\mathcal{H}\right)=\infty$, then the inverses are not continuous.
\end{proposition}
\begin{proof}
  Consult Rainone.
\end{proof}
\subsubsection{Order on $\B\left(\mathcal{H}\right)$}%
Since $\B\left(\mathcal{H}\right)$ is a $\ast$-algebra, we can talk about self-adjoint elements. We write
\begin{align*}
  \B\left(\mathcal{H}\right)_{\sa} &= \set{T\in \B\left(\mathcal{H}\right)|T = T^{\ast}}
\end{align*}
to denote the collection of self-adjoint operators.
\begin{example}
  Given $\lambda = \left(\lambda_n\right)_n$, the multiplication operator $D_{\lambda}\in \B\left(\ell_2\right)$ is self-adjoint if and only if $\lambda_n\in \R$ for all $n$.
\end{example}
Note that since adjoint operators are unique, we can say that $T = T^{\ast}$ if and only if $ \iprod{T\left(\xi\right)}{\eta} = \iprod{\xi}{T\left(\eta\right)} $. We can use the polarization identity to show another criterion for self-adjoint elements.
\begin{lemma}
  An operator $T\in \B\left(\mathcal{H}\right)$ is self-adjoint if and only if $ \iprod{T\left(\xi\right)}{\xi}\in \R $ for all $\xi\in \mathcal{H}$.
\end{lemma}
\begin{proof}
  We have
  \begin{align*}
    \iprod{T\left(\xi\right)}{\xi} &= \iprod{\xi}{T^{\ast}\left(\xi\right)}\\
                                   &= \iprod{\xi}{T\left(\xi\right)}\\
                                   &= \overline{ \iprod{T\left(\xi\right)}{\xi} },
  \end{align*}
  meaning $ \iprod{T\left(\xi\right)}{\xi}\in \R $.\newline

  In the reverse direction, we define $F\left(x,y\right) = \iprod{T\left(x\right)}{y}$ and $ G\left(x,y\right) = \iprod{x}{T\left(y\right)} $. Along the diagonal, we have
  \begin{align*}
    F\left(x,x\right) &= \iprod{T\left(x\right)}{x}\\
                      &= \overline{ \iprod{T\left(x\right)}{x} }\\
                      &= \iprod{x}{T\left(x\right)}\\
                      &= G\left(x,x\right),
  \end{align*}
  so $F = G$, meaning $ \iprod{T\left(x\right)}{x} = \iprod{x}{T\left(x\right)} $, so $T = T^{\ast}$.
\end{proof}
\begin{proposition}
  Let $A$ be a Banach $\ast$-algebra. The self-adjoint elements $A_{\sa}$ form a Banach space over $\R$.
\end{proposition}
\begin{proof}
  The self-adjoint elements $A_{\sa}$ form a vector space over $\R$. To see this, let $x,y\in A_{\sa}$, $\alpha\in \R$. Then,
  \begin{align*}
    \left(x + \alpha y\right)^{\ast} &= x^{\ast} + \overline{\alpha}y^{\ast}\\
                                     &= x^{\ast} + \alpha y^{\ast}\\
                                     &= x + \alpha y,
  \end{align*}
  so $x + \alpha y$ is self-adjoint.\newline

  We show that $A_{\sa}$ is norm-closed. Let $\left(a_n\right)_n$ be a sequence in $A_{\sa}$ that converges in norm to an element $a\in A$. Then, $\left(a_n\right)_n = \left(a_n^{\ast}\right)_n\rightarrow a^{\ast}$, since the adjoint operator is continuous. This implies $a^{\ast} = a$.
\end{proof}
If $A = \B\left(\mathcal{H}\right)$, then we can say more about the qualities of $A_{\sa}$.
\begin{proposition}
  The self-adjoint operators $\B\left(\mathcal{H}\right)_{\sa}\subseteq \B\left(\mathcal{H}\right)$ are closed in WOT, meaning they are closed in SOT.
\end{proposition}
\begin{proof}
  Let $\left(T_{\alpha}\right)_{\alpha}$ be a net in $\B\left(\mathcal{H}\right)_{\sa}$ converging in WOT to $T\in \B\left(\mathcal{H}\right)$. We have
  \begin{align*}
    \iprod{T\left(\xi\right)}{\xi} &= \lim_{\alpha} \iprod{T_{\alpha}\left(\xi\right)}{\xi}.
  \end{align*}
  Since each $T_{\alpha}$ is self-adjoint, we know that $ \iprod{T_{\alpha}\left(\xi\right)}{\xi}\in \R$ for every $\xi\in \mathcal{H}$, meaning $ \iprod{T\left(\xi\right)}{\xi}\in \R $ for every $\xi\in \mathcal{H}$, so $T$ is self-adjoint.
\end{proof}
\begin{definition}
  For $T\in \B\left(\mathcal{H}\right)$, we define the numerical range of $T$ to be
  \begin{align*}
    W(T) &= \set{ \iprod{T\left(\xi\right)}{\xi} | \xi\in B_{\mathcal{H}} }
  \end{align*}
  and the numerical radius of $T$ to be
  \begin{align*}
    \nu\left(T\right) &= \sup_{\xi \in B_{\mathcal{H}}} \left\vert \iprod{T\left(\xi\right)}{\xi} \right\vert.
  \end{align*}
\end{definition}
We see that for all $\xi$,
\begin{align*}
  \left\vert \iprod{T\left(\xi\right)}{\xi} \right\vert &\leq \nu\left(T\right)\norm{\xi}^2,
\end{align*}
and by Cauchy--Schwarz,
\begin{align*}
  \nu\left(T\right) &\leq \norm{T}_{\text{op}}.
\end{align*}
When $T$ is self-adjoint, we can say more.
\begin{proposition}
  If $T = T^{\ast}$, then $\nu\left(T\right) = \norm{T}_{\text{op}}$.
\end{proposition}
\begin{proof}
  Using the fact that $T$ is self-adjoint, we get
  \begin{align*}
    4\re\left( \iprod{T\left(x\right)}{y}\right) &= \iprod{T\left(x+y\right)}{x+y} - \iprod{T\left(x-y\right)}{x-y}
  \end{align*}
  for $x,y\in \mathcal{H}$. Using the parallelogram law, we get
  \begin{align*}
    \left\vert 4\re\left(T\left(x,y\right)\right) \right\vert &\leq \left\vert \iprod{T\left(x+y\right)}{x+y} \right\vert + \left\vert \iprod{T\left(x-y\right)}{x-y} \right\vert\\
                                                              &\leq \nu\left(\norm{x+y}^2 + \norm{x-y}^2\right)\\
                                                              &= 2\nu\left(T\right)\left(\norm{x}^2 + \norm{y}^2\right),
  \end{align*}
  giving
  \begin{align*}
    \left\vert \re\left( \iprod{T\left(x\right)}{y}\right) \right\vert &\leq \frac{1}{2}\nu\left(T\right)\left(\norm{x}^2 + \norm{y}^2\right).
  \end{align*}
  Let $x,y\in B_{\mathcal{H}}$, and set $\lambda = \sgn\left( \iprod{T\left(x\right)}{y}\right)$. Then, $\left\vert \overline{\lambda} \right\vert = 1$, yielding
  \begin{align*}
    \left\vert \iprod{T\left(x\right)}{x} \right\vert &= \lambda \iprod{T\left(x\right)}{y}\\
                                                      &= \iprod{T\left(x\right)}{\overline{\lambda}y}\\
                                                      &= \left\vert \re\left( \iprod{T\left(x\right)}{\overline{\lambda}y}\right) \right\vert\\
                                                      &\leq \frac{1}{2}\nu\left(T\right) \left(\norm{x} + \norm{\overline{\lambda}y}^2\right)\\
                                                      &= \frac{1}{2}\nu\left(T\right)\left(\norm{x}^2 + \norm{y}^2\right)\\
                                                      &\leq \frac{1}{2}\nu\left(T\right)\left(2\right)\\
                                                      &= \nu\left(T\right).
  \end{align*}
  Thus, taking the supremum, we get
  \begin{align*}
    \norm{T}_{\text{op}} &\leq \nu\left(T\right).
  \end{align*}
\end{proof}
We can now establish an ordering of $\B\left(\mathcal{H}\right)_{\sa}$ by constructing a cone of positive elements.
\begin{definition}
  Let $\mathcal{H}$ be a Hilbert space, and suppose $T\in \B\left(\mathcal{H}\right)$. We say $T$ is a positive operator if $W(T) \subseteq [0,\infty)$. In other words, for all $\xi\in \mathcal{H}$,
  \begin{align*}
    \iprod{T\left(\xi\right)}{\xi} &\geq 0.
  \end{align*}
  We write $\B\left(\mathcal{H}\right)_{+}$ for all the positive operators in $\B\left(\mathcal{H}\right)$.
\end{definition}
\begin{exercise}
  Suppose $T\in \B\left(\mathcal{H}\right)_{+}$. Prove that the sesquilinear form $\left(\xi,\eta\right)\mapsto \iprod{T\left(\xi\right)}{\eta}$ is a semi-inner product. Using the Cauchy--Schwarz inequality, show that
  \begin{align*}
    \norm{T\left(\xi\right)}^2 &\leq \iprod{T\left(\xi\right)}{\xi}^{1/2} \iprod{T^3\left(\xi\right)}{\xi}^{1/2}.
  \end{align*}
\end{exercise}
\begin{solution}
  Let $F: \mathcal{H}\rightarrow \mathcal{H}$ be defined by $\left(x,y\right) \rightarrow \iprod{T\left(x\right)}{y}$. We have
  \begin{align*}
    F\left(\lambda x_1 + \mu x_2,y\right) &= \iprod{T\left(\lambda x_1 + \mu x_2\right)}{y}\\
                                          &= \iprod{T\left(\lambda x_1\right) + T\left(\mu x_2\right)}{y}\\
                                          &= \lambda \iprod{T\left(x_1\right)}{y} + \mu \iprod{T\left(x_2\right)}{y}\\
                                          &= \lambda F\left(x_1,y\right) + \mu F\left(x_2,y\right)\\
                                          \\
    F\left(x,y\right) &= \iprod{T\left(x\right)}{y}\\
                      &= \overline{ \iprod{y}{T\left(x\right)} }\\
                      &= \overline{ \iprod{T^{\ast}\left(y\right)}{x} }\\
                      &= \overline{ \iprod{T\left(y\right)}{x} }\\
                      &= \overline{F\left(y,x\right)}\\
                      \\
    F\left(x,x\right) &= \iprod{T\left(x\right)}{x}\\
                      &\geq 0.
  \end{align*}
  Thus, $F$ is a semi-inner product.\newline

  We use the Cauchy--Schwarz inequality on $F$ to find
  \begin{align*}
    F\left(T\left(\xi\right),\xi\right) &\leq F\left(\xi,\xi\right)^{1/2}F\left(T\left(\xi\right),T\left(\xi\right)\right)^{1/2}\\
    \iprod{T^2\left(\xi\right)}{\xi} &\leq \iprod{T\left(\xi\right)}{\xi}^{1/2} \iprod{T\left(T\left(\xi\right)\right)}{T\left(\xi\right)}\\
    \norm{T\left(\xi\right)}^2 &\leq \iprod{T\left(\xi\right)}{\xi}^{1/2} \iprod{T^3\left(\xi\right)}{\xi}^{1/2}.
  \end{align*}
  
\end{solution}

\begin{example}
  Given $\lambda = \left(\lambda_n\right)_n\in \ell_{\infty}$, the multiplication operator $D_{\lambda}\in \B\left(\ell_2\right)$ is positive if and only if $\lambda_n\geq 0$ for all $n$. For $\xi = \left(\xi_n\right)_n$, we have
  \begin{align*}
    \iprod{D_{\lambda}\left(\xi\right)}{\xi} &= \sum_{n=1}^{\infty}\lambda_n\left\vert \xi_n \right\vert^2,
  \end{align*}
  which is greater than or equal to zero for $\lambda_n \geq 0$. Conversely, if $D_{\lambda}\in \B\left(\ell_2\right)_{+}$, then $ \iprod{D_{\lambda}\left(e_n\right)}{e_n} = \lambda_n \geq 0 $ for all $n\geq 1$.\newline

  Similarly, if $f\in L_{\infty}\left(\Omega,\mu\right)$, then the multiplication operator $M_{f}\in \B\left(L_{2}\left(\Omega,\mu\right)\right)$ is positive if and only if $f(x)\geq 0$ $\mu$-a.e.
\end{example}
\begin{example}
  If $M\subseteq \mathcal{H}$ is a closed subspace, and $P_{M}\in \B\left(\mathcal{H}\right)$ is the orthogonal projection, then $P_M \geq 0$. This is because
  \begin{align*}
    \iprod{P_M(x)}{x} &= \iprod{P_M(x)}{P_M(x)}\\
                      &= \norm{P_M(x)}^2\\
                      &\geq 0.
  \end{align*}
\end{example}
\begin{proposition}
  The positive operators $\B\left(\mathcal{H}\right)_{+}$ form a WOT-closed cone in $\B\left(\mathcal{H}\right)_{\sa}$. Thus, $\B\left(\mathcal{H}\right)_{+}$ is SOT-closed and norm-closed.\footnote{The positive operators, as well as self-adjoint operators, are convex.}
\end{proposition}
\begin{proof}
  Note that $\B\left(\mathcal{H}\right)_{+}\subseteq \B\left(\mathcal{H}\right)_{\sa}$.\newline

  Let $\left(T_{\alpha}\right)_{\alpha}$ be a net in $\B\left(\mathcal{H}\right)_{+}$ converging in WOT to $T\in \B\left(\mathcal{H}\right)$. Thus, we have
  \begin{align*}
    \iprod{T\left(\xi\right)}{\xi} &= \lim_{\alpha} \iprod{T_{\alpha}\left(\xi\right)}{\xi}\\
                                   &\geq 0,
  \end{align*}
  so $T$ is positive.\newline

  To see that $\B\left(\mathcal{H}\right)_{+}$ is a cone, let $T,S\in \B\left(\mathcal{H}\right)$, and let $t\in [0,\infty)$. We see that for any $\xi\in \mathcal{H}$,
  \begin{align*}
    \iprod{\left(T+S\right)\left(\xi\right)}{\xi} &= \iprod{T\left(\xi\right)}{\xi} + \iprod{S\left(\xi\right)}{\xi}\\
                                                  &\geq 0\\
                                                  \\
    \iprod{tT\left(\xi\right)}{\xi} &= t \iprod{T\left(\xi\right)}{\xi}\\
                                    &\geq 0.
  \end{align*}
  Thus, $T+S$ and $tT$ belong to $\B\left(\mathcal{H}\right)_{+}$.\newline

  Suppose $T$ and $-T$ are in $\B\left(\mathcal{H}\right)_{+}$. Then, we have $ \iprod{T\left(\xi\right)}{\xi} \geq 0 $ and $ - \iprod{T\left(\xi\right)}{\xi} \geq 0 $, so $ \iprod{T\left(\xi\right)}{\xi} = 0 $ for every $\xi \in \mathcal{H}$, meaning $\nu\left(T\right) = 0$. Since $T$ is self-adjoint, we have $\norm{T}_{\text{op}} = 0$.
\end{proof}
We can now define an ordering on the space of self-adjoint operators.
\begin{definition}
  Let $\mathcal{H}$ be a Hilbert space, and suppose $S,T\in \B\left(\mathcal{H}\right)_{\sa}$. We have $T\leq S$ if and only if $S-T\in \B\left(\mathcal{H}\right)$, which is true if and only if $ \iprod{T\left(\xi\right)}{\xi} \leq \iprod{S\left(\xi\right)}{\xi} $ for all $\xi \in \mathcal{H}$.
\end{definition}
\begin{remark}
  This ordering is generally not well-behaved. For instance, the product of positive operators is not necessarily positive, and it is not necessarily the case that $S\leq T$ implies $S^2 \leq T^2$.
\end{remark}
\begin{proposition}
  Let $\mathcal{H}$ and $\mathcal{K}$ be Hilbert spaces.
  \begin{enumerate}[(1)]
    \item If $T\in \B\left(\mathcal{H},\mathcal{K}\right)$, then $T^{\ast}T \geq 0$.
    \item If $T\geq 0$, then $W^{\ast}TW \geq 0$ For all $W\in \B\left(\mathcal{H}\right)$.
    \item If $S\leq T$ in $\B\left(\mathcal{H}\right)_{\sa}$, then $W^{\ast}SW \leq W^{\ast}TW$ for all $W\in \B\left(\mathcal{H}\right)$.
    \item If $0 \leq S \leq T$, then $\norm{S}_{\text{op}} \leq \norm{T}_{\text{op}}$.
    \item If $T$ is positive, then $T\leq I$ if and only if $\norm{T}_{\text{op}}\leq 1$.
    \item If $T$ is self-adjoint and $r\geq 0$, then $-rI \leq T \leq rI$ if and only if $\norm{T}_{\text{op}} \leq r$.
    \item For $T$ self-adjoint, we have $-\norm{T}_{\text{op}}I \leq T \leq \norm{T}_{\text{op}}I$, meaning $I$ is an order unit for $\B\left(\mathcal{H}\right)_{\sa}$, and $\norm{T}_{\text{op}} = \inf\set{r | -rI \leq T \leq rI}$.
  \end{enumerate}
\end{proposition}
\begin{proof}\hfill
  \begin{enumerate}[(1)]
    \item Given $\xi\in \mathcal{H}$, we have $ \iprod{T^{\ast}T\left(\xi\right)}{\xi} = \iprod{T\left(\xi\right)}{T\left(\xi\right)} = \norm{T\left(\xi\right)}^2 \geq 0 $.
    \item For $\xi\in \mathcal{H}$ and $W\in \B\left(\mathcal{H}\right)$, we have $ \iprod{W^{\ast}TW\left(\xi\right)}{\xi} = \iprod{T\left(W\left(\xi\right)\right)}{\xi} \geq 0$.
    \item If $S\leq T$, then $T - S \geq 0$, so $W^{\ast}TW - W^{\ast}SW = W^{\ast}\left(S-T\right)W \geq 0$.
    \item Let $0 \leq S \leq T$. Then,
      \begin{align*}
        \norm{S}_{\text{op}} &= \sup_{\xi\in B_{\mathcal{H}}} \iprod{S\left(\xi\right)}{\xi}\\
                             &\leq \sup_{\xi\in B_{\mathcal{H}}} \iprod{T\left(\xi\right)}{\xi}\\
                             &= \norm{T}_{\text{op}}.
      \end{align*}
    \item If $0 \leq T \leq I$, then $\norm{T}_{\text{op}}\leq \norm{I}_{\text{op}}$. Conversely, if $T\geq 0$ and $\norm{T}_{\text{op}}\leq 1$, then for $\xi\in \B\left(\mathcal{H}\right)$,
      \begin{align*}
        \iprod{I\left(\xi\right)}{\xi} &= \iprod{\xi}{\xi}\\
                                       &\leq \norm{\xi}^2\\
                                       &= 1\\
                                       &\geq \norm{T}_{\text{op}}\\
                                       &= \sup_{\xi\in \B\left(\mathcal{H}\right)} \iprod{T\left(\xi\right)}{\xi}.
      \end{align*}
    \item We have
      \begin{align*}
        -rI \leq T \leq rI &\Leftrightarrow \iprod{-r\xi}{\xi} \leq \iprod{T\left(\xi\right)}{\xi} \leq \iprod{r\xi}{\xi}\\
                           &\Leftrightarrow -r \leq \iprod{T\left(\xi\right)}{\xi} \leq r\\
                           &\Leftrightarrow \left\vert \iprod{T\left(\xi\right)}{\xi} \right\vert \leq r\\
                           &\Leftrightarrow \nu\left(T\right)\leq r\\
                           &\Leftrightarrow \norm{T}_{\text{op}}\leq r.
      \end{align*}
    \item Follows directly from (6).
  \end{enumerate}
\end{proof}
\begin{exercise}
  If $S,T\in \B\left(\mathcal{H}\right)$ are such that $S^{\ast}S\leq T^{\ast}T$, show that $\ker\left(T\right) \subseteq \ker\left(S\right)$.
\end{exercise}
\begin{solution}
  We are aware that $S^{\ast}S\leq T^{\ast}T$ if and only if for all $\xi$, $ \iprod{S^{\ast}S\left(\xi\right)}{\xi} \leq \iprod{T^{\ast}T\left(\xi\right)}{\xi} $, meaning $\norm{S\left(\xi\right)}^2 \leq \norm{T\left(\xi\right)}^2$.\newline

  Thus, if $\xi \in \ker\left(T\right)$, then $\norm{S\left(\xi\right)}^2 = 0$, so $S\left(\xi\right) = 0$, so $\xi \in \ker\left(S\right)$.
\end{solution}
\begin{proposition}[Douglas Factorization]
  Let $S,T\in \B\left(\mathcal{H}\right)$ be such that $S^{\ast}S\leq T^{\ast}T$. Then, there is a contraction $R\in \B\left(\mathcal{H}\right)$ such that $RT = S$.
\end{proposition}
\begin{proof}
  We see the map $R_0: \Ran\left(T\right)\rightarrow \Ran\left(S\right)$ defined by $R_0\left(T\left(x\right)\right) = S\left(x\right)$ is well-defined and linear. Additionally,
  \begin{align*}
    \norm{R_0\left(T\left(x\right)\right)}^2 &= \norm{S\left(x\right)}^2\\
                                             &= \iprod{S(x)}{S(x)}\\
                                             &= \iprod{S^{\ast}S\left(x\right)}{x}\\
                                             &\leq \iprod{T^{\ast}T\left(x\right)}{x}\\
                                             &= \iprod{T\left(x\right)}{T\left(x\right)}\\
                                             &= \norm{T\left(x\right)}^2,
  \end{align*}
  meaning $R_0$ is contractive.\newline

  We can extend $R_0$ continuously to $R_1: \overline{\Ran}\left(T\right)\rightarrow \mathcal{H}$. Define $R: \mathcal{H}\rightarrow \mathcal{H}$ by the direct sum decomposition $R\left(x+y\right) = R_1\left(x\right)$, where $x\in \overline{\Ran}\left(T\right)$ and $y\in \overline{\Ran}\left(T\right)^{\perp}$.\footnote{It is the case that $\ker\left(T^{\ast}\right) = \overline{\Ran}\left(T\right)$.}
\end{proof}
\begin{proposition}
  Let $\mathcal{H}$ be a Hilbert space, and let $\left(T_{\alpha}\right)_{\alpha}$ be a norm-bounded increasing net in $\B\left(\mathcal{H}\right)_{\sa}$. Then, there is $T\in \B\left(\mathcal{H}\right)_{\sa}$ such that $T = \lim_{\alpha}T_{\alpha}$ in SOT, and $\sup_{\alpha}T_{\alpha} = T$.
\end{proposition}
\begin{proof}
  Set $C = \sup_{\alpha}\norm{T_{\alpha}}_{\text{op}}$.\newline

  For $\xi\in \mathcal{H}$, we see that $ \left( \iprod{T_{\alpha}\left(\xi\right)}{\xi}\right)_{\alpha}$ is a bounded increasing net in $\R$, since
  \begin{align*}
    \left\vert \iprod{T_{\alpha}\left(\xi\right)}{\xi} \right\vert &\leq \norm{T_{\alpha}}_{\text{op}}\norm{\xi}^2\\
                                                                   &\leq C\norm{\xi}^2,
  \end{align*}
  and is increasing by the definition of the ordering on $\B\left(\mathcal{H}\right)_{\sa}$. Thus, this net is convergent in $\R$. \newline

  Since $\left(\xi,\eta\right)\mapsto \iprod{T_{\alpha}\left(\xi\right)}{\eta}$ is a sesquilinear form, we may use the polarization identity to write
  \begin{align*}
    F\left(\xi,\eta\right) &= \lim_{\alpha} \left( \sum_{k=0}^{3}i^{k} \iprod{T_{\alpha}\left(\xi + i^k\eta\right)}{\xi + i^{k}\eta}\right),
  \end{align*}
  which defines a sesquilinear form with
  \begin{align*}
    \left\vert F\left(\xi,\eta\right) \right\vert &= \left\vert \lim_{\alpha} \iprod{T_{\alpha}\left(\xi\right)}{\eta} \right\vert\\
                                                  &\leq C\norm{\xi}\norm{\eta}.
  \end{align*}
  Thus, there is a unique $T\in \B\left(\mathcal{H}\right)$ with $F\left(\xi,\eta\right) = \iprod{T\left(\xi\right)}{\eta}$, and $\norm{T}_{\text{op}} = \norm{F}_{\text{op}} \leq C$. By our definition of $F$, we have $\left(T_{\alpha}\right)_{\alpha}\xrightarrow{\text{WOT}} T$, and $T^{\ast} = T$.\newline

  Since $\sup_{\alpha} \iprod{T_{\alpha}\left(\xi\right)}{\xi} = \iprod{T\left(\xi\right)}{\xi}$ for each $\xi\in \mathcal{H}$, we see that $T_{\alpha}\leq T$ for every $\alpha$, and no lesser $S\in \B\left(\mathcal{H}\right)_{\sa}$ has this property. Thus, $\sup_{\alpha}T_{\alpha} = T$.\newline

  Finally, we must show that $\left(T_{\alpha}\right)_{\alpha}\xrightarrow{\text{SOT}}T$. If $\alpha_0$ is fixed in the indexing set, and $\alpha \geq \alpha_0$, then we have $0 \leq T - T_{\alpha}\leq T - T_{\alpha_0}$, so $\norm{T - T_{\alpha}}_{\text{op}}\leq \norm{T - T_{\alpha_0}}_{\text{op}}$. Thus, we have
  \begin{align*}
    \norm{\left(T - T_{\alpha}\right)\left(\xi\right)}^2 &\leq \iprod{\left(T - T_{\alpha}\right)\left(\xi\right)}{\xi}^{1/2} \iprod{\left(T - T_{\alpha}\right)^3\left(\xi\right)}{\xi}^{1/2}\\
                                                         &\leq \iprod{\left(T - T_{\alpha}\right)\xi}{\xi}^{1/2}\norm{T - T_{\alpha}}_{\text{op}}^{3/2}\norm{\xi}\\
                                                         &\leq \iprod{\left(T-T_{\alpha}\right)\left(\xi\right)}{\xi} \norm{T - T_{\alpha_0}}_{\text{op}}^{3/2}\norm{\xi}\\
                                                         &\rightarrow 0.
  \end{align*}
  Thus, $\left(T_{\alpha}\right)_{\alpha}\xrightarrow{\text{SOT}}T$.
\end{proof}
\subsection{Special Classes of Operators}%
\begin{lemma}
  Let $\mathcal{H},\mathcal{K}$ be Hilbert spaces. For any bounded operator $T \in \B\left(\mathcal{H},\mathcal{K}\right)$, the following are true.
  \begin{enumerate}[(1)]
    \item $\ker\left(T^{\ast}\right) = \Ran\left(T\right)^{\perp}$
    \item $\ker\left(T\right) = \Ran\left(T^{\ast}\right)^{\perp}$
    \item $\ker\left(T\right)^{\perp} = \overline{\Ran}\left(T^{\ast}\right)$
    \item $\ker\left(T^{\ast}\right)^{\perp} = \overline{\Ran}\left(T\right)$
  \end{enumerate}
\end{lemma}
\begin{proof}\hfill
  \begin{enumerate}[(1)]
    \item For $y\in \mathcal{K}$, we have, for all $x\in \mathcal{H}$,
      \begin{align*}
        T^{\ast}\left(y\right) = - &\Leftrightarrow \iprod{x}{T^{\ast}\left(y\right)} = 0\\
                                   &\Leftrightarrow \iprod{T\left(x\right)}{y} = 0\\
                                   &\Leftrightarrow y\in \Ran\left(T\right)^{\perp}.
      \end{align*}
    \item Apply (1) to $T^{\ast}$.
    \item Taking orthogonal complements, we get
      \begin{align*}
        \ker\left(T\right)^{\perp} &= \left(\Ran\left(T^{\ast}\right)^{\perp}\right)^{\perp}\\
                                   &= \overline{\Ran}\left(T^{\ast}\right).
      \end{align*}
    \item Apply (3) to $T^{\ast}$.
  \end{enumerate}
\end{proof}
\subsubsection{Normal Operators}%
Recall from linear algebra that a square matrix $a\in \Mat_{n}\left(\C\right)$ is called normal if $a^{\ast}a = aa^{\ast}$. These matrices are unitarily diagonalizable, which we studied in linear algebra. However, we can define normal operators in any $\ast$-algebras.
\begin{definition}
  Let $\mathcal{H}$ be a Hilbert space. A bounded operator $T\in \B\left(\mathcal{H}\right)$ is called normal if $TT^{\ast} = T^{\ast}T$.
\end{definition}
\begin{example}\hfill
  \begin{enumerate}[(1)]
    \item All self-adjoint operators are normal, as are all positive operators and orthogonal projections.
    \item The right shift operator $R: \ell_2\rightarrow \ell_2$ is not normal, since $RR^{\ast} \neq I$ and $R^{\ast}R = I$. Similarly, the left shift operator is not normal.
    \item The multiplication operator $D_{\lambda}:\ell_2\rightarrow \ell_2$, where $\lambda \in \ell_{\infty}$, is normal. This is because all multiplication operators commute. Similarly, the multiplication operators $M_{f}\in \B\left(L_{2}\left(\Omega,\mu\right)\right)$ with $f\in L_{\infty}\left(\Omega,\mu\right)$, are also normal.
  \end{enumerate}
\end{example}
\begin{lemma}
  A bounded operator $T\in \B\left(\mathcal{H}\right)$ is normal if and only if, for all $x\in \mathcal{H}$,
  \begin{align*}
    \norm{T\left(x\right)} &= \norm{T^{\ast}\left(x\right)}.
  \end{align*}
\end{lemma}
\begin{proof}
  For all $x\in \mathcal{H}$, we have
  \begin{align*}
    \norm{T(x)} = \norm{T^{\ast}\left(x\right)} &\Leftrightarrow \norm{T\left(x\right)}^2 = \norm{T^{\ast}\left(x\right)}^2\\
                                                &\Leftrightarrow \iprod{T\left(x\right)}{T\left(x\right)} = \iprod{T^{\ast}\left(x\right)}{T^{\ast}\left(x\right)}\\
                                                &\Leftrightarrow \iprod{T^{\ast}T\left(x\right)}{x} = \iprod{TT^{\ast}\left(x\right)}{x}\\
                                                &\Leftrightarrow T^{\ast}T = TT^{\ast}.
  \end{align*}
\end{proof}
\begin{exercise}
  Prove that the adjoint map is SOT-continuous on the set of normal operators.
\end{exercise}
\begin{solution}
  Let $\left(T_{\alpha}\right)_{\alpha} \xrightarrow{\text{SOT}} T$. Then,
  \begin{align*}
    \norm{\left(T_{\alpha}^{\ast}- T^{\ast}\right)\left(x\right)} &= \norm{\left(T_{\alpha} - T\right)^{\ast}\left(x\right)}\\ 
                                                               &\norm{\left(T_{\alpha} - T\right)\left(x\right)}\\
                                                               &\rightarrow 0.
  \end{align*}
\end{solution}
We know that the numerical radius coincides with the operator norm for self-adjoint operators. The same holds for normal operators.
\begin{exercise}
  If $T\in \B\left(\mathcal{H}\right)$ is normal, prove that $\nu\left(T\right) = \norm{T}_{\text{op}}$.
\end{exercise}
\begin{solution}\hfill
  \begin{enumerate}[(i)]
    \item From the same property on the sesquilinear form $F\left(x,y\right) = \iprod{T\left(x\right)}{y}$, we can see that
      \begin{align*}
        \left\vert \iprod{T\left(x\right)}{x} \right\vert &\leq \norm{T}\norm{x}^2,
      \end{align*}
      so $\nu\left(T\right)\leq \norm{T}$.
    \item We have, for every $x\in B_{\mathcal{H}}$, that
      \begin{align*}
        \left\vert \iprod{T\left(x\right)}{x} \right\vert &\leq \nu\left(T\right).
      \end{align*}
      For $y = \norm{y} x$, we scale both sides to get
      \begin{align*}
        \left\vert \iprod{T\left(y\right)}{y} \right\vert &\leq \norm{y}^2 \nu\left(T\right).
      \end{align*}
    \item Letting $F\left(x,y\right) = \iprod{T\left(x\right)}{y}$, we have
      \begin{align*}
        4F\left(x,y\right) + 4F\left(y,x\right) &= \left(F\left(x + y,x+y\right) + i F\left(x+iy,x+iy\right) - F\left(x-y,x-y\right) - iF\left(x-iy,x-iy\right)\right)\\
                                              &+ \left(F\left(y+x\right) + iF\left(y+ix,y+ix\right)-F\left(y-x,y-x\right) - iF\left(y-ix,y-ix\right)\right)\\
                                              &= 2\left(F\left(x+y\right) - F\left(x-y\right)\right),
      \end{align*}
      yielding
      \begin{align*}
        \frac{1}{2}\re\left(F\left(x,y\right) + F\left(y,x\right)\right) &= \frac{1}{4}\re\left(F\left(x+y\right)-F\left(x-y\right)\right).
      \end{align*}
    \item 
      \begin{align*}
        \frac{1}{4}\re\left( \iprod{T\left(x+y\right)}{x+y} - \iprod{T\left(x-y\right)}{x-y}\right) &\leq \frac{1}{4}\left\vert \iprod{T\left(x+y\right)}{x+y} - \iprod{T\left(x-y\right)}{x-y} \right\vert\\
                                                                                                    &\leq \frac{1}{4}\left(\left\vert \iprod{T\left(x+y\right)}{x+y} \right\vert + \left\vert \iprod{T\left(x-y\right)}{x-y} \right\vert\right)\\
                                                                                                    &\leq \frac{1}{4}\left\vert \nu\left(T\right)\norm{x+y}^2 + \nu\left(T\right)\norm{x-y}^2 \right\vert\\
                                                                                                    &\leq \frac{1}{4}\left(\nu\left(T\right) \left(2\norm{x}^2 + 2\norm{y}^2\right)\right)\\
                                                                                                    &\leq \nu\left(T\right).
      \end{align*}
      Setting $y = \frac{T\left(x\right)}{\norm{T\left(x\right)}}$, we get
      \begin{align*}
        \frac{1}{2}\re\left( \iprod{T\left(x\right)}{\frac{T\left(x\right)}{\norm{T\left(x\right)}}} + \iprod{T\left(\frac{T\left(x\right)}{\norm{T\left(x\right)}}\right)}{x}\right) &= \frac{1}{2}\re\left(\norm{T\left(x\right)} + \frac{1}{\norm{T\left(x\right)}}\iprod{T^2\left(x\right)}{x}\right)\\
                                                                                                                                                                                                                         &= \frac{1}{2}\norm{T(x)} + \frac{1}{2}\left(\frac{1}{\norm{T\left(x\right)}} \re\left( \iprod{T^2\left(x\right)}{x}\right)\right)\\
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       &\leq \nu\left(T\right)
      \end{align*}
      Thus, we recover
      \begin{align*}
        \norm{T(x)} + \frac{1}{\norm{T\left(x\right)}}\re\left( \iprod{T^2\left(x\right)}{x}\right) &\leq 2\nu\left(T\right).
      \end{align*}
    \item Let $\omega$ be such that $\omega^2 = \sgn\left( \iprod{T^2\left(x\right)}{x}\right)$. Then, we have
      \begin{align*}
        \norm{\omega T\left(x\right)} + \frac{1}{\norm{\omega T\left(x\right)}} \re\left( \iprod{\left(\omega T\right)^2\left(x\right)}{x}\right) &= \norm{T\left(x\right)} + \frac{1}{\norm{T\left(x\right)}}\re\left(\omega^2 \iprod{T\left(x\right)}{x}\right)\\
                        &= \norm{T\left(x\right)} + \frac{1}{\norm{T\left(x\right)}}\re\left( \left\vert \iprod{T\left(x\right)}{x} \right\vert\right)\\
                              &= \norm{T\left(x\right)} + \frac{1}{\norm{T\left(x\right)}} \left\vert \iprod{T\left(x\right)}{x} \right\vert\\
                              &\leq 2\nu\left(\omega T\right)\\
                              &= 2\nu\left(T\right).
      \end{align*}
    \item We have
      \begin{align*}
        \norm{T\left(x\right)} &\leq \norm{T\left(x\right)} + \frac{1}{\norm{T\left(x\right)}} \left\vert \iprod{T^2\left(x\right)}{x} \right\vert\\
                               &\leq 2\nu\left(T\right)
      \end{align*}
      for all $x\in B_{\mathcal{H}}$, meaning
      \begin{align*}
        \norm{T} &\leq 2\nu\left(T\right).
      \end{align*}
      Additionally, for $x\neq 0$, we have
      \begin{align*}
        \norm{T\left(x\right)}^2 + \left\vert \iprod{T^2\left(x\right)}{x} \right\vert &\leq 2\nu\left(T\right)\norm{T\left(x\right)},
      \end{align*}
      so taking the supremum on both sides, we get
      \begin{align*}
        \norm{T}^2 + \nu\left(T^2\right) &\leq 2\nu\left(T\right)\norm{T}.
      \end{align*}
    \item We have
      \begin{align*}
        \left(\norm{T} - \nu\left(T\right)\right)^2 &\geq 0\\
        \norm{T}^2 + \nu\left(T\right)^2 &\geq 2\nu\left(T\right)\\
                                         &\geq \norm{T}^2 + \nu\left(T^2\right),
      \end{align*}
      so
      \begin{align*}
        \nu\left(T^2\right) &\leq \nu\left(T\right)^2.
      \end{align*}
      Inductively, we have
      \begin{align*}
        \nu\left(T^{2^n}\right) &\leq \nu\left(T^{2^{n-1}}\right)^2,
      \end{align*}
      giving
      \begin{align*}
        \nu\left(T^{2^{n}}\right) &\leq \nu\left(T\right)^{2^n}.
      \end{align*}
    \item Let $T$ be normal. Then, $A = T^{\ast}T$ is self-adjoint, so $\norm{A}^2 = \norm{A^{\ast}A} = \norm{A^2}$. Additionally, since $T^{\ast}T = TT^{\ast}$, we have $\left(T^{\ast}T\right)^{2^n} = \left(T^{\ast}\right)^{2^n}T^{2^n}$. Combining, this gives
      \begin{align*}
        \norm{T}^{2^n} &= \left(\norm{T^{\ast}T}^{2^n}\right)^{1/2}\\
                       &= \norm{\left(T^{\ast}T\right)^{2^n}}^{1/2}\\
                       &= \norm{\left(T^{\ast}\right)^{2^n}T^{2^n}}^{1/2}\\
                       &= \norm{\left(T^{2^n}\right)^{\ast}T^{2^n}}^{1/2}\\
                       &= \norm{T^{2^n}}.
      \end{align*}
      Thus, we see that
      \begin{align*}
        \left(\nu\left(T\right)\right)^{2^n} &\leq \norm{T}^{2^n}\\
                                             &= \norm{T^{2^n}}\\
                                             &\leq 2\nu\left(T^{2^n}\right)\\
                                             &\leq 2\nu\left(T\right)^{2^n}.
      \end{align*}
      Taking roots and sending $n\rightarrow\infty$, we see that
      \begin{align*}
        \norm{T}\leq \nu\left(T\right),
      \end{align*}
      establishing $\nu\left(T\right) = \norm{T}$.
  \end{enumerate}
\end{solution}

%\begin{proof}
%  We know that $T^{\ast}T =  TT^{\ast} = \left(T^{\ast}T\right)^{\ast}$, meaning
%  \begin{align*}
%    \nu\left(T^{\ast}T\right) &= \norm{T^{\ast}T}\\
%                              &= \norm{T}^2.
%  \end{align*}
%\end{proof}
\begin{proposition}
  Let $\mathcal{H}$ be a Hilbert space, and suppose $T\in \B\left(\mathcal{H}\right)$ is normal. The following are true.
  \begin{enumerate}[(1)]
    \item $\ker\left(T\right) = \ker\left(T^{\ast}\right) = \left(\Ran\left(T\right)\right)^{\perp}$.
    \item $T$ is injective if and only if $\Ran\left(T\right)\subseteq \mathcal{H}$ is dense.
    \item $T$ is invertible if and only if $T$ is bounded below.
  \end{enumerate}
\end{proposition}
\begin{proof}\hfill
  \begin{enumerate}[(1)]
    \item Since $\norm{T} = \norm{T^{\ast}}$ and $\ker\left(T^{\ast}\right) = \left(\Ran\left(T\right)\right)^{\perp}$, we know that $\ker\left(T\right) = \ker\left(T^{\ast}\right) = \left(\Ran\left(T\right)\right)^{\perp}$.
    \item We see that $T$ is injective if and only if $\ker\left(T\right) = \set{0}$, which is true if and only if $\ker\left(T\right)^{\perp} = \mathcal{H}$, so $\left(\Ran\left(T\right)^{\perp}\right)^{\perp} = \mathcal{H}$, so $\overline{\Ran}\left(T\right) = \mathcal{H}$.
    \item We know that an invertible operator on a Banach space is always bounded below. If $T$ is bounded below, then $T$ is injective and has closed range. Since $T$ is assumed to be normal, its range is dense as well, so $\Ran\left(T\right) = \overline{\Ran}\left(T\right) = \mathcal{H}$.
  \end{enumerate}
\end{proof}
A linear operator fails to be invertible if it has a non-trivial kernel --- however, the converse is false. However, if $T$ is normal, then $T$ is non-invertible if it admits an approximate kernel.
\begin{corollary}
  Let $\mathcal{H}$ be a Hilbert space. A normal operator $T\in \B\left(\mathcal{H}\right)$ is noninvertible if and only if there is a sequence $\left(\xi_n\right)_n$ in $\mathcal{H}$ with $\norm{\xi_n} = 1$ and $\lim_{n\rightarrow\infty}\norm{T\left(\xi_n\right)}=0$.
\end{corollary}
\begin{proof}
  Such a sequence exists if and only if $T$ is not bounded below.
\end{proof}
\subsubsection{Isometric and Unitary Operators}%
\begin{lemma}
  Let $\mathcal{H}$ and $\mathcal{K}$ be Hilbert spaces and suppose $U,V\in \B\left(\mathcal{H},\mathcal{K}\right)$.
  \begin{enumerate}[(1)]
    \item $V$ is an isometry if and only if $V^{\ast}V = I_{\mathcal{H}}$.
    \item $U$ is a unitary if and only if $U^{\ast}U = I_{\mathcal{H}}$ and $UU^{\ast} = I_{\mathcal{K}}$.
  \end{enumerate}
\end{lemma}
\begin{proof}
  For $\xi\in \mathcal{H}$, we have
  \begin{align*}
    \norm{V\left(\xi\right)}^2 &= \iprod{V\left(\xi\right)}{V\left(\xi\right)}\\
                               &= \iprod{V^{\ast}V\left(\xi\right)}{\xi}.
  \end{align*}
  If $V^{\ast}V = I_{\mathcal{H}}$, then 
  \begin{align*}
    \norm{V\left(\xi\right)} &= \iprod{V^{\ast}V\left(\xi\right)}{\xi}\\
                             &= \iprod{\xi}{\xi}\\
                             &= \norm{\xi}^2,
  \end{align*}
  meaning $V$ is an isometry. Similarly, if $V$ is isometric, then $\norm{\xi}^2 = \norm{V\left(\xi\right)}^2 = \iprod{V^{\ast}V\left(\xi\right)}{\xi}$, so $V^{\ast}V = I_{\mathcal{H}}$.\newline

  A similar proof shows that $U$ is unitary if and only if $U^{\ast}U = I_{\mathcal{H}}$ and $UU^{\ast} = I_{\mathcal{K}}$.
\end{proof}
\begin{example}
  The left bilateral shift on $\ell_2\left(\Z\right)$ is defined by $U\left(\xi\right)\left(n\right) = \xi\left(n+1\right)$ for $n\in \Z$. This is a well-defined operator, since $U\left(\xi\right)\in \ell_2\left(\Z\right)$ for $\xi \in \ell_2\left(\Z\right)$, as
  \begin{align*}
    \norm{U\left(\xi\right)}^2 &= \sum_{n\in \Z}\left\vert U\left(\xi\right)\left(n\right) \right\vert^2\\
                               &= \sum_{n\in \Z}\left\vert \xi\left(n+1\right) \right\vert^2\\
                               &= \sum_{m\in \Z}\left\vert \xi\left(m\right) \right\vert^2\\
                               &= \norm{\xi}^2.
  \end{align*}
  We also see that $U$ is an isometry, as $U^{\ast}U = I$. We see that $U\left(e_k\right) = e_{k-1}$ for all $k\in \Z$, where $\left(e_k\right)_{k\in \Z}$ is the canonical orthonormal basis for $\ell_2\left(\Z\right)$.\newline

  We may also define the right bilateral shift operator by $V\left(\xi\right)\left(n\right) = \xi\left(n-1\right)$. We have $V\left(e_k\right) = e_{k+1}$. We have $UV = I$ and $VU = I$, so
  \begin{align*}
    V &= IV\\
      &= \left(U^{\ast}U\right)V\\
      &= U^{\ast}\left(UV\right)\\
      &= U^{\ast}\left(I\right)\\
      &= U^{\ast},
  \end{align*}
  so $U^{\ast}U = UU^{\ast} = V^{\ast}V = VV^{\ast} = I$, so the bilateral shifts are unitary.
\end{example}
\begin{example}
  The right and left unilateral shifts $R,L: \ell_2\rightarrow \ell_2$ are nonunitary isometries, since $R^{\ast}R = LL^{\ast} = I$, but $R^{\ast}R = L^{\ast}L \neq I$.
\end{example}
\begin{exercise}
  Show that the multiplication operator $D_{\lambda}$ associated to $\left(\lambda_n\right)_n\in \ell_{\infty}$ is unitary if and only if $\left\vert \lambda_n \right\vert = 1$ for all $n$.\newline

  Show that the multiplication operator $M_{f}$ on $L_2\left(\Omega,\mu\right)$ associated to $f\in L_{\infty}\left(\Omega,\mu\right)$ is unitary if and only if $\left\vert f \right\vert = 1$ $\mu$-a.e.
\end{exercise}
\begin{solution}
  Let $D_{\lambda}$ be unitary. Then, $D_{\lambda}^{\ast} D_{\lambda} = D_{\lambda}D_{\lambda}^{\ast} = I$. Thus, we have
  \begin{align*}
    \iprod{D_{\lambda}D_{\lambda}^{\ast}\left(\xi\right)}{\xi} &= \sum_{n\in \N}\left\vert \lambda_n\xi_n \right\vert^2\\
                                                               &= \sum_{n\in \N}\left\vert \lambda_n \right\vert^2 \left\vert \xi_n \right\vert\\
                                                               &= \sum_{n\in \N}\left\vert \xi_n \right\vert^2,
  \end{align*}
  which holds if and only if $\left\vert \lambda_n \right\vert^2 = 1$, or $\left\vert \lambda_n \right\vert = 1$ for each $n$.\newline

  Similarly, if $\left\vert \lambda_n \right\vert = 1$ for each $n$, then we have
  \begin{align*}
    \iprod{D_{\lambda}^{\ast}D_{\lambda}\left(\xi\right)}{\xi} &= \sum_{n\in \N}\left\vert \lambda_n \right\vert^2\left\vert \xi_n \right\vert^2\\
                                                               &= \sum_{n\in \N}\left\vert \xi_n \right\vert^2\\
                                                               &= \iprod{D_{\lambda}^{\ast}D_{\lambda}\left(\xi\right)}{\xi},
  \end{align*}
  meaning $D_{\lambda}^{\ast}D_{\lambda} = D_{\lambda}D_{\lambda}^{\ast}=I$.\newline

  Similarly, if $M_f$ is unitary, then
  \begin{align*}
    \iprod{M_f^{\ast}M_f\left(\xi\right)}{\xi} &= \iprod{M_fM_f^{\ast}\left(\xi\right)}{\xi}\\
                                               &= \int_{\Omega}^{} \left\vert f \right\vert^2\left\vert \xi \right\vert^2\:d\mu\\
                                               &= \int_{\Omega}^{} \left\vert \xi \right\vert^2\:d\mu,
  \end{align*}
  which holds if and only if $\left\vert f \right\vert^2 = 1$ $\mu$-a.e., meaning $\left\vert f \right\vert = 1$ $\mu$-a.e.\newline

  If $\left\vert f \right\vert = 1$ $\mu$-a.e., then $\left\vert f \right\vert^2 = 1$ $\mu$-a.e. We have
  \begin{align*}
    \int_{\Omega}^{} \left\vert f \right\vert^2\left\vert \xi \right\vert^2\:d\mu &= \iprod{M_f^{\ast}M_f\left(\xi\right)}{\xi}\\
                                                                                  &= \iprod{M_fM_f^{\ast}\left(\xi\right)}{\xi},
  \end{align*}
  meaning $M_fM_f^{\ast} = M_f^{\ast}M_f = I$.
\end{solution}
\begin{exercise}
  Let $\omega\in \mathbb{T}$. Consider the sequence $\left(\omega^n\right)_n\in \ell_{\infty}$. We know that the multiplication operator $d_{\omega} = D_{\left(\omega^n\right)_n}$ is unitary. If $R$ denotes the right shift operator, show that
  \begin{align*}
    d_\omega R &= \omega R d_{\omega}.
  \end{align*}
  Similarly, if $\left(\omega^n\right)_{n\in \Z}$ is a multiplier in $\ell_{\infty}\left(\Z\right)$, and $V$ is the right bilateral shift, show that
  \begin{align*}
    d_{\omega}V &= \omega V d_{\omega}.
  \end{align*}
\end{exercise}
\begin{definition}
  Let $\mathcal{H}$ and $\mathcal{K}$ be Hilbert spaces.
  \begin{enumerate}[(1)]
    \item We write $\mathcal{U}\left(\mathcal{H},\mathcal{K}\right)$ to be the set of all unitary operators between $\mathcal{H}$ and $\mathcal{K}$. We say $\mathcal{U}\left(\mathcal{H}\right) = \mathcal{U}\left(\mathcal{H},\mathcal{H}\right)$.
    \item Two operators $T\in \B\left(\mathcal{H}\right)$ and $S\in \B\left(\mathcal{K}\right)$ are said to be unitarily equivalent if there exists $U\in \mathcal{U}\left(\mathcal{H},\mathcal{K}\right)$ such that
      \begin{align*}
        UTU^{\ast} &= S.
      \end{align*}
  \end{enumerate}
\end{definition}
\begin{exercise}
  Let $T\in \B\left(\mathcal{H}\right)$, $S\in \B\left(\mathcal{K}\right)$, and $U\in \mathcal{U}\left(\mathcal{H},\mathcal{K}\right)$. Prove that $\norm{UT}_{\text{op}} = \norm{T}_{\text{op}}$ and $\norm{SU}_{\text{op}} = \norm{S}_{\text{op}}$. Conclude that unitarily equivalent operators have the same norm.
\end{exercise}
\begin{solution}
  We have, for any $x\in B_{\mathcal{H}}$, that
  \begin{align*}
    \norm{UT\left(x\right)}^2 &= \norm{T\left(x\right)}^2,
  \end{align*}
  so
  \begin{align*}
    \norm{UT}_{\text{op}} &= \norm{T}_{\text{op}}.
  \end{align*}
  Similarly, we must have $\norm{SU}_{\text{op}} = \norm{S}_{\text{op}}$. Thus, we must have
  \begin{align*}
    \norm{S}_{\text{op}} &= \norm{UTU^{\ast}}_{\text{op}}\\
                         &= \norm{\left(UT\right)U^{\ast}}_{\text{op}}\\
                                  &= \norm{UT}_{\text{op}}\\
                                  &= \norm{T}_{\text{op}}
  \end{align*}
\end{solution}
\begin{exercise}
  Suppose $U\in \mathcal{H}\left(\mathcal{K}\right)$ is a unitary isomorphism of Hilbert spaces. Prove that conjugation by $U$, $\operatorname{Ad}_{U}\left(T\right) = UTU^{\ast}$ is an isometric $\ast$-isomorphism of $C^{\ast}$-algebras.
\end{exercise}
\begin{fact}[Unitary Group]
If $\mathcal{H}$ is a Hilbert space, then $\mathcal{U}\left(\mathcal{H}\right)$ is a group under composition.
\end{fact}
\begin{proof}
  If $U,V\in \mathcal{U}\left(\mathcal{H}\right)$, then
  \begin{align*}
    \left(UV\right)^{\ast}\left(UV\right) &= V^{\ast}U^{\ast}UV\\
                                          &= V^{\ast}V\\
                                          &= I,
  \end{align*}
  and
  \begin{align*}
    \left(UV\right)\left(UV\right)^{\ast} &= UVV^{\ast}U^{\ast}\\
                                          &= UU^{\ast}\\
                                          &= I,
  \end{align*}
  meaning $UV\in \mathcal{H}$. We have $I$ is the neutral element of $\mathcal{U}\left(\mathcal{H}\right)$, and $U^{\ast} = U^{-1}$ is an element of $\mathcal{U}\left(\mathcal{H}\right)$ for $U\in \mathcal{U}\left(\mathcal{H}\right)$.
\end{proof}
\begin{definition}[Unitary Representation]
  Let $\Gamma$ be a group. A unitary representation of $\Gamma$ is a pair $\left(U,\mathcal{H}\right)$, where $\mathcal{H}$ is a Hilbert space, and $U: \Gamma \rightarrow \mathcal{U}\left(\mathcal{H}\right)$ is a group homomorphism.
\end{definition}
\begin{exercise}
  Let $\mathbb{T}$ be the circle group, and let $d_{\omega}$ be the corresponding multiplication operator on $\ell_{2}\left(\Z\right)$. Show that the map $\omega \xmapsto d_{\omega}$ is a unitary representation.
\end{exercise}
\begin{solution}
  We are aware that $d_{\omega}$ is a unitary operator if $\omega \in \mathbb{T}$. We must now show that the map $\omega \mapsto d_{\omega}$ is a homomorphism.\newline

  To do this, we show that for $\omega,\tau\in \mathbb{T}$, that $\omega\tau^{-1} \mapsto d_{\omega}d_{\tau}^{-1} = d_{\omega}d_{\tau}^{\ast}$. We have
  \begin{align*}
    \left(\omega\tau^{-1}\right) &\mapsto \left(\omega^n\tau^{-n}\right)_{n}\\
                                 &= \left(\omega^n\right)_{n}\left(\tau^{-n}\right)_n\\
                                 &= \left(\omega^n\right)_{n}\left(\overline{\tau}^n\right)_{n}\\
                                 &= d_{\omega}d_{\overline{\tau}}\\
                                 &= d_{\omega}d_{\tau}^{\ast}.
  \end{align*}
  Thus, this is a unitary representation.
\end{solution}
\begin{fact}
  Let $U: \Gamma\rightarrow \mathcal{U}\left(\mathcal{H}\right)$, $s\mapsto U_s$ be a unitary representation of $\Gamma$. Then,
  \begin{enumerate}[(1)]
    \item if $e$ is the neutral element of $\Gamma$, then $U_e = I$;
    \item for all $s\in \Gamma$, $U_{s^{-1}} = U_{s}^{-1} = U_s^{\ast}$.
  \end{enumerate}
\end{fact}
\begin{proof}
  A group homomorphism necessarily preserves identity, which shows (1).\newline

  To see (2), for $s\in \Gamma$, we have
  \begin{align*}
    I &= U_e\\
      &= U_{ss^{-1}}\\
      &= U_sU_s^{-1}\\
      \\
    I &= U_e\\
      &= U_{s^{-1}s}\\
      &= U_{s^{-1}}U_s,
  \end{align*}
  so by the uniqueness of inverses, we have $U_{s^{-1}} = U_s^{-1} = U_s^{\ast}$.
\end{proof}
\begin{example}[Left Regular Representation]
  Let $\Gamma$ be a group with neutral element $e$, and consider the Hilbert space $\ell_2\left(\Gamma\right)$. For every $s\in \Gamma$, we define $\lambda_s: \ell_2\left(\Gamma\right)\rightarrow \ell_2\left(\Gamma\right)$ by
  \begin{align*}
    \lambda_s\left(\xi\right)\left(t\right) &= \xi\left(s^{-1}t\right)
  \end{align*}
  for each $t\in \Gamma$. This map is linear and well-defined, as
  \begin{align*}
    \left\vert \lambda_s\left(\xi\right) \right\vert^2 &= \sum_{t\in \Gamma}\left\vert \lambda_s\left(\xi\right)\left(t\right) \right\vert^2\\
                                                       &= \sum_{t\in \Gamma}\left\vert \xi\left(s^{-1}t\right) \right\vert^2\\
                                                       &= \sum_{r\in \Gamma}\left\vert \xi\left(r\right) \right\vert^2\\
                                                       &= \norm{\xi}^2.
  \end{align*}
  This also shows that $\lambda_s$ is an isometry. Moreover, each $\lambda_s$ has an inverse $\lambda_{s^{-1}}$, so each $\lambda_s$ is unitary with $\lambda_s^{\ast} = \lambda_{s^{-1}}$.\newline

  For the vectors $\set{\delta_t}_{t\in \Gamma}$ that form the orthonormal basis for $\ell_2\left(\Gamma\right)$, we have
  \begin{align*}
    \lambda_s\left(\delta_t\right)\left(r\right) &= \delta_t\left(s^{-1}r\right)\\
                                                 &= \begin{cases}
                                                   1 & s^{-1}r = t\\
                                                   0 & s^{-1}r \neq t
                                                 \end{cases}\\
                                                 &= \begin{cases}
                                                   1 & r = st\\
                                                   0 & r \neq st
                                                 \end{cases}\\
                                                 &= \delta_{st}\left(r\right),
  \end{align*}
  meaning $\lambda_s\left(\delta_t\right) = \delta_{st}$.\newline

  For $s,r\in \Gamma$, we have
  \begin{align*}
    \lambda_s\circ \lambda_r\left(\xi\right)\left(t\right) &= \lambda_r\left(\xi\right)\left(s^{-1}t\right)\\
                                                           &= \xi\left(r^{-1}s^{-1}t\right)\\
                                                           &= \xi\left(\left(sr\right)^{-1}t\right)\\
                                                           &= \lambda_{sr}\left(\xi\right)\left(t\right).
  \end{align*}
  Thus, $\lambda_s\circ \lambda_r = \lambda_{sr}$.\newline

  We thus have a unitary representation $\lambda: \Gamma\rightarrow \mathcal{U}\left(\ell_2\left(\Gamma\right)\right)$, defined by $\lambda(s) = \lambda_s$ for $s\in \Gamma$. This is known as the left regular representation of $\Gamma$.
\end{example}
\begin{example}
  If $T\in \B\left(\mathcal{H}\right)_{\sa}$, then $U = \exp(iT)$ is unitary. We have
  \begin{align*}
    U^{-1} &= \exp\left(iT\right)^{-1}\\
           &= \exp\left(-iT\right)\\
           &= \exp\left(\left(iT\right)^{\ast}\right)\\
           &= \exp\left(iT\right)^{\ast}.
  \end{align*}
\end{example}
\begin{theorem}[Fuglede's Theorem]
  If $S,T\in \B\left(\mathcal{H}\right)$ are such that $T$ is normal and $ST = TS$, then $ST^{\ast} = T^{\ast}S$.
\end{theorem}
\begin{proof}
  Fix $z\in \C$, and consider the operator $\exp\left(i\overline{z}T\right)$. Since $S$ commutes with $T$, it follows that $ST^{n} = T^{n}S$ for all $n\geq 0$, and by linearity and continuity, we have $S\exp\left(i\overline{z}T\right) = \exp\left(i\overline{z}T\right)S$. Equivalently, we have
  \begin{align*}
    S &= \exp\left(i\overline{z}T\right)S \exp\left(i\overline{z}T\right)^{-1}\\
      &= \exp\left(i\overline{z}T\right)S \exp\left(-i\overline{z}T\right).
  \end{align*}
  Consider the entire function $f: \C\rightarrow \B\left(\mathcal{H}\right)$ defined by $f\left(z\right) = \exp\left(izT^{\ast}\right)S\exp\left(-izT^{\ast}\right)$.\newline

  We substitute the expression for $S$, and recall that $T$ commutes with $T^{\ast}$ to get
  \begin{align*}
    f\left(z\right) &= \exp\left(izT^{\ast}\right)\exp\left(i\overline{z}T\right)S\exp\left(-i\overline{z}T\right)\exp\left(-izT^{\ast}\right)\\
                    &= \exp\left(i\left(zT^{\ast} + \overline{z}T\right)\right)S\exp\left(-i\left(\overline{z}T + zT^{\ast}\right)\right).
  \end{align*}
  Note that $zT^{\ast} + \overline{z}T$ and $\overline{z}T + zT^{\ast}$ are self-adjoint operators, so both $\exp\left(i\left(zT^{\ast} + \overline{z}T\right)\right)$ and $\exp\left(-i\left(\overline{z}T + zT^{\ast}\right)\right)$ are both unitary. Thus, $\norm{f(z)}_{\text{op}}\leq \norm{S}_{\text{op}}$.\newline

  By Liouville's theorem, we must have $f$ is constant, so
  \begin{align*}
    0 &= f'(z)\\
      &= \exp\left(izT^{\ast}\right)iT^{\ast}S\exp\left(-izT^{\ast}\right) + \exp\left(izT^{\ast}\right)s\exp\left(-izT^{\ast}\right)\left(-iT^{\ast}\right).
  \end{align*}
  Setting $z = 0$, we have $0 = iT^{\ast}S - iST^{\ast}$, meaning $ST^{\ast} = T^{\ast}S$.
\end{proof}
\subsubsection{Projections and Partial Isometries}%
An operator $P\in \B\left(\mathcal{H}\right)$ is called a projection of $P^2 = P^{\ast} = P$. We set $\mathcal{P}\left(\B\left(\mathcal{H}\right)\right)$ to be the set of all projections.
\begin{fact}
  Every projection $P$ is positive.
\end{fact}
\begin{proof}
  For $x\in \mathcal{H}$, we have
  \begin{align*}
    \iprod{P\left(x\right)}{x} &= \iprod{P\left(P\left(x\right)\right)}{x}\\
                               &= \iprod{P\left(x\right)}{P\left(x\right)}\\
                               &= \norm{P\left(x\right)}^2\\
                               &\geq 0.
  \end{align*}
\end{proof}
We have studied orthogonal projections already, where we constructed $P_M\in \B\left(\mathcal{H}\right)$ that projects onto the closed subspace $M$. For each $x\in \mathcal{H}$, $P_M\left(x\right)$ is the point in $M$ closest to $x$. We have seen the following
\begin{enumerate}[(a)]
  \item $P_M^2 = P_M^{\ast} = P_M$, $P_M \geq 0$;
  \item $\Ran\left(P_M\right) = M$;
  \item $\norm{P_M} = 1$;
  \item $\ker\left(P_M\right) = M^{\perp}$.
\end{enumerate}
We know that, given an idempotent operator $E^2 = E \in \B\left(\mathcal{H}\right)$, we can decompose $\mathcal{H}$ as the topological direct sum $\mathcal{H} = \Ran\left(E\right) \oplus \ker\left(E\right)$. However, it may not be the case that $\Ran\left(E\right)$ and $\ker\left(E\right)$ are not orthogonal, or $E$ is not self-adjoint.\newline

However, we can prove that if $E$ is an idempotent, then $E$ is self-adjoint and equal to the projection onto its range.
\begin{proposition}
  Let $\mathcal{H}$ be a Hilbert space, and suppose $E\in \B\left(\mathcal{H}\right)$ is an idempotent. Setting $M = \Ran\left(E\right)$, the following are equivalent:
  \begin{enumerate}[(i)]
    \item $M = \ker\left(E\right)^{\perp}$;
    \item $E = P_M$;
    \item $E \in \B\left(\mathcal{H}\right)_{+}$;
    \item $E^{\ast}=E$;
    \item $E$ is normal;
    \item $\norm{E}_{\text{op}}\leq 1$.
  \end{enumerate}
\end{proposition}
\begin{proof}
  To see that (i) implies (ii), we remember that $\mathcal{H} = \Ran\left(E\right) \oplus \ker\left(E\right)$. By the assumption, $M^{\perp} = \left(\ker\left(E\right)^{\perp}\right)^{\perp} = \ker\left(E\right)$, meaning $H = M\oplus M^{\perp}$. Since $E$ and $P_M$ are the projections onto $M$, we must have $E = P_M$.\newline

  To see that (ii) implies (iii), we write $x = y + z$, where $y\in M$ and $z\in M^{\perp}$. Then, $P_M(x) = y$, so we have
  \begin{align*}
    \iprod{P_M\left(x\right)}{x} &= \iprod{y}{y+z}\\
                                 &= \iprod{y}{y}\\
                                 &= \norm{y}^2\\
                                 &= \norm{P_M\left(x\right)}^2\\
                                 &\geq 0.
  \end{align*}
  If $E \geq 0$, then $E$ is self-adjoint, and $E$ is normal, which proves the chain (iii) through (v).\newline

  To see that (v) implies (i), if $E$ is normal, then $\ker\left(E\right) = \ker\left(E^{\ast}\right) = \Ran\left(E\right)^{\perp}$. Moreover, since $E$ is bounded and idempotent, $\Ran\left(E\right)$ is closed, so
  \begin{align*}
    M &= \left(M^{\perp}\right)^{\perp}\\
      &= \left(\Ran\left(E\right)^{\perp}\right)^{\perp}\\
      &= \ker\left(E\right)^{\perp}.
  \end{align*}
  To see that (iv) implies (vi), we see
  \begin{align*}
    \norm{E}^2 &= \norm{E^{\ast}E}\\
               &= \norm{E^2}\\
               &= \norm{E},
  \end{align*}
  meaning $\norm{E} = 0$ or $\norm{E} = 1$.\newline

  To see that (vi) implies (iv), if $E$ is a contraction, then so is $E^{\ast}$, as $\norm{E} = \norm{E^{\ast}}$. If $y\in \mathcal{H}$, then
  \begin{align*}
    \norm{E\left(y\right) - E^{\ast}\left(y\right)}^2 &= \iprod{E\left(y\right) - E^{\ast}\left(y\right)}{E\left(y\right)-E^{\ast}\left(y\right)}\\
                                                      &= \norm{E\left(y\right)}^2 - 2\re\left( \iprod{E\left(y\right)}{E^{\ast}\left(y\right)}\right) + \norm{E^{\ast}\left(y\right)}\\
                                                      &\leq \norm{E\left(y\right)}^2 - 2\re\left( \iprod{E^2\left(y\right)}{y}\right) + \norm{y}^2\\
                                                      &= \norm{E\left(y\right)}^2 - 2\re\left( \iprod{E\left(y\right)}{y}\right)+ \norm{y}^2\\
                                                      &= \iprod{E\left(y\right) - y}{E\left(y\right)-y}\\
                                                      &= \norm{E\left(y\right) - y}.
  \end{align*}
  If $x\in \mathcal{H}$, we set $y = E\left(x\right)$ such that $E\left(y\right) = E^2\left(x\right) = E\left(x\right) = y$. We find $\norm{y - E^{\ast}y} = 0$, so $E\left(x\right) = E^{\ast}E\left(x\right)$. Since $x\in \mathcal{H}$ was arbitrary, we have $E = E^{\ast}E$, meaning
  \begin{align*}
    E^{\ast} &= \left(E^{\ast}E\right)^{\ast}\\
             &= E^{\ast}E\\
             &= E,
  \end{align*}
  so $E$ is self-adjoint.
\end{proof}
\begin{exercise}
  Let $E_{\lambda}\in \B\left(\ell_2\right)$ be the multiplication operator associated with $\left(\lambda_n\right)_n\in \ell_{\infty}$. Prove that $D_{\lambda}$ is a projection if and only if $\lambda_n\in \set{0,1}$ for all $n$.
\end{exercise}
\begin{solution}
  Let $D_{\lambda}$ be a projection. Then, $D_{\lambda} = D_{\lambda}^{\ast}$, implying that $\lambda_n = \overline{\lambda_n}$ for each $n$, so $\lambda_n \in \R$. Additionally, since $D_{\lambda} \geq 0$, we must have $\lambda_n \geq 0$ for each $n$. Finally, since $D_{\lambda}^2 = D_{\lambda}$, we have, for every $\left(\xi_n\right)_{n}\in \ell_2$, that
  \begin{align*}
    \lambda_n^2\xi_n &= \lambda_n\xi_n\\
    \xi_n\left(\lambda_n^2 - \lambda_n\right) &= 0\\
    \xi_n\left(\left(\lambda_n\right)\left(\lambda_n - 1\right)\right) &= 0.
  \end{align*}
  Since there exists a sequence $\left(\xi_n\right)_n\in \ell_2$ with all $\xi_n\neq 0$, it must be the case that $\lambda_n = 0$ or $\lambda_n = 1$ for each $n$.\newline

  If $\lambda_n \in\set{0,1}$ for each $n$, then $D_{\lambda}^2 = D_{\lambda}$, as
  \begin{align*}
    \lambda_n^2\xi_n = \lambda_n\xi_n
  \end{align*}
  for each $n$. Thus, $D_{\lambda}$ is a projection.
\end{solution}
\begin{example}
  Let $\left(\Omega,\mathcal{L},\mu\right)$ be a measure space, and suppose $E\in \mathcal{L}$ is measurable. We may identify $L_2\left(E,\mu_E\right)$ with the closed subspace of $L_2\left(\Omega,\mu\right)$ consisting of all essentially $E$-supported functions. The orthogonal projection is the multiplier $M_{\1_{E}}$.
\end{example}
\begin{exercise}
  Let $Q_n,Q$ be projections in $\B\left(\mathcal{H}\right)$ for each $n$. Prove that
  \begin{align*}
    \left(Q_n\right)_n\xrightarrow{\text{SOT}}Q &\Leftrightarrow \left(Q_n\right)_n\xrightarrow{\text{WOT}}Q
  \end{align*}
\end{exercise}
\begin{solution}
  We have
  \begin{align*}
    Q_n\xrightarrow{\text{WOT}}Q &\Leftrightarrow \iprod{Q_n\left(x\right)}{x} \rightarrow \iprod{Q\left(x\right)}{x}\\
                                 &\Leftrightarrow \iprod{\left(Q_n - Q\right)\left(x\right)}{x}\rightarrow 0\\
                                 &\Leftrightarrow \norm{\left(Q_n - Q\right)\left(x\right)}\rightarrow 0\\
                                 &\Leftrightarrow Q_n\xrightarrow{\text{SOT}}Q.
  \end{align*}
\end{solution}
\begin{lemma}
  If $P$ and $Q$ are projections in $\B\left(\mathcal{H}\right)$, then $PQ = 0$ if and only $QP = 0$ if and only if $\Ran\left(P\right)\perp \Ran\left(Q\right)$.
\end{lemma}
\begin{proof}
  If $PQ = 0$, then 
  \begin{align*}
    0 &= 0^{\ast}\\
      &= \left(PQ\right)^{\ast}\\
      &= Q^{\ast}P^{\ast}\\
      &= QP.
  \end{align*}
  If $PQ = 0$, then 
  \begin{align*}
    \Ran\left(Q\right) &\subseteq \ker\left(P\right)\\
                       &= \Ran\left(P^{\ast}\right)^{\perp}\\
                       &= \Ran\left(P\right)^{\perp},
  \end{align*}
  meaning $\Ran\left(Q\right) \perp \Ran\left(P\right)$. Conversely, if $\Ran\left(Q\right)\perp \Ran\left(P\right)$, then
  \begin{align*}
    \ker\left(P\right) &= \Ran\left(P^{\ast}\right)^{\perp}\\
                       &= \Ran\left(P\right)^{\perp}\\
                       &\supseteq \Ran\left(Q\right),
  \end{align*}
  so $PQ = 0$.
\end{proof}
\begin{definition}
  A family of projections $\set{P_i}_{i\in I}$ in $\B\left(\mathcal{H}\right)$ is said to be pairwise orthogonal if $P_iP_j = 0$ for $i \neq j$.
\end{definition}
Projections are pairwise orthogonal if their ranges are pairwise orthogonal subspaces of $\mathcal{H}$.
\begin{lemma}
  Let $P_1,\dots,P_n$ be pairwise orthogonal nonzero projections in $\B\left(\mathcal{H}\right)$. Let $\lambda_1,\dots,\lambda_n$ be scalars. Then,
  \begin{align*}
    \norm{\sum_{j=1}^{n}\lambda_jP_j}_{\text{op}} &= \max_{j=1}^{n}\left\vert \lambda_j \right\vert.
  \end{align*}
\end{lemma}
\begin{proof}
  Using the Pythagorean theorem, we get
  \begin{align*}
    \norm{\left(\sum_{j=1}^{n}\lambda_jP_j\right)\left(\xi\right)}^2 &= \norm{\sum_{j=1}^{n}\lambda_jP_j\left(\xi\right)}^2\\
                                                                     &= \sum_{j=1}^{n}\norm{\lambda_jP_j\left(\xi\right)}^2\\
                                                                     &= \sum_{j=1}^{n}\left\vert \lambda_j \right\vert^2\norm{P_j\left(\xi\right)}^2\\
                                                                     &\leq \max_{j=1}^{n}\left(\left\vert \lambda_j \right\vert^2\right)\sum_{j=1}^{n}\norm{P_j\left(\xi\right)}^2\\
                                                                     &= \left(\max_{j=1}^{n} \left\vert \lambda_j \right\vert\right)^2\norm{\sum_{j=1}^{n}P_j\left(\xi\right)}^2\\
                                                                     &\leq \left(\max_{j=1}^{n}\left\vert \lambda_j \right\vert\right)^2\norm{\xi}^2,
  \end{align*}
  meaning
  \begin{align*}
    \norm{\sum_{j=1}^{n}\lambda_jP_j}_{\text{op}} &\leq \max_{j=1}^{n}\left\vert \lambda_j \right\vert.
  \end{align*}
  In the other direction, if $e_i$ is a unit vector in $\Ran\left(P_i\right)$, we have
  \begin{align*}
    \norm{\sum_{j=1}^{n}\lambda_jP_j}_{\text{op}} &\geq \norm{\left(\sum_{j=1}^{n}\lambda_jP_j\right)\left(e_i\right)}\\
                                                  &= \norm{\lambda_ie_i}\\
                                                  &= \left\vert \lambda_i \right\vert,
  \end{align*}
  meaning
  \begin{align*}
    \max_{j=1}^{n}\left\vert \lambda_j \right\vert \leq \norm{\sum_{j=1}^{n}\lambda_jP_j}_{\text{op}}.
  \end{align*}
\end{proof}
We know that $\mathcal{P}\left(\B\left(\mathcal{H}\right)\right)\subseteq \B\left(\mathcal{H}\right)_{+}\subseteq \B\left(\mathcal{H}\right)_{\sa}$, so we are now interested in understanding the ordering on $\mathcal{P}\left(\B\left(\mathcal{H}\right)\right)$.
\begin{proposition}
  Let $\mathcal{H}$ be a Hilbert space, and let $P,Q\in \mathcal{P}\left(\B\left(\mathcal{H}\right)\right)$. The following are equivalent.
  \begin{enumerate}[(i)]
    \item $P\leq Q$;
    \item $PQ = P$;
    \item $QP = P$;
    \item $\Ran\left(P\right)\subseteq \Ran\left(Q\right)$.
    \item $\norm{P\left(x\right)}\leq \norm{Q\left(x\right)}$ for all $x\in \mathcal{H}$.
  \end{enumerate}
\end{proposition}
\begin{proof}
  To show that (ii) is true if and only if (iii) is true, we see that
  \begin{align*}
    P &= P^{\ast}\\
      &= \left(PQ\right)^{\ast}\\
      &= Q^{\ast}P^{\ast}\\
      &= QP.
  \end{align*}
  We see (iii) is true if and only if (iv) is true follows from the definition of $QP = P$.\newline

  To see that (iv) implies (i), suppose $\Ran\left(P\right)\subseteq \Ran\left(Q\right)$, and set $M = \Ran\left(P\right)$. If $x\in \mathcal{H}$, we write $x = y + z$ via the decomposition $\mathcal{H} = M \oplus M^{\perp}$. We know that $ \iprod{P\left(x\right)}{x} = \iprod{y}{y} = \norm{y}^2$, so
  \begin{align*}
    \iprod{Q\left(x\right)}{x} &= \iprod{Q\left(y\right) + Q\left(z\right)}{y + z}\\
                               &= \iprod{y + Q\left(z\right)}{y+z}\\
                               &= \norm{y}^2 + \iprod{Q\left(z\right)}{y} + \iprod{Q\left(z\right)}{z}\\
                               &= \norm{y}^2 + \iprod{z}{Q\left(y\right)} + \iprod{Q\left(z\right)}{z}\\
                               &= \norm{y}^2 + \iprod{Q\left(z\right)}{z}\\
                               &\geq \iprod{P\left(x\right)}{x},
  \end{align*}
  where we use the fact that $Q(y) = y$ and $ \iprod{z}{y} = 0 $. Thus, we see that $0 \leq P \leq Q$.\newline

  To see that (ii) implies (i), we know that since $0 \leq P \leq I$, and multiplying by $Q$ preserves order, we have $0 \leq QPQ \leq QIQ$, so $0 \leq P \leq Q$.\newline

  To see that (i) implies (iv), if $Q\left(x\right) = -$, then $ \iprod{Q\left(x\right)}{x} = 0 $, so $0 \leq \iprod{P\left(x\right)}{x} \leq \iprod{Q\left(x\right)}{x} = 0$, so $\norm{P\left(x\right)}^2 = \iprod{P\left(x\right)}{x} = 0$, so $P\left(x\right) = 0$. Thus, we have $\ker\left(Q\right)\subseteq \ker\left(P\right)$, so $\Ran\left(P\right)\subseteq \Ran\left(Q\right)$.\newline

  To see that (i) is true if and only if (v) is true, we recall that $\norm{P\left(x\right)}^2 = \iprod{P\left(x\right)}{x}$ and $\norm{Q\left(x\right)}^2 = \iprod{Q\left(x\right)}{x}$.
\end{proof}
Given a Hilbert space, the collection of all closed subspaces $\mathcal{M} = \set{M | M\subseteq H\text{ is a closed subspace}}$ is a complete lattice under inclusion. For $\set{M_i}_{i\in I}$ a collection of closed subspaces, we have an infimum of $\bigcap_{i\in I}M_i$ and a supremum of $\overline{\sum_{i\in I}M_i}$.\newline

We can extend this lattice to the projections in $\B\left(\mathcal{H}\right)_{\sa}$.
\begin{proposition}
  Let $\mathcal{H}$ be a Hilbert space. The set of projections $\mathcal{P}\left(\B\left(\mathcal{H}\right)\right)$ with the induced ordering from $\B\left(\mathcal{H}\right)_{\sa}$ forms a complete lattice. The map
  \begin{align*}
    \mathcal{M}\rightarrow \mathcal{P}\left(\B\left(\mathcal{H}\right)\right),
  \end{align*}
  defined by $M\mapsto P_M$, is a lattice isomorphism.
\end{proposition}
\begin{proof}
  We know that every $P\in \mathcal{P}\left(\B\left(\mathcal{H}\right)\right)$ is of the form $P_M$, where $M = \Ran\left(P\right)$ is a closed subspace. It follows that $P\mapsto \Ran\left(P\right)$ gives the inverse of the map $M\mapsto P_M$.\newline

  If $M\subseteq N$, then we have proven that $P_M\leq P_N$ previously.\newline

  For $M$ and $N$ closed subspaces, we will show that $P_{M\wedge N} = P_M\wedge P_N$ and $P_{M\vee N} = P_M\vee P_N$, where
  \begin{align*}
    M\wedge N &= M\cap N\\
    M\vee N &= \overline{M+N}.
  \end{align*}
  Since $M\cap N\subseteq M,N$, it follows that $P_{M\cap N}\leq P_M,P_N$. If $Q\leq P_{M},P_N$, it follows that $\Ran\left(Q\right)\subseteq M,N$, so $\Ran\left(Q\right)\subseteq M\cap N$, so $Q\leq P_{M\cap N}$. Thus, $P_{M\wedge N} = P_M\wedge P_N$.\newline

  Similarly, since $M,N\subseteq \overline{M+N}$, it follows that $P_M,P_N\subseteq P_{\overline{M+N}}$. For $Q$ with $P_M,P_N\leq Q$, we must have $M+N\subseteq \Ran\left(Q\right)$. Since $\Ran\left(Q\right)$ is closed, we must also have $\overline{M+N}\subseteq \Ran\left(Q\right)$, so $P_{\overline{M+N}}\leq Q$, meaning $P_{M\vee N} = P_{M}\vee P_N$.
\end{proof}
An operator can often be decomposed into smaller components acting on orthogonal pieces of the Hilbert space.
\begin{definition}
  Let $\mathcal{H}$ be a Hilbert space, and suppose $T\in \B\left(\mathcal{H}\right)$. A closed subspace $M\subseteq \mathcal{H}$ is said to be
  \begin{enumerate}[(1)]
    \item invariant for $T$ if $T\left(M\right)\subseteq M$;
    \item reducing for $T$ if $T\left(M\right)\subseteq M$ and $T\left(M^{\perp}\right) \subseteq M^{\perp}$.
  \end{enumerate}
\end{definition}
We can prove some simple properties of invariant and reducing subspaces.
\begin{lemma}
  Let $M\subseteq \mathcal{H}$ be a closed subspace of a Hilbert space, and let $T\in \B\left(\mathcal{H}\right)$.
  \begin{enumerate}[(1)]
    \item $M$ is invariant for $T$ if and only if $M^{\perp}$ is invariant for $T^{\ast}$.
    \item $M$ is invariant for $T^{\ast}$ if and only if $M^{\perp}$ is invariant for $T$.
    \item $M$ is reducing for $T$ if and only if $M$ is invariant for $T$ and $T^{\ast}$.
    \item $M$ reduces $T$ if and only if $M$ reduces $T^{\ast}$.
  \end{enumerate}
\end{lemma}
\begin{proof}
  To see (1), if $T\left(M\right)\subseteq M$, then for $x\in M$ and $y\in M^{\perp}$, we have $ \iprod{T\left(x\right)}{y} = \iprod{x}{T^{\ast}\left(y\right)} = 0 $, so $T^{\ast}\left(M^{\perp}\right)\subseteq M^{\perp}$. If $M^{\perp}$ is invariant for $T^{\ast}$, then for $y\in M^{\perp}$ and $x\in M$, we have $ \iprod{x}{T^{\ast}\left(y\right)} = \iprod{T\left(x\right)}{y} = 0 $, so $T$ is invariant for $\left(M^{\perp}\right)^{\perp} = M$.\newline

  To see (2), we replace $T$ with $T^{\ast}$ in the proof of (1).\newline

  It is the case that (3) and (4) follow from (1) and (2).
\end{proof}
\begin{definition}
  Let $M\subseteq \mathcal{H}$ reduce a bounded operator $T\in \B\left(\mathcal{H}\right)$. We write
  \begin{align*}
    T_M &= T|_{M}\\
    T_{M^{\perp}} &= T|_{M^{\perp}}
  \end{align*}
  to be the restrictions of $T$ to $M$ and $M^{\perp}$.
\end{definition}
\begin{exercise}
  Let $M\subseteq \mathcal{H}$ be a closed subspace.
  \begin{enumerate}[(a)]
    \item If $M$ reduces $T,S\in \B\left(\mathcal{H}\right)$, show that $M$ also reduces $T^{\ast}$, $TS$, and $T + \alpha S$ for any $\alpha \in \C$. Moreover, show that
      \begin{align*}
        \left(T + \alpha S\right)_{M} &= T_M + \alpha S_M\\
        \left(TS\right)_M &= T_MS_M\\
        \left(T^{\ast}\right)_{M} &= \left(T_M\right)^{\ast}.
      \end{align*}
    \item Suppose $M$ reduces a net of bounded operators $\left(T_{\alpha}\right)_{\alpha}$. If $\left(T_{\alpha}\right)_{\alpha}\xrightarrow{\text{WOT}} T$, show that $M$ reduces $T$ as well.
    \item Conclude that
      \begin{align*}
        R_M &= \set{T\in \B\left(\mathcal{H}\right) | M\text{ reduces }T}
      \end{align*}
      is a von Neumann algebra.
  \end{enumerate}
\end{exercise}
\begin{solution}\hfill
  \begin{enumerate}[(a)]
    \item Since $M$ reduces $T$, $M$ is invariant for $T$ and $T^{\ast}$, so $T^{\ast}\left(M^{\perp}\right)\subseteq M^{\perp}$, meaning $T^{\ast}\left(M\right) \subseteq M$.\newline

      Similarly, since $M$ reduces $T$ and $M$ reduces $S$, we have
      \begin{align*}
        TS\left(M\right)&\subseteq T\left(M\right)\\
        &\subseteq M.
      \end{align*}
      Similarly, $TS\left(M^{\perp}\right) \subseteq M^{\perp}$.
    \item Let $M$ reduce a net of bounded operators $\left(T_{\alpha}\right)_{\alpha}$ with $\left(T_{\alpha}\right)_{\alpha}\xrightarrow{\text{WOT}}T$. Then, we have, for all $\eta\in M^{\perp}$ and $\xi \in M$,
      \begin{align*}
        0 &= \iprod{T_{\alpha}\left(\xi\right)}{\eta}\\
          &\rightarrow \iprod{T\left(\xi\right)}{\eta},
      \end{align*}
      so $T\left(\xi\right)\in M$. Thus, $T\left(M\right)\subseteq M$, so $M$ is invariant for $T$. Similarly, we also find $M^{\perp}$ is invariant for $T$, so $M$ is reducing for $T$.
    \item We see that the collection $R_M$ is a WOT-closed subalgebra of $\B\left(\mathcal{H}\right)$, so $R_M$ is a von Neumann algebra.
  \end{enumerate}
\end{solution}
\begin{definition}
  Let $B\subseteq \B\left(\mathcal{H}\right)$ be a collection of bounded operators on a Hilbert space $\mathcal{H}$. A closed subspace $M\subseteq \mathcal{H}$ is said to be invariant/reducing for $B$ if $M$ is invariant/reducing for every $b\in B$.
\end{definition}
\begin{definition}
  Let $\mathcal{H}$ be a Hilbert space, $S\subseteq \mathcal{H}$ a set of vectors, and let $B\subseteq \B\left(\mathcal{H}\right)$ be a collection of bounded operators. Set
  \begin{align*}
    \left[BS\right] &= \overline{\Span}\set{b\left(\eta\right) | b\in B,\eta \in S}.
  \end{align*}
  If $S = \set{\xi}$, then we write $\left[B\xi\right]$. If $B\subseteq \B\left(\mathcal{H}\right)$ is a subspace, and $\xi\in \mathcal{H}$, then
  \begin{align*}
    \left[B\xi\right] &= \overline{\set{b\left(\xi\right) | b\in B}}.
  \end{align*}
\end{definition}
\begin{exercise}
  If $B\subseteq \B\left(\mathcal{H}\right)$ is a subalgebra of bounded operators on a Hilbert space $\mathcal{H}$ and $S\subseteq \mathcal{H}$ is a collection of vectors, prove that $\left[BS\right]$ is invariant for $B$. If $B$ is a $\ast$-subalgebra, prove that $\left[BS\right]$ is reducing for $B$.
\end{exercise}
\begin{solution}
  Let $B$ be a subalgebra. Then, for any $\xi\in \left[BS\right]$, we see that $b\left(\xi\right)\in \left[BS\right]$ for every $b\in B$, meaning $b\left(\left[BS\right]\right)\subseteq \left[BS\right]$ for each $b\in B$, so $\left[BS\right]$ is invariant.\newline

  Similarly, for a $\ast$-subalgebra $B$, since $b\left(\left[BS\right]\right)\subseteq \left[BS\right]$, and $b^{\ast}\left(\left[BS\right]\right)\subseteq \left[BS\right]$ for each $b\in B$, it is the case that $\left[BS\right]$ is reducing for $B$.
\end{solution}
We can understand invariant and reducing subspaces through purely algebraic expressions as well.
\begin{lemma}
  Let $\mathcal{H}$ be a Hilbert space, and suppose $M\subseteq \mathcal{H}$ is a closed subspace with orthogonal projection $P = P_M$.
  \begin{enumerate}[(1)]
    \item $M$ is invariant for $T\in \B\left(H\right)$ if and only if $PTP = TP$.
    \item $M$ is reducing for $T\in \B\left(H\right)$ if and only if $PT = TP$.
    \item $M$ is reducing for the family $B\subseteq \B\left(\mathcal{H}\right)$ if and only if $P\in B'$, where $B'$ is the commutant of $B$.
  \end{enumerate}
\end{lemma}
\begin{proof}\hfill
  \begin{enumerate}[(1)]
    \item If $PTP = TP$, then $T\left(M\right) = TP\left(M\right) = PTP\left(M\right)\subseteq \Ran\left(P\right) = M$. Conversely, if $M$ is invariant for $T$, then $TP(x)\in M$ for any $x\in \mathcal{H}$, so $PTP(x) = x$.
    \item We know that $M$ and $M^{\perp}$ are invariant for $T$, so we have $PTP = TP$ and $\left(I-P\right)T\left(I-P\right) = T\left(I-P\right)$, meaning $TP = PT$.
    \item Follows from (2).
  \end{enumerate}
\end{proof}
We can now understand the characterization of partial isometries, which are (effectively) a combination of a projection and isometry.
\begin{proposition}
  Let $T: \mathcal{H}\rightarrow \mathcal{K}$ be a bounded linear operator between Hilbert spaces, and let $L = \ker\left(T\right)^{\perp}$, $M = \Ran\left(T\right)$. The following are equivalent:
  \begin{enumerate}[(i)]
    \item $T^{\ast}T$ is the orthogonal projection onto $L$;
    \item $TT^{\ast}$ is the orthogonal projection onto $M$, which is a closed subspace;
    \item $T|_{L}\colon L\rightarrow K$ is an isometry;
    \item $TT^{\ast}T = T$;
    \item $T^{\ast}TT^{\ast} = T^{\ast}$.
  \end{enumerate}
  All of these cases imply that $T|_{L}\colon L\rightarrow M$ is an isometric isomorphism of Hilbert spaces.
\end{proposition}
\begin{proof}
  The equivalence between (iv) and (v) follows from adjoints.\newline

  To show that (v) implies (i), we see that $T^{\ast}T$ is self-adjoint, and that
  \begin{align*}
    \left(T^{\ast}T\right)\left(T^{\ast}T\right) &= \left(T^{\ast}TT^{\ast}\right)T\\
                                                 &= T^{\ast}T,
  \end{align*}
  so $T^{\ast}T$ is an idempotent. Thus, $T^{\ast}T$ is the orthogonal projection onto $\Ran\left(T^{\ast}T\right)$, which is close since $T^{\ast}T$ is idempotent. We also see that
  \begin{align*}
    \Ran\left(T^{\ast}T\right)&\subseteq \Ran\left(T^{\ast}\right)\\
                              &\subseteq \overline{\Ran\left(T^{\ast}\right)}\\
                              &= \ker\left(T\right)^{\perp}\\
                              &= L.
  \end{align*}
  Since $T^{\ast}TT^{\ast} = T^{\ast}$, we get $\Ran\left(T^{\ast}\right)\subseteq \Ran\left(T^{\ast}T\right)$. Taking closures, we get
  \begin{align*}
    L &= \ker\left(T\right)^{\perp}\\
      &= \overline{\Ran\left(T^{\ast}\right)}\\
      &\subseteq \Ran\left(T^{\ast}T\right),
  \end{align*}
  meaning $T^{\ast}T$ is the orthogonal projection onto $L$.\newline

  To see the implication (ii) to (v), we see that if $S\in \B\left(\mathcal{H},\mathcal{K}\right)$ satisfies $S^{\ast}S = 0$, then $S = 0$ by the $C^{\ast}$ identity. We will show that $T^{\ast}TT^{\ast} - T^{\ast} = 0$, by seeing
  \begin{align*}
    \left(T^{\ast}TT^{\ast} - T^{\ast}\right)^{\ast}\left(T^{\ast}TT^{\ast} - T^{\ast}\right) &= \left(TT^{\ast}T - T\right)\left(T^{\ast}TT^{\ast} - T^{\ast}\right)\\
                                                                                              &= TT^{\ast}TT^{\ast}TT^{\ast} - TT^{\ast}TT^{\ast} - TT^{\ast}TT^{\ast} + TT^{\ast}\\
                                                                                              &= TT^{\ast}TT^{\ast} - TT^{\ast} - TT^{\ast} + TT^{\ast}\\
                                                                                              &= 0.
  \end{align*}
  Similarly, the implication (i) to (iv) follows from replacing $TT^{\ast}$ with $T^{\ast}T$.\newline

  The implication (iv) to (ii) follows from the fact that $TT^{\ast}$ is a self-adjoint idempotent with closed range, meaning $\Ran\left(TT^{\ast}\right) = \Ran\left(T\right) = M$.\newline

  To see the implication (i) to (iii), we see that if $x\in L$ and $T^{\ast}T = P_{L}$, then
  \begin{align*}
    \norm{T\left(x\right)}^2 &= \iprod{T\left(x\right)}{T\left(x\right)}\\
                             &= \iprod{T^{\ast}T\left(x\right)}{x}\\
                             &= \iprod{x}{x}\\
                             &= \norm{x}^2,
  \end{align*}
  meaning $T|_{L}:L\rightarrow\mathcal{K}$ is an isometry.\newline

  If $T|_{L}:L\rightarrow \mathcal{K}$ is an isometry, we know that $ \iprod{T\left(x\right)}{T\left(z'\right)} = \iprod{z}{z'} $ for all $z,z'\in L$. Let $x\in \mathcal{H}$ be arbitrary. Note that $T^{\ast}T\left(x\right)\in \Ran\left(T^{\ast}\right)\subseteq \ker\left(T\right)^{\perp}$, so we write $x = y +z$ by the decomposition $\mathcal{H} = \ker\left(T\right) \oplus L$. We have $T^{\ast}T\left(x\right) = T^{\ast}T\left(z\right)$. For any $z'\in L$, we compute
  \begin{align*}
    \iprod{x - T^{\ast}T\left(x\right)}{z'} &= \iprod{z - T^{\ast}T\left(z\right)}{z'}\\
                                            &= \iprod{z}{z'} - \iprod{T^{\ast}T\left(z\right)}{z'}\\
                                            &= \iprod{z}{z'} - \iprod{T\left(z\right)}{T\left(z'\right)}\\
                                            &= 0.
  \end{align*}
  This means $x-T^{\ast}T\left(x\right) \in L^{\perp}$. The decomposition
  \begin{align*}
    x &= TT^{\ast}\left(x\right) + \left(x - TT^{\ast}\left(x\right)\right)
  \end{align*}
  implies $TT^{\ast}\left(x\right) = P_{L}\left(x\right)$. Since $x$ was arbitrary, we have $TT^{\ast} = P_{L}$.
\end{proof}
\begin{definition}
  An operator $T\in \B\left(\mathcal{H},\mathcal{K}\right)$ satisfying one of the above conditions is known as a partial isometry with initial projection $T^{\ast}T$ and final projection $TT^{\ast}$.
\end{definition}
\begin{exercise}
  Let $x$ and $y$ be unit vectors in $\mathcal{H}$. Prove that the rank-one operator $\theta_{x,y}$ is a partial isometry with initial projection $\theta_{y,y}$ and final projection $\theta_{x,x}$.
\end{exercise}
Partial isometries and unitaries are primarily useful to compare projections, which aid in the classification of von Neumann algebras.
\begin{exercise}
  Consider the following relations on the set of projections $\B\left(\mathcal{H}\right)$.
  \begin{enumerate}[(a)]
    \item For $P,Q\in \mathcal{P}\left(\B\left(\mathcal{H}\right)\right)$, we define $P\sim Q$ if there exists $V\in \B\left(\mathcal{H}\right)$ with $V^{\ast}V = P$ and $VV^{\ast} = Q$. This is known as Murray--von Neumann equivalence. Prove that this defines an equivalence relation on $\mathcal{P}\left(\B\left(\mathcal{H}\right)\right)$.
    \item For $P,Q\in \B\left(\mathcal{H}\right)$, we set $P\sim_{u} Q$ if there exists $U\in \mathcal{U}\left(\B\left(\mathcal{H}\right)\right)$ such that $UPU^{\ast} = Q$. This is known as unitary equivalence. Prove that $\sim_{u}$ defines an equivalence relation on $\mathcal{P}\left(\B\left(\mathcal{H}\right)\right)$.
    \item Prove that $P\sim_{u}Q \Rightarrow P\sim Q$.
  \end{enumerate}
\end{exercise}
\begin{solution}
  \begin{enumerate}[(a)]
    \item Reflexivity follows from $P^{\ast} = P$. Symmetry follows from the fact that $U = V^{\ast}$ yields $U^{\ast}U = Q$ and $UU^{\ast} = P$. Transitivity follows from composition.
    \item Reflexivity follows from $I\in \mathcal{U}\left(\B\left(\mathcal{H}\right)\right)$, symmetry from $U \in \mathcal{U}\left(\B\left(\mathcal{H}\right)\right)\Rightarrow U^{\ast}\in \mathcal{U}\left(\B\left(\mathcal{H}\right)\right)$, and transitivity from $U,V\in \mathcal{U}\left(\B\left(\mathcal{H}\right)\right) \Rightarrow UV\in \mathcal{U}\left(\B\left(\mathcal{H}\right)\right)$.
    \item Setting $V = UP$ in the unitary equivalence, we find that
      \begin{align*}
        V^{\ast}V &= \left(UP\right)^{\ast}\left(UP\right)\\
                  &= P^{\ast}U^{\ast}UP\\
                  &= P^{\ast}P\\
                  &= P\\
        VV^{\ast} &= \left(UP\right)\left(UP\right)^{\ast}\\
                  &= UPP^{\ast}U^{\ast}\\
                  &= UP^2U^{\ast}\\
                  &= UPU^{\ast}\\
                  &= Q.
      \end{align*}
  \end{enumerate}
\end{solution}
\begin{exercise}
  Let $\mathcal{H}$ be a Hilbert space. Prove the following.
  \begin{enumerate}[(a)]
    \item $P\sim Q$ if and only if $\Rank\left(P\right) = \Rank\left(Q\right)$.
    \item $P\sim_{u} Q$ if and only if $\Ran\left(P\right) = \Rank\left(Q\right)$ and $\Rank\left(I-P\right) = \Rank\left(I-Q\right)$.
  \end{enumerate}
\end{exercise}
\begin{solution}\hfill
  \begin{enumerate}[(a)]
    \item Let $P\sim Q$. Then, there exists $V\in \B\left(\mathcal{H}\right)$ such that $V^{\ast}V = P$ and $VV^{\ast} = Q$. Notice that for $x\in \mathcal{H}$, we have
      \begin{align*}
        \norm{VP\left(x\right)}^2 &= \iprod{VP\left(x\right)}{VP\left(x\right)}\\
                                  &= \iprod{VV^{\ast}V\left(x\right)}{VV^{\ast}V\left(x\right)}\\
                                  &= \iprod{V\left(x\right)}{V\left(x\right)}\\
                                  &= \iprod{V^{\ast}V\left(x\right)}{x}\\
                                  &= \iprod{P\left(x\right)}{x}\\
                                  &= \iprod{P\left(x\right)}{P\left(x\right)}\\
                                  &= \norm{P\left(x\right)}^2.
      \end{align*}
      By definition, we must have $V$ is the partial isometry with initial projection $P$ and final projection $Q$. In particular, this means $V|_{\Ran\left(P\right)}\colon \Ran\left(P\right)\rightarrow \Ran\left(Q\right)$ is an isometric isomorphism, meaning that $\hdim\left(\Ran\left(P\right)\right) =\hdim\left(\Ran\left(Q\right)\right)$, so $\Rank\left(P\right) = \Rank\left(Q\right)$.\newline

      If $\Rank\left(P\right) = \Rank\left(Q\right)$, then there exists an isometric isomorphism $T\colon \Ran\left(P\right)\rightarrow \Ran\left(Q\right)$. Defining $V$ to be equal to $T$ on $\Ran\left(P\right)$ and $0$ elsewhere, we then have $V^{\ast}V = P$ and $VV^{\ast} = Q$.
    \item If $P\sim_{u}Q$, then $P$ and $Q$ are Murray--von Neumann equivalent, so $\Rank\left(P\right) = \Rank\left(Q\right)$. Similarly, we have
      \begin{align*}
        U^{\ast}\left(I-P\right)U &= I-U^{\ast}PU\\
                                  &= I-Q,
      \end{align*}
      so $I-P$ and $I-Q$ are Murray--von Neumann equivalent, so $\Rank\left(I-P\right) = \Rank\left(I-Q\right)$.\newline

      If $\Rank\left(P\right) = \Rank\left(Q\right)$, then there exists $V\in \B\left(\mathcal{H}\right)$ such that $V^{\ast}V = P$ and $VV^{\ast} = Q$. Similarly, there exists $T\in \B\left(\mathcal{H}\right)$ such that $T^{\ast}T = I-P$ and $TT^{\ast} = I-Q$.
  \end{enumerate}
\end{solution}

\begin{fact}
  If $P$ and $Q$ are projections in $\B\left(\mathcal{H}\right)$ with $\norm{P-Q}_{\text{op}} < 1$, then $P$ and $Q$ are unitarily equivalent.
\end{fact}
\begin{proof}
  Suppose $0\neq \xi\in \Ran\left(P\right)$. If $Q\left(\xi\right) = 0$, then
  \begin{align*}
    \norm{\xi} &= \norm{P\left(\xi\right)}\\
               &= \norm{P\left(\xi\right) - Q\left(\xi\right)}\\
               &= \norm{\left(P-Q\right)\left(\xi\right)}\\
               &\leq \norm{P-Q}_{\text{op}} \norm{\xi}\\
               & < \xi.
  \end{align*}
  Thus, $Q\left(\xi\right) \neq 0$, meaning $Q|_{\Ran\left(P\right)}\colon \Ran\left(P\right)\rightarrow \Ran\left(Q\right)$ is injective. It follows that $\Rank\left(P\right) \leq \Rank\left(Q\right)$. Similarly, we must have $\Rank\left(Q\right) \leq \Rank\left(P\right)$, meaning $\Rank\left(Q\right) = \Rank\left(P\right)$.\newline

  Note that $\norm{P^{\perp} - Q^{\perp}}_{\text{op}} = \norm{Q - P}_{\text{op}} < 1$, meaning $\Rank\left(P^{\perp}\right) = \Rank\left(Q^{\perp}\right)$. Thus, $P\sim_{u}Q$.
\end{proof}
\subsection{Direct Sums and Diagonalizable Operators}%
To move towards constructing the matrix algebra $\Mat_{n}\left(\B\left(\mathcal{H}\right)\right)$ and prove the Double Commutant theorem, we begin by constructing the matrix representation of an operator.
\begin{proposition}
  Let $\set{\mathcal{H}_{i}}_{i\in I}$ be a family of Hilbert spaces, and suppose for each $i\in I$, we have a bounded operator $T_i\in \B\left(\mathcal{H}_i\right)$. If $\sup_{i\in I}\norm{T_i}_{\text{op}} < \infty$, then $T\colon \bigoplus_{i\in I}\mathcal{H}_i \rightarrow \bigoplus_{i\in I}\mathcal{H}_i$, defined by
  \begin{align*}
    T\left(\left(\xi_i\right)_i\right) &= \left(T_i\left(\xi_i\right)\right)_{i}
  \end{align*}
  is a well-defined bounded linear operator with $\norm{T}_{\text{op}} = \sup_{i\in I}\norm{T_i}_{\text{op}}$.
\end{proposition}
\begin{proof}
  For $\xi = \left(\xi_i\right)_i$ in $\bigoplus_{i\in I}\mathcal{H}_i$, we compute
  \begin{align*}
    \norm{T\left(\xi\right)}^2 &= \norm{\left(T_i\left(\xi_i\right)\right)_i}^2\\
                               &= \sum_{i\in I}\norm{T_i\left(\xi_i\right)}^2\\
                               &\leq \sum_{i\in I}\norm{T_i}^2_{\text{op}}\norm{\xi_i}^2\\
                               &\leq \sup_{i\in I}\norm{T_i}^2_{\text{op}}\sum_{i\in I}\norm{\xi_i}^2\\
                               &= \left(\sup_{i\in I}\norm{T_i}_{\text{op}}\right)^2\norm{\xi}^2,
  \end{align*}
  meaning $T$ is well-defined and $\norm{T}_{\text{op}} \leq \sup_{i\in I}\norm{T_i}_{\text{op}}$. Since $T$ restricts to $T_i$ on each $\mathcal{H}_i$, it follows that $\norm{T}_{\text{op}} \geq \norm{T_i}_{\text{op}}$ for every $i\in I$.
\end{proof}
\begin{definition}
  We call $T$ as defined above the external direct sum of the family $\set{T_i}_{i\in I}$. We write $T = \bigoplus_{i\in I}T_i$.\newline

  If $\mathcal{H}_i = \mathcal{H}$ and $T_i = T$ for all $i\in I$, we write $\bigoplus_{i\in I}T$ acting on $\bigoplus_{i\in I}\mathcal{H}$ as the $I$-fold amplification of $T$.\newline

  We write $T^{(\infty)}$ for $\bigoplus_{n\in \N}T$, and $T^{(n)}$ for $\bigoplus_{k=1}^{n}T$.
\end{definition}
\begin{exercise}
  Suppose $\bigoplus_{i\in I}T_i$ and $\bigoplus_{i\in I}S_i$ are external direct sums acting on $\bigoplus_{i\in I}\mathcal{H}_i$, and let $\alpha$ be a scalar. Prove the following algebraic properties.
  \begin{enumerate}[(a)]
    \item $\displaystyle \alpha \left(\bigoplus_{i\in I}T_i\right) + \bigoplus_{i\in I}S_i = \bigoplus_{i\in I}\left(\alpha T_i + S_i\right)$.
    \item $\displaystyle \left(\bigoplus_{i\in I}T_i\right) \circ \left(\bigoplus_{i\in I}S_i\right) = \bigoplus_{i\in I}\left(T_iS_i\right)$.
    \item $\displaystyle \left(\bigoplus_{i\in I}T_i\right)^{\ast}= \bigoplus_{i\in I}T_i^{\ast}$.
    \item $\displaystyle \left(\bigoplus_{i\in I}T_i\right)^{n}= \bigoplus_{i\in I}T_i^{n}$.
  \end{enumerate}
\end{exercise}
\begin{solution}
  Define
  \begin{align*}
    T &= \bigoplus_{i\in I}T_i\\
    S &= \bigoplus_{i\in I}S_i.
  \end{align*}
  \begin{enumerate}[(a)]
    \item 
      \begin{align*}
        \left(\alpha T + S\right)\left(\left(\xi_i\right)_i\right) &= \alpha T\left(\left(\xi_i\right)_i\right) + S\left(\left(\xi_i\right)_i\right)\\
                                                                   &= \alpha \left(T_i\left(\xi_i\right)\right)_i + \left(S_i\left(\xi_i\right)\right)_i\\
                                                                   &= \left(\left(\alpha T_i + S_i\right)\left(\xi_i\right)\right)_i\\
                                                                   &= \left(\bigoplus_{i\in I}\left(\alpha T_i + S_i\right)\right)\left(\xi_i\right)_i
      \end{align*}
    \item 
      \begin{align*}
        TS\left(\left(\xi_i\right)_i\right) &= T\left(\left(S_i\left(\xi_i\right)\right)_i\right)\\
                                            &= \left(T_iS_i\left(\xi_i\right)\right)_i\\
                                            &= \left(\bigoplus_{i\in I}T_iS_i\right)\left(\xi_i\right)_i.
      \end{align*}
    \item 
      \begin{align*}
        T^{\ast}\left(\left(\xi_i\right)_i\right) &= \left(T_i^{\ast}\left(\xi_i\right)\right)_i\\
                                                  &= \left(\bigoplus_{i\in I}T_i^{\ast}\right)\left(\xi_i\right)_i.
      \end{align*}
    \item 
      \begin{align*}
        T^n\left(\left(\xi_i\right)_i\right) &= T^{n-1}\left(\left(T_i\left(\xi_i\right)\right)_i\right)\\
                                             &\vdots\\
                                             &= \left(T_i^{n}\left(\xi_i\right)\right)_i\\
                                             &= \left(\bigoplus_{i\in I}T_i^n\right)\left(\xi_i\right)_i.
      \end{align*}
  \end{enumerate}
\end{solution}
We can start by looking at the direct sum of multiplication operators, which will lead us toward a better understanding of block-diagonal and diagonal operators.
\begin{example}
  Let $\set{\left(\Omega_n,\mathcal{M}_n,\mu_n\right)}_n$ be a countable family of measure spaces with disjoint union $\left(\Sigma,\mathcal{M},\mu\right)$. For every $n\geq 1$, we let $f_n\in L_{\infty}\left(\Omega_n,\mu_n\right)$, and suppose $\sup_{n\geq 1}\norm{f_n}_{\infty} < \infty$.\newline

  We can speak of the external direct sum operator
  \begin{align*}
    T &= \bigoplus_{n\geq 1}M_{f_n}
  \end{align*}
  acting on $\bigoplus_{n\geq 1}L_2\left(\Omega_n,\mu_n\right)$.\newline

  Let
  \begin{align*}
    V: L_2\left(\Sigma,\mu\right) \rightarrow \bigoplus_{n\geq 1}L_2\left(\Omega_n,\mu_n\right)
  \end{align*}
  be defined by
  \begin{align*}
    V\left(\xi\right) &= \left(\xi\circ \iota_n\right)_n.
  \end{align*}
  We claim that the unitarily equivalent $V^{\ast}TV$ on $L_2\left(\Sigma,\mu\right)$ is equivalent to $M_f$ on $f = \bigsqcup_{n}f_n$.\newline

  We see that for $\xi\in L_2\left(\Sigma,\mu\right)$, we have
  \begin{align*}
    TV\left(\xi\right) &= T\left(\left(\xi\circ \iota_n\right)_n\right)\\
                       &= \left(M_{f_n}\left(\xi\circ \iota_n\right)\right)_n\\
                       &= \left(f_n\left(\xi\circ \iota_n\right)\right)_n,
  \end{align*}
  and
  \begin{align*}
    VM_f\left(\xi\right) &= V\left(f\xi\right)\\
                         &= \left(f\xi\circ \iota_n\right)_n.
  \end{align*}
  Thus, for any $x\in \Omega_n$, we have
  \begin{align*}
    f\xi\circ \iota_n\left(x\right) &= f\xi \left(x,n\right)\\
                                    &= f\left(x,n\right)\xi\left(x,n\right)\\
                                    &= f_n\left(x\right)\left(\xi\circ \iota_n\right)(x)\\
                                    &= f_n\left(\xi\circ \iota_n\right)\left(x\right),
  \end{align*}
  so
  \begin{align*}
    f\xi\circ \iota_n &= f_n\left(\xi\circ \iota_n\right).
  \end{align*}
  This holds for every n, so $TV = VM_f$ as claimed.
\end{example}
A Hilbert space with $\hdim\left(\mathcal{H}\right) \geq 2$ admits infinitely many internal direct sum decompositions. For instance, if $\left(e_i\right)_{i\in I}$ is an orthonormal basis, then $\mathcal{H}$ is the internal direct sum of $\set{\Span\left(e_i\right)}_{i\in I}$.\newline

In general, if $\mathcal{H}$ is the internal direct sum of a family $\mathcal{M} = \set{M_i}_{i\in I}$, any operator $T\in \B\left(\mathcal{H}\right)$ can be represented and viewed as a matrix $\left[T\right]_{\mathcal{M}}$ acting on the external direct sum $\bigoplus_{i\in I}M_i$.\newline

Recall that if $\mathcal{H} = \bigoplus_{i\in I}$ is an internal direct sum, then $\mathcal{H}$ is unitarily isomorphic to the \textit{external} direct sum $\bigoplus_{i\in I}M_i$ through the operator
\begin{align*}
  U\left(\left(\xi_i\right)_i\right) &= \sum_{i\in I}\xi_i.
\end{align*}
\begin{proposition}
  Let $\mathcal{H}$ be the internal direct sum of the family $\mathcal{M} = \set{M_i}_{i\in I}$. Let $P_i$ be the orthogonal projection onto $M_i$, and $T\in \B\left(\mathcal{H}\right)$ be any operator. Set $T_{ij} = P_iTP_j$ for each $i,j\in I$.
  \begin{enumerate}[(1)]
    \item The map
      \begin{align*}
        \left[T\right]_{\mathcal{M}}: \bigoplus_{i\in I}M_i \rightarrow \bigoplus_{i\in I} M_i,
      \end{align*}
      defined by
      \begin{align*}
        \left[T\right]_{\mathcal{M}}\left(\left(\xi_i\right)_i\right) &= \left(\sum_{j\in I}T_{ij}\left(\xi_j\right)\right)_i
      \end{align*}
      defines a bounded operator on the external direct sum $\bigoplus_{i\in I}M_i$ with $\norm{\left[T\right]_{\mathcal{M}}}_{\text{op}} \leq \norm{T}_{\text{op}}$
    \item The operators $T$ and $\left[T\right]_{\mathcal{M}}$ are unitarily equivalent via $U$ as defined above. Thus, we have $\norm{\left[T\right]_{\mathcal{M}}}_{\text{op}} = \norm{T}_{\text{op}}$.
    \item The map $T \mapsto \left[T\right]_{\mathcal{M}}$ is an isometric $\ast$-isomorphism of $C^{\ast}$-algebras called the matrix representation of $T$ with respect to $\mathcal{M}$.
  \end{enumerate}
\end{proposition}
\begin{proof}
  We will write $\left[T\right] \coloneq \left[T\right]_{\mathcal{M}}$.
  \begin{enumerate}[(1)]
    \item If $\left(\xi_i\right)_{i\in I}$ belongs to $\bigoplus_{i\in I}M_i$, then $\sum_{j\in I}\norm{\xi_j}^2$ is summable by definition, so $\sum_{j\in I}\xi_j$ is summable in $\mathcal{H}$. If we fix $i\in I$, using continuity of $P_jT$ and the fact that $P_j\left(\xi_j\right) = \xi_j$ for each $j$, we have
      \begin{align*}
        P_i\left(\sum_{j\in I}\xi_j\right) &= \sum_{j\in I}P_iT\left(\xi_j\right)\\
                                           &= \sum_{j\in I}P_iTP_j\left(\xi_j\right)\\
                                           &= \sum_{j\in I}T_{ij}\left(\xi_j\right)
      \end{align*}
      is summable in $\mathcal{H}$. Additionally, $\sum_{i\in I}\norm{P_i\left(\eta\right)}^2 = \norm{\eta}^2$ for every $\eta \in \mathcal{H}$, so we have
      \begin{align*}
        \sum_{i\in I}\norm{\sum_{j\in I}T_{ij}\left(\xi_j\right)}^2 &= \sum_{i\in I}\norm{\sum_{j\in I}P_iTP_j\left(\xi_j\right)}^2\\
                                                                    &= \sum_{i\in I}\norm{P_i\left(\sum_{j\in I}T\left(\xi_j\right)\right)}^2\\
                                                                    &= \norm{\sum_{i\in I}T\left(\xi_j\right)}^2\\
                                                                    &= \norm{T\left(\sum_{j\in I}\xi_j\right)}^2\\
                                                                    &\leq \norm{T}_{\text{op}}^2 \norm{\sum_{j\in I}\xi_j}^2\\
                                                                    &= \norm{T}_{\text{op}}^2\sum_{j\in I}\norm{\xi_j}^2\\
                                                                    &= \norm{T}_{\text{op}}^2\norm{\left(\xi_i\right)_i}^2,
      \end{align*}
      showing that $\left[T\right]$ is linear and $\norm{\left[T\right]}_{\text{op}}\leq \norm{T}_{\text{op}}$.
    \item We will show that $U\left[T\right] = TU$. Let $\xi = \left(\xi_i\right)_i\in \bigoplus_{i\in I}M_i$. Then,
      \begin{align*}
        TU\left(\left(\xi_j\right)_j\right) &= T\left(\sum_{j\in I}\xi_j\right)\\
                                            &= \sum_{j\in I}TP_j\left(\xi_j\right)\\
                                            &= \sum_{i}P_i\left(\sum_{j\in I}T\left(\xi_j\right)\right)\\
                                            &= \sum_{i\in I}\left(\sum_{j\in I}P_iTP_j\left(\xi_j\right)\right)\\
                                            &= \sum_{i\in I}\left(\sum_{j\in I}T_{ij}\left(\xi_j\right)\right)\\
                                            &= U\left(\left(\sum_{j\in I}T_{ij}\left(\xi_j\right)\right)_i\right)\\
                                            &= U\left[T\right]\left(\left(\xi_j\right)_j\right),
      \end{align*}
      where we used the fact that $\eta = \sum_{i\in I}P_i\left(\eta\right)$ to move from the second to the third line. Thus, since unitary equivalence preserves norm, $\left[T\right]$ and $T$ have the same norm.
    \item We have shown that conjugation is an isometric $\ast$-isomorphism.
  \end{enumerate}
\end{proof}
\begin{remark}
  We will write $\left[T\right]_{\mathcal{M}}$ as
  \begin{align*}
    \left[T\right]_{\mathcal{M}} &= \left(T_{ij}\right)_{ij}
  \end{align*}
  to denote the matrix representation of $T$ with respect to the family $\mathcal{M}$.
\end{remark}
\begin{proposition}
  Let $\mathcal{H}$ be an internal direct sum of $\mathcal{M} = \set{M_{i}}_{i\in I}$. Suppose $T\in \B\left(\mathcal{H}\right)$.\newline

  If each $M_i$ is invariant for $T$, then each $M_i$ reduces $T$, and the matrix representation of $T$ with respect to $\mathcal{M}$ is the external direct sum
  \begin{align*}
    \left[T\right]_{\mathcal{M}} &= \bigoplus_{i\in I}T_{M_i}.
  \end{align*}
\end{proposition}
\begin{proof}
  We will start by showing that each $M_i$ reduces $T$. For a fixed $j\in I$, if $x\in M_j^{\perp}$, then there are $x_i\in M_i$ with
  \begin{align*}
    x &= \sum_{\substack{i\in I\\i\neq j}}x_i.
  \end{align*}
  By continuity, we have
  \begin{align*}
    T\left(x\right) &= \sum_{\substack{i\in I\\i\neq j}}T\left(x_i\right).
  \end{align*}
  Since $T\left(x_i\right)\in M_i$ for each $i\in I$, for any $y\in M_j$, we have
  \begin{align*}
    \iprod{T\left(x\right)}{y} &= \iprod{\sum_{\substack{i\in I\\i\neq j}}T\left(x_i\right)}{y}\\
                               &= \sum_{\substack{i\in I\\i\neq j}} \iprod{T\left(x_i\right)}{y}\\
                               &= 0,
  \end{align*}
  so $T\left(M_{j}^{\perp}\right)\subseteq M_{j}^{\perp}$.\newline

  If $P_i$ denotes the orthogonal projection onto $M_i$, we note that $P_iP_j = 0$ for $i\neq j$ since $M_i$ are mutually orthogonal. Additionally, all the $P_i$ commute with $T$, so if $i\neq j$, $T_{ij} = P_iTP_j = TP_iP_j = 0$. Thus,
  \begin{align*}
    \left[T\right]_{\mathcal{M}}\left(\left(\xi_i\right)_i\right) &= \left(\sum_{j\in I}T_{ij}\left(\xi_j\right)\right)_i\\
                                                                  &= \left(T_{ii}\left(\xi_i\right)\right)_i\\
                                                                  &= \left(P_iTP_i\left(\xi_i\right)\right)_i\\
                                                                  &= \left(P_iT\left(\xi_i\right)\right)_i\\
                                                                  &= \left(TP_i\left(\xi_i\right)\right)_i\\
                                                                  &= \left(T\left(\xi_i\right)\right)_i\\
                                                                  &= \left(\sum_{i\in I}T_{M_i}\right)\left(\left(\xi_i\right)_i\right).
  \end{align*}
\end{proof}
\begin{definition}
  Let $\mathcal{H}$ be a Hilbert space.
  \begin{itemize}
    \item A bounded operator $T\in \B\left(\mathcal{H}\right)$ is said to be block-diagonalizable if there exists a family $\mathcal{M} = \set{M_i}_{i\in I}$ of closed subspaces of $\mathcal{H}$ with $\mathcal{H} = \bigoplus_{i\in I}M_i$, with each $M_i$ reducing $T$. We say $T$ is block-diagonal with respect to $\mathcal{M}$.\newline

      If $T$ is block-diagonal with respect to $\mathcal{M}$, then we write $\left[T\right] = \bigoplus_{i\in I}T_{M_i}$. We say $T$ is the internal direct sum and write $T = \bigoplus_{i\in I}T_{M_i}$.
    \item A bounded operator $T\in \B\left(\mathcal{H}\right)$ is said to be diagonalizable if it is block-diagonalizable with each $M_i$ having $\Dim\left(M_i\right) = 1$.
  \end{itemize}
\end{definition}
\begin{proposition}
  Let $\mathcal{H}$ be a Hilbert space, and suppose $M\subseteq \mathcal{H}$ reduces $T\in \B\left(\mathcal{H}\right)$. Setting $T_M = T|_{M}$ and $T_{M^{\perp}} = T|_{M^{\perp}}$. Then,
  \begin{align*}
    T &= T_{M}\oplus T_{M^{\perp}}.
  \end{align*}
\end{proposition}
\begin{proof}
  Since $M$ reduces $T$, both $M$ and $M^{\perp}$ are invariant for $T$, so $T = T_{M} \oplus T_{M^{\perp}}$.
\end{proof}
\begin{proposition}
  Let $\mathcal{M} = \set{M_i}_{i\in I}$ be a family of closed subspaces of $\mathcal{H}$, with $\mathcal{H} = \sum_{i\in I}M_i$. Write $P_i$ to be the orthogonal projection to be the orthogonal projection onto $M_i$. For every $T\in \B\left(\mathcal{H}\right)$, the unconditional sum $\sum_{i\in I}P_iTP_i$ converges in the strong operator topology.\newline

  Letting $\mathbb{E}_{\mathcal{M}}\colon \B\left(\mathcal{H}\right)$ be defined by
  \begin{align*}
    \mathbb{E}_{\mathcal{M}}\left(T\right) &= \sum_{i\in I}P_iTP_i,
  \end{align*}
  the following are true:
  \begin{enumerate}[(1)]
    \item $\mathbb{E}_{\mathcal{M}}$ is linear, positive, contractive, and faithful;
    \item 
      \begin{align*}
        \Ran\left(\mathbb{E}_{\mathcal{M}}\right) = R_{\mathcal{M}} = \set{T\in \B\left(\mathcal{H}\right) | T\text{ is block diagonal with respect to $\mathcal{M}$}},
      \end{align*}
      and $\mathbb{E}_{\mathcal{M}}\left(S\right) = S$ for every $S\in R_{\mathcal{M}}$;
    \item If $T\in \B\left(\mathcal{H}\right)$ and $S\in R_{\mathcal{M}}$, then
      \begin{align*}
        \mathbb{E}_{\mathcal{M}}\left(ST\right) &= S\circ \mathbb{E}_{\mathcal{M}}\left(T\right)\\
        \mathbb{E}_{\mathcal{M}}\left(TS\right) &= \mathbb{E}_{\mathcal{M}}\left(T\right) \circ S.
      \end{align*}
  \end{enumerate}
  We say $\mathbb{E}_{\mathcal{M}}$ is the conditional expectation onto $R_{\mathcal{M}}$.
\end{proposition}
\begin{proof}\hfill
  \begin{enumerate}[(1)]
    \item For a given $\xi\in \mathcal{H}$, we find
      \begin{align*}
        \sum_{i\in I}\norm{P_iTP_i\left(\xi\right)}^2 &\leq \sum_{i\in I}\norm{TP_i\left(\xi\right)}^2\\
                                                      &\leq \norm{T}_{\text{op}}^2\sum_{i\in I}\norm{P_i\left(\xi\right)}^2\\
                                                      &= \norm{T}_{\text{op}}^2\norm{\xi}^2.
      \end{align*}
      Thus, $\sum_{i\in I}P_iTP_i\left(\xi\right)$ is summable in $\mathcal{H}$, and
      \begin{align*}
        \norm{\sum_{i\in I}P_iTP_i\left(\xi\right)}^2 &= \sum_{i\in I}\norm{P_iTP_i\left(\xi\right)}^2\\
                                                      &\leq \norm{T}_{\text{op}}^2\norm{\xi}^2.
      \end{align*}
      The map $S\colon \mathcal{H}\rightarrow \mathcal{H}$ defined by
      \begin{align*}
        S\left(\xi\right) &= \sum_{i\in I}P_iTP_i\left(\xi\right)
      \end{align*}
      is well-defined, linear, and bounded with $\norm{S}_{\text{op}}\leq \norm{T}_{\text{op}}$. It follows that $\mathbb{E}_{\mathcal{M}}$ is contractive, as well as linearity and positivity, as $\B\left(\mathcal{H}\right)_{+}$ is SOT-closed.\newline

      If $T^{\ast}T \geq 0$ and $E_{\mathcal{M}}\left(T^{\ast}T\right) = 0$, then we must have $P_iT^{\ast}TP_i = 0$ for every $i\in I$, as if a net of positive operators converges in SOT to $0$, every member of the net must be zero. Thus, we have
      \begin{align*}
        \norm{TP_i}^2 &= \norm{\left(TP_i\right)^{\ast}\left(TP_i\right)}\\
                      &= \norm{P_iT^{\ast}TP_i}\\
                      &= 0,
      \end{align*}
      so $TP_i = 0$ for all $i\in I$. Given $\xi\in \mathcal{H}$, we obtain
      \begin{align*}
        T\left(\xi\right) &= T\left(\sum_{i\in I}P_i\left(\xi\right)\right)\\
                          &= \sum_{i\in I}TP_i\left(\xi\right)\\
                          &= 0,
      \end{align*}
      meaning $T = 0$ and $\mathbb{E}_{\mathcal{M}}$ is a faithful map.
    \item Multiplication by a fixed operator is SOT-continuous, so for all $j\in I$, we see that
      \begin{align*}
        P_j \mathbb{E}_{\mathcal{M}}\left(T\right) &= E_{\mathcal{M}}\left(T\right)P_{j}\\
                                                   &= P_jTP_j,
      \end{align*}
      which means each $M_j$ reduces $\mathbb{E}_{\mathcal{M}}\left(T\right)$, so $E_{\mathcal{M}}\left(T\right)\in R_{\mathcal{M}}$. If each $M_i$reduces $S\in \B\left(\mathcal{H}\right)$, then $SP_i = P_iS = P_iSP_i$< so>
      \begin{align*}
        \mathbb{E}_{\mathcal{M}}\left(S\right) &= \sum_{i\in I}P_iSP_i\\
                                               &= \sum_{i\in I}SP_i\\
                                               &= S\left(\sum_{i\in I}P_i\right)\\
                                               &= SI\\
                                               &= S.
      \end{align*}
    \item Since we have $SP_i = P_iS = P_iSP_i$, we have
      \begin{align*}
        \mathbb{E}_{\mathcal{M}}\left(ST\right) &= \sum_{i\in I}P_iSTP_i\\
                                                &= \sum_{i\in I}SP_iTP_i\\
                                                &= S\left(\sum_{i\in I}P_iTP_i\right)\\
                                                &= S\circ \mathbb{E}_{\mathcal{M}}\left(T\right).
      \end{align*}
      Similarly, $\mathbb{E}_{\mathcal{M}}\left(TS\right) = \mathbb{E}_{\mathcal{M}}\left(T\right) \circ S$.
  \end{enumerate}
\end{proof}
We can now study the spectral decomposition of a diagonalizable operator.
\begin{proposition}
  Let $T\in \B\left(\mathcal{H}\right)$. The following are equivalent:
  \begin{enumerate}[(i)]
    \item $T$ is diagonalizable;
    \item there is an orthonormal basis $\left(e_i\right)_{i\in I}$ of $\mathcal{H}$ and a bounded family $\left(\mu_i\right)_{i\in I}$ of scalars with $T\left(e_i\right) = \mu_ie_i$ for each $i\in I$;
    \item there is an internal direct sum decomposition, $\mathcal{H} = \bigoplus_{j\in J}E_j$, with $E_j\neq \set{0}$ for all $j$, and a family $\set{\lambda_j}_{j\in J}$ of distinct scalars such that
      \begin{align*}
        T &= \bigoplus_{j\in J}\lambda_j\id_{E_j}.
      \end{align*}
  \end{enumerate}
  Moreover, the following are true.
  \begin{enumerate}[(1)]
    \item The collection $\set{\mu_i}_{i\in I}$ is a complete list of eigenvalues for $T$, and $\set{\lambda_j}_{j\in J}$ is a complete list of \textit{distinct} eigenvalues for $T$.
    \item If $E_{\lambda_j}\left(T\right) = \ker\left(T - \lambda_jI\right)$ is the eigenspace for $\lambda_j$, then $E_j = E_{\lambda_j}$.
    \item If $P_j$ denotes the orthogonal projection onto $E_j$, then
      \begin{align*}
        T &= \sum_{j\in J}\lambda_jP_j
      \end{align*}
      in SOT.
    \item $\norm{T}_{\text{op}} = \sup_{j\in J}\left\vert \lambda_j \right\vert$.
  \end{enumerate}
\end{proposition}
\begin{proof}
  To see (i) implies (ii), let $T$ be diagonalizable. Then, there is an internal direct sum decomposition $\mathcal{H} = \sum_{i\in I}M_i$, with each $M_i$ reducing $T$, and $\Dim\left(M_i\right) = 1$ for each $i$. We assume $M_i = \Span\left(e_i\right)$, for $e_i\in \mathcal{H}$ and $\norm{e_i} = 1$.\newline

  Since $M_i$ reduces $T$, we must have $T\left(e_i\right) = \mu_ie_i$ for scalars $\mu_i\in \C$. We see that $\left\vert \mu_i \right\vert = \norm{\mu_ie_i} \leq \norm{T}_{\text{op}}$, so we find our respective families $\left(e_i\right)_{i\in I}$ and $\left(\mu_i\right)_{i\in I}$.\newline

  To see (ii) implies (i), for each $i\in I$ we set $M_i = \Span\left(e_i\right)$, so $\mathcal{H} = \bigoplus_{i\in I}M_i$, and each $M_i$ is invariant under $T$. This yields $T$ as diagonalizable with respect to $\set{M_i}_{i\in I}$.\newline

  To see (ii) implies (iii), we partition $I$ into $I = \bigsqcup_{j\in J}I_j$, where $i,i'\in I_j$ implies $\mu_i = \mu_{i'}$, and $i\in I_j,i'\in I_{j'}$ with $j\neq j'$ implies $\mu_{i} \neq \mu_{i'}$. For each $j\in J$, we set
  \begin{align*}
    E_j &= \overline{\Span}\set{e_i|i\in I_j},
  \end{align*}
  and $\lambda_j = \mu_i$ for any $i\in I_j$. It is the case that $\set{E_j}_{j\in J}$ are mutually orthogonal, and the sum $\sum_{j\in J}E_j$ is dense in $\mathcal{H}$ by the definition of an orthonormal basis. Thus, $\mathcal{H} = \bigoplus_{j\in J}E_j$.\newline

  Since $T\left(e_i\right) = \mu_ie_i$ for each $i\in I$, linearity and continuity of $T$ imply that $T_{E_j} = \lambda_j\id_{E_j}$. Thus, each $E_j$ is invariant for $T$, meaning it is reducing, so we have $T = \bigoplus_{j\in J}\lambda_j\id_{E_j}$.\newline

  To see (iii) implies (ii), for each $j\in J$, let $\mathcal{E}_{j}$ be an orthonormal basis for $E_j$. Then, $\mathcal{E} = \bigoplus_{j\in J}\mathcal{E}_j$ is an orthonormal basis for $\mathcal{H}$. If $e\in \mathcal{E}$, then $e\in \mathcal{E}_j$ for some $j$, so $T\left(e\right) = \lambda_je_j$.\newline

  We now turn our attention towards evaluating facts (1)--(3).
  \begin{enumerate}[(1)]
    \item All the $\mu_i$ are eigenvalues for $T$, just by definition. Suppose $\lambda$ is an eigenvalue for $T$. That is, there exists $x\neq 0$ with $T\left(x\right) = \lambda x$. By Parseval's theorem, we can write $x = \sum_{i\in I} \iprod{x}{e_i} e_i$. Thus,
      \begin{align*}
        T\left(x\right) &= T\left(\sum_{i\in I} \iprod{x}{e_i}e_i\right)\\
                        &= \sum_{i\in I} \iprod{x}{e_i}T\left(e_i\right)\\
                        &= \sum_{i\in I} \iprod{x}{e_i}\mu_ie_i.
      \end{align*}
      We also have
      \begin{align*}
        T\left(x\right) &= \lambda x\\
                        &= \lambda\left(\sum_{i\in I} \iprod{x}{e_i}e_i\right)\\
                        &= \sum_{i\in I} \iprod{x}{e_i}\lambda e_i.
      \end{align*}
      For each $k\in I$, we apply the rank-one projection onto $\Span\left(e_k\right)$ to both expressions, yielding
      \begin{align*}
        \iprod{x}{e_k}\mu_ke_k &= \iprod{x}{e_k}\lambda e_k
      \end{align*}
      for each $k\in I$. Thus, $ \iprod{x}{e_k}\left(\mu_k - \lambda\right) = 0 $ for every $k\in I$. If $\lambda \notin \set{\mu_i}_{i\in I}$, then $ \iprod{x}{e_k} = 0 $ for all $k\in I$, implying $x = 0$, which is a contradiction. Thus, $\lambda = \mu_i$ for some $i\in I$.
    \item By the definition of $E_j$, it is the case that $E_j \subseteq E_{\lambda_j}\left(T\right)$. Suppose $T\left(x\right) = \lambda_j x$ for some $x\in \mathcal{H}$. Then, we find, by (3)
      \begin{align*}
        \sum_{k\in I}\lambda_jP_k\left(x\right) &= \lambda_j\left(\sum_{k\in I}P_k\left(x\right)\right)\\
                                                &= \lambda_j x\\
                                                &= T\left(x\right)\\
                                                &= \sum_{k\in J}\lambda_kP_k\left(x\right),
      \end{align*}
      meaning $\left(\lambda_j - \lambda_k\right)P_k\left(x\right) = 0$ for all $k\in I$. If $k\neq j$, we must have $P_k\left(x\right) = 0$, so $x = P_j\left(x\right) \in E_j$.
    \item Since $T$ is reduced by $\set{E_j}_{j\in J}$, we find that, for $P_j$ defined as the orthogonal projection onto $E_j$,
      \begin{align*}
        T &= \sum_{j\in J}P_jTP_j\\
          &= \sum_{j\in J}TP_j\\
          &= \sum_{j\in J}\lambda P_j
      \end{align*}
      in SOT.
    \item By construction, $\sup_{i\in I}\left\vert \mu_i \right\vert = \sup_{j\in J}\left\vert \lambda_j \right\vert$. We must have $\norm{T}_{\text{op}} \geq \norm{T\left(e_i\right)} = \left\vert \mu_i \right\vert$, so $\norm{T}_{\text{op}} \geq \sup_{i\in I}\left\vert \mu_i \right\vert$.\newline

      Given $x\in \mathcal{H}$, we use Parseval's theorem to compute
      \begin{align*}
        \norm{T\left(x\right)}^2 &= \norm{T\left(\sum_{i\in I} \iprod{x}{e_i}e_i\right)}^2\\
                                 &= \norm{\sum_{i\in I} \iprod{x}{e_i}T\left(e_i\right)}^2\\
                                 &= \norm{\sum_{i\in I} \iprod{x}{e_i}\mu_ie_i}^2\\
                                 &= \sum_{i\in I}\left\vert \iprod{x}{e_i} \right\vert^2 \left\vert \mu_i \right\vert^2\\
                                 &\leq \left(\sup_{i\in I}\left\vert \mu_i \right\vert^2\right)\sum_{i\in I} \left\vert \iprod{x}{e_i} \right\vert^2\\
                                 &= \left(\sum_{i\in I}\left\vert \mu_i \right\vert^2\right)\norm{x}^2.
      \end{align*}
      Thus, $\norm{T}_{\text{op}} \leq \sup_{i\in I}\left\vert \mu_j \right\vert$, so $\norm{T}_{\text{op}} = \sup_{i\in I}\left\vert \mu_i \right\vert = \sup_{j\in J}\left\vert \lambda_j \right\vert$.
  \end{enumerate}
\end{proof}
\begin{corollary}
  If $T\in \B\left(\mathcal{H}\right)$ is diagonalizable, then so is $T^{\ast}$. Additionally, $T$ is normal.
\end{corollary}
\begin{proof}
  Let $\left(e_i\right)_{i\in I}$ and $\left(\mu_i\right)_{i\in I}$ be as above. For all $i,j\in I$, we have
  \begin{align*}
    \iprod{e_j}{T^{\ast}\left(e_i\right)} &= \iprod{T\left(e_j\right)}{e_i}\\
                                          &= \iprod{\mu_je_j}{e_i}\\
                                          &= \mu_j \iprod{e_j}{e_i}\\
                                          &= \mu_i \iprod{e_j}{e_i}\\
                                          &= \iprod{e_j}{\overline{\mu_i}e_i}.
  \end{align*}
  Thus, we find $ \iprod{x}{T^{\ast}\left(e_i\right)} = \iprod{x}{\overline{\mu_i}e_i} $ for every $x\in \Span\set{e_j|j\in I}$, and by continuity, it follows that $T^{\ast}\left(e_i\right) = \overline{\mu_i}e_i$. It follows that $T^{\ast}$ is diagonalizable.\newline

  Note that $T^{\ast}T\left(e_i\right) = \left\vert \mu_i \right\vert^2e_i = TT^{\ast}\left(e_i\right)$ for all $i\in I$. Thus, $T^{\ast}T\left(x\right) = TT^{\ast}\left(x\right)$ for all $x\in \mathcal{H}$, so $T$ is normal.
\end{proof}
\begin{example}
  If $\lambda = \left(\lambda_n\right)_n$ belongs to $\ell_{\infty}$, then $D_{\lambda}$ is diagonalizable, since $D\left(e_n\right) = \lambda_ne_n$, where $\left(e_n\right)_n$ is the standard basis on $\ell_2$. Thus, $\left(\lambda_n\right)_n$ is a complete list of eigenvalues.
\end{example}
\subsection{The Matrix Algebra and Double Commutant Theorem}%
Fix a Hilbert space $\mathcal{H}$, and let
\begin{align*}
  \Mat_n\left(\B\left(\mathcal{H}\right)\right) &= \set{\left(T_{ij}\right)_{i,j=1}^{n} | T_{ij}\in \B\left(\mathcal{H}\right)}.
\end{align*}
This is a $\ast$-algebra that is $\ast$-isomorphic to $\Mat_n\left(\C\right) \otimes \B\left(\mathcal{H}\right)$. We would like to view each matrix $\left(T_{ij}\right)_{i,j=1}^{n}$ as an operator on the $n$-fold direct sum $\mathcal{H}^{(n)}$, similar to the way $n\times n$ matrix acts on a vector in $\ell_2^{n}$.
\begin{proposition}
  Let $\mathcal{H}$ be a Hilbert space, and suppose $\left(T_{ij}\right)_{i,j=1}^{n}\in \Mat_{n}\left(\B\left(\mathcal{H}\right)\right)$. The map $\left[T_{ij}\right]\colon \mathcal{H}^{(n)}\rightarrow \mathcal{H}^{(n)}$, defined by
  \begin{align*}
    \left[T_{ij}\right]\left(\xi_j\right)_{j=1}^{n}\left(\sum_{j=1}^{n}T_{ij}\left(\xi_j\right)\right)_{i=1}^{n}
  \end{align*}
  defines a bounded operator with 
  \begin{align*}
    \norm{T_{ij}}_{\text{op}} &\leq \left(\sum_{i,j=1}^{n}\norm{T_{ij}}_{\text{op}}^2\right)^{1/2}.
  \end{align*}
  Moreover, the map $\left(T_{ij}\right)_{i,j=1}^{n}\mapsto \left[T_{ij}\right]$ is a unital $\ast$-isomorphism of $\ast$-algebras.
\end{proposition}
\begin{proof}
  Using the Cauchy--Schwarz inequality, we find
  \begin{align*}
    \norm{\left[T_{ij}\right]\left(\xi_j\right)_{j=1}^{n}}^2 &= \norm{\left(\sum_{j=1}^{n}T_{ij}\left(\xi_j\right)\right)_{i=1}^{n}}^2\\
                                                             &= \sum_{i=1}^{n}\norm{\sum_{j=1}^{n}T_{ij}\left(\xi_j\right)}^2\\
                                                             &\leq \sum_{i=1}^{n}\left(\sum_{j=1}^{n}\norm{T_{ij}\left(\xi_j\right)}\right)^2\\
                                                             &\leq \sum_{i=1}^{n}\left(\sum_{j=1}^{n}\norm{T_{ij}}_{\text{op}}\norm{\xi_j}\right)^2\\
                                                             &\leq \sum_{i=1}^{n}\left(\sum_{j=1}^{n}\norm{T_{ij}}_{\text{op}}^2\right)\left(\sum_{j=1}^{n}\norm{\xi_{j}}^2\right)\\
                                                             &= \left(\sum_{i,j=1}^{n}\norm{T_{ij}}_{\text{op}}^2\right)\norm{\left(\xi_j\right)_{j=1}^{n}}^2.
  \end{align*}
  Thus,
  \begin{align*}
    \norm{\left[T_{ij}\right]}_{\text{op}} \leq \left(\sum_{i,j=1}^{n}\norm{T_{ij}}_{\text{op}}^2\right)^{1/2}.
  \end{align*}
  If $\left(T_{ij}\right)_{i,j=1}^{n}$ and $\left(S_{ij}\right)_{i,j=1}^{n}$ are in $\Mat_{n}\left(\B\left(\mathcal{H}\right)\right)$, and $\alpha \in \C$, we can see that
  \begin{align*}
    \alpha \left[T_{ij}\right] + \left[S_{ij}\right] &= \left[\alpha T_{ij} + S_{ij}\right]
  \end{align*}
  as operators on $\mathcal{H}^{(n)}$. To evaluate multiplication, we see
  \begin{align*}
    \left[T_ij\right]\circ \left[S_{ij}\right]\left(\xi_{j}\right)_{j} &= \left[T_{ij}\right]\left(\left(\sum_{j=1}^{n}S_{kj}\left(\xi_j\right)\right)_{k}\right)\\
                                                                       &= \left(\sum_{k=1}^{n}T_{ik}\left(\sum_{j=1}^{n}S_{kj}\left(\xi_j\right)\right)\right)_i\\
                                                                       &= \left(\sum_{j,k=1}^{n}T_{ik}S_{kj}\left(\xi_j\right)\right)\\
                                                                       &= \left(\sum_{j=1}^{n}\left(\sum_{k=1}^{n}T_{ik}S_{kj}\right)\left(\xi_j\right)\right)_{i}\\
                                                                       &= \left[\left(\sum_{k=1}^{n}T_{ik}S_{kj}\right)_{j}\right]\left(\xi_j\right)_j\\
                                                                       &= \left[\left(T_{ij}\right)\left(S_{ij}\right)\right]\left(\xi_j\right)_j.
  \end{align*}
  Evaluating the adjoint, we find
  \begin{align*}
    \iprod{\left[T_{ij}\right]\left(\xi_i\right)_i}{\left(\eta_i\right)_i} &= \iprod{\left(\sum_{j=1}^{n}T_{ij}\left(\xi_j\right)\right)_i}{\left(\eta_i\right)_i}\\
                                                                           &= \sum_{i=1}^n \iprod{\sum_{j=1}^{n}T_{ij}\left(\xi_j\right)}{\eta_i}\\
                                                                           &= \sum_{i,j=1}^{n} \iprod{T_{ij}\left(\xi_j\right)}{\eta_i}\\
                                                                           &= \sum_{i,j=1}^{n} \iprod{\xi_j}{T_{ij}^{\ast}\left(\eta_i\right)}\\
                                                                           &= \sum_{j=1}^{n} \iprod{\xi_j}{\sum_{i=1}^{n}T_{ij}^{\ast}\left(\eta_i\right)}\\
                                                                           &= \iprod{\left(\xi_j\right)_j}{\left(\sum_{i=1}^{n}T_{ij}^{\ast}\left(\eta_i\right)\right)_{j}}\\
                                                                           &= \iprod{\left(\xi_j\right)_j}{\left[T_{ij}\right]\left(\eta_j\right)_j}.
  \end{align*}
  Thus, $\left[T_{ij}\right]^{\ast} = \left[T_{ij}^{\ast}\right]$, meaning the map $\left(T_{ij}\right)_{i,j}\mapsto \left[T_{ij}\right]$ is an injective $\ast$-homomorphism.\newline

  To show surjectivity, let $T\in \B\left(\mathcal{H}^{(n)}\right)$ be arbitrary. Set $T_{ij} = \pi_iT\iota_j$, where $\pi_i\colon \mathcal{H}^{(n)}\rightarrow \mathcal{H}$ and $\iota_j\colon \mathcal{H}\rightarrow \mathcal{H}^{(n)}$ are the canonical projections and injections respectively. We claim that $\left[T_{ij}\right] = T$ on $\mathcal{H}^{(n)}$.\newline

  If $\xi = \left(\xi_i\right)_i \in \mathcal{H}^{(n)}$, then
  \begin{align*}
    \left[T_{ij}\right]\left(\xi\right) &= \left(\sum_{j=1}^{n}T_{ij}\left(\xi_j\right)\right)_{i=1}^{n}\\
                                        &= \left(\sum_{j=1}^{n}\pi_iT\iota_j\left(\xi_j\right)\right)_{i=1}^{n}\\
                                        &= \left(\pi_iT\left(\sum_{j=1}^{n}\iota_j\xi_j\right)\right)_{i=1}^{n}\\
                                        &= \left(\pi_iT\left(\xi\right)\right)_{i=1}^{n}\\
                                        &= T\left(\xi\right).
  \end{align*}
\end{proof}
\begin{remark}
  We will let $\diag\left(T_1,\dots,T_n\right)$ denote the operator $\left[T_{ij}\right]$ where $T_{ii} = T_i$ and $T_{ij} = 0$ for $i\neq j$. If $T\in \B\left(\mathcal{H}\right)$, the $n$-fold amplification $T^{(n)}$ on $\mathcal{H}^{(n)}$ is precisely $\diag\left(T,\dots,T\right)$.
\end{remark}
Since $\B\left(\mathcal{H}^{(n)}\right)$ is a $C^{\ast}$-algebra, we may identify $\Mat_{n}\left(\B\left(\mathcal{H}\right)\right)$ with $\B\left(\mathcal{H}^{(n)}\right)$, and use the given complete $C^{\ast}$-norm to find one on $\Mat_{n}\left(\B\left(\mathcal{H}\right)\right)$.
\begin{corollary}[]
  If $\mathcal{H}$ is a Hilbert space, and $n\geq 1$ is an integer, the $\ast$-algebra is a $C^{\ast}$-algebra when equipped with the norm
  \begin{align*}
    \norm{\left(T_{ij}\right)_{i,j=1}^{n}} = \norm{\left[T_{ij}\right]}_{\text{op}}.
  \end{align*}
\end{corollary}
We may now use the $n$-fold amplifications to resolve some properties of the double commutant. Recall that if $A\subseteq \B\left(\mathcal{H}\right)$ is a $\ast$-subalgebra of bounded operators, then $A''$ is a von Neumann algebra containing $A$. The Double Commutant Theorem actually shows that, under some mild conditions, $A''$ is actually the von Neumann algebra generated by $A$.
\begin{definition}[]
  Let $\mathcal{H}$ be a Hilbert space, and suppose $A\subseteq \B\left(\mathcal{H}\right)$ is a subset. We define
  \begin{align*}
    A^{(n)} &= \set{a^{(n)} | a\in A}
  \end{align*}
  to be the $n$-fold amplification of $A$. The kernel of $A$ is defined to be
  \begin{align*}
    \ker\left(A\right) &= \set{\xi\in \mathcal{H} | a\left(\xi\right) = 0,~\forall a\in A}.
  \end{align*}
  We say $A$ acts non-degenerately on $\mathcal{H}$ if $\ker\left(A\right) = \set{0}$.
\end{definition}
\begin{exercise}
  Let $A\subseteq \B\left(\mathcal{H}\right)$ be a $\ast$-subalgebra of operators. Prove that $A$ acts non-degenerately on $\mathcal{H}$ if and only if $\left[A \mathcal{H}\right] = \mathcal{H}$. If $A$ is unital, show that $A$ acts non-degenerately.
\end{exercise}
\begin{solution}
  We have that $A$ acts degenerately if and only if $\ker\left(A\right)\neq \set{0}$, meaning there exists some $\xi\neq 0$ such that $a\left(\xi\right) = 0$ for all $a\in A$, meaning that $\overline{\Span}\set{a\left(\xi\right) | a\in A} = 0$, meaning $\xi\in \left[A\mathcal{H}\right]^{\perp}$, so $\left[A\mathcal{H}\right]^{\perp}\neq \mathcal{H}$. The reverse direction follows from the fact that if $A$ is a $\ast$-subalgebra with $\left[A\mathcal{H}\right] = \mathcal{H}$, then $\mathcal{H}^{\perp} = \set{0}$, so $a\xi = 0$ for all $a\in A$ if and only if $\xi = 0$.
\end{solution}
\begin{lemma}
  Let $\mathcal{H}$ be a Hilbert space, and suppose $A\subseteq \B\left(\mathcal{H}\right)$ is a $\ast$-subalgebra.
  \begin{enumerate}[(1)]
    \item The collection $A^{(n)}\subseteq \B\left(\mathcal{H}^{(n)}\right)$ is also a $\ast$-subalgebra.
    \item If $\ker\left(A\right) = \set{0}$, then $\ker\left(A^{(n)}\right) = \set{0}$. Thus, if $A$ acts non-degenerately, then so does $A^{(n)}$.
    \item If $x\in A''$, then $x^{(n)}\in \left(A^{(n)}\right)''$.
  \end{enumerate}
\end{lemma}
\begin{proof}\hfill
  \begin{enumerate}[(1)]
    \item This result follows from the properties of $A^{(n)} = \bigoplus_{i=1}^{n}A$.
    \item If $\ker\left(A\right) = \set{0}$, then $ \diag\left(A,\dots,A\right)\left(\xi_j\right)_j = 0$ if and only if $\xi_j = 0$ for all $j$. Thus, $\ker\left(A^{(n)}\right) = \set{0}$.
    \item We identify $\Mat_{n}\left(\B\left(\mathcal{H}\right)\right)$ with $\B\left(\mathcal{H}^{(n)}\right)$. Let $x\in A''$, and $T = \left(T_{ij}\right)_{ij}\in \left(A^{(n)}\right)'$. Then,
      \begin{align*}
        \left(T_{ij}a\right)_{ij} &= \left(T_{ij}\right)_{ij}a^{(n)}\\
                                               &= a^{(n)}\left(T_{ij}\right)_{ij}\\
                                               &= \left(aT_{ij}\right)_{ij},
      \end{align*}
      meaning $T_{ij}a = aT_{ij}$ for all $a\in A$ and all $i,j$. Thus, for all $i,j$, we have $T_{ij}\in A'$, meaning $xT_{ij} = T_{ij}x$ for all $i,j$. Thus,
      \begin{align*}
        \left(T_{ij}\right)_{ij}x^{(n)} &= \left(T_{ij}x\right)_{ij}\\
                                        &= \left(xT_{ij}\right)_{ij}\\
                                        &= x^{(n)}\left(T_{ij}\right)_{ij}.
      \end{align*}
      Thus, $x^{(n)}\in \left(A^{(n)}\right)''$.
  \end{enumerate}
\end{proof}
\begin{lemma}
  Let $\mathcal{H}$ be a Hilbert space with $\xi\in \mathcal{H}$, and let $A\subseteq \B\left(\mathcal{H}\right)$ be a non-degenerate $\ast$-subalgebra.
  \begin{enumerate}[(1)]
    \item The closed subspace $\mathcal{K} = \left[A\xi\right]$ reduces $A$, and $\xi\in \mathcal{K}$.
    \item If $b\in A''$ and $\ve > 0$, there is $a\in A$ with $\norm{a\left(\xi\right) - b\left(\xi\right)} < \ve$.
  \end{enumerate}
\end{lemma}
\begin{proof}\hfill
  \begin{enumerate}[(1)]
    \item We have established that $\mathcal{K}$ reduces $A$ earlier. Now, we show that $\xi\in \mathcal{K}$. Let $P$ be the orthogonal projection onto $\mathcal{K}$. Thus, $P\in A'$, so $P^{\perp} = I-P \in A'$. Since $a\left(\xi\right) \in \mathcal{K}$ for all $a\in A$, we have
      \begin{align*}
        aP^{\perp}\left(\xi\right) &= P^{\perp}a\left(\xi\right)\\
                                   &= 0
      \end{align*}
      for all $a\in A$. Since $\ker\left(A\right) = \set{0}$, we must have $P^{\perp}\left(\xi\right) = 0$, so $P\left(\xi\right) = \xi$, so $\xi\in \mathcal{K}$.
    \item With $P$ as the orthogonal projection onto $\mathcal{K}$, we see that $bP = Pb$, since $P\in A'$ Thus, using $P\left(\xi\right) = \xi$, we have
      \begin{align*}
        b\left(\xi\right)&= bP\left(\xi\right)\\
                         &= Pb\left(\xi\right)\\
                         &\in \mathcal{K},
      \end{align*}
      meaning, by the definition of the closed span, there is an $a\in A$ with $\norm{a\left(\xi\right) - b\left(\xi\right)} < \ve$.
  \end{enumerate}
\end{proof}
\begin{proof}
  Since $A\subseteq A''$, and $A''$ is WOT-closed, we see that $\overline{A}^{\text{SOT}}\subseteq \overline{A}^{\text{WOT}} \subseteq A''$. It is thus sufficient to show that $A'' \subseteq \overline{A}^{\text{SOT}}$.\newline
  
  Let $b\in A''$, and consider a basic SOT-open neighborhood of $b$, which is of the form
  \begin{align*}
    U &= \bigcap_{j=1}^{n}\set{T\in \B\left(\mathcal{H}\right) | \norm{T\left(\xi_j\right) - b\left(\xi_j\right)} < \ve},
  \end{align*}
  where $\ve > 0$ and $\xi_1,\dots,\xi_n\in \mathcal{H}$. We only need to show that $U\cap A$ is nonempty. Set $\xi = \left(\xi_1,\dots,\xi_n\right)\in \mathcal{H}^{(n)}$ (as a column vector).\newline

  We are aware that $A^{(n)}\subseteq \B\left(\mathcal{H}^{(n)}\right)$ is a $\ast$-subalgebra with $\ker\left(A^{(n)}\right) = \set{0}$ and $b^{(n)}\subseteq \left(A^{(n)}\right)''$. Thus, we find $a^{(n)}$ with
  \begin{align*}
    \left(\sum_{j=1}^{n}\norm{a\left(\xi_j\right) - b\left(\xi_j\right)}^2\right)^{(1/2)} &= \norm{ \begin{pmatrix}a\left(\xi_1\right) - b\left(\xi_1\right)\\\vdots\\ a\left(\xi_n\right) - b\left(\xi_n\right)\end{pmatrix} }_{\mathcal{H}^{(n)}}\\
                                                                                          &= \norm{a^{(n)}\left(\xi\right) - b^{(n)}\left(\xi\right)}_{\mathcal{H}^{(n)}}\\
                                                                                          &< \ve,
  \end{align*}
  meaning that $\norm{a\left(\xi_j\right) - b\left(\xi_j\right)} < \ve$ for all $j = 1,\dots,n$, so $a\in U$.
\end{proof}
\begin{corollary}
  Let $A\subseteq \B\left(\mathcal{H}\right)$ be a unital $\ast$-subalgebra of operators. Then, $A$ is a von Neumann algebra if and only if $A = A''$.
\end{corollary}
\begin{definition}
  Let $\mathcal{H}$ be a Hilbert space. A MASA (maximal abelian self-adjoint algebra) in $\B\left(\mathcal{H}\right)$ is a maximal commutative $\ast$-algebra $N\subseteq \B\left(\mathcal{H}\right)$. A MASA is a maximal element of the set
  \begin{align*}
    \mathcal{A} &= \set{A\subseteq \B\left(\mathcal{H}\right) | A\text{ is a commutative $\ast$-algebra}}
  \end{align*}
  ordered by inclusion.
\end{definition}
\begin{remark}
  MASAs do exist --- since $\set{0}$  is an abelian self-adjoint subalgebra, and the union of any chain in $\mathcal{A}$ is also an abelian self-adjoint subalgebra, so Zorn's lemma provides a maximal element.
\end{remark}
\begin{proposition}
  Let $A$ be a commutative $\ast$-subalgebra of $\B\left(\mathcal{H}\right)$. Then, $A$ is a MASA if and only if $A = A'$.
\end{proposition}
\begin{proof}
  Let $A$ be a MASA. Since $A$ is commutative, we see that $A\subseteq A'$. Let $u\in A'$ be self-adjoint. The $\ast$-algebra $B$ generated by $A$ and $u$ is commutative and contains $A$, so by maximality, we must have $B = A$, meaning $u\in A$. Additionally, $A'$ is a $\ast$-subalgebra, so for a given $x\in A'$, we may write the Cartesian decomposition $x = u + iv$, where $u,v\in A'$ are self-adjoint. Thus, $u,v\in A$, so $x\in A$, so $A = A'$.\newline

  Conversely, if $A = A'$, and $B$ is a commutative $\ast$-subalgebra of $\B\left(\mathcal{H}\right)$ that contains $A$, we must have $B\subseteq B' \subseteq A' = A$, so $A = B$, meaning $A$ is a MASA.
\end{proof}
\begin{proposition}
  Let $\left(\Omega,\mathcal{M},\mu\right)$ be a $\sigma$-finite measure space. The multiplication operators, $\mathcal{L}_{\infty}\left(\Omega,\mu\right)\subseteq \B\left(L_{2}\left(\Omega,\mu\right)\right)$ is a MASA.
\end{proposition}
\begin{proof}
  We start with finite $\mu$, in which case every indicator function $\1_E$, where $E\in \mathcal{M}$, is an element of $L_2\left(\Omega,\mu\right)$. Essentially bounded functions are norm-dense in $L_2\left(\Omega,\mu\right)$.\newline

  We see that $\mathcal{L}_{\infty}\left(\Omega,\mu\right)$ is a unital commutative $\ast$-subalgebra, so we only need verify that any operator $T\in \mathcal{L}_{\infty}\left(\Omega,\mu\right)'$ belongs to $\mathcal{L}_{\infty}\left(\Omega,\mu\right)$. Let $g = T\left(\1_{\Omega}\right)$.\newline

  If $f\in L_{\infty}\left(\Omega,\mu\right)$, then
  \begin{align*}
    fg &= M_{f}\left(g\right)\\
       &= M_{f}T\left(\1_{\Omega}\right)\\
       &= TM_f\left(\1_{\Omega}\right)\\
       &= T\left(f\right).
  \end{align*}
  Thus,
  \begin{align*}
    \norm{fg} &= \norm{T\left(f\right)}\\
              &\leq \norm{T}_{\text{op}}\norm{f}
  \end{align*}
  where $\norm{\cdot}$ is the $L_2$ norm. Let $C > 0$ be such that $E_{C} = \set{x | \left\vert g(x) \right\vert \geq C}$ has strictly positive measure. Thus, we get
  \begin{align*}
    C^2\mu\left(E_C\right) &= \int_{E_C}^{} C^2\:d\mu\\
                           &\leq \int_{E_C}^{} \left\vert g \right\vert^2\:d\mu\\
                           &= \norm{\1_{E_C}g}^2\\
                           &\leq \norm{T}_{\text{op}}^2\norm{\1_{E_C}}^2\\
                           &\leq \norm{T}_{\text{op}}\mu\left(E_C\right),
  \end{align*}
  meaning $C \leq \norm{T}_{\text{op}}$. Thus, $g\in L_{\infty}\left(\Omega,\mu\right)$, and $\norm{g}_{\infty}\leq \norm{T}_{\text{op}}$. Thus, we see that $T$ agrees with $M_{g}$ on all essentially bounded functions --- however, since essentially bounded functions are norm-dense in $L_2$, we must have $T = M_g$.\newline

  In the $\sigma$-finite case, we let $\bigsqcup_{n\geq 1}E_n = \Omega$ be a partition with $\mu\left(E_n\right) < \infty$. Then, we have the internal direct sum
  \begin{align*}
    L_2\left(\Omega,\mu\right) &= \bigoplus_{n\geq 1}L_2\left(E_n,\mu_{E_n}\right),
  \end{align*}
  where $L_2\left(E_n,\mu_{E_n}\right)$ is a closed subspace of $L_2\left(\Omega,\mu\right)$. Recall that the orthogonal projection onto $L_2\left(E_n,\mu_{E_n}\right)$ is the multiplication operator $P_n = M_{\1_{E_n}}$.\newline

  If $T\in \mathcal{L}_{\infty}\left(\Omega,\mu\right)'$, then $TP_n = P_nT$ for every $n\geq 1$, so every subspace $L_2\left(E_n,\mu_{E_n}\right)$ reduces $T$, so $T$ is block-diagonal with
  \begin{align*}
    T &= \bigoplus_{n\geq 1}T_n,
  \end{align*}
  where $T_n$ is the restriction to $L_2\left(E_n,\mu_{E_n}\right)$. We can see that each $T_n\in \mathcal{L}_{\infty}\left(E_n,\mu_{E_n}\right)$, so there are $g_n\in L_{\infty}\left(E_n,\mu_{E_n}\right)$ such that $T_n = M_{g_n}$, with $\norm{g_n}_{\infty}\leq \norm{T_n}_{\text{op}}$. Thus,
  \begin{align*}
    \sup_{n\geq 1}\norm{M_{g_n}}_{\text{op}} &= \sup_{g\geq 1}\norm{g_n}_{\infty}\\
                                             &\leq \sup_{n\geq 1}\norm{T_n}_{\text{op}}\\
                                             &= \norm{T}_{\text{op}},
  \end{align*}
  meaning $\bigoplus_{n\geq 1}M_{g_n}$ is bounded and equal to $T$. Thus, the disjoint union $\bigsqcup_{n\geq 1}g_n$ is measurable and essentially bounded, with $T = M_{g}$.
\end{proof}
\begin{corollary}
  If $T\in \B\left(\mathcal{H}\right)$ is normal, then $W^{\ast}\left(T\right)= \set{T}''$.
\end{corollary}
\begin{proof}
  We know that $\set{T}'$ is a unital subalgebra of $\B\left(\mathcal{H}\right)$, and if $ST = TS$, then $ST^{\ast} = T^{\ast}S$ by Fuglede's theorem. Thus, we also get that $TS^{\ast} = S^{\ast}T$ by taking adjoints, implying that $\set{T}'$ is self-adjoint. Thus, we must have that $\set{T}''$ is a von Neumann algebra that contains $T$, so $W^{\ast}\left(T\right) \subseteq \set{T}''$.\newline

  Let $A_{T}$ be the unital subalgebra generated by $T$, and let $N$ be any von Neumann algebra containing $T$. Taking the double commutant and using the double commutant theorem, we get
  \begin{align*}
    \set{T}'' &\subseteq A_{T}''\\
              &= \overline{A_T}^{\text{WOT}}\\
              &\subseteq \overline{N}^{\text{WOT}}\\
              &= N.
  \end{align*}
  Thus, $\set{T}'' = W^{\ast}\left(T\right)$.
\end{proof}
\subsection{Finite-Rank and Compact Operators}%
Earlier, we developed a full picture of the finite-rank bounded operators between normed spaces $Y$ and $X$, seen as
\begin{align*}
  \F\left(Y,X\right) &= \set{T\in \B\left(Y,X\right) | \Dim\left(\Ran\left(T\right)\right) < \infty}\\
                     &= \set{\sum_{k=1}^{n}L_{x_k,\psi_k} | x_k\in X,\psi_k\in Y^{\ast}}.
\end{align*}
Recall that $L_{x,\psi}$ is the rank-one bounded operator defined by $L_{x,\psi}\left(y\right) = \psi(y)x$. We have also seen that there is an isometric isomorphism of normed spaces
\begin{align*}
  L\colon X\otimes Y^{\ast}\rightarrow \F\left(Y,X\right),
\end{align*}
where $X\otimes Y^{\ast}$ is endowed with the injective norm. The isometry extends to an isometric isomorphism of Banach spaces,
\begin{align*}
  \widetilde{L}\colon X\check{\otimes}Y^{\ast} \rightarrow \overline{\F\left(Y,X\right)}^{\norm{\cdot}_{\text{op}}}.
\end{align*}
We can now consider this in the context of Hilbert spaces. If $\mathcal{H}$ and $\mathcal{K}$ are Hilbert spaces, then $\mathcal{K}^{\ast}$ is isometrically isomorphic to the conjugate space $\overline{\mathcal{K}}$ by $\overline{y} \mapsto \psi_y = \iprod{\cdot}{y}$. The rank-one bounded operators have the expression
\begin{align*}
  L_{x,\psi_y}\left(z\right) &= \iprod{z}{y}x.
\end{align*}
These are often written as $\theta_{x,y}\left(z\right) = \iprod{z}{y}x$.
\begin{proposition}
  Let $\mathcal{H}$, $\mathcal{K}$, and $\mathcal{L}$ be Hilbert spaces, with $y,y'\in \mathcal{K}$, $x,x'\in \mathcal{H}$, $\alpha \in \C$, $T\in \B\left(\mathcal{H},\mathcal{L}\right)$, and $S\in \B\left(\mathcal{L},\mathcal{K}\right)$. Then, the following are true
  \begin{enumerate}[(1)]
    \item $\theta_{x,y} + \alpha \theta_{x',y} = \theta_{x + \alpha x',y}$;
    \item $\theta_{x,y} + \overline{\alpha}\theta_{x,y'} = \theta_{x,y + \alpha y'}$;
    \item $\norm{\theta_{x,y}}_{\text{op}} = \norm{x}\norm{y}$;
    \item $\left(\theta_{x,y}\right)^{\ast} = \theta_{y,x}$;
    \item $T\circ \theta_{x,y} = \theta_{T\left(x\right),y}$;
    \item $\theta_{x,y}\circ S = \theta_{x,S^{\ast}\left(y\right)}$;
    \item $\theta_{x,y}\circ \theta_{x',y'} = \iprod{x'}{y}\theta_{x,y'}$;
    \item $\theta_{x,x}\in \B\left(\mathcal{H}\right)_{+}$;
    \item $\theta_{x,x}$ is a projection if and only if $\norm{x} = 1$.
  \end{enumerate}
\end{proposition}
We can extend our knowledge of finite-rank operators from Banach spaces into Hilbert spaces as follows.
\begin{corollary}
  Let $\mathcal{H}$ and $\mathcal{K}$ be Hilbert spaces. There is a linear isomorphism between $\mathcal{H}\otimes \overline{\mathcal{K}}$ and $\F\left(\mathcal{K},\mathcal{H}\right)$, defined by $x\otimes \overline{y} \mapsto \theta_{x,y}$.\newline

  If $\mathcal{H}\otimes \overline{\mathcal{K}}$ is equipped with the injective norm, this isomorphism is isometric, and extends to an isometric isomorphism of Banach spaces
  \begin{align*}
    \mathcal{H}\check{\otimes}\overline{\mathcal{K}} \cong \overline{\F\left(\mathcal{K},\mathcal{H}\right)}^{\norm{\cdot}_{\text{op}}}.
  \end{align*}
\end{corollary}
We may use the notation $x\otimes \overline{y}$ to denote the rank=one bounded operator $\theta_{x,y}$ for a given $x\in \mathcal{H}$ and $y\in \mathcal{K}$.
\begin{corollary}
  Let $\mathcal{H}$ and $\mathcal{K}$ be Hilbert spaces. The set of finite rank bounded operators from $\mathcal{K}$ to $\mathcal{H}$ has the form
  \begin{align*}
    \F\left(\mathcal{K},\mathcal{H}\right) &= \set{\sum_{j=1}^{n}\theta_{x_j,y_j} | x_j\in \mathcal{H},y_j\in \mathcal{K}}.
  \end{align*}
  Moreover, $\F\left(\mathcal{H}\right)\subseteq \B\left(\mathcal{H}\right)$ is a $\ast$-ideal.
\end{corollary}
\begin{proof}
  We have already shown that $\F\left(\mathcal{H}\right)\subseteq \B\left(\mathcal{H}\right)$ is an algebraic ideal, as $\mathcal{H}$ is a Banach spaces. The only thing we need to show is that $\F\left(\mathcal{H}\right)$ is self-adjoint.\newline

  Let $T$ be finite-rank with $T = \sum_{j=1}^{n}\theta_{x_j,y_j}$. We find
  \begin{align*}
    T^{\ast} &= \left(\sum_{j=1}^{n}\theta_{x_j,y_j}\right)^{\ast}\\
             &= \sum_{j=1}^{n}\theta_{x_j,y_j}^{\ast}\\
             &= \sum_{j=1}^{n}\theta_{y_j,x_j}\\
             &\in \F\left(\mathcal{H}\right).
  \end{align*}
\end{proof}
We know that the $\ast$-ideal of bounded finite-rank operators is not operator norm closed if $\Dim\left(\mathcal{H}\right) = \infty$. However, the norm closure forms the compact operators, meaning that Hilbert spaces have the approximation property.
\begin{theorem}
  Let $\mathcal{H}$ and $\mathcal{K}$ be Hilbert spaces.
  \begin{enumerate}[(1)]
    \item $\overline{\F\left(\mathcal{H},\mathcal{K}\right)} = \mathbb{K}\left(\mathcal{H},\mathcal{K}\right)$.
    \item $\mathbb{K}\left(\mathcal{H}\right)\subseteq \B\left(\mathcal{H}\right)$ is a closed $\ast$-ideal, meaning $\mathbb{K}\left(\mathcal{H}\right)$ is a $C^{\ast}$-algebra.
  \end{enumerate}
\end{theorem}
\begin{proof}\hfill
  \begin{enumerate}[(1)]
    \item We know that $\overline{\F\left(\mathcal{H},\mathcal{K}\right)}\subseteq \mathbb{K}\left(\mathcal{H},\mathcal{K}\right)$, as $\mathbb{K}\left(\mathcal{H},\mathcal{K}\right)$ is closed. Fix $T\in \mathbb{K}\left(\mathcal{H},\mathcal{K}\right)$, and let $\ve > 0$.\newline

    Since $T\left(B_{\mathcal{H}}\right)$ is precompact, it is totally bounded, so there exist $y_1,\dots,y_m\in \mathcal{K}$ such that $T\left(B_{\mathcal{H}}\right)\subseteq \bigcup_{j=1}^{m}U\left(y_j,\ve/2\right)$. The subspace $M= \Span\left(y_1,\dots,y_m\right)\subseteq \mathcal{K}$ is finite-dimensional, so it is closed.\newline

    Let $P_M$ be the orthogonal projection onto $M$. Since $P_M$ is finite-rank, $P_M\circ T$ is also finite-rank, as the space of finite-rank operators is an ideal. Fix $x\in B_{\mathcal{H}}$. Then, there exists $j$ with $\norm{T\left(x\right) - y_j} < \ve/2$. Since $P_M\left(y_j\right) = y_j$, we get
    \begin{align*}
      \norm{\left(P_MT - T\right)\left(x\right)} &\leq \norm{P_MT\left(x\right) - P_M\left(y_j\right)} + \norm{P_M\left(y_j\right) - T\left(x\right)}\\
                                                 &= \norm{P_M\left(T\left(x\right) - y_j\right)} + \norm{T\left(x\right) - y_j}\\
                                                 &\leq \norm{P_M}\norm{T_x\left(y_j\right)} + \norm{T\left(x\right) - y_j}\\
                                                 &< \ve,
    \end{align*}
    where we use the fact that $\norm{P_M}_{\text{op}} \leq 1$. Since this holds for all $x\in B_{\mathcal{H}}$, we get $\norm{P_MT - T}_{\text{op}} < \ve$.
  \item Let $T\in \K\left(\mathcal{H}\right)$. There is a sequence $\left(S_n\right)_n\in \F\left(\mathcal{H}\right)$ with $\norm{S_n - T}_{\text{op}} \rightarrow 0$. Since the adjoint map is isometric, we have $\norm{S_n^{\ast} - T^{\ast}}_{\text{op}}\rightarrow 0$, and since $\F\left(\mathcal{H}\right)$ is a $\ast$-ideal, we have $T^{\ast}\in \overline{\F\left(\mathcal{H}\right)} = \K\left(\mathcal{H}\right)$.
  \end{enumerate}
\end{proof}
Thus, we may establish the following result.
\begin{corollary}
  Let $\mathcal{H}$ and $\mathcal{K}$ be Hilbert spaces. There is an isometric isomorphism of Banach spaces between $\mathcal{H}\check{\otimes} \overline{\mathcal{K}}$ and $\K\left(\mathcal{K},\mathcal{H}\right)$, defined by $x\otimes \overline{y} \mapsto \theta_{x,y}$. In particular, we have $\mathcal{H}\check{\otimes}\overline{\mathcal{H}} \cong \K\left(\mathcal{H}\right)$.
\end{corollary}
We may characterize the nonzero ideals of $\B\left(\mathcal{H}\right)$ using the finite-rank and compact operators.
\begin{proposition}
  Any nonzero ideal $J\subseteq \B\left(\mathcal{H}\right)$ contains $\F\left(\mathcal{H}\right)$. If $J$ is closed, then $J$ contains $\K\left(\mathcal{H}\right)$.
\end{proposition}
\begin{proof}
  Let $T\in J$, $T\neq 0$. There is a vector $x\in \mathcal{H}$ with $T\left(x\right) = y \neq 0$. Let $\xi,\eta\in \mathcal{H}$ be arbitrary. Since $J$ is an ideal, we must have
  \begin{align*}
    \theta_{\xi,y}T\theta_{x,\eta} &= \theta_{\xi,y}\theta_{T\left(x\right),\eta}\\
                                   &= \iprod{T\left(x\right)}{y}\theta_{\xi,\eta}\\
                                   &= \norm{y}^2\theta_{\xi,\eta}
  \end{align*}
  belongs to $J$, so $\theta_{\xi,\eta}\in J$. Since $\xi,\eta$ were arbitrarily chosen, and $J$ is a subspace, we get $\F\left(\mathcal{H}\right)\subseteq J$.\newline

  If $J$ is closed, then $\K\left(\mathcal{H}\right) = \overline{\F\left(\mathcal{H}\right)} \subseteq \overline{J} = J$.
\end{proof}
Recall that a diagonalizable operator is able to be written as a SOT-convergent infinite sum. If the operator is compact, we can upgrade this to a norm-convergent sum.
\begin{proposition}
  Let $\mathcal{H}$ be a Hilbert space, and let $T\in \B\left(\mathcal{H}\right)$. The following are equivalent.
  \begin{enumerate}[(i)]
    \item $T$ is compact and diagonalizable;
    \item there is a sequence $\left(\lambda_n\right)_n\in c_0$ consisting of distinct scalars and an internal direct sum $\mathcal{H} = \bigoplus_{n\geq 1}E_n$, with $E_n\neq \set{0}$ for all $n$ and $\Dim\left(E_n\right) < \infty$ for all $n$, with, for $\lambda_n\neq 0$,
      \begin{align*}
        T = \bigoplus_{n\geq 1} \lambda_n\id_{E_n}.
      \end{align*}
    \item There is a sequence $\left(\lambda_n\right)_n\in c_0$ consisting of distinct nonzero scalars and a sequence $\left(P_n\right)_n$ of mutually orthogonal finite-rank nonzero projections such that
      \begin{align*}
        T &= \sum_{n\geq 1}\lambda_nP_n
      \end{align*}
      is a norm-convergent sum.
    \item There is a sequence $\left(\mu_k\right)_k\in c_0$ consisting of nonzero scalars and an orthonormal sequence $\left(e_k\right)_k$ in $\mathcal{H}$ such that
      \begin{align*}
        T &= \sum_{k\geq 1}\mu_k\theta_{e_k,e_k}
      \end{align*}
      is a norm-convergent sum.
  \end{enumerate}
  Moreover, examining (ii) further, we have
  \begin{enumerate}[(1)]
    \item The sequence $\left(\lambda_n\right)_n$ is a complete list of eigenvalues for $T$.
    \item For every $n$, $E_{n} = E_{\lambda_n}\left(T\right)$ is the eigenspace for $T$ corresponding to $\lambda_n$.
  \end{enumerate}
\end{proposition}
\begin{proof}
  Let $T$ be diagonalizable. We know that there is an internal direct sum decomposition $\mathcal{H} = \bigoplus_{n\in N}E_n$ with $E_n\neq \set{0}$ and a family $\set{\lambda_n}_{n\in N}$ of distinct scalars such that $T = \sum_{n\in N}\lambda_n\id_{E_n}$. We claim that the indexing set $N$ is countable. To do this, we will show that $N_0 = \set{n\in N | \lambda_n \neq 0}$ is countable.\newline

  We choose a unit vector $e_n\in E_n$ for each $n\in N_0$, and note that for $n,k\in N_0$, we have
  \begin{align*}
    \iprod{T\left(e_n\right)}{T\left(e_k\right)} &= \iprod{\lambda_ne_n}{\lambda_ke_k}\\
                                                 &= \lambda_n \overline{\lambda_k} \iprod{e_n}{e_k}.
  \end{align*}
  This shows that $R = \set{T\left(e_n\right) | n\in N_0}$ is an orthogonal family of nonzero vectors. Since $T$ is compact, $\Ran\left(T\right) \subseteq \mathcal{H}$ is separable. Since $R\subseteq \Ran\left(T\right)$, it must be the case that $N_0$ is countable, and since $\lambda_n$ are distinct, there is at most one $n\in N$ with $\lambda_n = 0$.\newline

  By enumerating $N$, we have a sequence $\left(\lambda_n\right)_n$, a countable direct sum $\mathcal{H} = \bigoplus_{n\geq 1}E_n$, and the decomposition 
  \begin{align*}
    T &= \bigoplus_{n\geq 1}\lambda_n\id_{E_n}.
  \end{align*}
  We will now show that $\left(\lambda_n\right)_n$ belongs to $c_0$. We assume that the sequence is infinite --- if it is finite, we embed it into $c_{00}$, which is a subset of $c_0$ --- and for each $n\in N$, we choose a unit vector $e_n\in E_n$. Since $\left(e_n\right)_n$ is an orthonormal sequence, $\left(e_n\right)_n\xrightarrow{w} 0$, and since $T$ is compact, we must have $\left(T\left(e_n\right)\right)\rightarrow 0$ in norm. Thus, we have
  \begin{align*}
    \left\vert \lambda_n \right\vert &= \norm{\lambda_ne_n}\\
                                     &= \norm{T\left(e_n\right)}\\
                                     &\rightarrow 0.
  \end{align*}
  Finally, by the properties of diagonalizable operators, the spaces $E_n$ are the eigenspaces $E_{\lambda_n}$ corresponding to the eigenvalues $\lambda_n$, and $\Dim\left(E_{\lambda_n}\left(T\right)\right) < \infty$ if $\lambda_n\neq 0$.\newline

  Starting from the internal direct sum $T = \bigoplus_{n\geq 1}\lambda_n\id_{E_n}$, we relabel such that $\lambda_0 = 0$ and $\lambda_n \neq 0$ for all $n\geq 1$. For each $n$, we designate $P_n$ as the orthogonal projection onto $E_n$. Since $\Dim\left(E_n\right) < \infty$, and $E_n$ are mutually orthogonal, we see that $\left(P_n\right)_{n\geq 1}$ is a sequence of mutually orthogonal finite-rank projections.\newline

  We start by showing the series $T = \sum_{n \geq 1}\lambda_nP_n$ converges in operator norm. Given $\ve > 0$, find $N\in \N$ such that $\left\vert \lambda_n \right\vert < \ve$ for all $n\geq N$. Thus, we find, for $p\geq q \geq N$, that
  \begin{align*}
    \norm{\sum_{n=1}^{p}\lambda_nP_n - \sum_{n=1}^{q}\lambda_nP_n}_{\text{op}} &= \norm{\sum_{n=q+1}^{p}\lambda_nP_n}_{\text{op}}\\
                                                                               &= \max_{n=q+1}^{p}\left\vert \lambda_n \right\vert\\
                                                                               & < \ve.
  \end{align*}
  Thus, the sequence of partial sums is $\norm{\cdot}_{\text{op}}$-Cauchy, so the infinite series $S = \sum_{n=1}^{\infty}\lambda_nP_n$ converges in $\B\left(\mathcal{H}\right)$.\newline

  Now, we show $S = T$. If $n\geq 1$ and $x\in E_n$, then $T\left(x\right) = \lambda_n x = S\left(x\right)$. If $E_0 \neq \set{0}$, and $x\in E_0$, then $T\left(x\right) = 0 = S\left(x\right)$.\newline

  Since $\mathcal{H} = \bigoplus_{n\geq 0}E_n$, every $x\in \mathcal{H}$ can be written as a norm-convergent series
  \begin{align*}
    x &= \sum_{n=0}^{\infty}x_n,
  \end{align*}
  with $x_n\in E_n$. Since $T$ and $S$ are both continuous and agree at each $x_n$, we find $S(x) = T(x)$.\newline

  Letting $T = \sum_{n\geq 1}\lambda_nP_n$, we find an orthonormal basis $\set{e_n\left(j\right) | 1 \leq j \leq J_n}$ for each of the finite-dimensional subspaces $\Ran\left(P_n\right)$. Since $P_n$ are each finite-rank, we get
  \begin{align*}
    P_n &= \sum_{j=1}^{J_n}\theta_{e_n\left(j\right),e_n\left(j\right)},
  \end{align*}
  meaning we get
  \begin{align*}
    T &= \sum_{n\geq 1}\left(\sum_{j=1}^{J_n}\theta_{e_n\left(j\right),e_n\left(j\right)}\right),
  \end{align*}
  which, relabeled, gives
  \begin{align*}
    T &= \sum_{k\geq 1}\mu_k\theta_{e_k,e_k}.\tag*{(\textasteriskcentered)}
  \end{align*}
  Finally, assuming (\textasteriskcentered), and since $\overline{\F\left(\mathcal{H}\right)} = \K\left(\mathcal{H}\right)$, with each $\theta_{e_k,e_k}$ rank one, it follows that $T$ is compact. Extending $\set{e_k}_k$ to an orthonormal basis $\mathcal{E}$, we let $x\in \mathcal{E}$. If $x\neq e_k$, we see that $T\left(x\right) = 0$, and if $x = e_k$, then $T\left(x\right) = \mu_k x$, meaning $T$ is diagonalizable.
\end{proof}
\subsection{Introduction to Spectral Theory}%
Recall from undergraduate linear algebra that any normal matrix over $\C$, $a\in \Mat_{n}\left(\C\right)$, can be diagonalized by a unitary matrix,
\begin{align*}
  u &= \begin{pmatrix}u_1 & \cdots & u_n\end{pmatrix},
\end{align*}
where $u_j$ is a column vector corresponding to $\lambda_j$, and $u^{\ast}au = \diag\left(\lambda_1,\dots,\lambda_n\right)$.\newline

We may identify the matrix unit $e_{jj}$ with the rank-one projection $\theta_{e_j,e_j}$, and find
\begin{align*}
  a &= udu^{\ast}\\
    &= u\left(\sum_{j=1}^{n}\lambda_je_{jj}\right)u^{\ast}\\
    &= \sum_{j=1}^{n}\lambda_ju\theta_{e_j,e_j}u^{\ast}\\
    &= \sum_{j=1}^{n}\lambda_j\theta_{ue_j,ue_j}.
\end{align*}
Since the vectors $u_j$ form an orthonormal basis, the projections $P_j = \theta_{u_j,u_j}$ are mutually orthogonal rank-one projections, with $I = \sum_{j=1}^{n}P_j$. This is known as the resolution of the identity.\newline

Setting $M_j = \Ran\left(P_j\right)$, we find
\begin{align*}
  \ell_2^{n} &= \bigoplus_{j=1}^{n}M_j,
\end{align*}
and
\begin{align*}
  a &= \sum_{j=1}^{n}\lambda_jP_j.
\end{align*}
Since $P_iP_j = 0$ for $i\neq j$, inductively we get
\begin{align*}
  a^k &= \sum_{j=1}^{n}\lambda_j^{k}P_j,
\end{align*}
giving rise to the polynomial functional calculus, where for a given $q = \sum_{k=1}^{n}\alpha_kz^k\in \C[x]$, we get
\begin{align*}
  q\left(a\right) &= \sum_{j=1}^{n}q\left(\lambda_j\right)P_j.
\end{align*}
This result can be extended to normal operators on Hilbert spaces, but that will take some machinery to build up to. We start with understanding the spectrum of bounded operators, then proving an analogous result for compact operators.
\subsubsection{Properties of the Spectrum}%
In linear algebra, we learn that $\lambda \in \F$ is an eigenvalue for a linear operator $T\colon \F^n\rightarrow \F^n$ if and only if $T - \lambda I$ is not invertible. In infinite dimensions, we have to go a bit farther, where we start by defining the spectrum as the complement of the resolvent.
\begin{definition}
  Let $X$ be a normed space, and let $T\in \B\left(X\right)$.
  \begin{enumerate}[(1)]
    \item The resolvent of $T$ is the set
      \begin{align*}
        \rho\left(T\right) &= \set{\lambda\in \C | T - \lambda I \in \text{GL}\left(\B\left(X\right)\right)}.
      \end{align*}
    \item The spectrum of $T$ is the complement of the resolvent --- that is, $\sigma\left(T\right) = \C\setminus \rho\left(T\right)$.
  \end{enumerate}
\end{definition}
We can decompose the spectrum into four types, depending on how the bounded operator $S\colon X\rightarrow X$ between Banach spaces fails to be invertible. Recall that if $S$ is bijective then $S$ is invertible by the Open Mapping Theorem, so if $S$ is non-invertible, then $S$ fails to be either injective or surjective. The four types are as follows:
\begin{enumerate}[(I)]
  \item $S$ is not injective;
  \item $S$ is injective, $S$ is not surjective, $\Ran\left(S\right)\subsetneq X$ is dense and not closed;
  \item $S$ is injective, $S$ is not surjective, $\Ran\left(S\right)\subsetneq X$ is not dense and not closed;
  \item $S$ is injective, $S$ is not surjective, $\Ran\left(S\right)\subsetneq X$ is closed.
\end{enumerate}
\begin{remark}\hfill
  \begin{enumerate}[(1)]
    \item Every non-invertible operator is one of these four types, and they are mutually exclusive.
    \item We know that an operator $S\in \B\left(X\right)$ is not invertible if and only if $S$ is not onto or $S$ is not bounded below. For example, if $S\in \B\left(X\right)$ is type IV, then $S$ is not onto, but $S$ is bounded below.\newline

      Moreover, $S$ is bounded below if and only if $S$ is injective and has closed range, so if $S$ is of types I--III, then $S$ is not bounded below.\newline

      If $S$ is of type I, then there is a unit vector $x$ with $S\left(x\right) = 0$, and if $S$ is of type II or III, then $S$ has a trivial kernel, but $S$ has an approximate kernel, wherein $\left(x_n\right)_n\subseteq S_X$ is such that $\inf_{n\geq 1}\norm{S\left(x_n\right)} = 0$.
    \item If $\mathcal{H}$ is a Hilbert space, and $S\in \B\left(\mathcal{H}\right)$ is normal, then $S$ is invertible if and only if $S$ is bounded below, so a non-invertible normal operator cannot be of type IV. We also know that if $S$ is normal, then $S$ is injective if and only if its range is dense, so $S$ cannot be of type III either.
  \end{enumerate}
\end{remark}
\begin{definition}[Decomposing the Spectrum]
  Let $T\in \B\left(X\right)$. Then, we may decompose the spectrum as follows. Letting
  \begin{align*}
    \sigma_p\left(T\right) &= \set{\lambda\in \sigma\left(T\right) | T - \lambda I\text{ is type I}}\\
    \sigma_{c}\left(T\right) &= \set{\lambda\in \sigma\left(T\right) | T - \lambda I\text{ is type II}}\\
    \sigma_{r_1} &= \set{\lambda\in \sigma\left(T\right) | T - \lambda I\text{ is type III}}\\
    \sigma_{r_2} &= \set{\lambda\in \sigma\left(T\right) | T - \lambda I\text{ is type IV}}
  \end{align*}
  \begin{itemize}
    \item $\sigma_p$ is known as the point spectrum;
    \item $\sigma_{c}$ is known as the continuous spectrum;
    \item $\sigma_{r} = \sigma_{r_1}\cup \sigma_{r_2}$ is known as the residual spectrum;
    \item $\sigma_{ap} = \sigma_p \cup \sigma_c \cup \sigma_{r_1}$ is known as the approximate point spectrum.
  \end{itemize}
  If $\lambda \in \sigma_p$, then we say $\lambda$ is an eigenvalue for $T$, and $0\neq x\in \ker\left(T - \lambda I\right)$ is an eigenvector for $\lambda$. The linear subspace
  \begin{align*}
    E_{\lambda}\left(T\right) &= \ker\left(T - \lambda I\right)
  \end{align*}
  is the eigenspace of $T$ corresponding to $\lambda$.\newline

  A scalar $\lambda \in \sigma_{ap}$ is known as an approximate eigenvalue for $T$.
\end{definition}
\begin{exercise}
  Let $T\in \B\left(\mathcal{H}\right)$. Prove the following facts about eigenvalues:
  \begin{enumerate}[(a)]
    \item $\lambda\in \sigma_p\left(T\right) \Rightarrow \left\vert \lambda \right\vert \leq \norm{T}_{\text{op}}$;
    \item if $T\in \B\left(\mathcal{H}\right)_{\sa}$, then $\sigma_p\left(T\right) \subseteq \left\vert -\norm{T}_{\text{op}},\norm{T}_{\text{op}} \right\vert$;
    \item if $T\in \B\left(\mathcal{H}\right)_{+}$, then $\sigma_p\left(T\right)\subseteq \left[0,\norm{T}_{\text{op}}\right]$;
    \item if $T\in \mathcal{P}\left(\B\left(\mathcal{H}\right)\right)$, then $\sigma_p\left(T\right)\subseteq \set{0,1}$;
    \item if $T\in \mathcal{U}\left(\B\left(\mathcal{H}\right)\right)$, then $\sigma_p\left(T\right)\subseteq \mathbb{T}$.
  \end{enumerate}
\end{exercise}
\begin{solution}\hfill
  \begin{enumerate}[(a)]
    \item Let $\lambda\in \sigma_p\left(T\right)$. Then, if $v\in E_{\lambda}\left(T\right)$ is a unit vector, we have
      \begin{align*}
        \left\vert \lambda \right\vert &= \norm{\lambda v}\\
                                       &= \norm{T\left(v\right)}\\
                                       &\leq \norm{T}_{\text{op}}.
      \end{align*}
    \item This follows from the fact that if $T\in \B\left(\mathcal{H}\right)_{\sa}$, then all its eigenvalues are real.
    \item This follows from the fact that if $T\in \B\left(\mathcal{H}\right)$, then all its eigenvalues are positive.
    \item Let $P_M$ be a projection onto the closed subspace $M$. If $v\in M$, then we must have $P\left(v\right) = v$ meaning that if $v\in M$, then $v\in E_{1}\left(P_M\right)$. If $v\in M^{\perp}$, then $P\left(v\right) = 0$, so $v\in E_{0}\left(P_M\right)$. If $v\notin M\cup M^{\perp}$, then $P\left(v\right) \neq \lambda v$ for any $v$, meaning $\sigma_p\left(P\right) \subseteq \set{0,1}$.
    \item Let $x\in \sigma_p\left(U\right)$ for some $U\in \mathcal{U}\left(\B\left(\mathcal{H}\right)\right)$. Then,
      \begin{align*}
        \iprod{x}{x} &= \iprod{U\left(x\right)}{U\left(x\right)}\\
                     &= \iprod{\lambda x}{\lambda x}\\
                     &= \left\vert \lambda \right\vert^2 \iprod{x}{x},
      \end{align*}
      meaning $\left\vert \lambda \right\vert^2 = 1$, so $\lambda \in \mathbb{T}$.
  \end{enumerate}
\end{solution}
Similar results hold for the general spectrum of a normal operator.\newline

The following two facts are very useful to know regarding a bounded operator $T$ on a Banach space $X$:
\begin{itemize}
  \item $\sigma\left(T\right)\subseteq \C$ is nonempty and closed;
  \item $\sigma\left(T\right) \subseteq D\left(0,\norm{T}_{\text{op}}\right)$.
\end{itemize}
\begin{lemma}
  Let $T$ be a bounded operator on $\mathcal{H}$. Then, the following are true:
  \begin{enumerate}[(1)]
    \item if $\lambda\in \sigma_r\left(T\right)$, then $\overline{\lambda}\in \sigma_p\left(T^{\ast}\right)$;
    \item if $\lambda \in \sigma_p\left(T\right)$ and $\overline{\lambda}\notin \sigma_p\left(T^{\ast}\right)$, then $\overline{\lambda}\in \sigma_r\left(T^{\ast}\right)$.
  \end{enumerate}
\end{lemma}
\begin{proof}\hfill
  \begin{enumerate}[(1)]
    \item If $\lambda\in \sigma_r\left(T\right)$, then $\overline{\Ran}\left(T - \lambda I\right) \neq \mathcal{H}$, so we have
      \begin{align*}
        \ker\left(T^{\ast} - \overline{\lambda}I\right)^{\perp} &= \ker\left(\left(T-  \lambda I\right)^{\ast}\right)^{\perp}\\
                                                                &= \overline{\Ran}\left(T - \lambda I\right)\\
                                                                &\neq \mathcal{H},
      \end{align*}
      so $\ker\left(T^{\ast} - \overline{\lambda}I\right)\neq \set{0}$, so $\overline{\lambda}$ is an eigenvalue for $T^{\ast}$.
    \item Let $\lambda\in \sigma_p\left(T\right)$. We find
      \begin{align*}
        \set{0} &\neq \ker\left(T - \lambda I\right)\\
                &= \Ran\left(T^{\ast} - \overline{\lambda}I\right)^{\perp},
      \end{align*}
      so $\overline{\Ran}\left(T^{\ast} - \lambda I\right) \neq \mathcal{H}$, meaning $T^{\ast} - \overline{\lambda}I$ is non-invertible. Since $\overline{\lambda}\notin \sigma_p\left(T^{\ast}\right)$, we must have $\overline{\lambda}\in \sigma_r\left(T^{\ast}\right)$.
  \end{enumerate}
\end{proof}
We can refine these properties in the case of normal operators.
\begin{proposition}
  Let $\mathcal{H}$ be a Hilbert space, and let $T\in \B\left(\mathcal{H}\right)$ be normal. Then, the following are true:
  \begin{enumerate}[(1)]
    \item $\sigma\left(T\right) = \sigma_p\left(T\right) \cup \sigma_c\left(T\right)$;
    \item for any scalar $\lambda$, $\lambda\in \sigma_p\left(T\right)$ if and only if $\overline{\lambda}\in \sigma_p\left(T^{\ast}\right)$, and $E_{\lambda}\left(T\right) = E_{\overline{\lambda}}\left(T^{\ast}\right)$;
    \item for any scalar $\lambda$, $\lambda\in \sigma_{ap}\left(T\right)$ if and only if $\overline{\lambda}\in \sigma_{ap}\left(T^{\ast}\right)$;
    \item for any scalar $\lambda$, $\lambda\in \sigma_c\left(T\right)$ if and only if $\overline{\lambda}\in \sigma_c\left(T\right)$;
    \item if $\lambda,\mu\in \sigma_p\left(T\right)$ with $\lambda \neq \mu$, then $E_{\lambda}\left(T\right)\perp E_{\mu}\left(T\right)$.
  \end{enumerate}
\end{proposition}
\begin{proof}\hfill
  \begin{enumerate}[(1)]
    \item If $\lambda$ is a scalar, then $T - \lambda I$ is normal, so $T- \lambda I$ can only be of type I or II.
    \item Since $T - \lambda I$ is normal, we have
      \begin{align*}
        E_{\lambda}\left(T\right) &= \ker\left(T - \lambda I\right)\\
                                  &= \ker\left(\left(T - \lambda I\right)^{\ast}\right)\\
                                  &= \ker\left(T^{\ast} - \overline{\lambda}I\right)\\
                                  &= E_{\overline{\lambda}}\left(T^{\ast}\right).
      \end{align*}
    \item For any vector $\xi\in \mathcal{H}$, we have
      \begin{align*}
        \norm{\left(T - \lambda I\right)\left(\xi\right)} &= \norm{\left(T^{\ast} - \overline{\lambda}I\right)\left(\xi\right)},
      \end{align*}
      meaning that if $\left(\xi_n\right)_n$ is a sequence in $S_{\mathcal{H}}$, the convergence in norm to zero of $T - \lambda I$ holds if and only if $T^{\ast} - \overline{\lambda}I$ converges to zero.
    \item Follows from (1), (2), and (3).
    \item Let $x\in E_{\lambda}$ and $y\in E_{\mu}$. Then,
      \begin{align*}
        \lambda \iprod{x}{y} &= \iprod{\lambda x}{y}\\
                             &= \iprod{T\left(x\right)}{y}\\
                             &= \iprod{x}{T^{\ast}\left(y\right)}\\
                             &= \iprod{x}{\overline{\mu}y}\\
                             &= \mu \iprod{x}{y},
      \end{align*}
      so $\left(\lambda - \mu\right) \iprod{x}{y} = 0$. Since $\lambda - \mu \neq 0$, we must have $ \iprod{x}{y} = 0 $, meaning $E_{\lambda}$ and $E_{\mu}$ are orthogonal.
  \end{enumerate}
\end{proof}
\begin{proposition}
  Let $X$ be a Banach space, and let $T\in \B\left(X\right)$ be a compact operator. If $0\neq \lambda\in \sigma_{ap}\left(T\right)$, then $\lambda \in \sigma_p\left(T\right)$. If $\Dim\left(X\right) = \infty$, then $0 \in \sigma\left(T\right)$.
\end{proposition}
\begin{proof}
  We know there is a sequence of unit vectors $\left(x_n\right)_n$ with
  \begin{align*}
    \left(\left(T - \lambda I\right)x_n\right)_n \rightarrow 0.
  \end{align*}
  Since $T$ is compact, there is a subsequence $\left(x_{n_k}\right)_k$ with $\left(T\left(x_{n_k}\right)\right)_k\rightarrow x$ for some $x\in X$. Thus
  \begin{align*}
    \left(\lambda x_{n_k}\right)_k &= \left(\lambda x_{n_k} - T\left(x_{n_k}\right)\right)_k + \left(T\left(x_{n_k}\right)\right)_k\\
                                   &\rightarrow x.
  \end{align*}
  Thus, $T\left(x\right) = \lambda x$. We must now show that $x\neq 0$. However, we see that
  \begin{align*}
    \norm{x} &= \norm{\lim_{k\rightarrow\infty}\lambda x_{n_k}}\\
             &= \left\vert \lambda \right\vert \lim_{k\rightarrow\infty}\norm{x_{n_k}}\\
             &= \left\vert \lambda \right\vert\\
             &\neq 0.
  \end{align*}
  For the second assertion, we see that if $0\in \rho\left(T\right)$, then $T\in \text{GL}\left(\B\left(X\right)\right)$, so $I = T^{-1}T$ is compact, meaning $X$ is finite-dimensional, which is a contradiction.
\end{proof}
\begin{example}[Spectrum of the Left Shift]
  The left shift operator is defined
  \begin{align*}
    L\left(\xi_1,\xi_2,\xi_3,\dots\right) &= \left(\xi_2,\xi_3,\dots\right)
  \end{align*}
  for $\left(\xi_k\right)_k\in \ell_2$. To understand the spectrum, we consider $\lambda \in \mathbb{D} = \set{z | |z| < 1}$, and examine the vector $\left(\xi_k\right)_k = \left(\lambda^{k}\right)_{k\geq 0}$. Then, $L\left(\xi\right) = \lambda \xi$, meaning $\mathbb{D} \subseteq \sigma_p\left(L\right)$.\newline

  We will now show that any scalar $\lambda$ with $\left\vert \lambda  \right\vert\geq 1$ cannot be an eigenvalue. Let $\lambda$ be such a scalar, and let $\xi \neq 0$ be such that $L\left(\xi\right) = \lambda \xi$. Then, $\xi_k = \lambda^{k-1}\xi_1$. Since $\xi \neq 0$, we must have $\xi_1 \neq 0$, meaning
  \begin{align*}
    \norm{\xi}^2 &= \sum_{k=1}^{\infty}\left\vert \xi_k \right\vert^2\\
                 &= \sum_{k=1}^{\infty}\left\vert \lambda^{k-1}\xi_1 \right\vert^2\\
                 &= \sum_{k=1}^{\infty}\left\vert \lambda^{k-1} \right\vert\left\vert \xi_1 \right\vert^2\\
                 &\geq \sum_{k=1}^{\infty}\left\vert \xi_1 \right\vert^2\\
                 &= \infty,
  \end{align*}
  which means $\xi \notin \ell_2$.\newline

  The shift also admits approximate eigenvalues. Let $\lambda \in \mathbb{T}$, and consider $\eta_n = \left(1,\lambda,\lambda^2,\dots,\lambda^n,0,0,\dots\right)$. Then,
  \begin{align*}
    \norm{\left(L - \lambda I\right)\left(\eta_n\right)} &= \norm{-\lambda^{n+1}e_{n+1}}\\
                                            &= 1,
  \end{align*}
  and
  \begin{align*}
    \norm{\eta_n}^2 &= \sum_{k=0}^{n}\left\vert \lambda^k \right\vert^2\\
                    &= n+1.
  \end{align*}
  Setting
  \begin{align*}
    \xi_n &= \frac{\eta_n}{\sqrt{n+1}},
  \end{align*}
  we get $\norm{\eta_n} = 1$, and
  \begin{align*}
    \norm{\left(L - \lambda I\right)\left(\xi_n\right)} &= \frac{1}{\sqrt{n+1}}\\
                                                        &\rightarrow 0.
  \end{align*}
  These approximate eigenvalues belong to the continuous spectrum. To see this, we see that if $\lambda \in \sigma_r\left(L\right)$, then we must have $\overline{\lambda}\in \sigma\left(L^{\ast}\right)$. However, $L^{\ast} = R$, which has no eigenvalues, meaning $\sigma_c\left(L\right) = \mathbb{T}$. Since $\norm{L}_{\text{op}} = 1$, we get the spectrum of $\overline{\mathbb{D}}$, decomposed into $\sigma_p\left(L\right) = \mathbb{D}$ and $\sigma_c\left(L\right) = \mathbb{T}$.
\end{example}

\end{document}
