\documentclass[10pt]{mypackage}

% sans serif font:
%\usepackage{cmbright}
%\usepackage{sfmath}
%\usepackage{bbold} %better blackboard bold

%serif font + different blackboard bold for serif font
\usepackage{newpxtext,eulerpx}
\usepackage{eucal}
\renewcommand*{\mathbb}[1]{\varmathbb{#1}}
\renewcommand*{\hbar}{\hslash}
\DeclareMathOperator{\hdim}{hdim}
\DeclareMathOperator{\hDim}{hdim}
\DeclareMathOperator{\Hdim}{hdim}

\pagestyle{fancy} %better headers
\fancyhf{}
\rhead{Avinash Iyer}
\lhead{Functional Analysis: Hilbert Spaces and Operators}

\setcounter{secnumdepth}{0}

\begin{document}
\RaggedRight
\tableofcontents
\section{Introduction}%
This is going to be part of my notes for my Honors Thesis independent study, focused on Amenability and $C^{\ast}$-algebras. This set of notes will be focused on the theory of Hilbert spaces and bounded linear operators on Hilbert spaces. The primary source for this section of notes will be Timothy Rainone's \textit{Functional Analysis: En Route to Operator Algebras}.\newline

I do not claim any of this work to be original.
\section{Hilbert Spaces}%
In quantum mechanics, the state of a non-relativistic particle is given by a vector in some Hilbert space, which evolves by moving around that space. Specifically, the state of such a particle is determined entirely by the wave function $\xi = \xi\left(x,t\right)$, where $x\in \R$ is position and $t$ is time. The wave function is a probability distribution satisfying
\begin{align*}
  \int_{\R}^{} \left\vert \xi\left(x,t\right) \right\vert^2\:d\lambda &= 1.
\end{align*}
In particular, $\xi$ is an element of the space $L_{2}\left(\R,\lambda\right)$. The observables on $\xi$ are modeled as operators on $L_{2}\left(\R,\lambda\right)$.
\subsection{Theory of Hilbert Spaces}%
In undergraduate linear algebra, the dot product of vectors in $\R^n$, $v\cdot w$, is intimately tied to the geometry of $\R^n$ through the equations
\begin{align*}
  v\cdot v &= \norm{v}^2\\
  v\cdot w &= \norm{v}\norm{w}\cos\theta.
\end{align*}
Inner product spaces help generalize these properties.
\begin{definition}
  Let $X$ be a vector space over a field $\F$.
  \begin{enumerate}[(1)]
    \item An inner product on $X$ is a map 
      \begin{align*}
        \iprod{\cdot}{\cdot}: X\times X &\rightarrow \F\\
        \left(x,y\right) &\mapsto \iprod{x}{y}
      \end{align*}
      which satisfies the following conditions for all $x,y,z\in X$ and $\lambda,\mu\in \F$.
    \begin{enumerate}[(i)]
      \item $ \iprod{\lambda x + \mu y}{z} = \lambda \iprod{x}{z} + \mu \iprod{y}{z} $;
      \item $ \iprod{x}{y} = \overline{ \iprod{y}{x} } $;
      \item $ \iprod{x}{x} \geq 0 $;
      \item $ \iprod{x}{x} = 0 \Rightarrow x = 0_{X} $.
    \end{enumerate}
    If $ \iprod{\cdot}{\cdot} $ satisfies (i)--(iii), but not necessarily (iv), then it is called a semi-inner product.
  \item If $ \iprod{\cdot}{\cdot} $ is an inner product on $X$, the pair $\left(X, \iprod{\cdot}{\cdot}\right)$ is called an inner product space.
  \end{enumerate}
\end{definition}
\begin{remark}
  A semi inner product also satisfies, for all $x,y,z\in X$ and $\lambda,\mu \in \F$,
  \begin{align*}
    \iprod{x}{\lambda y + \mu z} &= \overline{\lambda} \iprod{x}{z} + \overline{\mu} \iprod{y}{z}.
  \end{align*}
  A semi-inner product is linear in the first variable and conjugate linear in the second variable.
\end{remark}
\begin{definition}
  Let $X$ be a complex vector space. A map
  \begin{align*}
    F: X\times X \rightarrow \C
  \end{align*}
  which is linear in the first variable and conjugate linear in the second variable is called a sesquilinear form on $X$.
\end{definition}
A fundamental fact about sesquilinear forms is that for any given sesquilinear form, we are able to pass it into a form that only consists of the same elements in both inputs.
\begin{lemma}[Polarization Identity]
Let $F: X\times X \rightarrow \C$ be a sesquilinear form on $X$. For all $x,y\in X$, we have
\begin{align*}
  4 F\left(x,y\right) &=  F\left(x+y,x+y\right) + iF\left(x+iy,x+iy\right) - F\left(x-y,x-y\right) + iF\left(x-iy,x-iy\right)\\
                      &= \sum_{k=0}^{3}i^{k}F\left(x + i^{k}y,x + i^{k}y\right).
\end{align*}
\end{lemma}
\begin{proof}
  Taking each expression
  \begin{align*}
    F\left(x+y,x+y\right) &= F\left(x,x\right) + F\left(x,y\right) + F\left(y,x\right) + F\left(y,y\right)\\
    iF\left(x + iy,x + iy\right) &= iF\left(x,x\right) - F\left(y,x\right) + F\left(x,y\right) + iF\left(y,y\right)\\
    -F\left(x-y,x-y\right) &= -F\left(x,x\right) + F\left(x,y\right) + F\left(y,x\right) - F\left(y,y\right)\\
    -iF\left(x-iy,x-iy\right) &= -iF\left(x,x\right) -F\left(y,x\right) + F\left(x,y\right) - iF\left(y,y\right).
  \end{align*}
  Adding these expressions up, we get the polarization identity.
\end{proof}
The following fact follows from the polarization identity.
\begin{fact}
  If $F$ and $G$ are two sesquilinear forms that agree on the diagonal --- i.e., $F(x,x) = G(x,x)$ --- then $F$ and $G$ agree everywhere.
\end{fact}

\begin{fact}
  Let $X$ be an inner product space, and suppose $z_1,z_2\in X$ are such that $ \iprod{x}{z_1} = \iprod{x}{z_2} $ for all $x\in X$. Then, $z_1 = z_2$.
\end{fact}
\begin{proof}
  We have $ \iprod{x}{z_1} = \iprod{x}{z_2} $. Then, $ \iprod{x}{z_1 - z_2} = 0 $ for all $x\in X$, so $ \iprod{z_1 - z_1}{z_1 - z_2} = 0 $, so $z_1 - z_2 = 0$.
\end{proof}
Let's see some inner product spaces.
\begin{example}[Finite-Dimensional Space]
  The finite dimensional space $\C^n$ admits an inner product space given by
  \begin{align*}
    \iprod{\xi}{\eta} &= \sum_{j=1}^{n}\xi_j \overline{\eta_j},
  \end{align*}
  where $\xi$ and $\eta$ are $n$ dimensional vectors over $\C$.
\end{example}
\begin{example}[Sequence Space]
  The space of square-summable sequences,
  \begin{align*}
    \ell_2 &= \set{\left(\lambda_k\right)_k | \sum_{n=1}^{\infty}\left\vert \lambda_n \right\vert^2 := \norm{\lambda}^2 < \infty}
  \end{align*}
  is an inner product space with the inner product
  \begin{align*}
    \iprod{\lambda}{\mu} &= \sum_{n=1}^{\infty}\lambda_n \overline{\mu_n}.
  \end{align*}
  The Cauchy--Schwarz inequality provides for this to be a well-defined inner product.
  \begin{align*}
    \sum_{n=1}^{N}\left\vert \lambda_n \overline{\mu_n} \right\vert &\leq \left(\sum_{n=1}^{N}\left\vert \lambda_n \right\vert^2\right)^{1/2}\left(\sum_{n=1}^{N}\left\vert \mu_n \right\vert^2\right)^{1/2}\\
                                                                    &\leq \norm{\lambda}_2\norm{\mu}_2\\
                                                                    &< \infty.
  \end{align*}
\end{example}
\begin{example}[Continuous Functions]
  The space $X = C\left([0,1]\right)$ admits an inner product given by
  \begin{align*}
    \iprod{f}{g} &= \int_{0}^{1} f(t)\overline{g(t)}\:dt.
  \end{align*}
\end{example}
\begin{example}[Sesquilinear Form on Continuous Function Space]
  Let $\Omega$ be a locally compact Hausdorff space and suppose $\varphi: C_0\left(\Omega\right)\rightarrow \F$ is a positive linear functional. We know that $\varphi = \varphi_{\mu}$ for some positive regular finite measure $\mu$ on $\left(\Omega,\mathcal{B}_{\Omega}\right)$, and
  \begin{align*}
    \varphi_{\mu}\left(f\right) &= \int_{\Omega}^{} f\:d\mu.
  \end{align*}
  We get a semi inner product on $C_{0}\left(\Omega\right)$ by
  \begin{align*}
    \iprod{\cdot}{\cdot}_{\varphi}: C_0\left(\Omega\right)\times C_0\left(\Omega\right) &\rightarrow \F\\
    \left(f,g\right) &\mapsto \int_{\Omega}^{} f\overline{g}\:d\mu.
  \end{align*}
  We claim that, when $\mu$ has full support, $ \iprod{\cdot}{\cdot}_{\varphi} $ is an inner product.\newline

  Suppose $g\in C_0\left(\Omega\right)$ with $g\geq 0$ and $g \neq 0$. Then, there is a nonempty open subset $U\subseteq \Omega$ and $\delta > 0$ such that $g(x) \geq \delta$ for all $x\in U$. Since $\mu$ has full support, it must be the case that $\mu\left(U\right) > 0$, so
  \begin{align*}
    \varphi\left(g\right) &= \int_{\Omega}^{} g\:d\mu\\
                          &\geq \int_{\Omega}^{} \delta \1_{U}\:d\mu\\
                          &= \delta \mu\left(U\right)\\
                          &> 0.
  \end{align*}
  Thus, if $ \iprod{f}{f}_{\varphi} = 0 $, then $\varphi\left(\left\vert f \right\vert^2\right) = 0$, so $f = 0$.
\end{example}
\begin{example}[Hilbert--Schmidt Operators]
  Let $\mathbb{M}_{n}$ be the $\ast$-algebra of $n\times n$ matrices over the complex numbers. Let $\tr: \mathbb{M}_{n}\rightarrow \C$ denote the trace. The trace is a linear, positive, faithful functional satisfying $\tr\left(a^{\ast}\right) = \overline{\tr\left(a\right)}$ for all $a\in \mathbb{M}_{n}$. The trace induces an inner product
  \begin{align*}
    \iprod{a}{b}_{\text{HS}} = \tr\left(b^{\ast}a\right),
  \end{align*}
  where the subscript HS stands for Hilbert--Schmidt.
\end{example}
\begin{definition}
  Let $X$ be an inner product space.
  \begin{enumerate}[(1)]
    \item We say two vectors $x,y\in X$ are orthogonal if $ \iprod{x}{y} = 0 $. We write $x\perp y$.
    \item Let $z\neq 0$ be a fixed vector in $X$. We define the one dimensional projection
      \begin{align*}
        P_{z}\left(x\right) &= \frac{ \iprod{x}{z} }{ \iprod{z}{z} } z.
      \end{align*}
      Note that $P_{z}$ is linear and its range is the one-dimensional subspace $\Span(z)$.
  \end{enumerate}
\end{definition}
\begin{note}
There are a lot of propositions, lemmas, and exercises in this section of my professor's textbook, but I'm not going to be going through all of them since we learn a lot of this in Real Analysis II.
\end{note}
We can turn any semi-inner product space into a seminormed vector space using the semi-inner product. If the semi-inner product is a true inner product, then we can use the inner product to define a norm.
\begin{definition}
  Let $X$ be a semi-inner product space. For each $x\in X$, we set
  \begin{align*}
    \norm{x} &= \iprod{x}{x}^{1/2}.
  \end{align*}
\end{definition}
\begin{theorem}[Pythagoras]
  Let $X$ be a semi-inner product space, and suppose $x_1,x_2,\dots,x_n$ are pairwise orthogonal. Then,
  \begin{align*}
    \norm{\sum_{j=1}^{n}x_j}^2 &= \sum_{j=1}^{n}\norm{x_j}^2
  \end{align*}
\end{theorem}
\begin{corollary}
  Let $X$ be an inner product space, and fix $z\neq 0$ in $X$. Then, for all $x,y\in X$, we have
  \begin{enumerate}[(1)]
    \item $\norm{x}^2 = \norm{x-P_z(x)}^2 + \norm{P_z(x)}^2$;
    \item $\norm{P_z(x)} \leq \norm{x}$;
    \item $\left\vert \iprod{x}{z} \right\vert \leq \norm{x}\norm{y}$, with equality if and only if $x$ and $y$ are linearly independent (the Cauchy--Schwarz inequality);
    \item $\norm{x + y} \leq \norm{x} + \norm{y}$;
    \item $\norm{\cdot}$ is a norm on $X$.
  \end{enumerate}
\end{corollary}
\begin{proposition}
  If $X$ is an inner product space, then the inner product
  \begin{align*}
    \iprod{\cdot}{\cdot}:X\times X \rightarrow \F
  \end{align*}
  is continuous.
\end{proposition}
We often start with a semi-inner product, then construct an inner product by quotient out by the null space.
\begin{proposition}
  Let $ \iprod{\cdot}{\cdot} $ be a semi-inner product on $X$.
  \begin{enumerate}[(1)]
    \item The set
      \begin{align*}
        N = \set{x\in X | \iprod{x}{x} = 0}
      \end{align*}
      is a subspace of $X$.
    \item The map
      \begin{align*}
        \iprod{x+N}{y+N}_{X/N} &= \iprod{x}{y}
      \end{align*}
      is an inner product on the quotient space $X/N$.
  \end{enumerate}
\end{proposition}
\begin{proposition}[Parallelogram Law]
Let $X$ be an inner product space. Then,
\begin{align*}
  \norm{x+y}^2 + \norm{x-y}^2 &= 2\norm{x}^2 + 2\norm{y}^2.
\end{align*}
\end{proposition}
Recall that Banach spaces include ideas regarding isometric isomorphisms --- however, we cannot immediately assume this extends to inner product spaces since they include an inherent geometric structure as well. As it turns out, this automatically appears from the definition of an isometry.
\begin{proposition}
  Let $X$ and $Y$ be inner product spaces. Suppose $V: X\rightarrow Y$ is a linear transformation. The following are equivalent.
  \begin{enumerate}[(i)]
    \item $V$ is an isometry;
    \item for each $x,x'\in X$, we have $ \iprod{V\left(x\right)}{V\left(x'\right)}_{Y} = \iprod{x}{x'}_{X} $.
  \end{enumerate}
\end{proposition}
\begin{proof}
  To show that (ii) implies (i), we see that for $x\in X$, 
  \begin{align*}
    \norm{V\left(x\right)}^2 &= \iprod{V\left(x\right)}{V\left(x\right)}\\
                &= \iprod{x}{x}\\
                &= \norm{x}^2.
  \end{align*}
  We define the sesquilinear forms
  \begin{align*}
    F\left(x,x'\right) &= \iprod{V\left(x\right)}{V\left(x'\right)}_{Y}\\
    G\left(x,x'\right) &= \iprod{x}{x'}.
  \end{align*}
  Since $V$ is norm-preserving, we have
  \begin{align*}
    F\left(x,x\right) &= \norm{V\left(x\right)}^2\\
                      &= \norm{x}^2\\
                      &= G\left(x,x\right),
  \end{align*}
  so by the polarization identity, $F$ and $G$ agree everywhere.
\end{proof}
\begin{definition}
  Let $X$ and $Y$ be inner product spaces. A surjective linear isometry $U: X\rightarrow Y$ is called a unitary operator.\newline

  Equivalently, a unitary operator is a linear isomorphism $U: X\rightarrow Y$ that preserves the inner product. We say $X$ and $Y$ are unitarily isomorphic.
\end{definition}
\begin{example}[A Nonunitary Isometry]
  Consider the right shift on $\ell_2$, defined by
  \begin{align*}
    R\left(\xi_1,\xi_2,\dots,\right) &= \left(0,\xi_1,\xi_2,\dots\right).
  \end{align*}
  Then, $R$ is not onto, but for each $\xi,\eta\in \ell_2$, we have $ \iprod{R\left(\xi\right)}{R\left(\eta\right)} = \iprod{\xi}{\eta} $. Thus, $R$ is isometric but not unitary.
\end{example}
\begin{definition}[Hilbert Space]
  A Hilbert space is an inner product space $\mathcal{H}$ over $\C$ such that the norm $\norm{x}^2 = \iprod{x}{x}$ is complete.
\end{definition}
\begin{example}
  The space $\ell_2$ of all square-summable sequences is a Hilbert space.
\end{example}
\begin{example}
  If $\left(\Omega,\mathcal{M},\mu\right)$ is any measure space, then $L_{2}\left(\Omega,\mu\right)$ is a Hilbert space with inner product
  \begin{align*}
    \iprod{f}{g} &= \int_{\Omega}^{} f\overline{g}\:d\mu.
  \end{align*}
  
\end{example}
\subsection{Orthogonal Projections}%
Recall that closed subspaces of Banach spaces may not always admit a topological complement (for instance, $c_0\subseteq \ell_{\infty}$). However, in a Hilbert space, a closed subspace always admits an orthogonal projection operator (hence a topological complement).
\begin{theorem}[Hilbert Projection Theorem]
  Let $\mathcal{H}$ be a Hilbert space. Suppose $C\subseteq \mathcal{H}$ is a closed and convex set. Given $x\in \mathcal{H}$, there is a unique $y_x\in C$ such that $\dist_{C}\left(x\right) = d\left(x,y_x\right)$. We say $y_x$ is the point in $C$ closest to $x$
\end{theorem}
\begin{proof}
  Set $d = \dist_{C}(x)$. If $x\in C$, we take $y=x$, so we assume $x\notin C$.\newline

  We find a sequence $\left(y_n\right)_{n\geq 1}$ with $d\left(x,y_n\right)\rightarrow d$ decreasing. Set $z_n = y_n - x$. We have $\norm{z_n}\rightarrow d$ decreasing, meaning $\norm{z_n}^2 \rightarrow d^2$ decreasing. Given $\ve > 0$, there is $N\in \N$ such that for $n\geq N$,
  \begin{align*}
    \norm{z_n}^2 < d^2 + \ve.
  \end{align*}
  We claim that $\left(y_n\right)_{n}$ is a Cauchy sequence in $C$. If $p,q\in \N$, we see that
  \begin{align*}
    y_p - y_q &= z_p - z_q\\
    \norm{\frac{1}{2}\left(z_p + z_q\right)} &= \norm{\frac{1}{2}\left(y_p + y_q\right) - x}\\
                                             &\geq d,
  \end{align*}
  as $\frac{1}{2}\left(y_p + y_q\right)$ belongs to $C$. Thus, for $p,q \geq N$, we have
  \begin{align*}
    \norm{y_p - y_q}^2 &= \norm{z_p - z_q}^2\\
                       &= 2\norm{z_p}^2 + 2\norm{z_q}^2 - \norm{z_p + z_q}^2\\
                       &= 2\norm{z_p}^2 + 2\norm{z_q}^2 - 4\norm{\frac{1}{2}\left(z_p + z_q\right)}^2\\
                       &\leq 2d^2 + 2\ve + 2d^2 + 2\ve - 4d^2\\
                       &= 4\ve.
  \end{align*}
  Since $C$ is closed, we thus have $d = \lim_{n\rightarrow\infty}d\left(x,y_n\right) = d\left(x,y\right)$ for $\left(y_n\right)_n \rightarrow y$ for some $y\in C$.\newline

  To see uniqueness, suppose $y_1,y_2\in C$ with $d\left(x,y_i\right) = d$. Set $z = y_j - x$ for each $j$. We have
  \begin{align*}
    0 &\leq \norm{z_1 - z_2}^2\\
      &= 2\norm{z_1}^2 + 2\norm{z_2}^2 - 4\norm{\frac{1}{2}\left(z_1 + z_2\right)}^2,
  \end{align*}
  meaning
  \begin{align*}
    0 &\leq \norm{y_1 - y_2}^2\\
      &= 2\norm{y_1 - x}^2 + 2\norm{y_2 - x}^2 - 4\norm{\frac{1}{2}\left(y_1 + y_2\right) - x}^2\\
      &\leq 2d^2 + 2d^2 - 4d^2\\
      &= 0.
  \end{align*}
  Thus, $y_1 = y_2$.
\end{proof}
\begin{definition}
  Let $\mathcal{H}$ be a Hilbert space, and let $M\subseteq \mathcal{H}$ be a closed subspace. We define
  \begin{align*}
    P_M: \mathcal{H}\rightarrow \mathcal{H}
  \end{align*}
  by $P_M\left(x\right) = y_x$, where $y_x$ is the unique point from the Hilbert projection theorem.\newline

  We call $P_M$ the orthogonal projection of $\mathcal{H}$ onto $M$.
\end{definition}
\begin{fact}
  There are some facts about the orthogonal projection that are useful for us to know.
  \begin{itemize}
    \item $P_M(x) = x \Leftrightarrow x\in M$;
    \item $\Ran\left(P_M\right) = M$;
    \item $P_M \circ P_M = P_M$ (i.e., that $P_M$ is idempotent).
  \end{itemize}
\end{fact}
\begin{definition}
  Let $X$ be an inner product space, and suppose $S\subseteq X$ is an arbitrary subset. We define the perp of $S$, $S^{\perp}$, to be
  \begin{align*}
    S^{\perp} &= \set{x\in X | \iprod{x}{y} = 0\text{ for all $y\in S$}}.
  \end{align*}
  
\end{definition}
\begin{exercise}
  Let $S\subseteq \mathcal{H}$ be an arbitrary subset. Prove the following.
  \begin{enumerate}[(1)]
    \item $S^{\perp}$ is always a closed subspace of $\mathcal{H}$.
    \item $S\subseteq \left(S^{\perp}\right)^{\perp}$.
    \item $S\cap S^{\perp} = \set{0}$.
  \end{enumerate}
\end{exercise}
\begin{solution}\hfill
  \begin{enumerate}[(1)]
    \item For $x,x'\in S^{\perp}$ and $\alpha \in \C$, we have for all $y\in S$,
      \begin{align*}
        \iprod{x + \alpha x'}{y} &= \iprod{x}{y} + \alpha \iprod{x'}{y}\\
                                 &= 0,
      \end{align*}
      so $S^{\perp}$ is a subspace. Additionally, for any sequence $\left(x_n\right)_n\subseteq S^{\perp}$ with $\left(x_n\right)_n\rightarrow x$ in $X$, the continuity of the inner product gives
      \begin{align*}
        \iprod{x_n}{y} &\rightarrow \iprod{x}{y}\\
                       &= 0.
      \end{align*}
    \item For $t\in S$, we have, for all $x\in S^{\perp}$,
      \begin{align*}
        \iprod{x}{t} &= 0\\
                     &= \iprod{t}{x},
      \end{align*}
      meaning $t \in \left(S^{\perp}\right)^{\perp}$.
    \item If $t\in S\cap S^{\perp}$, then $t\in S$ and $t\in S^{\perp}$, so
      \begin{align*}
        \iprod{t}{t} &= 0,
      \end{align*}
      so $t = 0$.
  \end{enumerate}
\end{solution}
One of the features of Hilbert spaces is that closed subspaces are always complemented. 
\begin{theorem}
  Let $M\subseteq \mathcal{H}$ be a closed subspace of a Hilbert space $\mathcal{H}$. Then, the following are true.
  \begin{enumerate}[(1)]
    \item $x-P_M\left(x\right)\in M^{\perp}$ for all $x\in \mathcal{H}$.
    \item $\mathcal{H} = M\oplus M^{\perp}$.
    \item $\left(M^{\perp}\right)^{\perp} = M$.
    \item Let $P$ and $Q$ denote the projection operators onto $M$ and $M^{\perp}$ according to the decomposition $\mathcal{H} = M\oplus M^{\perp}$. Then, $P = P_M$ and $Q = P_{M^{\perp}}$.
    \item $P_M$ is linear, $P_M^2 = P_M$, $\Ran\left(P_M\right) = M$, $\norm{P_M} = 1$, and $\ker\left(P_M\right) = M^{\perp}$.
    \item $\mathcal{H}/M \cong M^{\perp}$ are isometrically isomorphic.
  \end{enumerate}
\end{theorem}
\begin{proof}\hfill
  \begin{enumerate}[(1)]
    \item Let $y = P_M(x)$, and set $z = x-y$. We know that $\norm{z} = \dist_{M}(x) = d$. Let $0\neq \xi\in M$. Set $\zeta = P_{\xi}(z) = \frac{ \iprod{z}{\xi} }{ \iprod{\xi}{\xi} }\xi$.\newline

      We claim that $\zeta = 0$. Note that
      \begin{align*}
        \norm{z - \zeta}&= \norm{x - y-\zeta}\\
                        &= \norm{x - \left(y + \zeta\right)}\\
                        &\geq d,
      \end{align*}
      as $y + \zeta \in M$.\newline

      On the other hand, we have
      \begin{align*}
        \norm{z - \zeta}^2 + \norm{\zeta}^2 &= \norm{z}^2\\
                                            &= d^2.
      \end{align*}
      Thus, $\norm{ z - \zeta } \leq d$. With $\norm{z - \zeta} = d$, we have $\norm{x - y - \zeta} = d$. Thus, we must have $y + \zeta = y$, so $\zeta = 0$.
    \item If $x\in \mathcal{H}$, we have
      \begin{align*}
        x &= P_M\left(x\right) + x - P_M\left(x\right),
      \end{align*}
      and since $M\cap M^{\perp} = \set{0}$, we have $\mathcal{H} = M\oplus M^{\perp}$.
    \item It is the case that $M\subseteq \left(M^{\perp}\right)^{\perp}$. Let $x\in \left(M^{\perp}\right)^{\perp}$. Write $x = y + z$ according to the decomposition $\mathcal{H} = M\oplus M^{\perp}$. Then, $z = x - y \in \left(M^{\perp}\right)^{\perp}\cap \left(M^{\perp}\right) = \set{0}$, so $x = y\in M$, so $M = \left(M^{\perp}\right)^{\perp}$.
    \item By the way we have defined $P$ and $Q$, we must have $P(x)  = P_M(x)$ for every $x\in \mathcal{H}$. Let $\widetilde{P}$ and $\widetilde{Q}$ be the bounded linear projections according to the decomposition $\mathcal{H} = M^{\perp}\oplus \left(M^{\perp}\right)^{\perp}$. Since $M = \left(M^{\perp}\right)^{\perp}$, we have $\widetilde{Q} = P$. Additionally, we must have $\widetilde{P} = P_{M^{\perp}}$. Thus,
      \begin{align*}
        Q &= I - P\\
          &= I - \widetilde{Q}\\
          &= \widetilde{P}\\
          &= P_{M^{\perp}}.
      \end{align*}
    \item By the Pythagorean theorem, we have
      \begin{align*}
        \norm{x}^2 &= \norm{P_M(x)}^2 + \norm{x-P_M(x)}^2
      \end{align*}
      for every $x\in \mathcal{H}$, so $\norm{P_M(x)}\leq \norm{x}$, meaning $\norm{P_M} \leq 1$. Since $P_{M}^2 = P_{M}$, we also have $\norm{P_M} \geq 1$.
    \item Notice that $P_{M^{\perp}}:\mathcal{H}\rightarrow M^{\perp}$ is a $1$-quotient map with the kernel $\ker\left(P_{M^{\perp}}\right) = M$. Thus, we have $\mathcal{H}/M \cong M^{\perp}$.
  \end{enumerate}
\end{proof}
\begin{corollary}
  The following are true.
  \begin{enumerate}[(1)]
    \item The quotient of a Hilbert space is a Hilbert space.
    \item If $M\subsetneq \mathcal{H}$, then $M^{\perp}\neq \set{0}$. Additionally, if $M^{\perp} = \mathcal{H}$, then $M = \set{0}$.
    \item For any subset $S\subseteq \mathcal{H}$, we have $\left(S^{\perp}\right)^{\perp} = \overline{\Span}\left(S\right)$.
  \end{enumerate}
\end{corollary}
\begin{exercise}
  Let $\left(\Omega,\mathcal{M},\mu\right)$ be a measure space, and let $E\subseteq \mathcal{M}$ be measurable. We look at the set of essentially $E$-supported square-integrable functions:
  \begin{align*}
  M_{E} &= \set{\xi\in L_{2}\left(\Omega,\mu\right) | \xi|_{E^{c}} = 0 \text{ $\mu$-a.e.}}.
  \end{align*}
  \begin{enumerate}[(1)]
    \item Show that $M_{E}$ is a closed subspace of $L_{2}\left(\Omega,\mu\right)$, and prove that the orthogonal projection onto $M_{E}$ is given by
      \begin{align*}
        P_{M_E}\left(\xi\right) &= \xi \1_{E}.
      \end{align*}
    \item Note that the restriction $\left(E,\mathcal{M}|_{E},\mu_{E}\right)$ is a measure space, where
      \begin{align*}
        \mathcal{M}_E &= \set{F\cap E | F\in \mathcal{M}}\\
        \mu_{E} &= \mu|_{\mathcal{M}_E}.
      \end{align*}
      Prove that $L_{2}\left(E,\mu_E\right)$ and $M_{E}$ are unitarily isomorphic.
  \end{enumerate}
\end{exercise}
\begin{solution}[]\hfill
  \begin{enumerate}[(1)]
    \item If $\xi$ and $\eta$ are two functions that are essentially $E$-supported, then the sum $\xi + \alpha \eta$, where $\alpha\in \C$, is also essentially $E$-supported. Similarly, if $\left(\xi_n\right)_n\rightarrow \xi$ is a sequence of essentially $E$-supported functions converging in norm to $\xi$, then we have $\left(\xi_m - \xi_{n}\right)|_{E^{c}} = 0$ for each $\xi_{m},\xi_{n}$, so $\xi$ is also essentially $E$-supported.\newline

      To show that $P_{M_E}$ defined by $P_{M_E}\left(\xi\right) = \xi \1_{E}$ is the orthogonal projection onto $M_{E}$, we show that $P_{M_E}$ is idempotent and maps all members of $M_{E}$ to themselves. For $\xi\in L_{2}\left(\Omega,\mu\right)$, we see that
      \begin{align*}
        P_{M_E}^2\left(\xi\right) &= P_{M_E}\left(\xi \1_{E}\right)\\
                                  &= \xi\left(\1_{E}\right)\left(\1_{E}\right)\\
                                  &= \xi \1_{E}\\
                                  &= P_{M_E}\left(\xi\right).
      \end{align*}
      Additionally, for any $\xi\in M_{E}$, we have that $\xi \1_{E} \equiv \xi$ since $\xi|_{E^c} = 0$ $\mu$-a.e. Thus, $P_{M_E}$ is an idempotent operator that preserves the closed subspace $M_{E}$, so by the Hilbert projection theorem, it is necessarily the only (up to $\mu$-a.e. equivalence) orthogonal projection onto $M_{E}$.
    \item 
  \end{enumerate}
\end{solution}
\begin{proposition}
  Let $\mathcal{H}$ be a Hilbert space, and suppose $\set{M_i}_{i=1}^{n}$ is a finite family of mutually orthogonal closed subspaces. Write $M = \sum_{i=1}^{n}M_i$ for the internal sum.
  \begin{enumerate}[(1)]
    \item $M\subseteq \mathcal{H}$ is a closed subspace, and $M = \bigoplus_{i=1}^{n}M_i$ is the internal direct sum.
    \item $P_{M} = \sum_{i=1}^{n}P_{M_i}$.
  \end{enumerate}
\end{proposition}
\begin{proof}
  To see (1), we know that since $M_i\perp M_j$ for each $i\neq j$, it is the case that $M_i\cap M_j = \set{0}$ for each $i\neq j$, so it is indeed a direct sum.\newline

  To see (2), let $x\in \mathcal{H}$, and write $x = y + z$ according to the decomposition $\mathcal{H} = M\oplus M^{\perp}$. Since $M_j\subseteq M$, we have $\ker\left(P_{M_j}\right) \supseteq M^{\perp}$ for each $j$. Thus, $P_{M_j}(z) = 0$ for every $j$.\newline

  Since $M = \bigoplus_{i=1}^{n}M_i$, we write $y = \sum_{i=1}^{n}y_i$, with $y_i\in M_i$ uniquely. Since $M_i$ are mutually orthogonal, we know that $M_i\subseteq M_{j}^{\perp} = \ker\left(P_{M_j}\right)$ for each $i\neq j$. We compute
  \begin{align*}
    P_{M_j}\left(x\right) &= P_{M_j}\left(y + z\right)\\
                          &= P_{M_j}\left(y\right)\\
                          &= P_{M_j}\left(\sum_{i=1}^{n}y_i\right)\\
                          &= \sum_{i=1}^{n}P_{M_j}\left(y_i\right)\\
                          &= y_j.
  \end{align*}
  Thus, we get
  \begin{align*}
    \left(\sum_{i=1}^{n}P_{M_i}\right)\left(x\right) &= \sum_{i=1}^{n}P_{M_i}\left(x\right)\\
                                                     &= \sum_{i=1}^{n}y_i\\
                                                     &= y\\
                                                     &= P_{M}\left(x\right).
  \end{align*}
  
\end{proof}
We can now turn our attention to understanding the continuous dual of Hilbert spaces.
\begin{definition}
  Let $X$ be an inner product space, and fix $z\in X\setminus \set{0}$. We define $\varphi_z: X\rightarrow \F$ by $\varphi_z\left(x\right) = \iprod{x}{z}$.
\end{definition}
\begin{proposition}
  Let $X$ be an inner product space. Each $\varphi_z\in X^{\ast}$, and the map $X\rightarrow X^{\ast}$ defined by $z\mapsto \varphi_z$ is a conjugate linear isometry.
\end{proposition}
\begin{proof}
  We see that $\varphi_z$ is linear. We have
  \begin{align*}
    \left\vert \varphi_z\left(x\right) \right\vert &= \left\vert \iprod{x}{z} \right\vert\\
                                                   &\leq \norm{x}\norm{z},
  \end{align*}
  with
  \begin{align*}
    \varphi_z\left(\frac{z}{\norm{z}}\right) &= \frac{1}{\norm{z}} \iprod{z}{z}\\
                                             &= \norm{z},
  \end{align*}
  so $\norm{\varphi_z}_{\text{op}} = \norm{z}$. For every $x\in X$, we also have
  \begin{align*}
    \varphi_{z_1 + \alpha z_2} \left(x\right) &= \iprod{x}{z_1 + \alpha z_2}\\
                                              &= \iprod{x}{z_1} + \overline{\alpha} \iprod{x}{z_2}\\
                                              &= \left(\varphi_{z_1} + \overline{\alpha}\varphi_{z_2}\right) \left(x\right).
  \end{align*}
\end{proof}
If $\mathcal{H}$ is a Hilbert space, then the map $\mathcal{H}\rightarrow \mathcal{H}^{\ast}$ given by $z\mapsto \varphi_z$ is a bijection. This is known as the Riesz Representation Theorem (not to be confused for the Riesz representation Theorem for measures on $C_c\left(\Omega\right)$).
\begin{theorem}[Riesz Representation Theorem]
  Let $\mathcal{H}$ be a Hilbert space. If $\varphi\in H^{\ast}$, then there exists a unique $z\in \mathcal{H}$ such that $\varphi = \varphi_z$.
\end{theorem}
\begin{proof}
  We assume $\varphi\neq 0$. We have $M = \ker\left(\varphi\right)\subseteq \mathcal{H}$ is a proper closed subspace, so we can choose $w\in M^{\perp}$ such that $w\neq 0$.\newline

  We see that $\ker\left(\varphi\right)\subseteq \ker\left(\varphi_w\right)$, meaning that $\varphi = \lambda \varphi_w$ for some $\lambda\in \F$. We compute
  \begin{align*}
    \varphi(x) &= \lambda\varphi_w\left(x\right)\\
               &= \lambda \iprod{x}{w}\\
               &= \iprod{x}{\overline{\lambda}w}.
  \end{align*}
  Set $z = \overline{\lambda}w$.\newline

  To show uniqueness, if $\varphi = \varphi_{z_1} = \varphi_{z_2}$, then $ \iprod{x}{z_1 - z_2} = 0 $ for all $x\in \mathcal{H}$, so $z_1 - z_2 \in \mathcal{H}^{\perp} = \set{0}$, so $z_1 = z_2$.
\end{proof}
\begin{theorem}
  Every Hilbert space is reflexive.
\end{theorem}
\begin{proof}
  Let $\iota: \mathcal{H}\rightarrow \mathcal{H}^{\ast\ast}$ be the canonical embedding. Let $f\in \mathcal{H}^{\ast\ast}$, and define $\psi: \mathcal{H}\rightarrow \C$ by $\psi(x) = \overline{f\left(\varphi_x\right)}$. For all $x_1,x_2\in \mathcal{H}$ and $\lambda\in \C$, we have
  \begin{align*}
    \psi\left(x_1 + \lambda x_2\right) &= \overline{f\left(\varphi_{x_1 + \lambda x_2}\right)}\\
                                       &= \overline{f\left(\varphi_{x_1} + \overline{\lambda}\varphi_{x_2}\right)}\\
                                       &= \overline{f\left(\varphi_{x_1}\right) + \overline{\lambda}f\left(\varphi_{x_2}\right)}\\
                                       &= \overline{f\left(\varphi_{x_1}\right)} + \lambda \overline{f\left(\varphi_{x_2}\right)}\\
                                       &= \psi\left(x_1\right) + \lambda \psi\left(x_2\right).
  \end{align*}
  Moreover,
  \begin{align*}
    \left\vert \psi\left(x\right) \right\vert &= \left\vert \overline{f\left(\varphi_{x}\right)} \right\vert\\
                                              &= \left\vert f\left(\varphi_x\right) \right\vert\\
                                              &\leq \norm{f}\norm{\varphi_x}\\
                                              &= \norm{f}\norm{x}.
  \end{align*}
  Thus, $\psi\in \mathcal{H}^{\ast}$, so we know that $\psi = \varphi_{z}$ for some $z\in H$. Thus,
  \begin{align*}
    \overline{f\left(\varphi_x\right)} &= \psi\left(x\right)\\
                                       &= \varphi_z\left(x\right)\\
                                       &= \iprod{x}{z}\\
                                       &= \overline{ \iprod{z}{x} },
  \end{align*}
  so $f\left(\varphi_x\right) = \iprod{z}{x} = \varphi_x\left(z\right) = \hat{z}\left(\varphi_x\right)$, so $f = \hat{z}$, so $\iota$ is surjective.
\end{proof}
\subsection{Orthonormal Sets and Orthonormal Bases}%
\begin{definition}
  Let $X$ be an inner product space, and let $A$ be an indexing set.
  \begin{enumerate}[(1)]
    \item A subset $\set{x_{\alpha}}_{\alpha\in A}$ is called orthogonal if $ \iprod{x_{\alpha}}{x_{\beta}} = 0 $ for $\alpha \neq \beta$.
    \item An orthonormal set is an orthogonal set consisting of unit vectors. The set $\set{e_{\alpha}}_{\alpha \in A}$ is orthonormal if
      \begin{align*}
        \iprod{e_{\alpha}}{e_{\beta}} &= \begin{cases}
          1 & \alpha = \beta\\
          0 = \alpha \neq \beta
        \end{cases}.
      \end{align*}
  \end{enumerate}
\end{definition}
\begin{exercise}
  Show every orthogonal set is linearly independent.
\end{exercise}
\begin{solution}
  Let $\set{x_{\alpha}}_{\alpha\in A}$ be an orthogonal set. Then, for
  \begin{align*}
    \sum_{i=1}^{n}a_ix_{\alpha_i} &= 0,
  \end{align*}
  we take
  \begin{align*}
    \iprod{x_{\alpha_j}}{\sum_{i=1}^{n}a_ix_{\alpha_i}} &= a_j\norm{x_{\alpha_j}}^2\\
                                                        &= 0,
  \end{align*}
  so $a_i = 0$ for all $i$.
\end{solution}
\begin{remark}
  Given an inner product space $X$ and a finite linearly independent subset $F = \set{x_1,\dots,x_n}$, we can always use the Gram--Schmidt process to generate an orthonormal subset $G = \set{u_1,\dots,u_n}\subseteq X$ with $\Span(G) = \Span(F)$. Inductively, we take
  \begin{align*}
    v_1 &= x_1\\
    v_{k} &= x_k - \sum_{j=1}^{k-1}\frac{ \iprod{x_k}{v_j} }{ \iprod{v_j}{v_j} }v_j\\
    u_k &= \frac{1}{\norm{v_k}}v_k.
  \end{align*}
\end{remark}
\begin{exercise}
  Let $A$ be an arbitrary set, and consider the Hilbert space $\ell_{2}\left(A\right)$. Show that $\set{e_{\alpha}}_{\alpha \in A}\subseteq \ell_{2}\left(A\right)$ is an orthonormal set.
\end{exercise}
\begin{example}
  The family of continuous functions $\left(e_n\colon \mathbb{T}\rightarrow \C\right)_{n\in \Z}$ is an orthonormal basis for the arc length measure space $\left(\mathbb{T},\mathcal{L}_{\mathbb{T}},\nu\right)$.
  \begin{align*}
    \iprod{e_n}{e_m} &= \int_{\mathbb{T}}^{} e_{n}\overline{e_{m}}\:d\nu\\
                     &= \int_{\mathbb{T}}^{} e_{n}e_{-m}\:d\nu\\
                     &= \int_{\mathbb{T}}^{} e_{n-m}\:d\nu\\
                     &= \delta_{mn}.
  \end{align*}
\end{example}
\begin{theorem}
  Let $\mathcal{H}$ be a Hilbert space, and suppose $\left(e_{\alpha}\right)_{\alpha \in A}$ is an orthonormal family in $\mathcal{H}$.
  \begin{enumerate}[(1)]
    \item If $\left(c_{\alpha}\right)_{\alpha\in A}\in \ell_{2}\left(A\right)$, then $\sum_{\alpha \in A}c_{\alpha}e_{\alpha}$ is summable in $\mathcal{H}$, and
      \begin{align*}
        \norm{\sum_{a\in A}c_{\alpha}e_{\alpha}} &= \norm{\left(c_{\alpha}\right)_{\alpha}}.
      \end{align*}
    \item The map $T: \ell_{2}\left(A\right)\rightarrow \mathcal{H}$ defined by $T\left(\xi\right) = \sum_{\alpha \in A}\xi\left(\alpha\right)e_{\alpha}$ is a linear isometry.
    \item If $x\in \mathcal{H}$, then $\sum_{\alpha \in A}\left\vert \iprod{x}{e_{\alpha}} \right\vert^{2}\leq \norm{x}^2$. This is known as Bessel's inequality.
    \item If $M = \overline{\Span}\left(\set{e_{\alpha}}_{\alpha \in A}\right)$, then $P_{M}\left(x\right) = \sum_{\alpha \in A} \iprod{x}{e_{\alpha}}e_{\alpha}$ is the orthogonal projection onto $M$.
  \end{enumerate}
\end{theorem}
\begin{proof}\hfill
  \begin{enumerate}[(1)]
    \item We let $\mathcal{F}$ be the collection of finite subsets of $A$ directed by inclusion. For $F\in \mathcal{F}$, we define
      \begin{align*}
        s_F &= \sum_{\alpha \in F}c_{\alpha}e_{\alpha}\\
        c_{F} &= \sum_{\alpha \in F}\left\vert c_{\alpha} \right\vert^2.
      \end{align*}
      By the Pythagorean theorem, we have
      \begin{align*}
        \norm{s_F}^2 &= \norm{\sum_{\alpha \in F}c_{\alpha}e_{\alpha}}^2\\
                     &= \sum_{\alpha \in F}\norm{c_{\alpha}e_{\alpha}}^2\\
                     &= \sum_{\alpha \in F}\left\vert c_{\alpha} \right\vert^2\\
                     &= c_F.
      \end{align*}
      We claim the net $\left(s_{F}\right)_{F\in \mathcal{F}}$ is Cauchy in $\mathcal{H}$. For $F$ and $G$ in $\mathcal{F}$, we set
      \begin{align*}
        d_{\alpha} &= \begin{cases}
          c_{\alpha} & \alpha\in F\\
          -c_{\alpha} & \alpha \in G
        \end{cases}.
      \end{align*}
      Then,
      \begin{align*}
        \norm{s_{F} - s_{G}}^2 &= \norm{\sum_{\alpha \in F}c_{\alpha}e_{\alpha} - \sum_{\alpha \in G}c_{\alpha}e_{\alpha}}^2\\
                               &= \norm{\sum_{\alpha \in F\triangle G}d_{\alpha}e_{\alpha}}\\
                               &= \sum_{\alpha \in F\triangle G}\left\vert d_{\alpha} \right\vert^2\\
                               &= c_{F\triangle G}.
      \end{align*}
      Let $\ve > 0$. Since $\sum_{\alpha \in A}\left\vert c_{\alpha} \right\vert^2$ is summable, there is a finite $F_0\subseteq A$ such that for all $F\in \mathcal{F}$ with $F\cap F_0 = \emptyset$, we have $c_F\leq \ve^2$.\newline

      If $F$ and $G$ are finite subsets of $A$ with $F\supseteq F_0$ and $G\supseteq F_0$, then $F_0\subseteq F\cap G$, so $\left(F\triangle G\right)\cap F_0 = \emptyset$, so
      \begin{align*}
        \norm{s_F - s_G}^2 &= c_{F\triangle G}\\
                           &< \ve^2.
      \end{align*}
      We define $s = \sum_{\alpha \in A}c_{\alpha}e_{\alpha}$. This limit exists since $\mathcal{H}$ is complete and Cauchy nets converge. The norm of $s$ is computed as
      \begin{align*}
        \norm{s}^2 &= \sum_{\alpha \in A}\left\vert c_{\alpha} \right\vert^2.
      \end{align*}
    \item This follows directly from (1).
    \item Let $F\subseteq A$ be finite, and set $M_F = \Span\set{e_{\alpha} | \alpha \in F}$. Since $M_F$ is finite-dimensional, $M_F$ is closed. For $x\in \mathcal{H}$ and $\beta \in A\setminus F$, the orthogonality of $\left(e_{\alpha}\right)_{\alpha \in A}$ provides
      \begin{align*}
        \iprod{x - \sum_{\alpha \in F} \iprod{x}{e_{\alpha}}e_{\alpha}}{e_{\beta}} &= 0.
      \end{align*}
      Thus, we write
      \begin{align*}
        x &= x -\sum_{\alpha \in F} \iprod{x}{e_{\alpha}}e_{\alpha} + \sum_{\alpha \in F} \iprod{x}{e_{\alpha}}e_{\alpha},
      \end{align*}
      which gives $P_{M_F} = \sum_{\alpha \in F} \iprod{x}{e_{\alpha}}e_{\alpha}$. Using the Pythagorean theorem, we get
      \begin{align*}
        \sum_{\alpha \in F} \left\vert \iprod{x}{e_{\alpha}} \right\vert^2 &= \norm{P_{M_F}\left(x\right)}^2\\
                                                                           &\leq \norm{x}^2.
      \end{align*}
      The inequality follows by taking the supremum,
      \begin{align*}
        \sum_{\alpha \in A} \left\vert \iprod{x}{e_{\alpha}} \right\vert^2 &= \sup_{F\subseteq A}\left(\sum_{\alpha \in F}\left\vert \iprod{x}{e_{\alpha}} \right\vert^2\right)\\
                                                                           &\leq \norm{x}^2.
      \end{align*}
    \item Fix $x\in \mathcal{H}$, and for each $\alpha \in A$, we set $c_{\alpha} = \iprod{x}{e_{\alpha}}$. We have $\left(c_{\alpha}\right)_{\alpha \in A}\in \ell_2\left(A\right)$, so $\sum_{\alpha \in A}c_{\alpha}e_{\alpha}$ is norm-summable in $\mathcal{H}$. Continuity of the inner product yields
      \begin{align*}
        \iprod{x - \sum_{\alpha \in A} \iprod{x}{e_{\alpha}}e_{\alpha}}{e_{\beta}} &= 0,
      \end{align*}
      so $x - \sum_{\alpha \in A} \iprod{x}{e_{\alpha}}e_{\alpha} \in M^{\perp}$, meaning $P_{M}(x) = \sum_{\alpha \in A} \iprod{x}{e_{\alpha}}e_{\alpha}$.
  \end{enumerate}
\end{proof}
\begin{corollary}
  If $\mathcal{H}$ is a Hilbert space, and $\set{x_{\alpha}}_{\alpha\in A}$ is an orthogonal set such that $\sum_{\alpha \in A}\norm{x_{\alpha}}^2$ is summable, then $\sum_{\alpha \in A}x_\alpha$ is summable and
  \begin{align*}
    \norm{\sum_{\alpha \in A}x_{\alpha}}^2 &= \sum_{\alpha \in A}\norm{x_{\alpha}}^2.
  \end{align*}
\end{corollary}
\begin{proof}
  Set $e_{\alpha} = \frac{1}{\norm{x_{\alpha}}}x_{\alpha}$, and $c_{\alpha} = \norm{x_{\alpha}}$ in the proof of the theorem above.
\end{proof}
\begin{example}
  If $\left(e_n\right)_{n\geq 1}$ is the set of standard coordinate vectors in $\ell_2$, then $\sum_{n\in \N}\frac{1}{n}e_n$ is summable, but the series does not converge absolutely.
\end{example}
\begin{definition}
  Let $\mathcal{H}$ be a Hilbert space. An orthonormal basis in $\mathcal{H}$ is a maximal orthonormal set $E$. That is, if $E\subsetneq E'$, then $E'$ is not an orthonormal basis.
\end{definition}
\begin{lemma}
  Let $\mathcal{H}$ be a Hilbert space. Every orthonormal set in $\mathcal{H}$ is contained in an orthonormal basis.
\end{lemma}
\begin{proof}
  Let $F\subseteq \mathcal{H}$ be an orthonormal set. Let
  \begin{align*}
    \mathcal{E} &= \set{E\subseteq \mathcal{H} | F\subseteq E,~E \text{ orthonormal}},
  \end{align*}
  and order $\mathcal{E}$ by inclusion. For any chain $\mathcal{C}$ in $\mathcal{E}$, then $U = \bigcup_{C\in \mathcal{C}}C$ is an upper bound for $\mathcal{C}$, as for any two vectors $e_{\alpha},e_{\beta}\in U$, both $e_{\alpha}$ and $e_{\beta}$ are contained in some $C\in \mathcal{C}$, so $ \iprod{e_{\alpha}}{e_{\beta}} = \delta_{\alpha \beta}$. Applying Zorn's lemma, we get the desired result.
\end{proof}
Orthonormal bases, like Schauder bases, have dense linear span in a Hilbert space.
\begin{theorem}
  Let $\mathcal{H}$ be a Hilbert space, and $E = \left(e_{\alpha}\right)_{\alpha \in A}$ be an orthonormal set. Let $M = \overline{\Span}\set{e_{\alpha} | \alpha \in A}$. The following are equivalent:
  \begin{enumerate}[(i)]
    \item $E$ is an orthonormal basis;
    \item $M^{\perp} = \set{0}$;
    \item $M = \mathcal{H}$;
    \item for each $x\in \mathcal{H}$, we have $x = \sum_{\alpha \in A} \iprod{x}{e_{\alpha}}e_{\alpha}$;
    \item for each $x\in \mathcal{H}$, we have $\norm{x}^2 = \sum_{\alpha \in A} \left\vert \iprod{x}{e_{\alpha}} \right\vert^2$ (known as Parseval's identity);
    \item for each $x,y\in \mathcal{H}$, we have $ \iprod{x}{y} = \sum_{\alpha \in A} \iprod{x}{e_{\alpha}} \overline{ \iprod{y}{e_{\alpha}} }$.
  \end{enumerate}
\end{theorem}
\begin{proof}
  To see (i) implies (ii), we suppose there is $v\in M^{\perp}$ with $\norm{v} = 1$. Then, $\set{v}\cup E$ is an orthonormal set containing $E$, which contradicts the maximality of $E$.\newline

  The equivalence of (ii) and (iii) follows from the fact that $\mathcal{H}^{\perp} = \set{0}$ and $\set{0}^{\perp} = \mathcal{H}$.\newline

  To see that (iii) implies (i), we suppose there is $v\in \mathcal{H}$ such that $v\notin E$ and $\set{v}\cup E$ is an orthonormal set. THen, for each $\alpha \in A$, we have $ \iprod{v}{e_{\alpha}} = 0 $, so $ \iprod{v}{x} = 0 $ for each $x\in \Span\set{e_{\alpha} | \alpha \in A}$. Since the inner product is continuous, we have $ \iprod{v}{x} = 0 $ for each $x\in \overline{\Span}\set{e_{\alpha} | \alpha \in A} = M = \mathcal{H}$, implying that $\norm{v} =0$.\newline

  To see that (iii) implies (iv), recall that we proved that $P_M(x) = \sum_{\alpha \in A} \iprod{x}{e_{\alpha}}e_{\alpha}$, but since $M = \mathcal{H}$, we have $P_M(x) = x$.\newline

  We see that (v) follows from (iv) by the previous theorem.\newline

  To see that (v) implies (i), if $ \iprod{v}{e_{\alpha}} = 0 $ for each $\alpha \in A$, we must have $\norm{v} = 0$, so $E $ is a maximal orthonormal set.\newline

  To see that (vi) implies (v), we let $x = y$ in the hypothesis of (vi).\newline

  To see that (iv) implies (vi), we let $x,y\in \mathcal{H}$. We let $x = \sum_{\alpha \in A} \iprod{x}{e_{\alpha}}e_{\alpha}$, and $y = \sum_{\beta\in A} \iprod{y}{e_{\beta}} e_{\beta}$. By the continuity of the inner product and the orthonormality of $E$, we have
  \begin{align*}
    \iprod{x}{y} &= \iprod{\sum_{\alpha \in A} \iprod{x}{e_{\alpha}}e_{\alpha}}{ \sum_{\beta\in A} \iprod{y}{e_{\beta}}e_{\beta} }\\
                 &= \sum_{\alpha,\beta \in A} \iprod{x}{e_{\alpha}} \overline{\iprod{y}{e_{\beta}}} \iprod{e_{\alpha}}{e_{\beta}}\\
                 &= \sum_{\alpha \in A} \iprod{x}{e_{\alpha}} \overline{ \iprod{y}{e_{\beta}} }.
  \end{align*}
  
\end{proof}
For an orthonormal basis $\set{e_{\alpha}}_{\alpha \in A}$ and a given $x\in \mathcal{H}$, we often refer to the terms $ \iprod{x}{e_{\alpha}} $ as the Fourier coefficients of $x$ with respect to the basis $\set{e_{\alpha}}_{\alpha \in A}$.\newline

Recall that any two vector spaces $X$ and $Y$ are isomorphic if and only if $\Dim(X) = \Dim(Y)$. A similar idea holds for Hilbert spaces.
\begin{proposition}[]
Let $\mathcal{H}$ be a Hilbert space. Any two orthonormal bases for $\mathcal{H}$ have the same cardinality.
\end{proposition}
\begin{proof}
  Let $E = \set{e_{\alpha}}_{\alpha \in A}$ and $F = \set{f_{\beta}}_{\beta \in B}$ be two orthonormal bases for $\mathcal{H}$. If $E$ is finite, then it must be a Hamel basis as orthogonal sets are independent and finite orthonormal bases are spanning by Parseval's identity. Thus, $\Dim(\mathcal{H}) < \infty$, and since $F$ is independent, $F$ is finite, so it must be a Hamel basis, with $\Card(E) = \Card(F)$.\newline

  Suppose $A$ and $B$ are both infinite. For each $\beta \in B$, consider
  \begin{align*}
    A_{\beta} \coloneq \set{\alpha | \iprod{f_{\beta}}{e_{\alpha}} \neq 0}.
  \end{align*}
  Since
  \begin{align*}
    \norm{f_{\beta}}^2 &= \sum_{\alpha \in A} \left\vert \iprod{f_{\beta}}{e_{\alpha}} \right\vert^2\\
                       &= 1
  \end{align*}
  is summable, $A_{\beta}$ must be countable. Additionally, $A\subseteq \bigcup_{\beta \in B}A_{\beta}$, since
  \begin{align*}
    \norm{e_{\alpha}}^2 &= \sum_{\beta \in B}\left\vert \iprod{e_{\alpha}}{f_{\beta}} \right\vert^2.
  \end{align*}
  Since $\Card\left(A_{\beta}\right) \leq \aleph_0\leq \Card(B)$, we get
  \begin{align*}
    \Card(A) \leq \Card\left(\bigcup_{\beta \in B}A_{\beta}\right)\leq \Card(B).
  \end{align*}
  Similarly, $\Card(B) \leq \Card(A)$, so $\Card(A) = \Card(B)$ by Cantor--SchrÃ¶der--Bernstein.
\end{proof}
\begin{definition}
  Let $\mathcal{H}$ be a Hilbert space. The Hilbert dimension of $\mathcal{H}$, written $\hdim(\mathcal{H})$, is the cardinality of $E$ for any orthonormal basis $E$ of $\mathcal{H}$.
\end{definition}
We can characterize all Hilbert spaces with countable Hilbert dimension.
\begin{proposition}
  Let $\mathcal{H}$ be a Hamel basis with $\dim(H) = n < \infty$. Then, $\mathcal{H} \cong \ell_2^{n}$ are unitarily isomorphic.
\end{proposition}
\begin{proof}
  Let $\set{v_1,\dots,v_n}$ be a Hamel basis for $\mathcal{H}$. Applying the Gram--Schmidt process, we obtain an orthonormal set $\set{u_1,\dots,u_n}$ with the same span as $\set{v_1,\dots,v_n}$. The map $T\colon \ell_{2}^{n}\rightarrow \mathcal{H}$ given by $T\left(e_j\right) = u_j$ is a surjective isometry.
\end{proof}
\begin{proposition}
  Let $\mathcal{H}$ be an infinite-dimensional Hilbert space. The following are equivalent.
  \begin{enumerate}[(i)]
    \item $\mathcal{H}$ is separable;
    \item $\hdim\left(\mathcal{H}\right) = \aleph_0$;
    \item $\mathcal{H}\cong \ell_2$.
  \end{enumerate}
\end{proposition}
\begin{proof}
  Let $\set{x_k}_{k=1}^{\infty}\subseteq \mathcal{H}$ be norm-dense, and let $\left(e_{\alpha}\right)_{\alpha}$ be an orthonormal basis. Note that for $\alpha \neq \beta$, we have
  \begin{align*}
    \norm{e_{\alpha} - e_{\beta}}^2 &= \iprod{e_{\alpha} - e_{\beta}}{e_{\alpha} - e_{\beta}}\\
                                    &= 2,
  \end{align*}
  so $\norm{e_{\alpha} - e_{\beta}} = \sqrt{2}$. For each $\alpha \in A$, the density of $\set{x_k}_{k=1}^{\infty}$ allows us to find $J\left(\alpha\right)\in \N$ such that
  \begin{align*}
    \norm{e_{\alpha} - x_{J_{\alpha}}} < \frac{1}{2}.
  \end{align*}
  We have a map $J: A\rightarrow \N$. We claim that $J$ is injective. If not, then there are $\alpha,\beta \in A$ with $\alpha\neq \beta$, $J\left(\alpha\right) = J\left(\beta\right)$. We then have
  \begin{align*}
    \sqrt{2} &= \norm{e_{\alpha} - e_{\beta}}\\
             &\leq \norm{e_{\alpha} - x_{J\left(\alpha\right)}} + \norm{x_{J\left(\alpha\right)} - e_{\beta}}\\
             &= \norm{e_{\alpha} - x_{J\left(\alpha\right)}} + \norm{x_{J\left(\beta\right)} - e_{\beta}}\\
             &< 1.
  \end{align*}
  Thus, $J$ is injective, so $A$ is countable.\newline

  If $\left(f_n\right)_{n\in \N}$ is an orthonormal basis for $\mathcal{H}$, then we have $\mathcal{H} \cong \ell_2\left(\N\right) = \ell_2$.\newline

  If $\left(e_n\right)_{n\geq 1}$ is the canonical orthonormal basis for $\ell_2$, then we know that $\Span\left(E\right)$ is dense in $\ell_2$, so $E$ is a countable total subset of $\ell_2$, so $\mathcal{H}$ is separable.
\end{proof}
\subsection{Tensor Products and Direct Sums of Hilbert Spaces}%
We have shown that closed subspaces and quotient spaces of Hilbert spaces are Hilbert spaces. Now, we turn our attention to external direct sums and tensor products.
\subsubsection{Direct Sums}%
In linear algebra, we learn that, for a normal $n\times n$ matrix, we can decompose $\ell_2^{n}$ into orthogonal pieces that the matrix acts on by scalar multiplication. In order to understand the spectral theorem for normal operators on Hilbert spaces, we need to understand such a decomposition.
\begin{proposition}
  Let $\set{\mathcal{H}_i}_{i\in I}$ be a family of Hilbert spaces. The set
  \begin{align*}
    \bigoplus_{i\in I}\mathcal{H}_i = \set{\left(x_i\right)_{i\in I} | x_i\in \mathcal{H}_i\text{ and } \sum_{i\in I}\norm{x_i}^2\text{ is summable}}
  \end{align*}
  equipped with pointwise operations is a vector space, with inner product
  \begin{align*}
    \iprod{x}{y} &\coloneq \sum_{i\in I} \iprod{x_i}{y_i}
  \end{align*}
  for $\left(x_i\right)_{i\in I},\left(y_i\right)_{i\in I}\in \bigoplus_{i\in I}\mathcal{H}_i$ that induces the complete norm
  \begin{align*}
    \norm{\left(x_i\right)_i} &\coloneq \left(\sum_{i\in I}\norm{x_i}^2\right)^{1/2}.
  \end{align*}
    The Hilbert space $\bigoplus_{i\in I}\mathcal{H}_i$ is known as the external direct sum of the family $\set{\mathcal{H}_i}_{i\in I}$.
\end{proposition}
\begin{example}
  If $I$ is a set, and for each $i\in I$, we have $\mathcal{H}_{i} = \C$, then $\bigoplus_{i\in I}\mathcal{H}_{i} = \ell_2\left(I\right)$.
\end{example}
\begin{example}
  If we fix a Hilbert space $\mathcal{H}$, the external direct sum $\bigoplus_{n\geq 1}\mathcal{H}$ is often denoted by $\mathcal{H}^{\infty}$ or $\ell_2\left(\mathcal{H}\right)$.
\end{example}
\begin{example}
  Let $\set{\left(\Omega_n,\mathcal{M}_n,\mu_n\right)}_{n}$ be a countable family of measure spaces, and let $\left(\Sigma,\mathcal{M},\mu\right)$ be the coproduct of these spaces, defined by
  \begin{align*}
    \Sigma &\coloneq \coprod_{n=1}^{\infty}\Omega_n\\
    \mathcal{M}&\coloneq \set{E\subseteq \Sigma | \iota_n^{-1}\left(E\right)\in \mathcal{M}_n\text{ for all $n$}}\\
    \mu\left(E\right) &= \sum_{n=1}^{\infty}\mu_n\left(\iota_n^{-1}\left(E\right)\right).
  \end{align*}
  Then, the map
  \begin{align*}
    V: L_{2}\left(\Sigma,\mu\right) \rightarrow \bigoplus_{n\geq 1}L_2\left(\Omega_n,\mu_n\right),
  \end{align*}
  defined by
  \begin{align*}
    V\left(\xi\right) &= \left(\xi\circ \iota_n\right)_n
  \end{align*}
  is a well-defined unitary isomorphism.\newline

  Let $\xi \in L_{2}\left(\Sigma,\mu\right)$. Since each $\iota_n: \Omega_n\rightarrow \Sigma$ is measurable, $\xi\circ \iota_n: \Omega_n\rightarrow \C$ is also measurable. Additionally, if $\xi$ is $0$ $\mu$-a.e., then so is $\xi\circ \iota_n$. Moreover, we have
  \begin{align*}
    \norm{V\left(\xi\right)}^2 &= \norm{\left(\xi\circ \iota_n\right)_n}^2\\
                               &= \sum_{n\geq 1}\norm{\xi\circ \iota_n}^2\\
                               &= \sum_{n\geq 1}\int_{\Omega_n}^{} \left\vert \xi\circ \iota_n(x) \right\vert^2\:d\mu_n\\
                               &= \sum_{n\geq 1}\int_{\Omega_n}^{} \left\vert \xi \right\vert^2\circ \iota_n(x)\:d\mu_n\\
                               &= \int_{\Sigma}^{} \left\vert \xi \right\vert^2\:d\mu\\
                               &= \norm{\xi}^2.
  \end{align*}
  This shows $V$ is a well-defined linear map. Our calculation shows that $V$ is an isometry.\newline

  We only need to write an inverse, for which which we define
  \begin{align*}
    W: \bigoplus_{n\geq 2}L_{2}\left(\Omega_n,\mu_n\right)\rightarrow L_2\left(\Sigma,\mu\right),
  \end{align*}
  defined by
  \begin{align*}
    W\left(\left(\xi_n\right)_n\right) &= \xi,
  \end{align*}
  where
  \begin{align*}
    \xi &\coloneq \coprod_{n\geq 1}\left(\xi_n: \Omega\rightarrow \C\right)\\
    \xi\left(x,n\right) &= \xi_n\left(x\right).
  \end{align*}
\end{example}

\section{Bounded Operators on Hilbert Spaces}%
Hilbert spaces are, according to John Conway, anyway, ``boring,'' so we are interested in understanding the effects of operators on Hilbert spaces.\newline

In the case of quantum mechanics, a particle with wave function $\xi$ moving along the $x$ axis has position equivalent to its expected value,
\begin{align*}
  \int_{\R}^{} x \left\vert \xi\left(x\right) \right\vert^2\:d\lambda &= \iprod{\id_{\R} \xi}{\xi},
\end{align*}
where the $x$ coordinate is now an observable of an operator $\xi\xmapsto{Q} \id_{R}\xi$, which is known as position. This operator is only defined on its domain, as it is not bounded.\newline

Similarly, linear momentum is the map $\xi\xmapsto{P} \xi'$ (on the domain that it is defined), yielding
\begin{align*}
  \iprod{P\left(\xi\right)}{\xi} &= \int_{\R}^{} \diff{\xi}{x}\overline{\xi(x)}\:d\lambda,
\end{align*}
from which we get the uncertainty principle
\begin{align*}
  PQ\left(\xi\right) &= I\left(\xi\right) + QP\left(\xi\right).
\end{align*}
\subsection{Structure of $\mathcal{B}\left(\mathcal{H}\right)$}%
If $X$ is a Banach space, then $\mathcal{B}\left(X\right)$, the space of bounded linear operators on $X$, is a unital Banach algebra. We will study the structure of $\mathcal{B}\left(\mathcal{H}\right)$, which is the space of bounded linear operators on a Hilbert space.
\subsubsection{Algebraic-Analytic Structure}%
\begin{fact}
  Let $T,S\colon \mathcal{H}\rightarrow \mathcal{K}$ be linear maps between Hilbert spaces.
  \begin{enumerate}[(1)]
    \item We have $T=S$ if and only if $ \iprod{T(x)}{y} = \iprod{S(x)}{y} $ for all $x\in \mathcal{H}, y\in \mathcal{K}$.
    \item If $\mathcal{H} = \mathcal{K}$, then $T = S$ if and only if $ \iprod{T(x)}{x} = \iprod{S(x)}{x} $ for all $x\in \mathcal{H}$.
  \end{enumerate}
\end{fact}
\begin{proof}\hfill
  \begin{enumerate}[(1)]
    \item This follows from the fact that $ \iprod{x}{z_1} = \iprod{x}{z_2} $ for all $x$ if and only if $z_1 = z_2$.
    \item We define the sesquilinear forms $F\colon \mathcal{H}\times \mathcal{H}\rightarrow \C$, $G\colon \mathcal{H}\times \mathcal{H}\rightarrow \C$ by
      \begin{align*}
        F\left(x,y\right) &= \iprod{T(x)}{y}\\
        G\left(x,y\right) &= \iprod{S(x)}{y}.
      \end{align*}
      We see that $T = S$ if and only if $F = G$, if and only if $F$ and $G$ agree on the diagonal, meaning $ \iprod{T(x)}{x} = \iprod{S(x)}{x} $ for all $x\in \mathcal{H}$.
  \end{enumerate}
\end{proof}
\begin{fact}
  If $T\colon \mathcal{H}\rightarrow \mathcal{K}$ is a linear map, then
  \begin{align*}
    \norm{T}_{\text{op}} &= \sup\set{\left\vert \iprod{T(x)}{y} \right\vert | x\in B_{\mathcal{H}},y\in B_{\mathcal{K}}}.
  \end{align*}
\end{fact}
\begin{proof}
  By the Riesz Representation theorem, we have that $B_{K^{\ast}} = \set{ \iprod{\cdot}{y} | y\in B_{\mathcal{K}} }$, meaning we have
  \begin{align*}
    \norm{T(x)} &= \sup_{y\in B_{\mathcal{K}}}\left\vert \iprod{T(x)}{y} \right\vert.
  \end{align*}
  Taking the supremum over $x\in B_{\mathcal{Y}}$ yields
  \begin{align*}
    \norm{T}_{\text{op}} &= \sup_{x\in B_{\mathcal{H}}} \norm{T(x)}\\
                         &= \sup\set{ \left\vert \iprod{T(x)}{y} \right\vert | x\in B_{\mathcal{H}},y\in B_{\mathcal{K}} }.
  \end{align*}
\end{proof}
\begin{definition}
  Let $F: \mathcal{H}\times \mathcal{K}\rightarrow \C$ be a sesquilinear form. We define the norm
  \begin{align*}
    \norm{F} &\coloneq \sup\set{\left\vert F(x,y) \right\vert | x\in B_{\mathcal{H}},y\in B_{\mathcal{K}}}.
  \end{align*}
  We say $F$ is bounded if $\norm{F} < \infty $.
\end{definition}
\begin{proposition}
  If $F: \mathcal{H}\times \mathcal{K}\rightarrow \C$ is a bounded sesquilinear form, then there exists a unique $S\in B\left(\mathcal{K},\mathcal{H}\right)$ such that
  \begin{align*}
    F\left(x,y\right) &= \iprod{x}{S(y)}.
  \end{align*}
\end{proposition}
\begin{proof}[]
Fix $y\in \mathcal{K}$, and consider the linear functional $\varphi: \mathcal{H}\rightarrow \C$ given by $\varphi(x) = F\left(x,y\right)$. Since $\varphi$ is linear, we have
\begin{align*}
  \left\vert \varphi(x) \right\vert &= \left\vert F\left(x,y\right) \right\vert\\
                                    &\leq \norm{F}\norm{y}
\end{align*}
for all $x\in B_{\mathcal{H}}$, meaning $\varphi\in \mathcal{H}^{\ast}$. Thus, there is a unique $z\in \mathcal{H}$ such that $\varphi = \varphi_z$. We define $S(y) \coloneq z$. Doing this for each $y\in \mathcal{K}$, we get a map $S: \mathcal{K}\rightarrow \mathcal{H}$ such that
\begin{align*}
  F\left(x,y\right) &= \iprod{x}{S(y)}.
\end{align*}
We show that $S$ is linear and bounded. Let $y_1,y_2\in \mathcal{K}$ and $\alpha \in \mathcal{C}$. For all $x\in \mathcal{H}$, we have
\begin{align*}
  \iprod{x}{S\left(y_1 + \alpha y_2\right)} &= F\left(x,y_1 + \alpha y_2\right)\\
                                            &= F\left(x,y_1\right) + \overline{\alpha}F\left(x,y_2\right)\\
                                            &= \iprod{x}{S\left(y_1\right)} + \overline{\alpha} \iprod{x}{S\left(y_2\right)}\\
                                            &= \iprod{x}{S\left(y_1\right) + \alpha S\left(y_2\right)}.
\end{align*}
Thus, $S$ is linear. We also have
\begin{align*}
  \norm{S}_{\text{op}} &= \sup\set{\left\vert \iprod{x}{S(y)} \right\vert | x\in B_{\mathcal{H}},y\in B_{\mathcal{K}}}\\
                       &= \sup\set{\left\vert F(x,y) \right\vert | x\in B_{\mathcal{H}},y\in B_{\mathcal{K}}}\\
                       &= \norm{F}.
\end{align*}
For uniqueness, we see that if $ \iprod{x}{S_1(y)} = F(x,y) = \iprod{x}{S_2(y)} $, then $S_1 = S_2$ necessarily.
\end{proof}
\begin{theorem}
  Let $\mathcal{H}, \mathcal{K},\mathcal{L}$ be Hilbert spaces. If $T\in \mathcal{B}\left(\mathcal{H},\mathcal{K}\right)$, then there is a unique bounded operator $T^{\ast}\in \mathcal{B}\left(\mathcal{K},\mathcal{H}\right)$ such that 
  \begin{align*}
    \iprod{T(x)}{y} &= \iprod{x}{T^{\ast}\left(y\right)}
  \end{align*}
  for all $x\in \mathcal{H}$ and $y\in \mathcal{K}$. We call $T^{\ast}$ the Hilbert space adjoint of $T$. Moreover, the following are true for $T,S\in \mathcal{B}\left(\mathcal{H},\mathcal{K}\right)$, $R\in \mathcal{B}\left(\mathcal{K},\mathcal{L}\right)$, and $\lambda \in \C$:
  \begin{enumerate}[(1)]
    \item $\left(T + \lambda S\right)^{\ast} = T^{\ast} + \overline{\lambda}S^{\ast}$;
    \item $T^{\ast\ast} = T$;
    \item $\left(R\circ T\right)^{\ast} = T^{\ast}\circ R^{\ast}$;
    \item if $T$ is invertible, then $\left(T^{-1}\right)^{\ast} = \left(T^{\ast}\right)^{-1}$;
    \item $\norm{T^{\ast}} = \norm{T}$;
    \item $\norm{T^{\ast}T} = \norm{T}^2$ (known as the $C^{\ast}$-property).
  \end{enumerate}
\end{theorem}
\begin{proof}
  We define $F: \mathcal{H}\times \mathcal{K}\rightarrow \C$ by $F\left(x,y\right) = \iprod{T(x)}{y}$. We have $F$ is a sesquilinear form, and
  \begin{align*}
    \norm{F} &= \sup\set{\left\vert F(x,y) \right\vert | x\in B_{\mathcal{H}},y\in B_{\mathcal{K}}}\\
             &= \sup\set{\left\vert \iprod{T(x)}{y} \right\vert | x\in B_{\mathcal{H}},y\in B_{\mathcal{K}}}\\
             &= \norm{T}_{\text{op}}.
  \end{align*}
  Thus, there is a unique operator $S_T\in \mathcal{B}\left(\mathcal{K},\mathcal{H}\right)$ such that $ \iprod{T(x)}{y} = \iprod{x}{S_T(y)} $, with $\norm{S_T} = \norm{T}$. We define $T^{\ast} = S_T$.\newline

  We will show (6).
  \begin{align*}
    \norm{T^{\ast}T} &= \sup_{\substack{x\in B_{\mathcal{H}}\\y\in B_{\mathcal{K}}}} \left\vert \iprod{T^{\ast} T (x)}{y} \right\vert\\
                     &\geq \sup_{x\in B_{\mathcal{H}}} \left\vert \iprod{T^{\ast}T\left(x\right)}{x} \right\vert\\
                     &= \sup_{x\in B_{\mathcal{H}}}\left\vert \iprod{T(x)}{T(x)} \right\vert\\
                     &= \sup_{x\in B_{\mathcal{H}}} \norm{T(x)}^2\\
                     &= \left(\sup_{x\in B_{\mathcal{H}}}\norm{T(x)}\right)^2\\
                     &= \norm{T}^2\\
                     &= \norm{T}\norm{T}\\
                     &= \norm{T^{\ast}}\norm{T}\\
                     &\geq \norm{T^{\ast}T}.
  \end{align*}
\end{proof}
\begin{exercise}
  Let $\mathcal{H}$ and $\mathcal{K}$ be Hilbert spaces, and suppose $T\in \mathcal{B}\left(\mathcal{H},\mathcal{K}\right)$. Write $T^{\ast}\in \mathcal{B}\left(\mathcal{K},\mathcal{H}\right)$ to be the (Hilbert space) adjoint, and $T^{\dagger}: K^{\ast}\rightarrow H^{\ast}$ to be the Banach space adjoint. Let $\rho_{\mathcal{H}}:\mathcal{H}\rightarrow \mathcal{H}^{\ast}$ be the conjugate linear isometry $x\mapsto \varphi_x$, and let $\rho_{\mathcal{K}}: \mathcal{K}\rightarrow \mathcal{K}^{\ast}$ to be the conjugate linear isometry $y \mapsto \varphi_{y}$. Show that the following diagram commutes.
  \begin{center}
    % https://tikzcd.yichuanshen.de/#N4Igdg9gJgpgziAXAbVABwnAlgFyxMJZABgBoBGAXVJADcBDAGwFcYkQAdDgW3pwAsAxk2ABpAL4hxpdJlz5CKchWp0mrdl14DhjYAAlJ02djwEiZYqoYs2iTjz5CREgHrAu9ODiMyQGUwUiZSsaGw17LSddA3F3T28jVRgoAHN4IlAAMwAnCG4kMhAcCCRlEEZ6ACMYRgAFOTNFEBysVP4cEDD1OxAAFXiOLx8pP1z8wpoSpAAmbttNDhz+CAB9D0cdF3FfbLyCxHLpxABmGkqa+sag+1b2zvmIh2W1je1nPUNdkHGDueLSqdHr0BhsoPRUukcklxEA
\begin{tikzcd}
\mathcal{K}^{\ast} \arrow[r, "T^{\dagger}"]                        & \mathcal{H}^{\ast}                           \\
\mathcal{K} \arrow[r, "T^{\ast}"'] \arrow[u, "\rho_{\mathcal{K}}"] & \mathcal{H} \arrow[u, "\rho_{\mathcal{H}}"']
\end{tikzcd}
  \end{center}
\end{exercise}
\begin{proof}
  Let $x\in \mathcal{H}$, $y\in \mathcal{K}$. By the Riesz representation theorem, we have $\varphi_{x} = \iprod{\cdot}{x}$ and $\varphi_{y} = \iprod{\cdot}{y}$. Thus, we have
  \begin{align*}
    T^{\dagger}\left(\varphi_y\right)\left(\left(x\right)\right) &= \varphi_{y}\left(T\left(x\right)\right)\\
                                                                 &= \iprod{T(x)}{y}\\
                                                                 &= \iprod{x}{T^{\ast}(y)}\\
                                                                 &= \varphi_{x}\left(T^{\ast}\left(y\right)\right).
  \end{align*}
  
\end{proof}
\begin{corollary}
  The adjoint map $\ast: \mathcal{B}\left(\mathcal{H}\right)\rightarrow \mathcal{B}\left(\mathcal{H}\right)$ defined by $T\mapsto T^{\ast}$ is an involution, meaning $\mathcal{B}\left(\mathcal{H}\right)$ is a unital $\ast$-algebra. If $\Dim\left(\mathcal{H}\right) > 1$, then $\mathcal{B}\left(\mathcal{H}\right)$ is noncommutative.
\end{corollary}
\begin{definition}
  A Banach $\ast$-algebra is a Banach algebra $A$ with an involution satisfying
  \begin{align*}
    \norm{a^{\ast}} = \norm{a}
  \end{align*}
  for all $a\in A$. If $A$ is a Banach $\ast$-algebra that satisfies the $C^{\ast}$-property, then $A$ is called a $C^{\ast}$-algebra.
\end{definition}
We can now look at some examples of operators and adjoints.
\begin{example}
  Let $a = \left(a_{ij}\right)_{i,j}\in \Mat_{m,n}\left(\C\right)$, with the linear operator
  \begin{align*}
    T_{a}\colon \ell_{2}^{n}\rightarrow \ell_{2}^{m}
  \end{align*}
  defined by $T_a\left(\xi\right) = a\xi$. Since $\ell_2^{n}$ is finite-dimensional, $T_a$ is bounded. The conjugate transpose $a^{\ast} = \left(\overline{a_{ji}}\right)_{i,j}$ is an $n\times m$ matrix satisfying
  \begin{align*}
    \iprod{T_{a}\left(\xi\right)}{\eta} &= \iprod{a\eta}{\xi}\\
                                        &= \left(a\xi\right)^{\ast}\eta\\
                                        &= \xi^{\ast}a^{\ast}\eta\\
                                        &= \iprod{\xi}{a^{\ast}\eta}\\
                                        &= \iprod{\xi}{T_{a^{\ast}}\left(\eta\right)},
  \end{align*}
  meaning $T_{a}^{\ast} = T_{a^{\ast}}$.
\end{example}
\subsubsection{Topologies on $\mathcal{B}\left(\mathcal{H}\right)$}%
Given a Banach space $X$, we can introduce two locally convex topologies on $\mathcal{B}\left(X\right)$ --- namely, the weak operator topology and the strong operator topology, both of which are weaker than the norm topology.
\begin{lemma}
  Let $\mathcal{H}$ be a Hilbert space, and let $\left(T_{\alpha}\right)_{\alpha}$ be a net in $\mathcal{B}\left(\mathcal{H}\right)$. The following are equivalent:
  \begin{enumerate}[(i)]
    \item $\left(T_{\alpha}\right)_{\alpha}\xrightarrow{\text{WOT}}T$;
    \item for all $\xi,\eta\in \mathcal{H}$, $ \iprod{T_{\alpha}\left(\xi\right)}{\eta}\rightarrow \iprod{T\left(\xi\right)}{\eta} $;
    \item for all $\xi,\eta\in B_{\mathcal{H}}$, $ \iprod{T_{\alpha}\left(\xi\right)}{\eta}\rightarrow \iprod{T\left(\xi\right)}{\eta} $;
    \item for all $\xi\in \mathcal{H}$, $ \iprod{T_{\alpha}\left(\xi\right)}{\xi} \rightarrow \iprod{T\left(\xi\right)}{\xi} $;
    \item for all $\xi\in B_{\mathcal{H}}$, $ \iprod{T_{\alpha}\left(\xi\right)}{\xi} \rightarrow \iprod{T\left(\xi\right)}{\xi} $.
  \end{enumerate}
\end{lemma}
\begin{proof}
  We only need to prove the equivalence between (i) and (ii). The rest follow from scaling or the polarization identity.\newline

  We know that $\left(T_{\alpha}\right)_{\alpha}\xrightarrow{\text{WOT}}T$ in $\mathcal{B}\left(\mathcal{H}\right)$ if and only if $\varphi\left(T_{\alpha}\left(\xi\right)\right)\rightarrow \varphi\left(T\left(\xi\right)\right)$ for each $\xi\in \mathcal{H}$ and $\varphi\in \mathcal{H}^{\ast}$. By the Riesz representation theorem, each $\varphi\in \mathcal{H}^{\ast}$ is of the form $\varphi\left(\cdot\right) = \iprod{\cdot}{\eta}$.
\end{proof}
\begin{example}
  Let $\left(\Omega,\mathcal{M},\mu\right)$ be a semi-finite\footnote{A measure space where, for any $E\in \mathcal{M}$ with $\mu(E) = \infty$, there is $F\subseteq E$ and $0 < \mu(F) < \infty$.} measure space. We consider the multiplication operators $M_{f}\in \mathcal{B}\left(L_{2}\left(\Omega,\mu\right)\right)$, where $f\in L_{\infty}\left(\Omega,\mu\right)$. If $f\in L_{\infty}\left(\Omega,\mu\right)$ and $\left(f_{\alpha}\right)_{\alpha}$ is a net in $L_{\infty}\left(\Omega,\mu\right)$, we claim that $\left(f_{\alpha}\right)_{\alpha}\xrightarrow{w^{\ast}}f$ if and only if $M_{f_{\alpha}}\xrightarrow{\text{WOT}}M_{f}$. Here, the $w^{\ast}$ topology on $L_{\infty}\left(\Omega,\mu\right)$ is given by the duality $\left(L_{1}\left(\Omega,\mu\right)\right)^{\ast}\cong L_{\infty}\left(\Omega,\mu\right)$.\newline

  If $\left(f_{\alpha}\right)_{\alpha}\xrightarrow{w^{\ast}}f$, then $\int_{\Omega}^{} f_{\alpha}g\:d\mu\rightarrow \int_{\Omega}^{} fg\:d\mu$ for every $g\in L_{1}\left(\Omega,\mu\right)$. For $\xi\in L_{2}\left(\Omega,\mu\right)$, we have $\left\vert \xi \right\vert^2\in L_{1}\left(\Omega,\mu\right)$, so
  \begin{align*}
    \iprod{M_{f_{\alpha}}\left(\xi\right)}{\xi} &= \int_{\Omega}^{} f_{\alpha}\overline{\xi}\xi\:d\mu\\
                                                &= \int_{\Omega}^{} f_{\alpha}\left\vert \xi \right\vert^2\:d\mu\\
                                                &\rightarrow \int_{\Omega}^{} f\left\vert \xi \right\vert^2\:d\mu\\
                                                &= \iprod{M_{f}\left(\xi\right)}{\xi}.
  \end{align*}
  Thus, $M_{f_{\alpha}}\xrightarrow{\text{WOT}} M_{f}$.\newline

  Suppose $M_{f_{\alpha}}\xrightarrow{\text{WOT}}M_{f}$. Given $g\in L_{1}\left(\Omega,\mu\right)$, we can write $g = \xi \overline{\eta}$ for $\xi,\eta \in L_{2}\left(\Omega,\mu\right)$. Thus, we have
  \begin{align*}
    \int_{\Omega}^{} f_{\alpha}g\:d\mu &= \int_{\Omega}^{} f_{\alpha}\xi \overline{\eta}\:d\mu\\
                                       &= \iprod{M_{f_{\alpha}}\xi}{\eta}\\
                                       &\rightarrow \iprod{M_{f}\xi}{\eta}\\
                                       &= \int_{\Omega}^{} f \xi \overline{\eta}\:d\mu\\
                                       &= \int_{\Omega}^{} fg\:d\mu,
  \end{align*}
  so $\left(f_{\alpha}\right)_{\alpha}\xrightarrow{w^{\ast}}f$ in $L_{\infty}\left(\Omega,\mu\right)$.\newline

  We can define
  \begin{align*}
    \mathcal{L}_{\infty}\left(\Omega,\mu\right) &= \set{M_{f} | f\in L_{\infty}\left(\Omega,\mu\right)},
  \end{align*}
  and we see that $M: L_{\infty}\left(\Omega,\mu\right) \rightarrow \mathcal{L}_{\infty}\left(\Omega,\mu\right)$ is an isometric $\ast$-isomorphism and a $w^{\ast}$-WOT-homeomorphism.
\end{example}
\begin{proposition}
  Let $\mathcal{H}$ be a Hilbert space.
  \begin{enumerate}[(1)]
    \item Left and right multiplication defined by a fixed operator is SOT-continuous. If $S\in \mathcal{B}\left(\mathcal{H}\right)$, the maps $L_{S}\colon \mathcal{B}\left(\mathcal{H}\right)\rightarrow \mathcal{B}\left(\mathcal{H}\right)$ and $R_{S}\colon \mathcal{B}\left(\mathcal{H}\right)\rightarrow \mathcal{B}\left(\mathcal{H}\right)$ defined by
      \begin{align*}
        L_S\left(T\right) &= ST\\
        R_{S}\left(T\right) &= TS
      \end{align*}
      are SOT-SOT-continuous.
    \item The maps $L_S$ and $R_S$ are WOT-WOT-continuous.
    \item The adjoint map $\ast\colon \mathcal{B}\left(\mathcal{H}\right)\rightarrow \mathcal{B}\left(\mathcal{H}\right)$, defined by $T\mapsto T^{\ast}$, is WOT-WOT-continuous. If $\Dim(\mathcal{H}) = \infty$, the adjoint map is not SOT-SOT-continuous.
    \item If $\Dim\left(\mathcal{H}\right) = \infty$, joint multiplication, $\mathcal{B}\left(\mathcal{H}\right)\times \mathcal{B}\left(\mathcal{H}\right)\rightarrow \mathcal{B}\left(\mathcal{H}\right)$, defined by $\left(T,S\right)\mapsto TS$, is neither WOT-WOT-continuous nor SOT-SOT-continuous.
  \end{enumerate}
\end{proposition}
\begin{proof}\hfill
  \begin{enumerate}[(1)]
    \item Let $\left(T_{\alpha}\right)_{\alpha}\xrightarrow{\text{SOT}}T$ in $\mathcal{B}\left(\mathcal{H}\right)$. For $\xi\in \mathcal{H}$, we have
      \begin{align*}
        \norm{ST_{\alpha}\left(\xi\right) - ST\left(\xi\right)} &= \norm{S\left(T_{\alpha}\left(\xi\right) - T\left(\xi\right)\right)}\\
                                                                &\leq \norm{S}_{\text{op}}\norm{T_{\alpha}\left(\xi\right) - T\left(\xi\right)}\\
                                                                &\rightarrow 0,
      \end{align*}
      meaning $\left(ST_{\alpha}\right)_{\alpha}\xrightarrow{\text{SOT}}ST$, meaning $L_S$ is SOT-SOT-continuous.\newline

      Similarly, we have
      \begin{align*}
        \norm{T_{\alpha}S\left(\xi\right) - TS\left(\xi\right)} &= \norm{T_{\alpha}\left(\xi\right) - T\left(S\left(\xi\right)\right)}\\
                                                                &\rightarrow 0,
      \end{align*}
      so $\left(T_{\alpha}S\right)_{\alpha}\xrightarrow{\text{SOT}}TS$, meaning $R_{S}$ is SOT-SOT-continuous.
    \item Let $\left(T_{\alpha}\right)_{\alpha}\xrightarrow{\text{WOT}}T$. For $\xi,\eta\in \mathcal{H}$, we have
      \begin{align*}
        \iprod{ST_{\alpha}\left(\xi\right)}{\eta} &= \iprod{T_{\alpha}\left(\xi\right)}{S^{\ast}\left(\eta\right)}\\
                                                  &\rightarrow \iprod{T\left(\xi\right)}{S^{\ast}\left(\eta\right)}\\
                                                  &= \iprod{ST\left(\xi\right)}{\eta},
      \end{align*}
      meaning $\left(ST_{\alpha}\right)_{\alpha}\xrightarrow{\text{WOT}}ST$, so $L_{S}$ is WOT-WOT-continuous. Additionally, by definition, we must have $ \iprod{T_{\alpha}\left(S\left(\xi\right)\right)}{\eta}\rightarrow \iprod{T\left(S\left(\xi\right)\right)}{\eta} $, so $\left(T_{\alpha}S\right)_{\alpha}\xrightarrow{\text{WOT}}TS$, so $R_{S}$ is also WOT-WOT-continuous.
    \item If $\left(T_{\alpha}\right)_{\alpha}\xrightarrow{\text{WOT}}T$, then we have
      \begin{align*}
        \iprod{T^{\ast}_{\alpha}\left(\xi\right)}{\eta} &= \iprod{\xi}{T_{\alpha}\left(\eta\right)}\\
                                                        &\rightarrow \iprod{\xi}{T\left(\eta\right)}\\
                                                        &= \iprod{T^{\ast}\left(\xi\right)}{\eta},
      \end{align*}
      so $\left(T_{\alpha}^{\ast}\right)_{\alpha}\xrightarrow{\text{WOT}} T^{\ast}$.\newline

      To see that the adjoint map is not SOT-SOT-continuous, we consider $\ell_2$ with the orthonormal basis of canonical coordinate vectors, $\left(e_n\right)_{n\geq 1}$. Then, the outer product operators
      \begin{align*}
        T_n &= \theta_{e_1,e_n}\\
        T_n\left(\xi\right) &= \iprod{\xi}{e_n}e_1
      \end{align*}
      give
      \begin{align*}
        \norm{T_n\left(\xi\right)} &= \norm{ \iprod{\xi}{e_n}e_1 }\\
                                   &= \left\vert \iprod{\xi}{e_n} \right\vert\\
                                   &\rightarrow 0,
      \end{align*}
      since, by Bessel's inequality, the sum of the squares of $\left\vert \iprod{\xi}{e_n} \right\vert$ converges. Thus, $\left(T_n\right)_n\xrightarrow{\text{SOT}} 0$. However, since $T^{\ast}_{n} = \theta_{e_n,e_1}$, we have
      \begin{align*}
        \norm{T^{\ast}_{n}\left(e_1\right)} &= \norm{ \iprod{e_1}{e_1}e_n }\\
                                            &= \left\vert \iprod{e_1}{e_1} \right\vert\\
                                            &= 1.
      \end{align*}
      Thus, $\left(T_n^{\ast}\right)_{n}\not\rightarrow 0$ in SOT.
    \item Consider $\left(T_n\right)_n$ as above. Since $\left(T_n\right)_n\xrightarrow{\text{SOT}} 0$, we know that $\left(T_n\right)_n\xrightarrow{\text{WOT}}T$. However, though $\left(T_n^{\ast}\right)_n\not\rightarrow0$ in SOT, we do have $\left(T_n^{\ast}\right)_n\xrightarrow{\text{WOT}}0$ . We have
      \begin{align*}
        T_nT_n^{\ast} &= \theta_{e_1,e_n}\circ \theta_{e_n,e_1}\\
                      &= \theta_{e_1,e_1},
      \end{align*}
      which does not converge in WOT to $0$, since $ \iprod{\theta_{e_1,e_1}\left(e_1\right)}{e_1} = 1 $.
  \end{enumerate}
\end{proof}
\begin{exercise}
  Let $X$ be a Banach space, and suppose $\left(T_n\right)_n\xrightarrow{\text{SOT}}T$ and $\left(S_n\right)_n\xrightarrow{\text{SOT}}S$ in $\mathcal{B}\left(\mathcal{X}\right)$. Show that $\left(T_nS_n\right)_n\xrightarrow{\text{SOT}}TS$.
\end{exercise}
\begin{solution}
  Let $x\in X$. We have that $\norm{T_n\left(x\right)-T(x)}\xrightarrow{n\rightarrow\infty}0$, so we see that the $\left(T_n\right)_n$ are a pointwise bounded family. Similarly, we see that $\norm{S_n(x) - S(x)}\xrightarrow{n\rightarrow\infty}0$, so the $\left(S_n\right)_n$ are a pointwise bounded family.\newline

  Thus, we see that
  \begin{align*}
    \norm{T_nS_n(x) - TS(x)} &\leq \norm{T_nS_n(x) - T_nS(x)} + \norm{T_nS(x) - TS(x)}\\
                             &\leq \sup_{n\in \N}\norm{T_n}_{\text{op}}\norm{S_n(x) - S(x)} + \norm{T_n\left(S(x)\right) - T\left(S(x)\right)}\\
                             &\rightarrow 0.
  \end{align*}
  
\end{solution}
\begin{theorem}
  Let $B$ be the closed unit ball of $\mathcal{B}\left(\mathcal{H}\right)$, where $\mathcal{H}$ is a Hilbert space. Then, $B$ is compact in WOT.
\end{theorem}
\begin{proof}[]
  Let $K$ be defined by
  \begin{align*}
    K &= \prod_{\xi,\eta\in B_{\mathcal{H}}}\overline{\mathbb{D}},
  \end{align*}
  where $\overline{\mathbb{D}}$ is the closed unit disk in the complex plane. Then, $K$ is compact in the product topology.\newline

  Consider the map $\phi\colon B\rightarrow K$ defined by
  \begin{align*}
    \phi(T) &= \left( \iprod{T\left(\xi\right)}{\eta}\right)_{\xi,\eta\in B_{\mathcal{H}}}.
  \end{align*}
  Since, by Cauchy--Schwarz, we have that
  \begin{align*}
    \left\vert \iprod{T\left(\xi\right)}{\eta} \right\vert &\leq \norm{T}_{\text{op}}\norm{\xi}\norm{\eta}\\
                                                           &\leq 1,
  \end{align*}
  for all $\xi,\eta\in B_{\mathcal{H}}$, it is the case that $\phi$ is well-defined. Additionally, $\phi$ is injective since $T = S$ if and only if $ \iprod{T\left(\xi\right)}{\eta} = \iprod{S\left(\xi\right)}{\eta} $ for all $\xi,\eta\in B_{\mathcal{H}}$, and $\phi$ is an embedding by the definition of the weak operator topology.\newline

  We wish to show that the range of $\phi$ is closed. Let
  \begin{align*}
    \left( \iprod{T_{\alpha}\left(\xi\right)}{\eta}\right)_{\xi,\eta} \rightarrow \left(z_{\xi,\eta}\right)_{\xi,\eta}\in K
  \end{align*}
  be a net in $K$. Scaling, we see that $\left( \iprod{T_{\alpha}\left(\xi\right)}{\eta}\right)_{\xi,\eta}$ converges in $\C$ for all $\xi,\eta\in \mathcal{H}$, so we have a bounded sesquilinear form defined by
  \begin{align*}
    F\left(\xi,\eta\right) &= \lim_{\alpha \in A} \iprod{T_{\alpha}\left(\xi\right)}{\eta},
  \end{align*}
  with $\norm{F} \leq 1$. Thus, there is $T\in \mathcal{B}\left(\mathcal{H}\right)$ with $\norm{T}_{\text{op}} = \norm{F} \leq 1$ and $ \iprod{T\left(\xi\right)}{\eta} = F\left(\xi,\eta\right) $, meaning $\phi(T) = \left(z_{\xi,\eta}\right)_{\xi,\eta}$.
\end{proof}

\end{document}
