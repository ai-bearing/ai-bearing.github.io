The primary goal of this section will be to introduce the idea of a paradoxical decomposition (and its effects on the analytic properties of $\R^3$) through the Banach--Tarski Paradox. The ultimate goal is to prove the following statement.
\begin{proposition}[General Banach--Tarski Paradox]
  If $A$ and $B$ are bounded subsets of $\R^3$ with nonempty interior, there is a partition of $A$ into finitely many disjoint subsets such a sequence of isometries applied to these subsets yields $B$.\label{prop:banachtarski}
\end{proposition}
The existence of the Banach--Tarski paradox throws a wrench into a major idea that we may have about subsets of $\R^3$ --- namely, that they always have some ``volume'' to them that is invariant under isometry, similar to how ``area'' in $\R^2$ is invariant under isometry.
\section{Essentials of Group Actions}
We begin by discussing some of the basic properties of group actions.
\begin{definition}[Group Action]
  Let $G$ be a group, and $A$ be a set. A left group action of $G$ onto $A$ is a map $\alpha\colon G\times A\rightarrow A$ that satisfies
  \begin{itemize}
    \item $\alpha\left(g_1,\left(g_2,a\right)\right) = \alpha\left(g_1g_2,a\right)$ for all $g_1,g_2\in G$ and $a\in A$;
    \item $\alpha\left(e_G,a\right) = a$ for all $a\in A$.
  \end{itemize}
  For the sake of brevity, we write $\alpha \left(g,a\right) = g\cdot a$.
\end{definition}
Every group action can be represented by a permutation on $A$.
\begin{definition}[Permutation Representation]
  For each $g$, the map $\sigma_g\colon A\rightarrow A$ defined by $\sigma_g\left(a\right) = g\cdot a$ is a permutation of $A$. There is a homomorphism associated to these actions, $\varphi\colon G\rightarrow \operatorname{Sym}(A)$, where $\operatorname{Sym}(A)$ is the symmetric group on the elements of $A$.
\end{definition}
The permutation representation can run in the opposite direction in the following sense --- given a nonempty set $A$ and a homomorphism $\psi\colon G\rightarrow \sym(A)$, we can take $g\cdot a = \psi(g)(a)$, where $\psi(g) = \sigma_g\in \sym(A)$ is a permutation.\newline

Just as we can pass group actions into permutation representations, and discuss ideas like the kernel of homomorphisms, we can also discuss the kernel of an action.
\begin{definition}[Kernel]
  The {kernel} of the action of $G$ on $A$ is the set of elements in $g$ that act trivially on $A$:
  \begin{align*}
    \set{g\in G\mid \forall a\in A,~g\cdot a = a}.
  \end{align*}
  The kernel of the group action is the kernel of the permutation representation $\varphi\colon G\rightarrow \sym(A)$.
\end{definition}
\begin{definition}[Stabilizer]
  For each $a\in A$, we define the {stabilizer} of $a$ under $G$ to be the set of elements in $G$ that fix $a$:
  \begin{align*}
    G_a &= \set{g\in G\mid g\cdot a = a}.
  \end{align*}
\end{definition}
\begin{remark}
The kernel of the group action is the intersection of the stabilizers of every element of $A$.\newline

For each $a\in A$, $G_{a}$ is a subgroup of $G$.
\end{remark}
\begin{definition}[Faithful Action]
  An action is {faithful} if the kernel of the action is the identity, $e_G$. Equivalently, the permutation representation $\varphi\colon G\rightarrow \sym(A)$ is injective.
\end{definition}
The following definition will be useful in the future as we dig deeper into the idea of paradoxical groups.
\begin{definition}[Free Action]
For a set $X$ with $G$ acting on $X$, the action of $G$ on $X$ is free if, for every $x\in X$, $g\cdot x = x$ if and only if $g = e_G$.
\end{definition}
The most important theorem relating to group actions is the orbit-stabilizer theorem. As we prove the following theorem, we will reveal the definition of an orbit as a type of equivalence class.
\begin{theorem}[Orbit-Stabilizer Theorem]
  Let $G$ be a group that acts on a nonempty set $A$. We define a relation $a\sim b$ if and only if $a = g\cdot b$ for some $g\in G$. This is an equivalence relation, with the number of elements in $\left[a\right]_{\sim}$ found by taking the index of the stabilizer of $a$ in $G$, $\left\vert G:G_a \right\vert$.
\end{theorem}
\begin{proof}
  We start by seeing that $a\sim a$, as $e_G\cdot a = a$. Similarly, if $a\sim b$, then there exists $g\in G$ such that $a = g\cdot b$. Thus,
  \begin{align*}
    g^{-1}\cdot a &= g^{-1}\cdot \left(g\cdot b\right)\\
                  &= g^{-1}g\cdot b\\
                  &= e\cdot b\\
                  &= b,
  \end{align*}
  meaning that $b\sim a$. Finally, if we have $a\sim b$ and $b\sim c$, we have $a = g\cdot b$ and $b = h\cdot c$ for some $g,h\in G$. Therefore,
  \begin{align*}
    a &= g\cdot \left(h\cdot c\right)\\
      &= \left(gh\right)\cdot c,
  \end{align*}
  meaning $a\sim c$. Thus, the relation $\sim$ is reflexive, symmetric, and transitive, so it is an equivalence relation.\newline

  We claim there is a bijection between the left cosets of $G_a$ and the elements of $\left[a\right]_{\sim}$.\newline

  Define $C_a = \set{g\cdot a\mid g\in G}$, which is the set of elements in the equivalence class of $a$. Define the map $g\cdot a \mapsto gG_a$. Since $g\cdot a$ is always an element of $C_a$, this map is surjective. Additionally, since $g\cdot a = h\cdot a$ if and only if $\left(h^{-1}g\right)\cdot a = a$, we have $h^{-1}g \in G_a$, which is only true if $gG_a = hG_a$. Thus, the map is injective.\newline

  Since there is a one to one map between the equivalence classes of $a$ under the action of $G$, and the number of left cosets of $G_a$, we know that the number of equivalence classes of $a$ under the action of $G$ is $\left\vert G:G_a \right\vert$.
\end{proof}
\begin{definition}[Orbit]
  Let $G$ act on $A$, and let $a\in A$. The {orbit} of $a$ under $G$ is the set
\begin{align*}
  G\cdot a &= \set{g\cdot a\in A\mid g\in G}
\end{align*}
\end{definition}
\section{Free Groups, Free Products, and the Ping Pong Lemma}%
A fundamental fact that we will use to show the general Banach--Tarski is the fact that the group of isometries on $\R^3$ (also known as the Euclidean group $\text{E}(3)$) contains a copy of the free group on two generators. We will need to understand some basic facts about free groups to deepen our understanding. This understanding will evolve into the fundamental result of this section --- the Ping Pong Lemma.
\subsection{Essentials of Free Groups}%
\begin{definition}
  Let $G$ be a group, and $S\subseteq G$ be a subset. We define the subgroup {generated by} $S$ to be
  \begin{align*}
    \left\langle S \right\rangle_{G} &= \bigcap \set{H | S\subseteq H,~H\text{ a subgroup}}.
  \end{align*}
  We say $S$ generates $G$ if $\left\langle S \right\rangle_{G} = G$.\newline

  Generated subgroups can be broadly characterized as follows:
  \begin{align*}
    \left\langle S \right\rangle_{G} &= \set{s_1^{a_1}s_2^{a_2}\cdots s_n^{a_n} | n\in\N,~s_1,\dots,s_n\in S,~a_1,\dots,a_n\in \set{-1,1}}.
  \end{align*}
  We say $\left\langle S \right\rangle_{G}$ is finitely generated if $\Card(S) < \infty$.
\end{definition}
There are two major ways we can conceive of the free group. One way (used in \cite{loh_geometric_group_theory}) characterizes the free group directly through the universal property --- the traditional definition of the free group is then shown to satisfy the universal property.\newline

We will not be using this method, though, instead we will be using the construction in \cite{delaHarpe_topics_in_geometric_group_theory}, which constructs a more general object (the free product) on a collection of groups by taking a quotient on the coproduct (or disjoint union), of which the free group is a special case. For the sake of completeness, we will state the universal property characterization.
\begin{definition}
  Let $S$ be a set. A group $F$ containing $S$ is said to be {freely generated} if, for every group $G$, and every map $\phi\colon S\rightarrow G$, there is a unique group homomorphism $\varphi\colon F\rightarrow G$ that extends $\varphi$. The following diagram, where $\iota$ denotes the inclusion of $S$ into $F$, commutes:
\begin{center}
  % https://tikzcd.yichuanshen.de/#N4Igdg9gJgpgziAXAbVABwnAlgFyxMJZABgBpiBdUkANwEMAbAVxiRAGUQBfU9TXfIRQBGclVqMWbAOLdeIDNjwEiZYePrNWiEADFu4mFADm8IqABmAJwgBbJGRA4ISAEzUcdLAzYALCBAA1iDUDHQARjAMAAr8ykIgVljGvjghElpsADpZ+J5yljb2iO5OLoiiIGGRMXGCbEkpadSaUjo59FZovlgFINZ2Dh7lla3aIDndvVwUXEA
\begin{tikzcd}
S \arrow[d, "\iota"', hook] \arrow[r, "\phi"] & G \\
F \arrow[ru, "\varphi"']                      &  
\end{tikzcd}
\end{center}
We say $F$ is the {free group} generated by $S$.
\end{definition}
\begin{definition}[Free Monoid]
  A {monoid} is a set with multiplication that is associative and contains a neutral element.\newline

  Given a set $A$, the free monoid on $A$ is the set $W(A)$ of all finite sequences of elements of $A$. We write an element $W(A)$ as $w = a_1a_2\cdots a_n$, with $a_j\in A$ For each $j$. We identify $A$ with the subset $W(A)$ of words with length $1$.\newline

  The operation on $W(A)$ is concatenation.
\end{definition}

\begin{definition}
  Let $\set{\Gamma_i}_{i\in I}$ be a family of groups. Set $A = \coprod_{i\in I}\Gamma_i = \set{\left(g_i,i\right) | g_i\in \Gamma_i,~i\in I}$ to be the coproduct of the family $\set{\Gamma_i}_{i\in I}$.\newline

  Let $\sim$ be the equivalence relation generated by
  \begin{align*}
    we_iw' &\sim ww'\\
    wabw' &\sim wcw',
  \end{align*}
  for all $w,w'\in W(A)$, where $e_i\in \Gamma_i$ is the neutral element, and $a,b,c\in \Gamma_i$ with $ab = c$ for some $i\in I$.\newline

  The quotient $W(A) / \sim$ with the operation of concatenation is a group, known as the {free product} of the groups $\set{\Gamma_i}_{i\in I}$. We write it as
  \begin{align*}
    \bigstar_{i\in I}\Gamma_i.
  \end{align*}
  The inverse of the equivalence class for $w = a_1a_2\cdots a_n$ is $w^{-1} = a_{n}^{-1}a_{n-1}^{-1}\cdots a_{1}^{-1}$. The neutral element is $\epsilon$, denoting the empty word.\newline

  A word $w = a_1a_2\cdots a_n\in W(A)$ with $a_j\in \Gamma_{i_j}$ is said to be {reduced} if $i_{j + 1}\neq i_j$ and $a_j \neq e_{i_j}$ for each $j$.\label{def:free_product}
\end{definition}
It is the case that free products exist.
\begin{proposition}
  Let $\set{\Gamma_i}_{i\in I}$ be a family of groups, with $A = \coprod_{i\in I}\Gamma_i$, and $\bigstar_{i\in I}\Gamma_i = W(A) / \sim$ as in Definition \ref{def:free_product}.\newline

  Then, any element in $\bigstar_{i\in I}\Gamma_i$ is represented by a unique reduced word in $W(A)$.\label{prop:reduced_words}
\end{proposition}
\begin{proof}
  We start by showing existence. Consider an integer $n \geq 0$ and a reduced word $w = a_1a_2\cdots a_n$ in $W(A)$, an element $a\in A$, and the word $aw \in W(A)$.\newline

  If $k$ is the index for which $a_1\in \Gamma_k$, we set
  \begin{align*}
    \mathcal{R}\left(aw\right) &= \begin{cases}
      w & a = e_i\\
      aa_1a_2\cdots a_n & a\in \Gamma_i,~a\neq e_i,~i\neq k\\
      ba_2\cdots a_n & a\in \Gamma_k,aa_1 = b\neq e_k\\
      a_2\cdots a_n & a\in \Gamma_k, a = a_1^{-1} \in \Gamma_k.
    \end{cases}
  \end{align*}
  Then, $\mathcal{R}\left(aw\right)$ is another reduced word, and $\mathcal{R}\left(aw\right) \sim aw$ by our construction, meaning that any word $w\in W(A)$ is equivalent to some reduced word by inducting on the length of $w$.\newline

  Now, we show uniqueness. For each $a\in A$, let $T\left(a\right) $ be the map $ w\xmapsto{T(a)} \mathcal{R}\left(aw\right)$, which is a self-map on the set of reduced words. For each $w = b_1b_2\cdots b_n$, we set $T(w) = T\left(b_1\right)T\left(b_2\right)\cdots T\left(b_n\right)$. For $a,b,c\in \Gamma_i$ with $ab = c$, we have $T\left(a\right)T\left(b\right) = T\left(c\right)$, and $T\left(e_i\right) = \epsilon$ for all $i\in I$.\newline

  If $w$ is a reduced word, notice that $T\left(w\right)\left(\epsilon\right) = w$.\newline

  Let $w$ be some word in $W(A)$ with $w_1,w_2$ being reduced words equivalent to $w$ under the equivalence relation $\sim$. Since $w_1\sim w_2$, we have $T\left(w_1\right) = T\left(w_2\right)$, and
  \begin{align*}
    w_1 &= T\left(w_1\right)\left(\epsilon\right)\\
        &= T\left(w_2\right)\left(\epsilon\right)\\
        &= w_2.
  \end{align*}
  Since $w_1 = w_2$, it is the case that the reduced representations of any word $w\in W(A)$ are unique.
\end{proof}
\begin{corollary}
  If $\set{\Gamma_i}_{i\in I}$ and $\Gamma = \bigstar_{i\in I}\Gamma_i$ are as in Definition \ref{def:free_product}, then for each $i_0\in I$, the canonical inclusion
  \begin{align*}
    \iota\colon \Gamma_{i_0}\hookrightarrow \Gamma,
  \end{align*}
  where an element $a\in \Gamma_{i_0}$ maps to its one-letter reduced word representation in $\Gamma$, is injective.
\end{corollary}
\begin{proof}
  For any $a\in \Gamma_{i_0}\setminus \set{e_{i_0}}$, the one-letter reduced word representation $\iota(a)$ is unique, and not equivalent to the empty word, meaning $\ker\left(\iota\right) = \set{e_{i_0}}$, so $\iota$ is injective.
\end{proof}
We can now define the free group as a special type of free product.
\begin{definition}
  Let $X$ be a set. The {free group} over $X$ is the free product of the infinite cyclic groups generated by elements $a\in X$:
  \begin{align*}
    F(X) &= \bigstar_{a\in X}\left\langle a \right\rangle.
  \end{align*}
  As the free product is in one-to-one correspondence with the collection of reduced words over a collection $\set{\Gamma_i}_{i\in I}$, it is also the case that $F(X)$ is the collection of reduced words with the ``alphabet'' in $X\sqcup X^{-1}$.\newline

  The cardinality of $X$ is the rank of $F(X)$.\label{def:free_group_as_product}
\end{definition}
We can now state and prove a universal property for free products of groups, which we will then apply to the case of the free group.
\begin{theorem}[Universal Property for Free Products]
  Let $\Gamma$ be a group, and let $\set{\Gamma_{i}}_{i\in I}$ be a family of groups. Let $\set{h_i\colon \Gamma_i\rightarrow \Gamma}_{i\in I}$ be a family of homomorphisms.\newline

  Then, there exists a unique homomorphism $h\colon \bigstar_{i\in I}\Gamma_i \rightarrow \Gamma$ that extends each $h_{i_{0}}$. The following diagram commutes:
  \begin{center}
    % https://tikzcd.yichuanshen.de/#N4Igdg9gJgpgziAXAbVABwnAlgFyxMJZABgBpiBdUkANwEMAbAVxiRAB12BxOgW17oB9YFkHEAviHGl0mXPkIoAjOSq1GLNpx786UmSAzY8BImSVr6zVog7sARlgDmcHHQBOwrJyxgABACS4tp8Al6S4mowUE7wRKAAZu4QvEhkIDgQSABM1Ax09jAMAApyJoog7s4AFjgg1Faatj4QbvqJyamI6ZlIKurWbNVeYhEGSSk51L2I-fmFJWUKbFVOtfUDTSDVUhTiQA
\begin{tikzcd}
\Gamma_{i_0} \arrow[d, "\iota"'] \arrow[r, "h_{i_0}"] & \Gamma \\
\bigstar_{i\in I}\Gamma_{i} \arrow[ru, "h"']          &       
\end{tikzcd}
  \end{center}
  In particular, if $\Gamma$ is a group, and $\phi\colon X\rightarrow \Gamma$ is a set map, there exists a unique homomorphism $\Phi\colon F(X)\rightarrow \Gamma$ such that $\Phi(x) = \phi(x)$ for each $x\in X$.
\end{theorem}
\begin{proof}
  For a reduced word $a_1a_2\cdots a_n\in \bigstar_{i\in I}\Gamma_i$, where $a_j\in \Gamma_{i_j}\setminus \set{e_{i_j}}$, and $i_{j+1} \neq i_j$ for each $j$, we set
  \begin{align*}
    h\left(w\right) &= h_{i_1}\left(a_1\right)h_{i_2}\left(a_2\right)\cdots h_{i_n}\left(a_n\right),
  \end{align*}
  which defines $h$ uniquely in terms of the homomorphisms $h_{i}$.
\end{proof}
\subsection{The Ping Pong Lemma and Applications}%
If we are given an arbitrary group, we may be curious as to whether or not the group (or a subgroup of it) is freely generated. The Ping Pong Lemma allows us to ascertain various sufficient conditions that yield a free group.
\begin{theorem}[Ping Pong Lemma]
  Let $G$ be a group that acts on a set $X$, and let $\Gamma_1,\Gamma_2$ be subgroups of $G$. Let $\Gamma = \left\langle \Gamma_1,\Gamma_2 \right\rangle$. Assume $\Gamma_1$ contains at least $3$ elements, and $\Gamma_2$ contains at least $2$ elements.\newline

  Suppose there exist nonempty subsets $X_1,X_2\subseteq X$ with $X_1\triangle X_2 \neq \emptyset$ such that for all $\gamma\in \Gamma_1$ with $\gamma \neq e_{G}$,
  \begin{align*}
    \gamma\left(X_2\right)\subseteq X_1,
  \end{align*}
  and for all $\gamma \in \Gamma_2$ with $\gamma \neq e_G$,
  \begin{align*}
    \gamma\left(X_1\right)\subseteq X_2.
  \end{align*}
  Then, $\Gamma$ is isomorphic to the free product $\Gamma_1\star \Gamma_2$.\label{thm:ping_pong}
\end{theorem}
\begin{proof}
  Let $w$ be a nonempty reduced word with letters in the disjoint union of $\Gamma_1\setminus \set{e_G}$ and $\Gamma_2\setminus \set{e_G}$. We must show that the element of $\Gamma$ defined by $w$ is not the identity.\newline

  If $w = a_1b_1a_2b_2\cdots a_k$ with $a_1,\dots,a_k\in \Gamma_1\setminus \set{e_G}$ and $b_1,\dots,b_{k-1}\in \Gamma_{2}\setminus \set{e_G}$, then,
  \begin{align*}
    w\left(X_2\right) &= a_1b_1\cdots a_{k-1}b_{k-1}a_k\left(X_2\right)\\
                      &\subseteq a_1b_1\cdots a_{k-1}b_{k-1}\left(X_1\right)\\
                      &\subseteq a_1b_1\cdots a_{k-1}\left(X_2\right)\\
                      &\vdots\\
                      &\subseteq a_1\left(X_2\right)\\
                      &\subseteq X_1.
  \end{align*}
  Seeing as $X_2\nsubseteq X_1$ (by the definition of symmetric difference), it is the case that $w\neq e_{G}$.\newline

  If $w = b_1a_2b_2a_2\cdots b_k$, we select $a\in \Gamma_1\setminus \set{e_G}$, and we find that $awa^{-1}\neq e_G$, meaning $w\neq e_G$. Similarly, if $w = a_1b_1\cdots a_kb_k$, we select $a\in \Gamma_1\setminus \set{e_G,a_{1}^{-1}}$, similarly finding that $awa^{-1}\neq e_{G}$. If $w = b_1a_2b_2\cdots a_k$, then we select $a\in \Gamma_1\setminus \set{1,a_k}$, and find $awa^{-1}\neq e_G$.
\end{proof}
We can refine Theorem \ref{thm:ping_pong} to the case of ``doubles'' wherein we find a sufficient condition for a group that contains a copy of the free group on two generators.
\begin{corollary}[Ping Pong Lemma for ``Doubles'']
  Let $G$ act on $X$, and let $A_{+}, A_{-},B_{+},B_{-}$ be disjoint subsets of $X$ whose union is not equal to $X$. Then, if
  \begin{align*}
    a\cdot \left(X\setminus A_{-}\right) &\subseteq A_{+}\\
    a^{-1}\cdot \left(X\setminus A_{+}\right) &\subseteq A_{-}\\
    b\cdot \left(X\setminus B_{-}\right) &\subseteq B_{+}\\
    b^{-1}\cdot \left(X\setminus B_{+}\right) &\subseteq B_{-},
  \end{align*}
  then it is the case that $\left\langle a,b \right\rangle$ is isomorphic to the free group on two generators.\label{corollary:ping_pong_doubles}
\end{corollary}
\begin{proof}
  We let $A = A_{+}\sqcup A_{-}$, $B = B_{+}\sqcup B_{-}$, $\Gamma_1 = \left\langle a \right\rangle$, and $\Gamma_2 = \left\langle b \right\rangle$. Then, $A,B,\Gamma_1,\Gamma_2$ satisfy the conditions for Theorem \ref{thm:ping_pong}.
\end{proof}
\begin{remark}
Instead of typing out ``the free group on two generators,'' we will henceforth use $F(a,b)$ to refer to the free group on two generators.
\end{remark}

We can apply Theorem \ref{thm:ping_pong} to show the existence of a set of isometries of $\R^n$ that is isomorphic to the free group on two generators.
\begin{definition}[Special Orthogonal Group]
  For $n\in \N$, we define $SO(n)$ to be the group of all real $n\times n$ matrices $A$ such that $A^{T} = A^{-1}$ and $\det(A) = 1$.
\end{definition}
In terms of an isometry of $\R^3$, the group $\text{SO}(3)$ denotes the set of all rotations about any line through the origin.
\begin{theorem}
  There are elements $a,b\in \text{SO}(3)$ such that $\left\langle a,b \right\rangle_{\text{SO}(3)} \cong F(a,b)$.\label{thm:free_group_so3}
\end{theorem}
\begin{proof}
  We let
  \begin{align*}
    a &= \begin{pmatrix}3/5 & 4/5 & 0 \\ -4/5 & 3/5 & 0 \\ 0 & 0 & 1\end{pmatrix}\\
    a^{-1} &= \begin{pmatrix}3/5 & -4/5 & 0 \\ 4/5 & 3/5 & 0 \\ 0 & 0 & 1\end{pmatrix}\\
    b &= \begin{pmatrix}1 & 0 & 0 \\ 0 & 3/5 & -4/5 \\ 0 & 4/5 & 3/5\end{pmatrix}\\
    b^{-1} &= \begin{pmatrix}1 & 0 & 0 \\ 0 & 3/5 & 4/5 \\ 0 & -4/5 & 3/5\end{pmatrix}.
  \end{align*}
  We specify
  \begin{align*}
    X &= A_{+} \sqcup A_{-} \sqcup B_{+} \sqcup B_{-} \sqcup \begin{pmatrix}0\\1\\0\end{pmatrix},
  \end{align*}
  where
  \begin{align*}
    A_{+} &= \set{\frac{1}{5^{k}} \begin{pmatrix}x\\y\\z\end{pmatrix} | k\in \Z, x \equiv 3y\text{ modulo $5$}, z\equiv0\text{ modulo $5$}}\\
    A_{-} &= \set{\frac{1}{5^{k}} \begin{pmatrix}x\\y\\z\end{pmatrix} | k\in \Z, x \equiv -3y\text{ modulo $5$}, z\equiv 0\text{ modulo $5$}}\\
    B_{+} &= \set{\frac{1}{5^{k}} \begin{pmatrix}x\\y\\z\end{pmatrix} | k\in \Z, z \equiv 3y\text{ modulo $5$}, x\equiv 0\text{ modulo $5$}}\\
    B_{-} &= \set{\frac{1}{5^{k}} \begin{pmatrix}x\\y\\z\end{pmatrix} | k\in \Z, z \equiv -3y\text{ modulo $5$}, x\equiv 0\text{ modulo $5$}}.
  \end{align*}
  To verify that the conditions of Theorem \ref{thm:ping_pong} hold, we calculate
  \begin{align*}
    \begin{pmatrix}3/5 & 4/5 & 0 \\ -4/5 & 3/5 & 0 \\ 0 & 0 & 1\end{pmatrix}\left(\frac{1}{5^k} \begin{pmatrix}x\\y\\z\end{pmatrix}\right) &= \frac{1}{5^{k+1}} \begin{pmatrix}3x + 4y \\ -4x + 3y \\ 5z\end{pmatrix}\tag*{(1)}\\
    \begin{pmatrix}3/5 & -4/5 & 0 \\ 4/5 & 3/5 & 0 \\ 0 & 0 & 1\end{pmatrix} \left(\frac{1}{5^k} \begin{pmatrix}x\\y\\z\end{pmatrix}\right) &= \frac{1}{5^{k+1}} \begin{pmatrix}3x - 4y \\ 4x + 3y \\ 5z\end{pmatrix}\tag*{(2)}\\
    \begin{pmatrix}1 & 0 & 0 \\ 0 & 3/5 & -4/5 \\ 0 & 4/5 & 3/5\end{pmatrix}\left(\frac{1}{5^{k}} \begin{pmatrix}x\\y\\z\end{pmatrix}\right) &= \frac{1}{5^{k+1}} \begin{pmatrix}5x \\ 3y- 4z \\ 4y + 3z\end{pmatrix}\tag*{(3)}\\
    \begin{pmatrix}1 & 0 & 0 \\ 0 & 3/5 & 4/5 \\ 0 & -4/5 & 3/5\end{pmatrix} \left(\frac{1}{5^{k}} \begin{pmatrix}x\\y\\z\end{pmatrix}\right) &= \frac{1}{5^{k+1}} \begin{pmatrix}5x \\ 3y + 4z \\ -4y + 3z\end{pmatrix}.\tag*{(4)}
  \end{align*}
  We verify that the conditions for Corollary \ref{corollary:ping_pong_doubles} hold for each of these four conditions.
  \begin{enumerate}[(1)]
    \item For any vector
      \begin{align*}
        \frac{1}{5^{k}} \begin{pmatrix}x\\y\\z\end{pmatrix} \notin A_{-},
      \end{align*}
      we see that $k+1\in \Z$, $x' = 3x + 4y \equiv 3\left(-4x + 3y\right)$  modulo $5$, and that $z' = 5z\equiv 0$ modulo $5$.
    \item For any vector
      \begin{align*}
        \frac{1}{5^{k}} \begin{pmatrix}x\\y\\z\end{pmatrix} \notin A_{+},
      \end{align*}
      we see that $k+1\in \Z$, $x' = 3x - 4y\equiv -3\left(4x + 3y\right)$ modulo $5$, and $z' = 5z \equiv 0$ modulo $5$.
    \item For any vector
      \begin{align*}
        \frac{1}{5^{k}} \begin{pmatrix}x\\y\\z\end{pmatrix}\notin B_{-},
      \end{align*}
      we see that $k+1\in \Z$, $z' = 4y + 3z \equiv 3\left(3y-4z\right)$ modulo $5$, and $x' = 5x\equiv 0$ modulo $5$.
    \item For any vector
      \begin{align*}
        \frac{1}{5^{k}} \begin{pmatrix}x\\y\\z\end{pmatrix}\notin B_{+},
      \end{align*}
      we see that $k+1\in \Z$, $z' = -4y + 3z \equiv -3\left(3y + 4z\right)$ modulo $5$, and $x' = 5x \equiv 0$ modulo $5$.
  \end{enumerate}
  Thus, by Theorem \ref{thm:ping_pong} and Corollary \ref{corollary:ping_pong_doubles}, it is the case that $\left\langle a,b \right\rangle\cong F(a,b)$.
\end{proof}

\section{Paradoxical Decompositions in $\R^3$}%
With the essential facts about free groups and group actions in mind, we can turn our attention to ``paradoxical'' actions that seem to recreate a set by using some of its disjoint proper subsets.
\begin{definition}[Paradoxical Decompositions and Paradoxical Groups]
  Let $G$ be a group that acts on a set $X$, with $E\subseteq X$. We say $E$ is $G${-paradoxical} if there exist pairwise disjoint proper subsets $A_1,\dots,A_n$ and $B_1,\dots,B_m$ of $E$ and group elements $g_1,\dots,g_n,h_1,\dots,h_m\in G$ such that
  \begin{align*}
    E &= \bigcup_{j=1}^{n}g_j\cdot A_j
  \end{align*}
  and
  \begin{align*}
    E &= \bigcup_{j=1}^{m}h_j\cdot B_j.
  \end{align*}
  If $G$ acts on itself by left-multiplication, and $G$ satisfies these conditions, we say $G$ is a {paradoxical group}.
\end{definition}
\begin{example}
  The free group on two generators, $F(a,b)$, is a paradoxical group.\newline
  %The free group is defined to be the set of all reduced words over the set $\set{a,b,a^{-1},b^{-1},e_{F(a,b)}}$, where $aa^{-1}$, $a^{-1}a$, $bb^{-1}$, and $b^{-1}b$ are replaced with the identity $e_{F(a,b)}$.\newline

  To see that $F(a,b)$ is a paradoxical group, we let $W(x) = \set{w\in F(a,b)\mid w\text{ starts with }x}$. For instance, $ba^2ba^{-1}\in W(b)$.\newline

  Since every word in $F$ is either the empty word, or starts with one of $a,b,a^{-1},b^{-1}$, we see that
  \begin{align*}
    F(a,b) &= \set{e_{F(a,b)}} \sqcup W(a) \sqcup W(b) \sqcup W\left(a^{-1}\right) \sqcup W\left(b^{-1}\right).
  \end{align*}
  For $w\in F(a,b)\setminus W(a)$, it is the case that $a^{-1}w\in W\left(a^{-1}\right)$, so $w\in aW\left(a^{-1}\right)$. Thus, for any $t\in F(a,b)$, $t\in W(a)$ or $t\in F(a,b)\setminus W(a) = aW\left(a^{-1}\right)$, so $F(a,b) = W(a)\sqcup aW\left(a^{-1}\right)$.

  Similarly, for any $w\in F(a,b)\setminus W(b)$, it is the case that $b^{-1}w\in W\left(b^{-1}\right)$, so $w\in bW\left(b^{-1}\right)$. Thus, for any $t\in F(a,b)$, $t\in W(b)$ or $t\in F(a,b) \setminus W(b) = bW\left(b^{-1}\right)$. Thus, $F(a,b) = W(b)\sqcup bW\left(b^{-1}\right)$.\newline

  We have thus constructed
  \begin{align*}
    F(a,b) &= W(a)\sqcup aW\left(a^{-1}\right)\\
           &= W(b)\sqcup bW\left(b^{-1}\right),
  \end{align*}
  a paradoxical decomposition of $F(a,b)$ with the action of left-multiplication.
\end{example}
Now that we understand a little more about paradoxical groups, we now want to understand the actions of paradoxical groups on sets.
\begin{proposition}
  Let $G$ be a paradoxical group that acts freely on $X$. Then, $X$ is $G$-paradoxical.
\end{proposition}
\begin{proof}
  Let $A_1,\dots,A_n,B_1,\dots,B_m\subset G$ be pairwise disjoint, and let $g_1,\dots,g_n,h_1,\dots,h_m\in G$ such that
  \begin{align*}
    G &= \bigcup_{j=1}^{n}g_jA_j\\
      &= \bigcup_{j=1}^{m}h_jB_j.
  \end{align*}
  Let $M\subseteq X$ contain exactly one element from every orbit in $X$.\newline

  {Claim:} The set $\set{g\cdot M\mid g\in G}$ is a partition of $X$.\\
  \vspace{12pt}
  \begin{proof}[of Claim]
  Since $M$ contains exactly one element from every orbit in $X$, it is the case that $G\cdot M = X$, so
  \begin{align*}
    \bigcup_{g\in G} g\cdot M &= X
  \end{align*}
  Additionally, for $x,y\in M$, if $g\cdot x = h\cdot y$, then $\left(h^{-1}g\right)\cdot x = y$, meaning $y$ is in the orbit of $x$ and vice versa, implying $x = y$. Since $G$ acts freely on $X$, we must have $h^{-1}g = e_G$.\newline

  Thus, we can see that $g_1\cdot M \neq g_2\cdot M$, implying $\set{g\cdot M\mid g\in G}$ is a partition of $X$.
  \end{proof}
  We define
  \begin{align*}
    A_j^{\ast} &= \bigcup_{g\in A_j}g\cdot M,
  \end{align*}
  and similarly define
  \begin{align*}
    B_j^{\ast} &= \bigcup_{h\in B_j}h\cdot M.
  \end{align*}
  As a useful shorthand, we can also write $A_j^{\ast} = A_j\cdot M$, and similarly, $B_j^{\ast} = B_j\cdot M$, to denote the union of the elements of $A_j$ and $B_j$ respectively acting on $M$.\newline

  Since $\set{g\cdot M\mid g\in G}$ is a partition of $X$, and $A_1,\dots,A_n,B_1,\dots,B_m\subset G$ are pairwise disjoint, it must be the case that $A_1^{\ast},\dots,A_n^{\ast},B_1^{\ast},\dots,B_m^{\ast}\subset X$ are also pairwise disjoint.\newline

  For the original $g_1,\dots,g_n,h_1,\dots,h_m$ that defined the paradoxical decomposition of $G$, we thus have
  \begin{align*}
    \bigcup_{j=1}^{n}g_j\cdot A_j^{\ast} &= \bigcup_{j=1}^{n}\left(g_jA_j\right)\cdot M\\
                                         &= G\cdot M\\
                                         &= X,
  \end{align*}
  and
  \begin{align*}
    \bigcup_{j=1}^{m}h_j\cdot B_j^{\ast} &= \bigcup_{j=1}^{m}\left(h_jB_j\right)\cdot M\\
                                         &= G\cdot M\\
                                         &= X.
  \end{align*}
  Thus, $X$ is $G$-paradoxical.
\end{proof}
\begin{remark}
  This proof requires the axiom of choice, as we invoked it to define $M$ to contain exactly one element from every orbit in $X$.
\end{remark}

Now that we have established $F(a,b)$ as being a paradoxical group, we wish to use it to construct paradoxical decompositions of the unit sphere $S^2 \subseteq \R^3$.
\begin{fact}
  If $H$ is a paradoxical group, and $H\leq G$, then $G$ is a paradoxical group.
\end{fact}
With this fact in mind, we will show that $\text{SO}(3)$ is a paradoxical group.
\begin{theorem}
  There are rotations $A$ and $B$ that about lines through the origin in $\R^3$ that generate a subgroup of $\text{SO}(3)$ isomorphic to $F(a,b)$
\end{theorem}
\begin{proof}
  We take $a$ and $b$ as in the proof of Theorem \ref{thm:free_group_so3}.
%  We take
%  \begin{align*}
%    A &= \begin{bmatrix}1/3 & -\frac{2\sqrt{2}}{3} & 0\\ \frac{2\sqrt{2}}{3} & 1/3 & 0 \\ 0 & 0 & 1\end{bmatrix}\\
%    A^{-1} &= \begin{bmatrix}1/3 & \frac{2\sqrt{2}}{3} & 0\\ -\frac{2\sqrt{2}}{3} & 1/3 & 0 \\ 0 & 0 & 1\end{bmatrix}\\
%    B &= \begin{bmatrix}1 & 0 & 0 \\ 0 & 1/3 & -\frac{2\sqrt{2}}{3} \\ 0 & \frac{2\sqrt{2}}{3} & 1/3\end{bmatrix}\\
%    B^{-1} &= \begin{bmatrix}1 & 0 & 0 \\ 0 & 1/3 & \frac{2\sqrt{2}}{3} \\ 0 & -\frac{2\sqrt{2}}{3} & 1/3\end{bmatrix}
%  \end{align*}
%  We let $A^{\pm}$ denote $A$ and $A^{-1}$ respectively, and similarly for $B^{\pm}$.\newline
%
%  Let $w$ be a reduced word in $\set{A,A^{-1},B,B^{-1}}$ which is not the empty word. We claim that $w$ cannot be the identity.\newline
%
%  Without loss of generality, we assume that $w$ ends in $A$ or $A^{-1}$ --- this is because if $w$ is the identity, then $AwA^{-1}$ and $A^{-1}wA$ are also the identity.\newline
%
%  We will show that there exist $a,b,c\in \Z$ with $b\not\equiv 0$ mod $3$ such that
%  \begin{align*}
%    w \cdot \begin{pmatrix}1\\0\\0\end{pmatrix} &= \frac{1}{3^k} \begin{pmatrix}a\\b\sqrt{2}\\c\end{pmatrix}.
%  \end{align*}
%  If $b\not\equiv 0$ mod $3$, and $w$ is not empty, then $w$ cannot act as the identity.\newline
%
%  We induct on the length of $w$. For $w = A^{\pm}$, we have
%  \begin{align*}
%    w\cdot \begin{pmatrix}1\\0\\0\end{pmatrix} &= \frac{1}{3}\begin{pmatrix}1\\\pm2\sqrt{2}\\0\end{pmatrix},
%  \end{align*}
%  proving the base case.\newline
%
%  Let $k > 0$, meaning $w = A^{\pm}w'$, or $w = B^{\pm}w'$, with $w'$ not equal to the empty. The inductive hypothesis says
%  \begin{align*}
%    w'\cdot \begin{pmatrix}1\\0\\0\end{pmatrix} &= \frac{1}{3^{k-1}} \begin{pmatrix}a'\\b'\sqrt{2}\\c'\end{pmatrix}
%  \end{align*}
%  for some $a',b',c'\in \Z$, and $b'\not\equiv 0$ mod $3$. In particular,
%  \begin{align*}
%    A^{\pm}w' \cdot \begin{pmatrix}1\\0\\0\end{pmatrix} &= \frac{1}{3^k} \begin{pmatrix}a\mp 4b \\ \left(b'\pm 2a'\right)\sqrt{2} \\ 3c'\end{pmatrix}\\
%    B^{\pm}w' \cdot \begin{pmatrix}1\\0\\0\end{pmatrix} &= \frac{1}{3^k} \begin{pmatrix}3a' \\ \left(b'\mp 2c'\right)\sqrt{2} \\ c'\pm 4b'\end{pmatrix}.
%  \end{align*}
%  Now, we set
%  \begin{align*}
%    w \cdot \begin{pmatrix}1\\0\\0\end{pmatrix} &= \frac{1}{3^k} \begin{pmatrix}a\\b\sqrt{2}\\c\end{pmatrix},
%  \end{align*}
%  meaning
%  \begin{align*}
%    a &= \begin{cases}
%      a'\mp 4b', & w = A^{\pm} w'\\
%      3a', & w = B^{\pm}w'
%    \end{cases}\\
%      b &= \begin{cases}
%        b'\pm 2a', & w = A^{\pm}w'\\
%        b'\mp 2c', & w = B^{\pm}w'
%      \end{cases}\\
%        c &= \begin{cases}
%          3c', & w = A^{\pm}w'\\
%          c' \pm 4b', & w = B^{\pm}w'
%        \end{cases}
%  \end{align*}
%  Let $w^{\ast}$ denote the word such that $w' = A^{\pm}w^{\ast}$ or $w' = B^{\pm}w^{\ast}$. We write
%  \begin{align*}
%    w^{\ast} &= \frac{1}{3^{k-2}} \begin{pmatrix}a''\\b''\sqrt{2}\\c''\end{pmatrix},
%  \end{align*}
%  where $a'',b'',c''\in \Z$. Note that it may not be the case that $w^{\ast}$ is a non-empty word. We examine the following four cases.
%  \begin{description}
%    \item[Case 1:] Suppose $w = A^{\pm}B^{\pm}w^{\ast}$. Then, $b = b'\mp 2a'$, where $a' = 3a''$. Since $b'\not\equiv 0$ mod $3$ (by the inductive hypothesis), it is also the case $b\equiv 0$ mod $3$.
%    \item[Case 2:] Suppose $w = B^{\pm}A^{\pm}w^{\ast}$. Then, $b = b'\mp 2c'$, where $c' = 3c''$. Since $b'\not\equiv 0$ mod $3$ (by the inductive hypothesis), it is also the case that $b\not\equiv 0$ mod $3$.
%    \item[Case 3:] Suppose $w = A^{\pm}A^{\pm}w^{\ast}$. Then, we have
%      \begin{align*}
%        b &= b' \pm 2a'\\
%          &= b' \pm 2\left(a'' \pm 4b''\right)\\
%          &= b'+ \left(b'' \pm 2a''\right) - 9b''\\
%          &= 2b' - 9b''.
%      \end{align*}
%      Thus, regardless of the value of $b''$, since $b'\not\equiv 0$ mod $3$ by the inductive hypothesis, it is the case that $b\not\equiv 0$ mod $3$.
%    \item Suppose $w = B^{\pm}B^{\pm}w^{\ast}$. Then, we have
%      \begin{align*}
%        b &= b' \mp 2c'\\
%          &= b' \mp 2\left(c'' \pm 4b''\right)\\
%          &= b' + \left(b'' \mp 2c''\right) - 9b''\\
%          &= 2b' - 9b''.
%      \end{align*}
%      Thus, regardless of the value of $b''$, since $b'\not\equiv 0$ mod $3$ by the inductive hypothesis, it is the case that $b\not\equiv 0$ mod $3$.
%  \end{description}
%  We have thus shown that any non-empty reduced word over $\set{A,A^{-1},B,B^{-1}}$ does not act as the identity. The subgroup of $\text{SO}(3)$ generated by $\set{A,A^{-1},B,B^{-1}}$ is isomorphic to $F(a,b)$.
\end{proof}
\begin{remark}
  Since $SO(n)$ contains a subgroup isomorphic to $\text{SO}(3)$ for all $n\geq 3$, it is the case that $SO(n)$ also contains a subgroup isomorphic to $F(a,b)$.
\end{remark}
Since we have shown that $\text{SO}(3)$ is paradoxical, as it contains a paradoxical subgroup, we can now begin to examine the action of $\text{SO}(3)$ on subsets of $\R^3$.
\begin{theorem}[Hausdorff Paradox]
  There is a countable subset $D$ of $S^{2}$ such that $S^{2}\setminus D$ is $\text{SO}(3)$-paradoxical.
\end{theorem}
\begin{proof}
  Let $A$ and $B$ be the rotations in $\text{SO}(3)$ that serve as the generators of the subgroup isomorphic to $F(a,b)$.\newline

  Since $A$ and $B$ are rotations, so too is any reduced word over $\set{A,A^{-1},B,B^{-1}}$. Thus, any such non-empty word contains two fixed points.\newline

  We let
  \begin{align*}
    F &= \set{x\in S^{2}\mid s\text{ is a fixed point for some word }w}.
  \end{align*}
  Since the set of all reduced words in $\set{A,A^{-1},B,B^{-1}}$ (henceforth $F(A,B)$) is countably infinite, so too is $F$. Thus, the union of all these fixed points under the action of all such words $w$ is countable.
  \begin{align*}
    D &= \bigcup_{w\in F(A,B)} w\cdot F.
  \end{align*}
  Therefore, $F(A,B)$ acts freely on $S^{2}\setminus D$, so $S^{2}\setminus D$ is $\text{SO}(3)$-paradoxical.
\end{proof}
Unfortunately, the Hausdorff paradox is not enough for us to be able to prove the Banach--Tarski paradox. In order to do this, we need to be able to show that two sets are ``similar'' under the action of a group.
\begin{definition}[Equidecomposable Sets]
  Let $G$ act on $X$, and let $A,B\subseteq X$. We say $A$ and $B$ are $G$-{equidecomposable} if there are partitions $\set{A_j}_{j=1}^{n}$ of $A$ and $\set{B_j}_{j=1}^{n}$ of $B$, and elements $g_1,\dots,g_n\in G$, such that for all $j$,
  \begin{align*}
    B_j &= g_j\cdot A_j.
  \end{align*}
  We write $A\sim_{G}B$ if $A$ and $B$ are $G$-equidecomposable.
\end{definition}
\begin{fact}
  The relation $\sim_{G}$ is an equivalence relation.
\end{fact}
\begin{proof}
  Let $A$, $B$, and $C$ be sets.\newline

  To show reflexivity, we can select $g_1 = g_2 = \cdots = g_n = e_G$. Thus, $A\sim_{G}A$.\newline

  To show symmetry, let $A\sim_{G} B$. Set $\set{A_j}_{j=1}^{n}$ to be the partition of $A$, and set $\set{B_j}_{j=1}^{n}$ to be the partition of $B$, such that there exist $g_1,\dots,g_n\in G$ with $g_j\cdot A_j = B_j$. Then,
  \begin{align*}
    g_j^{-1}\cdot \left(g_j\cdot A_j\right) &= g_j^{-1}\cdot B_j\\
    A_j &= g_j^{-1}\cdot B_j,
  \end{align*}
  so $B_j\sim_{G}A_j$.\newline

  To show transitivity, let $A\sim_{G} B$ and $B\sim_{G} C$. Let $\set{A_i}_{i=1}^{n}$ and $\set{B_i}_{i=1}^{n}$ be the partitions of $A$ and $B$ respectively and $g_1,\dots,g_n\in G$ such that $g_i\cdot A_i = B_i$. Let $\set{B_j}_{j=1}^{m}$ and $\set{C_j}_{j=1}^{m}$ be partitions of $B$ and $C$, and $h_1,\dots,h_m\in G$, such that $h_j\cdot B_j = C_j$.\newline

  We refine the partition of $A$ to $A_{ij}$ by taking $A_{ij} = g_i^{-1}\left(B_{i}\cap B_j\right)$, where $i = 1,\dots,n$ and $j = 1,\dots,m$. Then, $\left(h_jg_i\right)\cdot A_{ij}$ maps the refined partition of $A$ to a refined partition of $C$, meaning $A$ and $C$ are $G$-equidecomposable.
\end{proof}
\begin{fact}
  For $A\sim_{G} B$, there is a bijection $\phi\colon A\rightarrow B$ by taking $C_{i} = C\cap A_i$, and mapping $\phi\left(C_i\right) = g_i\cdot C_i$.\newline

  In particular, this means that for any subset $C\subseteq A$, it is the case that $C\sim \phi(C)$.\label{fact:bijections}
\end{fact}

We can now use this equidecomposability to glean information about the existence of paradoxical decompositions.
\begin{proposition}
  Let $G$ act on $X$, with $E,E'\subseteq X$ such that $E\sim_{G}E'$. Then, if $E$ is $G$-paradoxical, then so too is $E'$.
\end{proposition}

\begin{proof}
Let $A_1,\dots,A_n,B_1,\dots,B_m\subset E$ be pairwise disjoint, with $g_1,\dots,g_n,h_1,\dots,h_m\in G$ such that
\begin{align*}
  E &= \bigcup_{i=1}^{n}g_i\cdot A_i\\
    &= \bigcup_{j=1}^{m}h_j\cdot B_j.
\end{align*}
We let
\begin{align*}
  A &= \bigsqcup_{i=1}^{n}A_i\\
  B &= \bigsqcup_{j=1}^{m}B_j.
\end{align*}
It follows that $A\sim_{G}E$ and $B\sim_{G}E$, since we can take the partition of $A$ to be $A_1,\dots,A_n$, and partition $E$ by taking $g_i\cdot A_i$ for $i=1,\dots,n$, and similarly for $B$.\newline

Since $E\sim_{G}E'$, and $\sim_{G}$ is an equivalence relation, it follows that $A\sim_{G}E'$ and $B\sim_{G}E'$. Thus, there is a paradoxical decomposition of $E'$ in $A_1,\dots,A_n$ and $B_1,\dots,B_m$.
\end{proof}
We will now show that $S^{2}$ is $\text{SO}(3)$ paradoxical.
\begin{proposition}
  Let $D\subseteq S^{2}$ be countable. Then, $S^{2}$ and $S^{2}\setminus D$ are $\text{SO}(3)$-equidecomposable.
\end{proposition}

\begin{proof}
  Let $L$ be a line in $\R^3$ such that $L\cap D = \emptyset$. Such an $L$ must exist since $S^{2}$ is uncountable.\newline

  Define $\rho_{\theta}\in \text{SO}(3)$ to be a rotation about $L$ by an angle of $\theta$. For a fixed $n\in \N$ and fixed $\theta\in [0,2\pi)$, define $R_{n,\theta} = \set{x\in D\mid \rho^{n}_{\theta}\cdot x \in D}$. Since $D$ is countable, $R_{n,\theta}$ is necessarily countable.\newline

  We define $W_n = \set{\theta\mid R_{n,\theta}\neq \emptyset}$. Since the map $\theta \mapsto \rho_{\theta}^{n}\cdot x$ into $D$ is injective, it is the case that $W_n$ is countable. Therefore,
  \begin{align*}
    W &= \bigcup_{n\in \N}W_n
  \end{align*}
  is countable.\newline

  Thus, there must exist $\omega \in [0,2\pi)\setminus W$. We define $\rho_{\omega}$ to be a rotation about $L$ by $\omega$. Then, for every $n,m\in \N$, we have
  \begin{align*}
    \rho_{\omega}^n\cdot D \cap \rho_{\omega}^{m}\cdot D &= \emptyset.
  \end{align*}
  We define $\widetilde{D} = \bigsqcup_{n=0}^{\infty}\rho^{n}_{\omega}D$. Note that 
  \begin{align*}
    \rho_{\omega}\cdot \widetilde{D} &= \rho_{\omega}\cdot\bigsqcup_{n=0}^{\infty}\rho_{\omega}^{n}\cdot D\\
                                     &= \bigsqcup_{n=1}^{\infty}\rho_{\omega}^{n}\cdot D\\
                                     &= \widetilde{D} \setminus D,
  \end{align*}
  meaning $\widetilde{D}$ and $D$ are $\text{SO}(3)$-equidecomposable.\newline

  Thus, we have
  \begin{align*}
    S^{2} &= \widetilde{D}\sqcup \left(S^{2}\setminus \widetilde{D}\right)\\
          &\sim_{\text{SO}(3)}\left(\rho_{\omega}\cdot \widetilde{D}\right)\sqcup \left(S^{2}\setminus\widetilde{D}\right)\\
          &= \left(\widetilde{D}\setminus D\right)\sqcup \left(S^{2}\setminus\widetilde{D}\right)\\
          &= S^{2}\setminus D,
  \end{align*}
  establishing $S^{2}$ and $S^{2}\setminus D$ as $\text{SO}(3)$-equidecomposable.\newline

  In particular, this means $S^{2}$ is also $\text{SO}(3)$-paradoxical.
\end{proof}
To prove the Banach--Tarski paradox, we need a slightly larger group than $\text{SO}(3)$ --- one that includes translations in addition to the traditional rotations. This is the Euclidean group.
\begin{definition}[Euclidean Group]
  The {Euclidean group}, $\text{E}(n)$, consists of all isometries of a Euclidean space. An isometry of a Euclidean space consists of translations, rotations, and reflections.\newline
  %We have $E(n) = T(n) \rtimes O(n)$, where $T(n)$ is the translation group, and $O(n)$ is the orthogonal group, which is the group of all rotations and reflections about the origin.\newline

  A further refinement of $\text{E}(n)$, $\text{E}_{+}(n)$, consists of all orientation-preserving isometries.
\end{definition}
\begin{corollary}[Weak Banach--Tarski Paradox]
  Every closed ball in $\R^3$ is $\text{E}(3)$-paradoxical.
\end{corollary}

\begin{proof}
  We only need to show that $B(0,1)$ is $\text{E}(3)$-paradoxical. To do this, we start by showing that $B(0,1)\setminus \set{0}$ is $\text{SO}(3)$-paradoxical.\newline

  Since $S^{2}$ is $\text{SO}(3)$-paradoxical, there exists pairwise disjoint subsets $A_1,\dots,A_n,B_1,\dots,B_m\subset S^2$ and elements $g_1,\dots,g_n,h_1,\dots,h_m\in \text{SO}(3)$ such that
  \begin{align*}
    S^{2} &= \bigcup_{i=1}^{n}g_i\cdot A_i\\
          &= \bigcup_{j=1}^{m}h_j\cdot B_j.
  \end{align*}
  Define
  \begin{align*}
    A_i^{\ast} &= \set{tx\mid t\in (0,1], x\in A_i}\\
    B_j^{\ast} &= \set{ty\mid t\in (0,1], y\in B_j}.
  \end{align*}
  Then, $A_1^{\ast},\dots,A_n^{\ast},B_1^{\ast},\dots,B_m^{\ast}\subset B(0,1)\setminus \set{0}$ are pairwise disjoint, and
  \begin{align*}
    B(0,1)\setminus \set{0} &= \bigcup_{i=1}^{n}g_i\cdot A_i^{\ast}\\
                            &= \bigcup_{j=1}^{m}h_j\cdot B_j^{\ast}.
  \end{align*}
  Thus, we have established that $B(0,1)\setminus \set{0}$ is $\text{E}(3)$-paradoxical.\newline

  Now, we want to show that $B(0,1)\setminus \set{0}$ and $B(0,1)$ are $\text{E}(3)$-equidecomposable. Let $x\in B(0,1)\setminus \set{0}$, and let $\rho$ be a rotation through $x$ by a line not through the origin such that $\rho^{n}\cdot 0\neq \rho^{m}\cdot 0$ when $n\neq m$.\newline

  Let $D = \set{\rho^{n}\cdot 0\mid n\in \N}$. We can see that $\rho\cdot D = D\setminus \set{0}$, and that $D$ and $\rho\cdot D$ are $\text{E}(3)$-equidecomposable. Thus,
  \begin{align*}
    B(0,1) &= D\sqcup \left(B(0,1)\setminus D\right)\\
           &\sim_{\text{E}(3)}\left(\rho\cdot D\right) \sqcup \left(B(0,1)\setminus D\right)\\
           &= \left(D\setminus \set{0}\right)\sqcup \left(B\left(0,1\right)\setminus D\right)\\
           &= B\left(0,1\right)\setminus \set{0}.
  \end{align*}
  Therefore, $B(0,1)$ is $\text{E}(3)$-equidecomposable.
\end{proof}
In order to prove the general case of the Banach--Tarski paradox, we need one more piece of mathematical machinery.\newline

Our relation of $A \sim_{G} B$ is useful, but in order to show the general case, we want to refine the relation slightly.
\begin{definition}
  Let $G$ act on a set $X$ with $A,B\subseteq X$. We write $A\preceq_{G}B$ if $A$ is equidecomposable with a subset of $B$.
\end{definition}
\begin{fact}
  The relation $\preceq_{G}$ is a reflexive and transitive relation.\label{fact:preorder}
\end{fact}
\begin{proof}
  To see reflexivity, we can see that since $A\sim_{G}A$, and $A\subseteq A$, $A\preceq_{G} A$.\newline

  To see transitivity, let $A\preceq_{G}B$ and $B\preceq_{G}C$. Then, there exist $g_1,\dots,g_n\in G$ such that $g_i\cdot A_i = B_{\alpha,i}$ for each $i$, where $A\sim_{G}B_{\alpha}\subseteq B$. Similarly, there exist $h_1,\dots,h_m\in G$ such that $h_j\cdot B_j= C_{\beta,j}$ for each $j$, where $B\sim_{G}C_{\beta}\subseteq C$.\newline

  We take a refinement of $B$ by taking intersections $B_{\alpha,ij} = B_{\alpha,i}\cap B_j$, with $i=1,\dots,n$ and $j = 1,\dots,m$. We define $C_{\beta,\alpha,ij} = h_j\cdot B_{\alpha,ij}$ for each $j = 1,\dots,m$. Then, $h_jg_i\cdot A_i = C_{\beta,\alpha,ij}$, meaning $A\sim_{G}C_{\beta,\alpha,ij}\subseteq C_{\beta}\subseteq C$, so $A\preceq_{G}C$.
\end{proof}

We know from Fact \ref{fact:bijections} that $A\preceq_{G}B$ implies the existence of a bijection $\phi\colon A\rightarrow B'\subseteq B$, meaning $\phi\colon A\hookrightarrow B$ is an injection. Similarly, if $B\preceq_{G}A$, then Fact \ref{fact:bijections} implies the existence of an injection $\psi\colon B\hookrightarrow A$.\newline

One may ask if an analogue of the Cantor--Schröder--Bernstein theorem exists in the case of the relation $\preceq_{G}$, implying that the preorder established in Fact \ref{fact:preorder} is indeed a partial order. The following theorem establishes this result.
\begin{theorem}
  Let $G$ act on $X$, and let $A,B\subseteq X$. If $A\preceq_{G}B$ and $B\preceq_{G}A$, then $A\sim_{G}B$.\label{thm:csb_for_equidecomposability}
\end{theorem}
\begin{proof}
  Let $B'\subseteq B$ with $A\sim_{G}B'$, and let $A'\subseteq A$ with $B\sim_{G}A'$. Then, we know from Fact \ref{fact:bijections} that there exist bijections $\phi\colon A\rightarrow B'$ and $\psi\colon B\rightarrow A'$.\newline

  Define $C_0 = A\setminus A'$, and $C_{n+1} = \psi\left(\phi\left(C_n\right)\right)$. We set
  \begin{align*}
    C &= \bigcup_{n\geq 0}C_{n}.
  \end{align*}
  Since $\psi^{-1}\left(\psi\left(\phi\left(C_n\right)\right)\right) = \phi\left(C_n\right)$, we have
  \begin{align*}
    \psi^{-1}\left(A\setminus C\right) &= B\setminus \phi(C).
  \end{align*}
  Having established in Fact \ref{fact:bijections} that for any subset of $C\subseteq A$, $C\sim_{G} \phi(C)$, we also see that $A\setminus C \sim_{G} B\setminus \phi(C)$.\newline

  Thus, we can see that
  \begin{align*}
    A &= \left(A\setminus C\right)\sqcup C\\
      &\sim_{G}\left(B\setminus \phi(C)\right)\sqcup \phi(C)\\
      &= B.
  \end{align*}
  
\end{proof}
Finally, we are able to prove Proposition \ref{prop:banachtarski}.\newline

\begin{proof}
  By symmetry, it is enough to show that $A\preceq_{\text{E}(3)} B$.\newline

  Since $A$ is bounded, there exists $r > 0$ such that $A\subseteq B(0,r)$.\newline

  Let $x_0\in B^{\circ}$. Then, there exists $\ve > 0$ such that $B\left(x_0,\ve\right) \subseteq B$.\newline

  Since $B(0,r)$ is compact (hence totally bounded), there are translations $g_1,\dots,g_n$ such that
  \begin{align*}
    B\left(0,r\right) \subseteq g_1\cdot B\left(x_0,\ve\right) \cup \cdots \cup g_n\cdot B\left(x_0,\ve\right).
  \end{align*}
  We select translations $h_1,\dots,h_n$ such that $h_j\cdot B\left(x_0,\ve\right) \cap h_k\cdot B\left(x_0,\ve\right) = \emptyset$ for $j\neq k$. We set
  \begin{align*}
    S &= \bigcup_{j=1}^{n}h_j\cdot B\left(x_0,\ve\right).
  \end{align*}
  Each $h_j\cdot B\left(x_0,\ve\right)\subseteq S$ is $\text{E}(3)$-equidecomposable with any arbitrary closed ball subset of $B\left(x_0,\ve\right)$, it is the case that $S\preceq B\left(x_0,\ve\right)$.\newline

  Thus, we have
  \begin{align*}
    A &\subseteq B\left(0,r\right)\\
      &\subseteq g_1\cdot B\left(x_0,\ve\right)\cup\cdots\cup b_n\cdot B\left(x_0,\ve\right)\\
      &\preceq S\\
      &\preceq B\left(x_0,\ve\right)\\
      &\preceq B.
  \end{align*}
\end{proof}

