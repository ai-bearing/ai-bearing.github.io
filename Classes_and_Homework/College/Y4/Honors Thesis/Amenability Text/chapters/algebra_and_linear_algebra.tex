In general, as we progress through these appendices, we will consistently add additional structure to a set. First, we begin by developing groups, rings, and fields, vector spaces, and algebras. In the following appendices, we will apply metric structures, topologies, and measures, building up to the central structure of functional analysis: normed vector spaces and the operators on these normed vector spaces.\newline

These appendices were largely written to provide essential background for the techniques and results that will appear in the main body of the text. As such, they do not include detailed proofs --- occasionally, we will include outlines for certain proofs in the remarks. The proofs for many of these results can be found in relevant (and some not-as-relevant) texts.\newline

We make heavy use of results from algebra and linear algebra in this thesis. Some excellent resources to learn more about algebra and linear algebra are \cite{dummit_and_foote} and \cite{algebra_chapter_0}. Most of the theorems are presented without proof, not because we do not want to state their proofs, but because this thesis is already long enough.
\section{Group, Rings, (some) Fields}%
\subsection{Groups}%
\begin{definition}[Groups]
  Let $A$ be a set, and let $\star$ be a binary operation on $A$. We say $A$ is a \textit{group} if
  \begin{itemize}
    \item $A$ is closed under the operation $\star$;
    \item $\star$ is associative, such that for all $a,b,c\in A$, $\left(a\star b\right)\star c = a\star \left(b\star c\right)$;
    \item $A$ has an identity element $e_A$, where $a\star e_A = e_A\star a = a$ for any $a\in A$;
    \item for any $a\in A$, there exists $a^{-1}\in A$ such that $a^{-1}\star a = a\star a^{-1} = e$.
  \end{itemize}
  If the operation $\star$ is such that $a\star b = b\star a$ for all $a,b\in A$, then we say $A$ is an \textit{abelian} group.
\end{definition}
\begin{remark}
  Generally, we abbreviate $a\star b \coloneq ab$.
\end{remark}
\begin{definition}[Subgroups, Normal Subgroups, and Quotient Groups]
  If $G$ is a group, $H\subseteq G$ is a \textit{subgroup} if $H$ is closed under the group operation and inverses. We write $H\leq G$.\newline

  If $H$ is a subgroup, a \textit{left coset} of $H$ is the set $gH \coloneq \set{gh | h\in H}$, where $g\in G$. Similarly, a \textit{right coset} of $H$ is the set $Hg\coloneq \set{hg | h\in H}$. The \textit{index} of $H$, denoted $\left[G:H\right]$, is the number of left (or right) cosets of $H$.\newline

  If $H\leq G$ is also such that, for any $g\in G$ and $h\in H$, $ghg^{-1}\in H$, then we call $H$ a \textit{normal subgroup} of $G$. We write $H\trianglelefteq G$.\newline

  Defining the equivalence relation $g\sim g'$ if and only if $g^{-1}g'\in H$, the group of equivalence classes $gH\coloneq \left[g\right]$ is known as the \textit{quotient group} $G/H$.\newline

  If the only normal subgroups of a group $G$ are $G$ itself and $\set{e_{G}}$, then we say the group $G$ is \textit{simple}.
\end{definition}
\begin{definition}
  Let $G$ and $H$ be groups. A map $\varphi\colon G\rightarrow H$ is called a (group) \textit{homomorphism} if, $\varphi$ ``preserves the group structure,'' in the sense that
  \begin{align*}
    \varphi\left(ab\right) &= \varphi(a)\varphi(b)\\
    \varphi\left(a^{-1}\right) &= \varphi(a)^{-1}
  \end{align*}
  for all $a,b\in G$.\newline

  We define the \textit{kernel}, $\ker\left(\varphi\right)$, to be the set of all $g\in G$ such that $\varphi\left(g\right) = e_H$.\newline

  If $H\trianglelefteq G$, the map $\pi\colon G\rightarrow G/H$ that sends $g\mapsto gH$ is known as the \textit{canonical projection}.\newline

  If $\varphi$ is a bijection, then $\varphi$ is known as an \textit{isomorphism}. We write $G\cong H$ if there exists an isomorphism $\varphi\colon G\rightarrow H$.
\end{definition}
\begin{theorem}[First Isomorphism Theorem for Groups]
  Let $G$ and $H$ be groups, and let $\varphi\colon G\rightarrow H$ be a group homomorphism. Then, $\ker\left(\varphi\right)\trianglelefteq G$ is a normal subgroup, and $G/\ker\left(\varphi\right)\cong \img\left(\varphi\right)$.
\end{theorem}
There is a complete classification of finitely generated (and finite) abelian groups.\footnote{There is also a complete classification of all the finite simple groups, but we do not have enough space for that one.}
\begin{theorem}
  Let $G$ be a finitely generated (see definition \ref{def:generating_sets}) abelian group. Then, there is some $d\in \N$ and some $k_1,\dots,k_n$ such that
  \begin{align*}
    G &\cong \underbrace{\Z^{d}}_{F}\times \underbrace{\Z/k_1\Z \times \Z/k_2\Z \times \cdots \times \Z/k_n\Z}_{T}. 
  \end{align*}
  The group $F$ is known as the \textit{free subgroup} of $G$, and the group $T$ is known as the \textit{torsion subgroup} of $G$. If $G$ is finite, then $G$ is isomorphic to some torsion group $\Z/k_1\Z\times \cdots \times \Z/k_1\Z$.\newline

  Furthermore, we may also take each of $k_i$ in both cases to be equal to $p_i^{e_i}$ for some prime $p_i$ and some $e_i\in \N$.
\end{theorem}
\begin{definition}
  A group $G$ is \textit{solvable} if if admits a finite series of normal subgroups
  \begin{align*}
    e_G = G_0\trianglelefteq G_1\trianglelefteq \cdots \trianglelefteq G_n \trianglelefteq G
  \end{align*}
  such that $G_{j}/G_{j-1}$ is abelian for each $j = 1,\dots,n$.
\end{definition}

\begin{definition}[Group Actions]
  Let $G$ be a group, and let $A$ be a set. A (left) \textit{group action} of $G$ on $A$ is a map $\rho\colon G\times A \rightarrow A$ such that, for all $a\in A$,
  \begin{itemize}
    \item $\rho\left(e_G,a\right) = a$;
    \item $\rho\left(g,\rho\left(h,a\right)\right) = \rho\left(gh,a\right)$.
  \end{itemize}
  We abbreviate $\rho\left(g,a\right) = g\cdot a$.\newline

  The permutation representation of the action $\rho$ is a homomorphism $\varphi\colon G\rightarrow \sym(A)$.
\end{definition}
\begin{definition}[Kernels, Stabilizers, and Orbits]
  Let $G$ act on $A$, and let $a\in A$.
  \begin{itemize}
    \item The \textit{stabilizer} of $a$ under $G$ is the set of elements in $G$ that fix $a$:
      \begin{align*}
        G_{a} \coloneq \set{g\in G | g\cdot a = a}.
      \end{align*}
    \item The \textit{kernel} of the action of $G$ on $A$ is the intersection of the stabilizers of $G$:
      \begin{align*}
        \text{kernel} &\coloneq \bigcap_{a\in A}G_a\\
                      &= \set{g\in G | g\cdot a\text{ for all }a\in A}.
      \end{align*}
    \item The action is \textit{faithful} if the kernel is $e_G$.
    \item The action is \textit{free} if $G_a = \set{e_G}$ for all $a\in A$.
    \item The \textit{orbit} of $a$ is the equivalence class $\left[a\right]_{\sim}$ under the relation $a\sim b$ if there exists some $g\in G$ such that $a = g\cdot b$:
      \begin{align*}
        G\cdot a &= \set{b\in A | b = g\cdot a\text{ for some }g\in G}.
      \end{align*}
  \end{itemize}
\end{definition}
\begin{theorem}[Orbit-Stabilizer Theorem]
  If $G$ acts on $A$, and $a\in A$, then the number of elements in the orbit of $a$ is the index of the stabilizer of $a$. In symbolic form,
  \begin{align*}
    \left\vert G\cdot a \right\vert &= \left[G:G_a\right].
  \end{align*}
\end{theorem}
\begin{remark}
  Various celebrated theorems, such as the Sylow Theorems and Lagrange's Theorem, fall out of the Orbit-Stabilizer theorem.
\end{remark}
\subsection{Rings and Fields}%
\begin{definition}[Rings]
  Let $A$ be a set. Specifically, let $A$ be an abelian group, letting $+$ denote the operation on $A$ and $0\coloneq e_A$. Then, $A$ is a \textit{ring} if $A$ also admits a multiplication, $\cdot$, such that
  \begin{itemize}
    \item $a\cdot \left(b+c\right) = a\cdot b + a\cdot c$;
    \item $\left(a+b\right)\cdot c = a\cdot c + b\cdot c$;
    \item $\left(a\cdot b\right)\cdot c = a\cdot \left(b\cdot c\right)$.
  \end{itemize}
  If the multiplication on $A$ is commutative, then we say $A$ is a commutative ring. If $A$ admits an element $1_A$ such that $a\cdot 1_A = 1_A \cdot a = a$, then we say $A$ is a \textit{unital} ring.\newline

  When referring to the abelian group of $A$ under $+$, we often write $\left(A,+\right)$.
\end{definition}
\begin{definition}[Subrings, Ideals, and Quotient Rings]
  Let $R$ be a ring. A subset $A\subseteq R$ is known as a \textit{subring} if $A$ is a subgroup of $\left(R,+\right)$, and $A$ is closed under multiplication. In other words, for all $a,b\in A$, we have
  \begin{itemize}
    \item $a-b\in A$;
    \item $ab \in A$,
  \end{itemize}
  where $a-b = a + (-b)$.\newline

  If $I\subseteq R$ is a subring that also has the property that, for all $x\in I$ and $r\in R$, $rx\in I$ and $xr\in I$, then we say $I$ is an \textit{ideal}.\newline

  Similar to the case of groups and normal subgroups, if $I$ is an ideal, we can form the \textit{quotient ring} $R/I$ by defining the equivalence relation $a\sim b$ if $a-b\in I$, and defining $a + I\coloneq \left[a\right]_{\sim}$.
\end{definition}
\begin{definition}[Ring Homomorphism]
  If $R$ and $S$ are rings, then a map $\varphi\colon R\rightarrow S$ is a \textit{ring homomorphism} if $\varphi$ ``preserves the ring structure,'' in the sense that, for all $a,b\in R$,
  \begin{itemize}
    \item $\varphi\left(a+b\right) = \varphi\left(a\right) + \varphi\left(b\right)$;
    \item $\varphi\left(ab\right) = \varphi\left(a\right)\varphi\left(b\right)$.
  \end{itemize}
  The \textit{kernel} of the ring homomorphism is defined to be the set of all elements $a\in R$ such that $\varphi\left(a\right) = 0_{S}$.\newline

  If $I \subseteq R$ is an ideal, then the map $\pi\colon R\rightarrow R/I$ that sends $a \mapsto a + I$ is known as the \textit{canonical projection}.\newline

  If $\varphi$ is a bijection, then $\varphi$ is known as a \textit{ring isomorphism}. We write $R\cong S$ if there exists an isomorphism $\varphi\colon R\rightarrow S$.

  If $A\subseteq R$ is any subset, then we define the ideal \textit{generated by} $A$ to be the smallest ideal that contains $A$. In other words,
  \begin{align*}
    \operatorname{ideal}(R) &= \bigcap\set{J | A\subseteq J,J\subseteq R\text{ is an ideal}}.
  \end{align*}
\end{definition}
Analogously, there is a first isomorphism theorem for rings.
\begin{theorem}[First Isomorphism Theorem for Rings]
  Let $R$ and $S$ be rings, and let $\varphi\colon R\rightarrow S$ be a ring homomorphism. Then, $\ker\left(\varphi\right)\subseteq R$ is an ideal, and $R/\ker\left(\varphi\right)\cong \img\left(\varphi\right)$.
\end{theorem}
The ideal structure of a ring $R$ admits some more specification.
\begin{definition}
  An ideal $I\subsetneq R$ is said to be \textit{maximal} if, for any other ideal $J\subseteq R$ with $I\subseteq J$, either $I = J$ or $I = R$.
\end{definition}
\begin{theorem}[Krull's Theorem]
  If $I\subseteq R$ is a proper ideal, then there exists some maximal ideal $M\subseteq R$ such that $I\subseteq M$.
\end{theorem}
\begin{remark}
  Krull's Theorem can be proven using Zorn's Lemma \ref{thm:zorns_lemma} applied to the partially ordered set of proper ideals ordered by inclusion.
\end{remark}
\begin{definition}
  Let $R$ be a unital ring.
  \begin{itemize}
    \item If $a,b\in R$ are nonzero elements such that $ab = 0$, then we say $a$ and $b$ are \textit{zero divisors} in $R$.
    \item If $R$ is commutative and does not contain any zero divisors, then we say $R$ is an \textit{integral domain}.
    \item If an element $a\in R$ is such that there exists some $b$ such that $ab = ba = 1_R$, then we call $a$ a \textit{unit}.
    \item If $R$ is a such that every element of $R$ is a unit, then we say $R$ is a \textit{division algebra}.
    \item If $R$ is a division algebra that is commutative, then $R$ is a \textit{field}.
  \end{itemize}
\end{definition}
\begin{remark}
  Generally, when we deal with fields, we will usually be dealing with the complex numbers, $\C$, unless otherwise stated.
\end{remark}
\section{Linear Algebra}%
Certain constructions in linear algebra are extremely important in understanding functional analysis. We provide an overview of the theory of vector spaces and linear transformations in the purely algebraic context. Analytic properties that result from applying norms on these vector spaces will appear in Appendix \ref{ch:functional_analysis}.
\subsection{The Structure of Vector Spaces}%
\begin{definition}
  Let $X$ be some set, and $\F$ some field (generally, we assume $\F = \C$). We say $X$ is an $\F$\textit{-vector space} if $X$ is equipped with two operations:
  \begin{itemize}
    \item scalar multiplication: $m\colon \F\times X \rightarrow X$, which sends $\left(\alpha,x\right)\mapsto \alpha x$; and
    \item vector addition: $a\colon X\times X \rightarrow X$, which sends $\left(x,y\right)\mapsto x + y$.
  \end{itemize}
  In general, $\left(X,+\right)$ is an abelian group, and scalar multiplication satisfies the following identities, for all $\alpha,\beta \in \F$ and $x,y\in X$:
  \begin{itemize}
    \item $\alpha \left(\beta x\right) = \left(\alpha\beta\right)x$;
    \item $\alpha\left(x+y\right) = \alpha x + \alpha y$;
    \item $\left(\alpha + \beta\right)x = \alpha x + \beta x$;
    \item $1_{\F}x = x$;
    \item $0_{\F} x = 0_X$.
  \end{itemize}
\end{definition}
\begin{example}\hfill
  \begin{itemize}
    \item The set $\C^n$, defined by
      \begin{align*}
        \C^n &\coloneq \set{\left( x_i \right)_{i=1}^{n} | x_i\in \C},
      \end{align*}
      is a vector space under the operations
      \begin{align*}
        \left( x_{i} \right)_{i=1}^{n} + \left( y_i \right)_{i=1}^{n} &= \left( x_i + y_i \right)_{i=1}^{n}\\
        \alpha \left( x_i \right)_{i=1}^{n} &= \left( \alpha x_i \right)_{i=1}^{n}.
      \end{align*}
    \item The set $\Mat_{m,n}\left( \C \right)$, defined by
      \begin{align*}
        \Mat_{m,n}\left( \C \right) &\coloneq \set{\left( x_{ij} \right)_{ij} | 1\leq i\leq m,1\leq j\leq n,x_{ij}\in \C},
      \end{align*}
      is a vector space under element-wise operations. If $m = n$, then we write $\Mat_n\left( \C \right)$.
    \item We may extend $\Mat_n\left( \C \right)$ to have entries in any vector space $V$, yielding the space
      \begin{align*}
        \Mat_n\left( V \right) &\coloneq \set{\left( x_{ij} \right)_{ij} | 1\leq i,j\leq n,x_{ij}\in V}.
      \end{align*}
  \end{itemize}
\end{example}
There are certain geometric properties of subsets of vector spaces that we will be using a lot, especially when we discuss locally convex topologies on these vector spaces.
\begin{definition}\label{def:vector_space_subset_operations}
  Let $X$ be a $\C$-vector space.
  \begin{itemize}
    \item If $A,B\subseteq X$, then we define
      \begin{align*}
        A + B &= \set{x + y | x\in A,y\in B}.
      \end{align*}
      If $A = \set{x_0}$, we abbreviate $\set{x_0} + B$ as $x_0 + B$, which is called the translation of $B$ by $x_0$.
    \item If $A\subseteq X$, and $\alpha\in \C$, then
      \begin{align*}
        \alpha A &= \set{\alpha x | x\in A}
      \end{align*}
      is the scaling of $A$ by $\alpha$. We write $(-1)A = -A$.
    \item A subset $A\subseteq X$ is called \textit{symmetric} if $-A = A$.
    \item A subset $A\subseteq X$ is called \textit{balanced} if $\alpha A\subseteq A$ for all $\left\vert \alpha \right\vert\leq 1$.
    \item A subset $C\subseteq X$ is called \textit{convex} if for all $t\in [0,1]$ and $x_1,x_2\in C$, $\left(1-t\right)x_1 + tx_2 \in C$.
  \end{itemize}
  We define the \textit{convex hull} of $A\subseteq X$ by
  \begin{align*}
    \operatorname{conv}\left(A\right) &= \bigcap\set{C | A\subseteq C\subseteq X,C\text{ is convex}}\\
                                      &= \set{\sum_{j=1}^{n}t_ja_j | n\in\N,t_j\geq 0,\sum_{j=1}^{n}t_j = 1,a_j\in A}.
  \end{align*}
\end{definition}
\begin{definition}
  If $X$ is a vector space, and $M\subseteq X$ is a subset such that, for all $x,y\in M$ and $\alpha\in \C$, $\alpha x + y\in M$, then $M$ is called a \textit{subspace} of $X$.\newline

  If $M$ is a subspace, we may define the equivalence relation $x\sim_{M} y$ if and only if $x-y\in M$. Equivalence classes under the relation $\sim_{M}$ are written $x + M\coloneq \left[x\right]_{\sim}$, and form the \textit{quotient vector space} $X/M$.\newline

  Furthermore, if $\set{M_i}_{i\in I}$ is a family of subspaces of $X$ and, for any $x\in X$, there is a unique sum
  \begin{align*}
    x &= \sum_{i\in I}x_i,
  \end{align*}
  where $x_i\in M_i$, then we say $X$ is the internal \textit{direct sum} of the family of subspaces $\set{M_i}_{i\in I}$,
  \begin{align*}
    X &= \bigoplus_{i\in I}M_i.
  \end{align*}
\end{definition}
\begin{definition}
  Let $X$ be a vector space, and let $\set{x_i}_{i\in I}\subseteq X$ be a subset.
  \begin{itemize}
    \item The set $\set{x_i}_{i\in I}$ is called \textit{linearly independent} if, for any finite linear combination such that
      \begin{align*}
        \sum_{i\in I}\alpha_ix_i &= 0_X,
      \end{align*}
      it is the case that all $\alpha_i = 0$.
    \item The set $\set{x_i}_{i\in I}$ is called \textit{spanning} for $X$ if the set of all finite linear combinations $\sum_{i\in I}\alpha_ix_i$ is equal to $X$.
    \item The set $\set{x_i}_{i\in I}$ is called a basis for $X$ if it is linearly independent and spanning.
  \end{itemize}
\end{definition}
\begin{example}
  In the vector space $\C^n$, the coordinate vectors $\set{e_i}_{i=1}^{n}$, with entry $1$ at index $i$, are a basis known as the canonical coordinate vectors.\newline

  Similarly, in the vector space of matrices $\Mat_n\left( \C \right)$, the set of matrices $\set{\left( e_{ij} \right)_{ij}}_{i,j=1}^{n}$ with $1$ at row $i$ and index $j$, form a basis known as the system of matrix units.
\end{example}
\begin{definition}
  If $X$ is a vector space, and $\mathcal{B}\subseteq X$ is a basis, then $\Dim\left(X\right)\coloneq \left\vert \mathcal{B} \right\vert$.\newline

  If $M\subseteq X$ is a subspace, then the \textit{codimension} of $M$ is $\Dim\left(X/M\right)$.
\end{definition}
\begin{remark}
  Every vector space has a basis. This can be proven with Zorn's Lemma (Theorem \ref{thm:zorns_lemma}) applied on the partially ordered set (Definition \ref{def:ordered_sets}) of linearly independent subsets ordered by inclusion.\newline

  Additionally, not only does every vector space have a basis, but for any set, there is a vector space with the set as its basis (see Theorem \ref{thm:free_vector_space}).
\end{remark}
\subsection{Linear Maps}%
Linear algebra is not only the study of vector spaces, but also the study of linear maps on these vector spaces. 
\begin{definition}
  Let $X$ and $Y$ be vector spaces. A map $T\colon X\rightarrow Y$ is called linear if for every $x,x_1,x_2\in X$ and $\alpha\in \C$, we have
  \begin{align*}
    T\left(x_1 + x_2\right) &= T\left(x_1\right) + T\left(x_2\right)\\
    T\left(\alpha x\right) &= \alpha T\left(x\right).
  \end{align*}
  We write $I_{X} \coloneq \id_{X}$.\newline

  The set of linear maps between $X$ and $Y$ is denoted $\mathcal{L}\left(X,Y\right)$. The set of all linear maps between $X$ and $X$ is abbreviated $\mathcal{L}\left(X\right)$.\newline

  A linear map $\varphi\colon X\rightarrow \C$ is called a \textit{linear functional} on $X$. The collection of linear functionals on $X$ is called the \textit{algebraic dual} of $X$, written $X' \coloneq \mathcal{L}\left(X,\C\right)$.
\end{definition}
%\begin{remark}
%  The space $\mathcal{L}\left(X,Y\right)$ equipped with pointwise operations is a vector space over $\C$.
%\end{remark}

\begin{definition}[Four Fundamental Subspaces]
  Let $T\colon X\rightarrow Y$ be a linear map.
  \begin{itemize}
    \item The \textit{kernel} of $T$, $\ker\left(T\right)$, is the set of all $x\in X$ such that $T(x) = 0_X$.
    \item The \textit{range} of $T$, $\Ran\left(T\right)$, is the set of all $y\in Y$ such that there exists $x\in X$ with $T(x) = y$.
    \item The \textit{cokernel} of $T$ is $\operatorname{coker}(T) = Y/\Ran\left(T\right)$.
    \item The \textit{coimage} of $T$ is $\operatorname{coim}\left(T\right) = X/\ker\left(T\right)$.
  \end{itemize}
  We write $\Dim\left(\Ran\left(T\right)\right) = \operatorname{rank}\left(T\right)$, and $\Dim\left(\ker\left(T\right)\right) = \operatorname{null}\left(T\right)$.
\end{definition}
%\begin{remark}
%  By an analogous version of the first isomorphism theorem, we have $\operatorname{coim}\left(T\right) \cong \Ran\left(T\right)$.\newline
%
%  Additionally, $T$ is injective if and only if $\ker\left(T\right) = \set{0}$, and $T$ is surjective if and only if $\operatorname{coker}\left(T\right) = \set{0}$.\newline
%\end{remark}

\begin{definition}
  Let $T\in \mathcal{L}\left(X\right)$, and let $\lambda\in \C$. The \textit{eigenspace} for $\lambda$ is the subspace $E_{\lambda}\left(T\right) = \ker\left(T - \lambda I\right)$.\newline

  If $E_{\lambda}\left(T\right) \neq \set{0}$, then $\lambda$ is called an \textit{eigenvalue} for $T$ The nonzero vectors in $E_{\lambda}\left(T\right)$ are called \textit{eigenvectors} for $T$.\newline

  The set
  \begin{align*}
    \sigma_p\left(T\right) &= \set{\lambda | \lambda\text{ is an eigenvalue for }T}
  \end{align*}
  is known as the \textit{point spectrum} of $T$.
\end{definition}
\begin{theorem}[Rank--Nullity]
  If $T\colon X\rightarrow Y$ is a linear map between vector spaces, then $\operatorname{rank}\left(T\right) + \operatorname{null}\left(T\right) = \Dim\left(Y\right)$.
\end{theorem}
The separation properties of linear functionals are used heavily in proofs of various results in analysis. The following theorem is refined via the Hahn--Banach theorems (see \ref{thm:hb_separation}), as in infinite dimensions, continuity becomes an issue that analysts are forced to deal with. However, we start with the algebraic case.
\begin{proposition}
  Let $X$ be a vector space. If $0\neq x_0\in X$, then there is a $\varphi\in X'$ such that $\varphi\left(x_0\right) \neq 0$.
\end{proposition}
Geometrically, linear functionals are tied to hyperplanes within vector spaces.
\begin{proposition}
  Let $X$ be a vector space with $\Dim\left(X\right) \geq 2$, and let $H\subseteq X$ be a subspace. The following are equivalent:
  \begin{enumerate}[(i)]
    \item $H=\ker\left(\varphi\right)$ for some nonzero $\varphi\in X'$;
    \item $H\subseteq X$ is a maximal \textit{proper} subspace;
    \item $\Dim\left(X/H\right) = 1$ (i.e., $H$ has codimension $1$).
  \end{enumerate}
\end{proposition}
\begin{definition}
  A subspace that satisfies any of these equivalent properties is called a \textit{hyperplane}.\newline

  If $U = H + x_0$ for some fixed $x_0$, then $U$ is known as an \textit{affine} hyperplane.
\end{definition}
\section{Algebras}%
In our definition of vector spaces, we stated that they are akin to abelian groups, equipped with an operation of scalar multiplication. We may extend the analogy towards ``rings'' that include scalar multiplication, which are known as algebras.
\subsection{The Structure of Algebras}%
\begin{definition}
  Let $A$ be a $\C$-vector space. We say $A$ is an \textit{algebra} if $A$ admits a multiplication, $\left(a,b\right)\mapsto a\cdot b$, that satisfies, for all $a,b,c\in A$ and $\alpha \in \C$,
  \begin{itemize}
    \item $\left(a\cdot b\right)\cdot c = a\cdot \left(b\cdot c\right)$;
    \item $a\cdot \left(b+c\right) = a\cdot b + a\cdot c$;
    \item $\left(a+b\right)\cdot c = a\cdot c + b\cdot c$;
    \item $\left(\alpha a\right)\cdot b = \alpha \left(a\cdot b\right) = a \cdot \left(\alpha b\right)$.
  \end{itemize}
  If $A$, considered as a ring, is also unital, then we say $A$ is a \textit{unital} algebra. If $a\cdot b = b\cdot a$, then we say $A$ is commutative.\newline

  If $A$ also admits a unary operation $\ast\colon A\rightarrow A$ that satisfies, for all $a,b\in A$ and $\alpha \in \C$,
  \begin{itemize}
    \item $a^{\ast\ast} = a$;
    \item $\left(ab\right)^{\ast} = b^{\ast}a^{\ast}$;
    \item $\left(\alpha a + b\right)^{\ast} = \overline{\alpha}a^{\ast} + b^{\ast}$,
  \end{itemize}
  then we say $A$ is a $\ast$-algebra. The $\ast$ operation is also known as an involution.
\end{definition}
\begin{example}
  Returning to the case of $\Mat_n\left( \C \right)$, we can see that, more than a vector space, it is also an algebra under matrix multiplication. Furthermore, if $\left( a_{ij} \right)_{ij} = T\in \Mat_n\left( \C \right)$ is any matrix, then
  \begin{align*}
    A^{\ast} &= \left( \overline{a_{ji}} \right)_{ij},
  \end{align*}
  or the conjugate transpose of $A$, satisfies the definitions of the involution.\newline

  Furthermore, we can substitute the $\C$ within $\Mat_n\left( \C \right)$ with any other algebra $A$, yielding the matrix algebra $\Mat_n\left( A \right)$ with element-wise addition, scalar multiplication, and matrix multiplication.
\end{example}
In an algebra, the ideal structure requires compatibility with the underlying field, and in a $\ast$-algebra, we may further specify compatibility with the star structure.
\begin{definition}
  Let $A$ be an algebra, and let $J\subseteq A$. Then,
  \begin{itemize}
    \item we say $J$ is a \textit{subalgebra} of $A$ if $J$ is a linear subspace of $A$ that is closed under multiplication of elements in $J$;
    \item we say $J$ is an \textit{ideal} of $A$ if $J$ is a subalgebra of $A$ that is closed under multiplication by elements in $A$.
  \end{itemize}
  If $A$ is a $\ast$-algebra, then
  \begin{itemize}
    \item we say $J$ is \textit{$\ast$-closed} if for any $t\in J$, $t^{\ast}\in J$;
    \item if $J$ is a $\ast$-closed subalgebra, then we say $J$ is a $\ast$-subalgebra;
    \item if $J$ is a $\ast$-closed ideal, then we say $J$ is a $\ast$-ideal.
  \end{itemize}
\end{definition}
There are a variety of important, named elements in any $\ast$-algebra. Most of these elements inherit their name from the fact that they are abstractions of elements of spaces of bounded linear operators (see \ref{def:distinguished_operators}). However, despite their name and origins, the definitions are purely algebraic in nature, so we include them here.
\begin{definition}
  Let $A$ be a $\ast$-algebra.
  \begin{itemize}
    \item We say $e\in A$ is an idempotent if $e^2 = e$.
    \item We say $x\in A$ is invertible if there exists a unique $y\in A$ such that $xy = yx = 1_A$. We write
      \begin{align*}
        \text{GL}\left(A\right) &\coloneq \set{a\in A | a\text{ is invertible}}
      \end{align*}
      for the group of invertible elements in $A$.
    \item An element $x\in A$ is called Hermitian (or self-adjoint) if $x = x^{\ast}$. We write
      \begin{align*}
        A_{\sa} &\coloneq \set{x\in A | x = x^{\ast}}
      \end{align*}
      for the set of self-adjoint elements in $A$.
    \item An element $a\in A$ is called positive if there exists $b\in A$ such that $a = b^{\ast}b$. We write
      \begin{align*}
        A_{+} &\coloneq \set{a\in A | a\text{ is positive}}
      \end{align*}
      for the set of positive elements in $A$.
    \item An element $p\in P$ is called a projection if it is self-adjoint and idempotent. We write
      \begin{align*}
        \mathcal{P}\left(A\right) &\coloneq \set{p\in A | p = p^{\ast} = p^2}
      \end{align*}
      for the set of projections in $A$.
    \item If $A$ is unital, then an element $u\in A$ is called unitary if $u^{\ast}u = uu^{\ast} = 1_A$. We write
      \begin{align*}
        \mathcal{U}\left(A\right) &= \set{u\in A | u^{\ast}u = uu^{\ast} = 1_A}
      \end{align*}
      for the set of unitary elements in $A$.
    \item An element $z\in A$ is called normal if $z^{\ast}z = zz^{\ast}$. We write $\operatorname{Nor}\left(A\right)$ for the set of normal elements in $A$.
  \end{itemize}
\end{definition}
\begin{fact}
  The following inclusions hold:
  \begin{align*}
    \mathcal{P}\left(A\right) \subseteq A_{+} \subseteq A_{\sa}\subseteq \operatorname{Nor}\left(A\right),
  \end{align*}
  and
  \begin{align*}
    \mathcal{U}\left(A\right)\subseteq \operatorname{Nor}\left(A\right).
  \end{align*}
  Furthermore, $\Span\left(A_{\sa}\right) = A$, where the self-adjoint elements
  \begin{align*}
    h &= \frac{1}{2}\left(x + x^{\ast}\right)\\
    k &= \frac{i}{2}\left(x^{\ast}-x\right)
  \end{align*}
  form the Cartesian decomposition $x = h + ik$.
\end{fact}
\subsection{Algebra Homomorphisms}%
Just as there are group homomorphisms, ring homomorphisms, and linear maps, there are also algebra homomorphisms.
\begin{definition}
  Let $A$ and $B$ be algebras over $\C$.
  \begin{enumerate}[(1)]
    \item An \textit{algebra homomorphism} between $A$ and $B$ is a linear map $\varphi\colon A\rightarrow B$ that is also a ring homomorphism --- i.e., $\varphi\left(ab\right) = \varphi\left(a\right)\varphi\left(b\right)$.
    \item If $\varphi$ is an algebra homomorphism that is also bijective, then $\varphi$ is called an \textit{algebra isomorphism}. An \textit{automorphism} is an algebra isomorphism $\alpha\colon A\rightarrow A$. We write
      \begin{align*}
        \operatorname{Aut}\left(A\right) &\coloneq \set{\alpha | \alpha\colon A\rightarrow A\text{ is an automorphism}}.
      \end{align*}
    \item A \textit{character} on $A$ is a nonzero homomorphism $h\colon A\rightarrow \C$. We write
      \begin{align*}
        \Omega\left(A\right) &\coloneq \set{h | h\colon A\rightarrow \C\text{ is a character}}
      \end{align*}
      to denote the character space of $A$.
    \item If $A$ and $B$ are $\ast$-algebras, then an algebra homomorphism $\varphi\colon A\rightarrow B$ that satisfies $\varphi\left(a^{\ast}\right) = \varphi\left(a\right)^{\ast}$ (known as $\ast$-preserving) is known as a \textit{$\ast$-homomorphism}.
    \item If $\varphi$ is a bijective $\ast$-homomorphism, then we say $\varphi$ is a \textit{$\ast$-isomorphism}.
    \item If $A$ and $B$ are $\ast$-algebras, a linear map $\phi\colon A\rightarrow B$ is said to be \textit{positive} if $\phi\left(A_{+}\right)\subseteq B_{+}$. A positive linear map $\phi\colon A\rightarrow B$ between $\ast$-algebras is called \textit{faithful} if $\ker\left(\phi\right)\cap A_{+} = \set{0}$ --- i.e., $\phi$ is faithful if it is injective on the positive elements.
  \end{enumerate}
\end{definition}
One of the benefits of working with $\ast$-algebras (as opposed to algebraic objects with less structure) is that, even if our $\ast$-algebras aren't unital, we can extend them to contain units, and specifically in an ``essential'' manner. We formalize this below.
\begin{definition}
  Let $A$ be an algebra. An ideal $I\subseteq A$ is said to be \textit{essential} if, for any other ideal $J\subseteq A$, $J\cap I \neq \set{0}$.
\end{definition}
In other words, essential ideals are ``big'' in the ideal structure of an algebra.
\begin{theorem}[Existence of a Unitization]
  Let $A$ be a nonunital ($\ast$-) algebra. Then, there exists a unital algebra $\widetilde{A}$ and an injection $\iota\colon A\hookrightarrow \widetilde{A}$ such that $\iota(A)\subseteq \widetilde{A}$ is an essential ideal.\newline

  Furthermore, if $\varphi\colon A\rightarrow B$ is a ($\ast$-) homomorphism between ($\ast$-) algebras, then $\varphi$ extends to a unital ($\ast$-) homomorphism $\widetilde{\varphi}\colon \widetilde{A}\rightarrow \widetilde{B}$. If $B$ is unital, then there exists a unital ($\ast$-) homomorphism $\overline{\varphi}\colon \widetilde{A}\rightarrow B$ that extends $\varphi$.\newline

  Similarly, if $h\colon A\rightarrow \Omega$ is a character, then $h$ extends to a character $\widetilde{h}\colon \widetilde{A}\rightarrow \C$ on $\widetilde{A}$ that extends $h$.
\end{theorem}
