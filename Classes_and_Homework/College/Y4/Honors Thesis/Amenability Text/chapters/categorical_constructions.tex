In this book, we cover certain structures --- like the free group, free $\ast$-algebra, tensor product, etc. --- that are usually not covered in the undergraduate algebra or analysis curriculum in depth. We discuss these ``free'' constructions\footnote{Hence the name of this chapter.} here, with the general theme that these constructions allow us to, in a ``universal'' manner, convert one type of map (a set-map or a bilinear map) into another type of map (a group homomorphism or a linear map).
\section{Free Groups}%
Given a set $A$, we want to know how exactly we can create a group structure from the elements in $A$ such that they extend from $A$ to a group generated by $A$ in a particularly ``natural'' way. This will be the free group.
\begin{definition}\label{def:generating_sets}
  Let $G$ be a group, and $S\subseteq G$ be a subset. We define the subgroup \textit{generated by} $S$ to be
  \begin{align*}
    \left\langle S \right\rangle_{G} &= \bigcap \set{H | S\subseteq H,~H\text{ a subgroup}}.
  \end{align*}
  We say $S$ generates $G$ if $\left\langle S \right\rangle_{G} = G$.\newline

  We say $\left\langle S \right\rangle_{G}$ is \textit{finitely generated} if $\Card(S) < \infty$.\newline

  If $S$ is such that, for any $x\in S$, we have $x^{-1}\in S$, then we say $S$ is \textit{symmetric}.
\end{definition}
\begin{fact}
  If $S = \set{s_1,\dots,s_n}\subseteq G$, then the picture of $\left\langle S \right\rangle$ is as follows:
  \begin{align*}
    \left\langle S \right\rangle_{G} &= \set{s_1^{a_1}s_2^{a_2}\cdots s_n^{a_n} | n\in\N,~s_1,\dots,s_n\in S,~a_1,\dots,a_n\in \set{-1,1}}.
  \end{align*}
\end{fact}
To construct a free group, we begin by stating its universal property --- that is, its innate nature as an ``extension'' of a set-function into a group structure. Then, we will show that a more constructive definition of the free group satisfies this universal property. The following section draws heavily from \cite{loh_geometric_group_theory}, but we will mostly focus on the construction of the free group rather than the proof of uniqueness.
\begin{definition}\label{def:free_group}
  Let $S$ be a set. A group $F$ containing $S$ is said to be \textit{freely generated} if, for every group $G$, and every map $\phi\colon S\rightarrow G$, there is a unique group homomorphism $\varphi\colon F\rightarrow G$ that extends $\varphi$. The following diagram, where $\iota$ denotes the inclusion of $S$ into $F$, commutes:
    \begin{center}
      \begin{tikzcd}
        S \arrow[d, "\iota"', hook] \arrow[r, "\phi"] & G \\
        F \arrow[ru, "\varphi"']                      &  
      \end{tikzcd}
    \end{center}
  We say $F$ is the \textit{free group} generated by $S$.
\end{definition}
Intuitively, to construct the free group, if we have $a\mapsto \phi(a)$ between $S$ and $G$, then we will define $\varphi\left(a^n\right) = \phi(a)^n$ inside $F(S)$. Uniqueness will follow from the fact that we can take two groups that satisfy the universal property, $F$ and $F'$, and apply the universal property on set-valued functions between $S$ and $F$ and $S$ and $F'$ respectively. 
\begin{theorem}\label{thm:free_group_existence}
  If $S$ is some set, then there is some freely generated group $F(S)$ that satisfies \ref{def:free_group}.
\end{theorem}
\begin{proof}
  We will construct a group consisting of ``words'' made up of elements of $S$ and their inverses. This starts by considering the alphabet $A = S\cup \widehat{S}$, where $\widehat{S}$ is a disjoint copy of $S$ --- every $\hat{s}\in \widehat{S}$ will play the role of an inverse to $s$ in our group.
  \begin{itemize}
    \item Define $A^{\ast}$ to be the set of all words over the alphabet $A$, including the empty word, $\epsilon$. We define the operation $A^{\ast}\times A^{\ast}\rightarrow A^{\ast}$ by concatenating words, which is an associative operation with neutral element $\epsilon$.
    \item Define the equivalence relation $\sim$ generated by the following two relations, where for all $x,y\in A^{\ast}$ and $s\in S$, we have
      \begin{align*}
        xs\hat{s}y &\sim xy\\
        x\hat{s}sy &\sim xy.
      \end{align*}
      The equivalence classes with respect to $\sim$ will be denoted $\left[\cdot\right]$.\newline

      We have a well-defined composition $\left[x\right]\left[y\right] = \left[xy\right]$ mapping $F(S) \times F(S) \rightarrow F(S)$ for all $x,y\in A^{\ast}$.
  \end{itemize}
  We show that $F(S)$ with the concatenation operation is a group. Here, we see that $\left[\epsilon\right]$ is the neutral element for the composition, and associativity is inherited from associativity of concatenation in $A^{\ast}$. To show the existence of inverses, we define the inverse map inductively by taking $I\left(\epsilon\right) = \epsilon$, and
  \begin{align*}
    I\left(sx\right) &= I(x)\hat{s}\\
    I\left(\hat{s}x\right) &= I(x)s
  \end{align*}
  for all $x\in A^{\ast}$  and $s\in S$. Inductively, we can see that $I\left(I\left(x\right)\right) = x$ and
  \begin{align*}
    \left[I(x)\right]\left[x\right] &= \left[I(x)x\right]\\
                                    &= \left[\epsilon\right]\\
    \left[x\right]\left[I(x)\right] &= \left[xI(x)\right]\\
                                    &= \left[\epsilon\right].
  \end{align*}
  Thus, $F(S)$ is a group.\newline

  Now, we show $F(S)$ is freely generated. Let $i\colon S\rightarrow F(S)$ be the map that sends $s\mapsto \left[s\right]$. By our construction, we know that $i(S)\subseteq F(S)$ is a generating set for $F(S)$. We will show the universal property holds for $F(S)$.\newline

  To start, let $\phi\colon S\rightarrow G$ be a set-valued map between $S$ and an arbitrary group $G$. We construct $\phi^{\ast}\colon A^{\ast}\rightarrow G$ by taking
  \begin{align*}
    \epsilon &\mapsto e\\
    sx &\mapsto \phi(s)\phi^{\ast}\left(x\right)\\
    \hat{s}x &\mapsto \left(\phi(s)\right)^{-1}\phi^{\ast}\left(x\right)
  \end{align*}
  for all $x\in A^{\ast}$ and $s\in S$. This definition of $\phi^{\ast}$ is compatible with the equivalence relation on $A^{\ast}$, and we see that $\phi^{\ast}\left(xy\right) = \phi^{\ast}\left(x\right)\phi^{\ast}\left(y\right)$. Thus, we get a well-defined map $\varphi\colon F(S)\rightarrow G$, taking $\left[x\right]\mapsto \left[\phi^{\ast}\left(x\right)\right]$.\newline

  It remains to be shown that the map $i\colon S\rightarrow F(S)$ is injective, which will show that $F(S)$ is freely generated by $S$. Let $s_1,s_2\in S$, and consider the set-function $\phi\colon S\rightarrow \Z$ given by $\phi\left(s_1\right) = 1$ and $\phi\left(s_2\right) = -1$. Then, we must have
  \begin{align*}
    \varphi\left(i\left(s_1\right)\right) &= \phi\left(s_1\right)\\
                                          &= 1\\
                                          &\neq -1\\
                                          &= \phi\left(s_2\right)\\
                                          &= \varphi\left(i\left(s_2\right)\right).
  \end{align*}
  Thus, we have $i\left(s_1\right)\neq i\left(s_2\right)$, so $i$ is injective.
\end{proof}
Most of the definitions of the free group automatically default to the characterization of $F(S)$ as the set of reduced words in $S\cup S^{-1}$. This is the characterization we will be using in the future, but it is still important to understand where exactly the ``free'' in free group comes from, and how it relates to the particular universal property that actually characterizes $F(S)$ uniquely up to isomorphism.
\section{Free Vector Spaces}%
Given a set $A$, just as we are able to construct a free group, $F(A)$, we can take any set $A$ and construct a ``universal'' vector space out of the set.\newline

The free vector space (as it is known) is the universal object that extends any set-valued function into a linear map, treating elements of the set as its basis (Definition \ref{def:basis}). We are interested in the case of the free vector space over the complex numbers, but note that the following definition of the free vector space applies over any field. 
\begin{theorem}\label{thm:free_vector_space}
  Let $\Gamma$ be a nonempty set. There is a vector space, $\C\left[\Gamma\right]$, with $\Dim\left(\C\left[\Gamma\right]\right) = \Card\left(\Gamma\right)$, and an injective map $\delta\colon \Gamma\rightarrow \C\left[\Gamma\right]$ such that the following universal property holds: if $V$ is a $\C$-vector space, and $\phi\colon \Gamma\rightarrow V$ is a set-valued function, then there is a unique linear map $T_{\phi}\colon \C\left[\Gamma\right]\rightarrow V$ such that $T_{\phi}\circ \delta = \phi$.
  \begin{center}
    % https://tikzcd.yichuanshen.de/#N4Igdg9gJgpgziAXAbVABwnAlgFyxMJZABgBpiBdUkANwEMAbAVxiRAB12BxOgW17ogAvqXSZc+QigCM5KrUYs2nAMLJOPfnQrDRIDNjwEis6fPrNWiEADVh8mFADm8IqABmAJwi8kZEDgQSLIKlsrssAw4giIe3r6IIYFIAEzUDHQARjAMAAriRlIgDDDuOCDUFkrWACoA+sCcaAAWWEK6cT5+1MmIacVZOfmGkmyeWE7N5ZWKVhzsLVj2QkA
\begin{tikzcd}
\Gamma \arrow[r, "\delta"] \arrow[rd, "\phi"'] & {\C[\Gamma]} \arrow[d, "T_{\phi}"] \\
                                               & V                                 
\end{tikzcd}
  \end{center}
\end{theorem}
\begin{proof}
  Consider the linear subspace of finitely supported functions, $\C\left[\Gamma\right]\subseteq \mathcal{F}\left(\Gamma,\C\right)$. For each $t\in \Gamma$, we define
  \begin{align*}
    \delta_t\left(s\right) &= \begin{cases}
      1 & s=t\\
      0 & \text{else}
    \end{cases}.
  \end{align*}
    We see that $\delta_t\neq \delta_s$ whenever $s\neq t$, meaning that the map $\delta\colon \Gamma\rightarrow \C\left[\Gamma\right]$, defined by $s \mapsto \delta_s$, is injective.\newline

    We will show that $\set{\delta_s}_{s\in \Gamma}$ is a linear basis for $\C\left[\Gamma\right]$. If $f\in \C\left[\Gamma\right]$, with $\supp\left(f\right) = \set{s_1,\dots,s_n}\subseteq \Gamma$, we set $\alpha_j = f\left(t_j\right)$, and see that
    \begin{align*}
      f &= \sum_{j=1}^{n}\alpha_j\delta_{s_j},
    \end{align*}
    which shows that $\set{\delta_s}_{s\in\Gamma}$ is a spanning set.\newline

    To show that $\set{\delta_s}_{s\in\Gamma}$ is linearly independent, consider $g = \sum_{j=1}^{n}\alpha_j\delta_{s_j}\in \C\left[\Gamma\right]$ such that $g = 0$. Then, $g(t) = 0$ for all $t\in\Gamma$, and in particular, $g\left(s_i\right) = 0$ for every $1 \leq i \leq n$. Thus, we have
    \begin{align*}
      0 &= g\left(s_j\right)\\
        &= \sum_{j=1}^{n}\alpha_j\delta_{s_j}\left(s_i\right)\\
        &= \alpha_i,
    \end{align*}
    so $\alpha_j = 0$ for each $j$. Thus, $\set{\delta_s}_{s\in \Gamma}$ is linearly independent.\newline

    Turning to the universal property, we define $T_{\phi}\colon \C\left[\Gamma\right]\rightarrow V$ in terms of $\phi$ as follows:
    \begin{align*}
      T_{\phi}\left(\sum_{j=1}^{n}\alpha_j\delta_{s_j}\right) &= \sum_{j=1}^{n}\alpha_j\phi\left(s_j\right).
    \end{align*}
    This yields an expression of $T_{\phi}$ uniquely in terms of $\phi$ and $\delta$.
\end{proof}
\begin{example}
  Let $z$ be an abstract variable, and consider the set of ``formal powers'' of $z$, $\set{z^k}_{k\in\N}$. Then, the free vector space generated by this set, $\C\left[z\right]$, is the set of all polynomials with coefficients in $\C$. By the universal property, we know that every polynomial $p\in \C\left[z\right]$ has a unique expression $p = \sum_{j=0}^{n}a_jz^j$.
\end{example}
One of the primary uses of the free vector space is that, via this construction, we can show that vector spaces are particularly nice algebraic objects. We often use these properties implicitly in linear algebra.
\begin{theorem}\label{thm:injective_projective_objects}
  Let $X$, $Y$, and $Z$ be vector spaces.
  \begin{enumerate}[(a)]
    \item If $\iota\colon Y\hookrightarrow X$ is an injective linear map, and $\varphi\colon Y\rightarrow Z$ is a linear map, then there is a (not necessarily unique) map $T\colon X\rightarrow Y$ such that $T\circ\iota = \varphi$.
      \begin{center}
        % https://tikzcd.yichuanshen.de/#N4Igdg9gJgpgziAXAbVABwnAlgFyxMJZABgBpiBdUkANwEMAbAVxiRGJAF9T1Nd9CKAIzkqtRizYBNLjxAZseAkRFCx9Zq0QgAWrN6KBRAEyjqGydoAaXMTCgBzeEVAAzAE4QAtkhEgcEEgAzOYSWiAAOhH4OHQg1LFYDGwAFhAQANb6IB7evgmBiKYgDHQARjAMAAp8SoIg7lgOKTjx4ppsUfTuaClY2bk+iCH+hcWlFdW1RtoMMK6toR3aACoDnkNko76cFJxAA
\begin{tikzcd}
0 \arrow[r] & Y \arrow[r, "\iota", hook] \arrow[d, "\varphi"'] & X \arrow[ld, "T"] \\
            & Z                                                &                  
\end{tikzcd}
      \end{center}
This shows that vector spaces are injective objects --- any linear map factors through an injective map.
    \item If $\pi\colon X\rightarrow Z$ is a surjective linear map, and $\varphi\colon Y\rightarrow Z$ is a linear map, then there is a (not necessarily unique) map $\delta\colon Y\rightarrow X$ such that $\pi\circ\delta = \varphi$.
      \begin{center}
        % https://tikzcd.yichuanshen.de/#N4Igdg9gJgpgziAXAbVABwnAlgFyxMJZARgBoAGAXVJADcBDAGwFcYkQBNEAX1PU1z5CKMsWp0mrdgC0efEBmx4CRcqTE0GLNohAANOfyVCiAJnXitU3eR7iYUAObwioAGYAnCAFskakDgQSOYgjPQARjCMAAoCysIgHliOABY4IJqSOiAAOjmwjDj0hiCePsE0gUhkoRFRscYqukmp6Zna7HloWCVlvoj+VYg1Vtl5DB5oKT00YZExcSa6jDBu6bzuXv01QwDM3JTcQA
        \begin{tikzcd}
                            & Y \arrow[ld, "\delta"'] \arrow[d, "\varphi"] &   \\
        X \arrow[r, "\pi"'] & Z \arrow[r]                                  & 0
        \end{tikzcd}
      \end{center}
      This shows that vector spaces are projective objects --- any linear map factors through a surjective map.
  \end{enumerate}
\end{theorem}
\begin{proof}\hfill
  \begin{enumerate}[(a)]
    \item Let $\mathcal{A}$ be a basis for $Y$. Then, since $\iota$ is an injective linear map, the set $\mathcal{B}_0 = \set{\iota(y) | y\in \mathcal{A}}$ can be extended to a basis $\mathcal{B}$ for $X$.\newline

      We set $t\colon \mathcal{B}\rightarrow Z$ to be
      \begin{align*}
        t\left(x\right) &= \begin{cases}
          \varphi(x) & x\in \mathcal{B}_0\\
          0 & x\in \mathcal{B}\setminus \mathcal{B}_0
        \end{cases}.
      \end{align*}
      By the universal property of the free vector space, this extends to a linear map $T\colon X\rightarrow Y$. Since $T\circ\iota$ agrees with $\varphi$ on $\mathcal{A}$, the universal property of the free vector space states that $T\circ\iota$ agrees with $\varphi$ on all of $Y$.
    \item Let $\set{y_i}_{i\in I}$ be a basis for $Y$. We define $d\left( y_i \right) = x_i\in  \pi^{-1}\circ \varphi\left( y_i \right)$ for each $i\in I$, where $x_i\in \pi^{-1}\circ \varphi\left( y_i \right)$ is some representative.  By the universal property of the free vector space, this extends to a unique linear map $\delta\colon Y\rightarrow X$ that agrees on the basis of $Y$.
  \end{enumerate}
\end{proof}

\section{Free Algebras}%
Later chapters of this thesis will require understanding results from the theory of operator algebras and algebras more generally. Here, we establish a purely algebraic understanding of a free construction, similar to the free vector space and free group. Just as there are free groups and free vector spaces, we can also talk about free algebras. In Chapter \ref{ch:nuclearity}, we will construct special norms on free algebras to elucidate properties of the underlying group.\newline

Similar to a free group, the free algebra (or free $\ast$-algebra) is constructed by taking a certain collection of ``words'' over a set of symbols, and then, if desired, ``modding out'' by the ideal generated by a set of relations. We formalize this in steps.
\begin{definition}\label{def:free_algebra}
  Let $E=\set{x_i}_{i\in I}$ be a collection of symbols that may not commute. The space of all polynomials over $E$ is the free vector space over the set of words formed by symbols in $E$,
  \begin{align*}
    \Gamma_E &= \set{x_{i_1}x_{i_2}\cdots x_{i_n} | n\in\N,i_1,\dots,i_n\in I}.
  \end{align*}
  We denote this space $\C \left\langle E \right\rangle$.\newline

  In the free vector space $\C \left\langle E \right\rangle$, we may define multiplication by concatenation:
  \begin{align*}
    \left(x_{i_1}x_{i_2}\cdots x_{i_n}\right)\left(x_{j_1}x_{j_2}\cdots x_{j_m}\right) &= x_{i_1}x_{i_2}\cdots x_{i_n}x_{j_1}x_{j_2}\cdots x_{j_m},
  \end{align*}
  where $i_1,\dots,i_n,j_1,\dots,j_m\in I$. The space $\C\left\langle E \right\rangle$, equipped with multiplication by concatenation, is known as the \textit{free algebra} on $E$.\newline

  To turn $\C\left\langle E \right\rangle$ into a $\ast$-algebra, we define the formal set $E^{\ast} = \set{x_{i}^{\ast}}_{i\in I}$, and define the involution on $\C\left\langle E\cup E^{\ast} \right\rangle$ by taking
  \begin{align*}
    \left(\alpha x_{i_1}^{\ve_1}x_{i_2}^{\ve_2}\cdots x_{i_n}^{\ve_n}\right)^{\ast} &= \overline{\alpha}x_{i_n}^{\delta_n}x_{i_{n-1}}^{\delta_{n-1}}\cdots x_{i_2}^{\delta_2}x_{i_1}^{\delta_1},
  \end{align*}
  where
  \begin{align*}
    \delta_j &= \begin{cases}
      \ast & \ve_j = 1\\
      1 & \ve_j = \ast
    \end{cases}.
  \end{align*}
  The set $\C\left\langle E\cup E^{\ast} \right\rangle$ with the involution defined above is known as the \textit{free $\ast$-algebra} on $E$, and is usually denoted $\mathbb{A}^{\ast}\left(E\right)$.\newline

  If $R\subseteq \mathbb{A}^{\ast}\left(E\right)$ is a collection of relations, we let $I(R) = \operatorname{ideal}\left(R\right)$. Then, the quotient algebra
  \begin{align*}
    \mathbb{A}^{\ast}\left(E|R\right) &= \mathbb{A}^{\ast}\left(E\right)/I(R)
  \end{align*}
  is known as the \textit{universal $\ast$-algebra on $E$ with relations $R$}.
\end{definition}
Evident from the name, the universal $\ast$-algebra(s) admit universal properties that characterize them as unique.
\begin{theorem}[Universal Properties]\label{thm:universal_property_free_algebra}
  Let $E = \set{x_i}_{i\in I}$ be a set of abstract symbols, and let $B$ be a $\ast$-algebra. Let $\phi\colon E\rightarrow B$ be an injective map, and define $b_i = \phi\left(x_i\right)$.
  \begin{itemize}
    \item There is a unique $\ast$-homomorphism $\varphi\colon \mathbb{A}^{\ast}\left(E\right) \rightarrow B$ such that $x_i \mapsto b_i$. The following diagram commutes.
      \begin{center}
        % https://tikzcd.yichuanshen.de/#N4Igdg9gJgpgziAXAbVABwnAlgFyxMJZABgBpiBdUkANwEMAbAVxiRAFEQBfU9TXfIRQBGclVqMWbAELdeIDNjwEiZYePrNWiEAB1dAWzo4AFgCMzwAIJcAFOwCU3cTCgBzeEVAAzAE4QDJDIQHAgkUQktNn00Eyw5H39AxGDQpAAmagY6MxgGAAV+ZSEQXyw3ExwQak0pHX18HDoEkD8AjOo0xAjs3IKiwTYyiqqayW09XXpfWPiuCi4gA
        \begin{tikzcd}
        E \arrow[r, "\phi"] \arrow[d, "\iota"'] & B \\
        \mathbb{A}^{\ast}(E) \arrow[ru, "\varphi"']    &  
        \end{tikzcd}
      \end{center}
    \item If $R\subseteq \mathbb{A}^{\ast}\left(E\right)$ is a set of relations, and $\set{b_i}_{i\in I}$ satisfies the relations $R$, then there is a unique $\ast$-homomorphism $\mathbb{A}^{\ast}\left(E|R\right) \rightarrow B$ such that $x_i + I(R) \mapsto b_i$. The following diagram commutes.
      \begin{center}
        % https://tikzcd.yichuanshen.de/#N4Igdg9gJgpgziAXAbVABwnAlgFyxMJZABgBpiBdUkANwEMAbAVxiRAFEQBfU9TXfIRQBGclVqMWbAELdeIDNjwEiZYePrNWiEAB1dAWzo4AFgCMzwAIJcAesH104OLgAp2AHwBKASm7iYKABzeCJQADMAJwgDJDIQHAgkUQktNn00Eyw5COjYxHjEpAAmagY6MxgGAAV+ZSEQSKwgkxwQak0pHX18HDockCiYkuoixBTyypq6wTYmlraOyW09XXpIzOyuCi4gA
\begin{tikzcd}
E \arrow[r, "\phi"] \arrow[d, "\iota"']       & B \\
\mathbb{A}^{\ast}(E|R) \arrow[ru, "\varphi"'] &  
\end{tikzcd}
      \end{center}
  \end{itemize}
\end{theorem}
One of the most important $\ast$-algebras we will study is generated from a group by taking the free vector space over the group.
\begin{definition}\label{def:group_star_algebra}
  Let $\Gamma$ be a group with identity element $e$, and let $\C\left[\Gamma\right]$ be the free vector space generated by $\Gamma$. We define a multiplication $f \ast g$, where $f,g\in \C\left[\Gamma\right]$ are finitely supported functions, by convolution:
  \begin{align*}
    f\ast g(s) &= \sum_{t\in\Gamma}f(t)g\left(t^{-1}s\right)\\
               &= \sum_{r\in\Gamma}f\left(sr^{-1}\right)g\left(r\right).
  \end{align*}
  The involution on $\C\left[\Gamma\right]$ is defined by $f^{\ast}\left(t\right) = \overline{f\left(t^{-1}\right)}$. The multiplicative identity is $\delta_e$, and multiplication satisfies $\delta_s\ast \delta_t = \delta_{st}$. Furthermore, this gives $\delta_{s}^{\ast} = \delta_{s^{-1}}$.\newline

  This is known as the \textit{group $\ast$-algebra}.
\end{definition}
\begin{remark}
  In Chapter \ref{ch:nuclearity}, we will endow the group $\ast$-algebra with special norms to create the group $C^{\ast}$-algebra(s).
\end{remark}
\section{Tensor Products}%
Given two vector spaces $V,W$, and a bilinear map $b\colon V\times W \rightarrow Z$ (for some vector space $Z$), it's tempting to use the property of the free vector space to find a linear map on some structure that incorporates both $V$ and $W$ and stays faithful to the bilinear map $b$. Indeed, this is what the tensor product of the vector spaces $V$ and $W$ is --- a universal construction that ``turns'' bilinear maps into linear maps.\newline

In this section, we detail the construction of the tensor product $V\otimes W$, and apply it to the specific case when $V$ and $W$ are Banach spaces (see definition \ref{def:norms}) to obtain certain norms on the tensor product that ``play nicely'' with the norms on $V$ and $W$.
\subsection{Algebraic Fundamentals}%
\begin{definition}\label{def:bilinear_map}
  Let $V,W,Z$ be vector spaces, and let $b\colon V\times W\rightarrow Z$ be a map such that, for all $\alpha\in \C$, $v,v_1,v_2\in V$, and $w,w_1,w_2\in W$,
  \begin{align*}
    b\left( \alpha v_1 + v_2,w \right) &= \alpha b\left( v_1,w \right) + b\left( v_2,w \right)\\
    b\left( v,\alpha w_1 + w_2 \right) &= b\left( v,w_1 \right) + \alpha b\left( v,w_2 \right).
  \end{align*}
  Then, we say $b$ is \textit{bilinear}. The space of bilinear maps is denoted $\operatorname{Bil}\left( V,W;Z \right)$.
\end{definition}
Just as we defined the free vector space and free group, we define the tensor product through a universal property --- and, just as with the case of the free group, we will focus more on the construction of the tensor product than on showing uniqueness.
\begin{theorem}[Universal Property of Tensor Products]\label{thm:tensor_product_existence}
  Let $V,W,Z$ be vector spaces, and let $b\colon V\times W \rightarrow Z$ be a bilinear map. Then, there exists a vector space, $V\otimes W$ and a linear map $T\colon V\otimes W \rightarrow Z$ such that for any $v\in V$ and $w\in W$, $T\left( v\otimes w \right) = b\left( v,w \right)$. The following diagram, where $\iota\colon V\times W \hookrightarrow V\otimes W$ is defined by $\left( v,w \right)\mapsto v\otimes w$, commutes.
  \begin{center}
      % https://tikzcd.yichuanshen.de/#N4Igdg9gJgpgziAXAbVABwnAlgFyxMJZABgBpiBdUkANwEMAbAVxiRADUAdTvAW3gAEAdRABfUuky58hFAEZyVWoxZsunCH0Ejxk7HgJEFcpfWatEIAFpilMKAHN4RUADMAThF5IyIHBCQAJmoGOgAjGAYABSkDWRB3LAcACxwQajNVSzCxCRAPLx9qfyQFZXM2bnwcOnS-OiwGNkgwVl18z29EMpLEYJBQiOjYmTYGGFc0jJULEAAVW1EgA
    \begin{tikzcd}
    V\times W \arrow[rd, "b"'] \arrow[r, "\iota"] & V\otimes W \arrow[d, "T"] \\
                                                  & Z                        
    \end{tikzcd}
  \end{center}
  The vector space $V\otimes W$ is unique up to linear isomorphism, and is known as the \textit{tensor product} of $V$ and $W$.
\end{theorem}
\begin{proof}
  We focus on showing existence. With $V$ and $W$ as in Theorem \ref{thm:tensor_product_existence}, we consider the free vector space (Theorem \ref{thm:free_vector_space}) on $V\times W$, $\C\left[ V\times W \right]$. Elementary elements of $V\times W$ are of the form $\delta_{(v,w)}$, where
  \begin{align*}
    \delta_{(v,w)} \left( s,t \right) &= \begin{cases}
      1 & v=s,w=t\\
      0 & \text{else}
    \end{cases}.
  \end{align*}
  Intuitively, from the way we have defined the tensor product as a linear map that extends a bilinear map, we would find the following properties of tensors desirable, for any $v,v_1,v_2\in V$, $w,w_1,w_2\in W$, and $\alpha\in \C$
  \begin{align*}
    \left( v_1 + v_2 \right)\otimes w &= v_1\otimes w + v_2\otimes w\label{eq:rel_1}\tag{1}\\
    v\otimes\left( w_1 + w_2 \right) &= v\otimes w_1 + v\otimes w_2\label{eq:rel_2}\tag{2}\\
    \left( \alpha v \right)\otimes w &= \alpha \left( v\otimes w \right)\label{eq:rel_3}\tag{3}\\
    v\otimes \left( \alpha w \right) &= \alpha \left( v\otimes w \right)\label{eq:rel_4}\tag{4}.
  \end{align*}
  With these four desirable properties in mind, we define a certain set of relations on the free vector space that we will ``mod out'' to obtain our desired tensor product. 
  \begin{itemize}
    \item To satisfy \eqref{eq:rel_1}, we define the set $N_1 = \set{\delta_{\left( v_1 + v_2,w \right)} - \delta_{\left( v_1,w \right)} - \delta_{\left( v_2,w \right)} | v_1,v_2\in V,w\in W}$, as this will be equivalent to the statement $\left( v_1 + v_2 \right)\otimes w - v_1\otimes w - v_2\otimes w = 0$.
    \item To satisfy \eqref{eq:rel_2}, we define the set $N_2 = \set{\delta_{\left( v,w_1 + w_2 \right)} - \delta_{\left( v,w_1 \right)} - \delta_{\left( v,w_2 \right)} | v\in V,w_1,w_2\in W}$, as this will be equivalent to the statement $v\otimes \left( w_1 + w_2 \right) - v\otimes w_1 - v\otimes w_2 = 0$.
    \item To satisfy \eqref{eq:rel_3}, we define the set $N_3 = \set{\delta_{\left( \alpha v,w \right)} - \alpha \delta_{\left( v,w \right)} | \alpha\in\C,v\in V,w\in W}$, as this will be equivalent to the statement $\left( \alpha v \right)\otimes w - \alpha \left( v\otimes w \right) = 0$.
    \item To satisfy \eqref{eq:rel_4}, we define the set $N_4 = \set{\delta_{\left(  v,\alpha w \right)} - \alpha \delta_{\left( v,w \right)} | \alpha\in\C,v\in V,w\in W}$, as this will be equivalent to the statement $v\otimes \left( \alpha w \right) - \alpha \left( v\otimes w \right) = 0$.
  \end{itemize}
  We define the ``zero set'' of our tensor product to be
  \begin{align*}
    N &= \Span\left( N_1 \cup N_2\cup N_3\cup N_4 \right),
  \end{align*}
  and consider the quotient space (Definition \ref{def:subspace_quotient_space_direct_sum}) $\C\left[ V\times W \right]/N$. We define
  \begin{align*}
    v\otimes w &\coloneq \delta_{(v,w)} + N.
  \end{align*}
  It can be verified that this definition is faithful to our requirements in \eqref{eq:rel_1}--\eqref{eq:rel_4}. Elements of $V\otimes W$ are of the form $\sum_{i\in I}v_i \otimes w_i$. We call elements of the form $v\otimes w$ \textit{elementary tensors}.\newline

  Define $\iota\colon V\times W \rightarrow V\otimes W$ by $\left( v,w \right) \mapsto v\otimes w$, and set $b = T\circ \iota$.\newline

  We verify that this definition satisfies the universal property of tensor products. We let $v_1,v_2,v\in V$, $w_1,w_2,w\in W$, and $\alpha\in \C$. Then,
  \begin{align*}
    b\left( v_1 + cv_2,w \right) &= T\left( \iota\left( v_1 + cv_2,w \right) \right)\\
                                 &= T\left( \left( v_1 + cv_2 \right)\otimes w \right)\\
                                 &= T\left( v_1\otimes w + c\left( v_2\otimes w \right) \right)\\
                                 &= T\left( v_1\otimes w \right) + cT\left( v_2\otimes w \right)\\
                                 &= b\left( v_1,w \right) + cb\left( v_2,w \right)\\
                                 \\
    b\left( v,w_1 + cw_2 \right) &= T\left( \iota\left( v,w_1 + cw_2 \right) \right)\\
                                 &= T\left( v\otimes \left( w_1 + cw_2 \right) \right)\\
                                 &= T\left( v\otimes w_1 + c\left( v\otimes w_2 \right) \right)\\
                                 &= T\left( v\otimes w_1 \right) + cT\left( v\otimes w_2 \right)\\
                                 &= b\left( v,w_1 \right) + cb\left( v,w_2 \right).
  \end{align*}
  Thus, by the universal property of the free vector space, there is a unique linear map $\tilde{b}\colon \C\left[ V\times W \right]\rightarrow Z$, defined by $\tilde{b}\left( \delta_{(v,w)} \right) = b\left( v,w \right)$.\newline

  Note that $\tilde{b}$ vanishes on $N$, so by the First Isomorphism Theorem there is a unique linear map $T_{b}\colon \C\left[ V\times W \right]/N\rightarrow Z$ that is defined by $T_{b} \circ \pi = \tilde{b}$, where $\pi\colon \C\left[ V\times W \right] \rightarrow \C\left[ V\times W \right]/N$ is the canonical projection.\newline

  Thus, we know that $T = T_{b}$ satisfies the universal property of tensor products.
\end{proof}
\begin{remark}
  Elements of the tensor product $X\otimes Y$ are of the form
  \begin{align*}
    t &= \sum_{k=1}^{n}x_k\otimes y_k,
  \end{align*}
  where $x_k\in X$ and $y_k\in Y$. Elements of the form $x_k\otimes y_k$ are known as \textit{elementary tensors}.\newline

  We note that any such $t$ has a variety of representations as elements of the tensor product.
\end{remark}
In linear algebra, we often use the universal property of tensor products to convert from bilinear maps to linear maps. However, we can also apply tensor products to spaces of linear maps by using the universal property.
\begin{proposition}[{\cite[Proposition E.6.14]{rainone_analysis}}]
  Let $X,Y,V,W$ be $\C$-vector spaces.
  \begin{enumerate}[(1)]
    \item If $T\in \mathcal{L}\left( X,V \right)$ and $S\in \mathcal{L}\left( Y,W \right)$, then there is a unique linear map
      \begin{align*}
        T\bar{\otimes} S \colon X\otimes Y \rightarrow V\otimes W
      \end{align*}
      that satisfies $T\bar{\otimes} S\left( x\otimes y \right) = T\left( x \right)\otimes S\left( y \right)$ for all $x\in X$ and $y\in Y$.
    \item For all $\varphi\in X'$ and $\psi\in Y'$, there is a linear map $\varphi\times\psi \in \left( X\otimes Y \right)'$ such that $\left( \varphi\times\psi \right)\left( x\otimes y \right) = \varphi\left( x \right)\psi\left( y \right)$ for all $x\in X$ and $y\in y$.
  \end{enumerate}
\end{proposition}
\begin{proof}\hfill
  \begin{enumerate}[(1)]
    \item The map $X\times Y \rightarrow V\otimes W$ that sends $\left( x,y \right)\mapsto T\left( x \right)\otimes S\left( y \right)$ is bilinear. Thus, by the universal property of tensor products, there exists a linear map $T \bar{\otimes} S \colon X\otimes Y \rightarrow V\otimes W$.
    \item Similarly, the map $X\times Y \rightarrow \C$ given by $\left( x,y \right)\mapsto \varphi(x)\psi(y)$ is bilinear, so the universal property gives us $\varphi\times\psi\colon X\otimes Y \rightarrow \C$ such that $\left( \varphi\times \psi \right)\left( x\otimes y \right) = \varphi\left( x \right)\psi\left( y \right)$.
  \end{enumerate}
\end{proof}
\begin{remark}
Technically, the map $T\bar{\otimes} S$ is an element of $\mathcal{L}\left( X\otimes Y,V\otimes W \right)$, rather than the vector space $\mathcal{L}\left( X,V \right)\otimes \mathcal{L}\left( Y,W \right)$. The next proposition will show an injection of the latter space into the former.
\end{remark}
\begin{proposition}[{\cite[Proposition E.6.17]{rainone_analysis}}]
  Let $X,Y,V,W$ be $\C$-vector spaces. There is a natural linear embedding
  \begin{align*}
    \iota\colon \mathcal{L}\left( X,V \right)\otimes \mathcal{L}\left( Y,W \right) \hookrightarrow \mathcal{L}\left( X\otimes Y,V\otimes W \right)
  \end{align*}
  such that $\iota\left( T\otimes S \right) = T\bar{\otimes}S$.
\end{proposition}
\begin{proof}
  We see that for any $T,T_1,T_2\in \mathcal{L}\left( X,V \right)$, $S,S_1,S_2\in \mathcal{L} \left( Y,W \right)$, and $\alpha \in \C$, that
  \begin{align*}
    \left( T_1 + \alpha T_2 \right)\bar{\otimes}S &= T_1\bar{\otimes}S + \alpha \left( T_2\bar{\otimes}S \right)\\
    T\bar{\otimes}\left( S_1 + \alpha S_2 \right) &= T\bar{\otimes}S_1 + \alpha \left( T\bar{\otimes}S_2 \right).
  \end{align*}
  Therefore, the map $\mathcal{L}\left( X,V \right)\times \mathcal{L}\left( Y,W \right) \rightarrow \mathcal{L}\left( X\otimes Y,V\otimes W \right)$, sending $\left( T,S \right)\mapsto T\bar{\otimes}S$. Thus, there is a map $\iota\colon \mathcal{L}\left( X,V \right)\otimes \mathcal{L}\left( Y,W \right)\rightarrow \mathcal{L}\left( X\otimes V,Y\otimes W \right)$ such that $\iota\left( T\otimes S \right) = T\bar{\otimes}S$.\newline

  Now, we will show that $\iota$ is injective. Suppose that
  \begin{align*}
    0 &= \iota\left( \sum_{k=1}^{n}T_k\otimes S_k \right)\\
      &= \sum_{k=1}^{n}T_k\bar{\otimes}S_k,
  \end{align*}
  where $T_k,S_k$ are linearly independent. Now, for any $x\in X$ and $y\in Y$, we have
  \begin{align*}
    0 &= \left( \sum_{k=1}^{n}T_k\bar{\otimes}S_k \right)\left( x\otimes y \right)\\
      &= \sum_{k=1}^{n}T_k\left( x \right)\otimes S_k\left( y \right).
  \end{align*}
  Furthermore, for any $\varphi\in V'$ and $\psi\in W'$, we have
  \begin{align*}
    0 &= \left( \varphi\times \psi \right)\left( \sum_{k=1}^{n}T_k\left( x \right)\otimes S_k\left( y \right) \right)\\
      &= \sum_{k=1}^{n}\varphi\left( T_k\left( x \right) \right)\psi\left( S_k\left( y \right) \right)\\
      &= \psi\left( \sum_{k=1}^{n}\varphi\left( T_k\left( x \right) \right)S_k\left( y \right) \right).
  \end{align*}
  Now, since $W'$ separates points, we have that
  \begin{align*}
    0 &= \sum_{k=1}^{n}\varphi\left( T_k\left( x \right) \right)S_k\left( y \right)\\
      &= \left( \sum_{k=1}^{n} T_k\left( x \right)S_k\right)\left( y \right),
  \end{align*}
  meaning $\displaystyle\sum_{k=1}^{n}\varphi\left( T_k\left( x \right) \right)S_k = 0$ in $\mathcal{L}\left( Y,W \right)$. Since we have defined $S_k$ to be linearly independent, we have $\varphi\left( T_k\left( x \right) \right) = 0$ for all $k$, $x\in X$, and $\varphi\in V'$. Since $V'$ separates points, we have $T_k(x) = 0$ for all $k$ and $x\in X$, so $T_k = 0$ for all $k$.\newline

  Thus, 
  \begin{align*}
    \sum_{k=1}^{n}T_k\otimes S_k &= 0,
  \end{align*}
  so $\ker\left( \iota \right) = \set{0}$, and $\iota$ is injective.
\end{proof}
Now that we understand how tensor products play with spaces of linear maps, we may prove some crucial results related to tensor products of algebras. Note that in all of these cases, we use the universal property of tensor products to ensure that our expression is unique.
\begin{proposition}[{\cite[Proposition F.2.24]{rainone_analysis}}]\label{prop:tensor_product_algebras}
  Let $A$ and $B$ be algebras. The vector space $A\otimes B$ admits a multiplication $\left( A\otimes B \right)\times \left( A\otimes B \right)\rightarrow A\otimes B$, given by
  \begin{align*}
    \left( a\otimes b \right)\left( c\otimes d \right) &= ac\otimes bd.
  \end{align*}
  If $A$ and $B$ are unital, then so too is $A\otimes B$. If $A$ and $B$ are $\ast$-algebras, then $A\otimes B$ admits an involution given by
  \begin{align*}
    \left( a\otimes b \right)^{\ast} &= a^{\ast}\otimes b^{\ast}.
  \end{align*}
\end{proposition}
\begin{proof}
  Fixing $a\in A$ and $b\in B$, we define linear maps $L_a\colon A\rightarrow A$ and $L_b\colon B\rightarrow B$  by
  \begin{align*}
    L_a\left( x \right) &= ax\\
    L_b\left( y \right) &= by.
  \end{align*}
  The maps $a\mapsto L_a$ and $b\mapsto L_b$ are linear by the fact that ring multiplication is left-distributive. Therefore, the map $A\times B \rightarrow \mathcal{L}\left( A \right)\otimes \mathcal{L}\left( B \right)$, given by $\left( a,b \right)\mapsto L_a\otimes L_b$ is bilinear.\newline

  By the universal property of tensor products, we have a linear map $L\colon A\otimes B \rightarrow \mathcal{L}\left( A \right)\otimes \mathcal{L}\left( B \right)$, given by $a\otimes b \mapsto L_a\otimes L_b$.\newline

  Now, by above, there is an embedding $\mathcal{L}\left( A \right)\otimes \mathcal{L}\left( B \right) \hookrightarrow \mathcal{L}\left( A\otimes B \right)$, so we may identify elements of $\mathcal{L}\left( A \right)\otimes \mathcal{L}\left( B \right)$ with linear maps on $A\otimes B$.\newline

  We define $\left( A\otimes B \right)\times \left( A\otimes B \right)\rightarrow A\otimes B$ by $\left( t,s \right)\mapsto ts \coloneq L(t)(s)$.\newline

  Since $L$ is linear, and $L(t)$ is linear for all $t\in A\otimes B$, both scalar multiplication and distributivity are preserved.\newline

  For all $a\in A$ and $b\in B$, we have
  \begin{align*}
    \left( a\otimes b \right)\left( c\otimes d \right) &= L\left( a\otimes b \right)\left( c\otimes d \right)\\
                                                       &= L_a\otimes L_b\left( c\otimes d \right)\\
                                                       &= \left( L_a\left( c \right) \right)\otimes \left( L_b\left( d \right) \right)\\
                                                       &= ac\otimes bd.
  \end{align*}
  Since multiplication in $A$ and $B$ is associative, multiplication in $A\otimes B$ is also associative.\newline

  Now, if $A$ and $B$ are unital, then $1_A\otimes 1_B$ is a unit for $A\otimes B$, as
  \begin{align*}
    \left( 1_A\otimes 1_B \right)\left( a\otimes b \right) &= \left( 1_A a \right)\otimes \left( 1_B b \right)\\
                                                           &= a\otimes b.
  \end{align*}
  Now, if $A$ and $B$ are $\ast$-algebras, we write $\overline{A\otimes B}$ to refer to the conjugate space. Regarding the conjugate space, we if $V$ is a vector space, then $\overline{V}$ is defined by
  \begin{align*}
    \overline{v} + \overline{w} &= \overline{v+w}\\
    \alpha\cdot \left( \overline{x} \right) &= \overline{\overline{\alpha}x}.
  \end{align*}
  Thus, if $\overline{A\otimes B}$ is the conjugate space, we can see from the definition of the involution that the map $A\times B \rightarrow \overline{A\otimes B}$, given by $\left( a,b \right)\mapsto \overline{a^{\ast}\otimes b^{\ast}}$ is a bilinear map.\newline

  There is a unique linear map $\psi\colon A\otimes B \rightarrow \overline{A\otimes B}$ such that $\psi\left( a\otimes b \right) = \overline{a^{\ast}\otimes b^{\ast}}$. Additionally, the map $\mu\colon \overline{A\otimes B}\rightarrow A\otimes B$, given by $\mu\left( \overline{t} \right) = t$ is conjugate linear.\newline

  Thus, the map $\nu\colon A\otimes B \rightarrow A\otimes B$, given by $a\otimes b \mapsto a^{\ast}\otimes b^{\ast}$ is conjugate linear, and we may define an involution $A\otimes B \rightarrow A\otimes B$ by $t\mapsto t^{\ast}\coloneq \nu(t)$. We see that
  \begin{align*}
    \left( \left( a\otimes b \right)\left( c\otimes d \right) \right)^{\ast} &= \left( ac\otimes bd \right)^{\ast}\\
                                                                             &= \left( ac \right)^{\ast}\otimes \left( bd \right)^{\ast}\\
                                                                             &= c^{\ast}a^{\ast} \otimes d^{\ast}b^{\ast}\\
                                                                             &= \left( c^{\ast}\otimes d^{\ast} \right)\left( a^{\ast}\otimes b^{\ast} \right)\\
                                                                             &= \left( c\otimes d \right)^{\ast}\left( a\otimes b \right)^{\ast}.
  \end{align*}
  A similar approach gives $t^{\ast\ast} = t$ for all $t\in A\otimes B$, meaning that this is a bona fide involution on $A\otimes B$, universal by definition.
\end{proof}
Now, we turn our attention towards matrix algebras. Recall that if $A$ is an algebra, then the matrix algebra $\Mat_n\left( A \right)$ is the set of $n\times n$ matrices $\left( a_{ij} \right)_{ij}$ such that $a_{ij}\in A$ for each $i,j$. This is also an algebra, but perhaps even more importantly, it is able to be expressed as a tensor product, which is often used in the definition of nuclearity for $C^{\ast}$-algebras. We will discuss more on this in Chapter \ref{ch:nuclearity}.
\begin{theorem}[{\cite[Example E.6.21, Example F.4.11]{rainone_analysis}}]\label{thm:matrix_algebras_tensor_product}
  Let $A$ be a $\ast$-algebra, and let $n\in \N$. Then, there is a $\ast$-isomorphism of $\ast$-algebras, $\varphi\colon \Mat_n\left( A \right)\rightarrow \Mat_n\left( \C \right)\otimes A$, given by
  \begin{align*}
    \varphi\left( \left( a_{ij} \right)_{ij} \right) &= \sum_{i,j=1}^{n}e_{ij}\otimes a_{ij},
  \end{align*}
  where $\set{e_{ij}}_{i,j=1}^{n}$ are the system of matrix units.
\end{theorem}
\begin{proof}
  We start by showing that $\varphi$ is an isomorphism of vector spaces. Note that by the definition of the tensor product, we know that $\varphi$ is a linear map. Now, we start by showing that $\varphi$ is injective. Suppose
  \begin{align*}
    \varphi\left( \left( a_{ij} \right)_{ij} \right) &= \sum_{i,j=1}^{n}e_{ij}a_{ij}\\
                                                     &= 0.
  \end{align*}
  Then, since the system of matrix units is linearly independent in $\Mat_n\left( \C \right)$, we have that $x_{ij} = 0$ for all $i,j$, so $\left( x_{ij} \right)_{ij} = 0$, so $\varphi$ is injective.\newline

  Now, we show that $\varphi$ is surjective. Let $t\in \Mat_n\left( \C \right)\otimes A$ be given by
  \begin{align*}
    t &= \sum_{k=1}^{m}m_k\otimes a_k,
  \end{align*}
  where $m_k\in \Mat_n\left( \C \right)$ and $a_k\in A$. Since every matrix over $\C$ is a linear combination of the matrix units, we write
  \begin{align*}
    m_k &= \sum_{i,j=1}^{n} m_k\left( i,j \right)e_{ij}.
  \end{align*}
  Substituting, we get
  \begin{align*}
    t &= \sum_{k=1}^{m}\left( \sum_{i,j=1}^{n}m_k\left( i,j \right)e_{ij} \right)\otimes a_k\\
      &= \sum_{i,j=1}^{n}e_{ij}\otimes \left( \sum_{k=1}^{m}m_k\left( i,j \right)a_k \right),
      \intertext{and defining $a_{ij}\coloneq \sum_{k=1}^{m}m_k\left( i,j \right)a_k$, we obtain}
      &= \sum_{i,j=1}^{n}e_{ij}\otimes a_{ij}.
  \end{align*}
  Thus, $\varphi\left( \left( a_{ij} \right)_{ij} \right) = t$, and $\varphi$ is surjective, hence a linear isomorphism.\newline

  Now, we show that $\varphi$ is multiplicative and preserves the involution. Let $\left( a_{ij} \right)_{ij},\left( b_{ij} \right)_{ij}\in \Mat_n\left( A \right)$. Then,
  \begin{align*}
    \varphi\left( \left( a_{ik} \right)_{ik} \right)\varphi\left( \left( b_{\ell j} \right)_{\ell j} \right) &= \left( \sum_{i,k=1}^{n}e_{ik}\otimes a_{ik} \right)\left( \sum_{\ell,j=1}^{n}e_{\ell j}\otimes b_{\ell j} \right)\\
                                                                               &= \sum_{i,j,k,\ell=1}^{n}\left( e_{ik}\otimes a_{ik} \right)\left( e_{\ell j}\otimes b_{\ell j} \right)\\
                                                                               &= \sum_{i,j,k,\ell=1}^{n}e_{ik}e_{\ell j}\otimes a_{ik}b_{\ell j}\\
                                                                               &= \sum_{i,j,k=1}^{n}e_{ik}e_{kj}\otimes a_{ik}b_{kj}\\
                                                                               &= \sum_{i,j,k=1}^{n}e_{ij}\otimes a_{ik}b_{kj}\\
                                                                               &= \sum_{i,j=1}^{n}e_{ij}\otimes \left( \sum_{k=1}^{n}a_{ik}b_{kj} \right)\\
                                                                               &= \varphi\left( \left( \sum_{k=1}^{n}a_{ik}b_{kj} \right)_{ij} \right)\\
                                                                               &= \varphi\left( \left( a_{ij} \right)_{ij}\left( b_{ij} \right)_{ij} \right),
  \end{align*}
  meaning $\varphi$ is multiplicative.\newline

  Finally, we have
  \begin{align*}
    \varphi\left( \left( a_{ij} \right)_{ij} \right)^{\ast} &= \left( \sum_{i,j=1}^{n}e_{ij}\otimes a_{ij} \right)^{\ast}\\
                                                            &= \sum_{i,j=1}^{n}\left( e_{ij}\otimes a_{ij} \right)^{\ast}\\
                                                            &= \sum_{i,j=1}^{n}e_{ij}^{\ast}\otimes a_{ij}^{\ast}\\
                                                            &= \sum_{i,j=1}^{n}e_{ji}\otimes a_{ij}^{\ast}\\
                                                            &= \sum_{i,j=1}^{n}e_{ij}\otimes a_{ji}^{\ast}\\
                                                            &= \varphi\left( \left( a_{ji}^{\ast} \right)_{ij} \right)\\
                                                            &= \varphi\left( \left( a_{ij} \right)_{ij}^{\ast} \right),
  \end{align*}
  meaning that $\varphi$ is a $\ast$-isomorphism.
\end{proof}
\subsection{Applying Norms to Tensor Products}%
When our vector spaces are equipped with a norm --- specifically, if they are Banach spaces --- not only does it matter that the tensor product preserves the vector space structure, but also that it preserves the norm structure in a particular manner. This is the domain of the injective and projective norms. The injective and projective norms will become more relevant when we discuss $C^{\ast}$-algebras, nuclearity, and amenability in Chapter \ref{ch:nuclearity}.\newline
 
Before discussing the injective and projective norms, however, we begin by elaborating on the connection between tensor products and linear maps. Recall that a linear map $T\colon X\rightarrow Y$ is called finite rank if $\Dim\left( \Ran\left( T \right) \right) < \infty$.
\begin{definition}
  Let $X$ and $Y$ be vector spaces. For each $\psi \in Y'$ and $x\in X$, we define the rank-one operator
  \begin{align*}
    L_{x,\psi}\left( y \right) &= \psi\left( y \right)x.
  \end{align*}
\end{definition}
\begin{fact}
  The map $T\colon X\times Y'\rightarrow \mathcal{L}\left( Y,X \right)$ that sends $\left( x,\psi \right)\mapsto L_{x,\psi}$ is bilinear.
\end{fact}
\begin{proof}
  We have, for a fixed $\psi\in Y'$ and for all $y\in Y$, $x_1,x_2\in X$, and $\alpha\in\C$,
  \begin{align*}
    T\left( x_1 + \alpha x_2,\psi \right)(y) &= \psi\left( y \right)\left( x_1 + \alpha x_2 \right)\\
                                             &= \psi\left( y \right)x_1 + \alpha \psi\left( y \right)x_2\\
                                             &= T\left( x_1,\psi \right)\left( y \right) + \alpha T\left( x_2,\psi \right)\left( y \right).
  \end{align*}
  Furthermore, for a fixed $x\in X$ and for all $y\in Y$, $\psi_1,\psi_2\in Y'$, and $\alpha\in \C$,
  \begin{align*}
    T\left( x,\psi_1 + \alpha \psi_2 \right)\left( y \right) &= \left( \psi_1 + \alpha \psi_2 \right)\left( y \right)x\\
                                                             &= \psi_1\left( y \right)x + \alpha \psi_2\left( y \right)x\\
                                                             &= T\left( x,\psi_1 \right)\left( y \right) + \alpha T\left( x,\psi_2 \right)\left( y \right).
  \end{align*}
\end{proof}
Note that since $T$ is bilinear, $T$ extends to a linear map $X\otimes Y' \rightarrow \mathcal{L}\left( Y,X \right)$. With a little bit more work, it can be shown that the space of finite-rank operators is linearly isomorphic to $X\otimes Y'$.\newline

Furthermore, for any $\varphi\in X'$ and $\psi\in Y'$, there is a linear functional $\varphi\times \psi\in \left( X\otimes Y \right)'$ such that $\left( \varphi\times \psi \right)\left( x\otimes y \right) = \varphi(x)\varphi(y)$.\newline

With these facts in mind, we desire an extension to the case when $X$ and $Y$ are normed spaces such that continuity and the preservation of operator norms of elements in $X^{\ast}$ and $Y^{\ast}$ are desirable. This is what the injective tensor product will resolve.
\begin{proposition}[{\cite[Proposition 3.5.1]{rainone_analysis}}]
  Let $X$ and $Y$ be normed vector spaces. Given some $t\in X\otimes Y$, we define
  \begin{align*}
    \norm{t}_{\vee} &= \sup_{\substack{\varphi\in B_{X^{\ast}}\\\psi\in B_{Y^{\ast}}}} \left\vert \left( \varphi\times \psi \right)\left( t \right) \right\vert
  \end{align*}
  as the \textit{injective norm} on $X\otimes Y$. The injective norm is cross, in that for all $x\in X$ and $y\in Y$,
  \begin{align*}
    \norm{x\otimes y} &= \norm{x}\norm{y}.
  \end{align*}
\end{proposition}
\begin{proof}
  We start by showing that the supremum is finite. Let
  \begin{align*}
    t &= \sum_{k=1}^{n} x_k\otimes y_k
  \end{align*}
  be any representation of $t\in X\otimes Y$, and let $\varphi\in B_{X^{\ast}}$ and $\psi\in B_{Y^{\ast}}$. Using Corollary \ref{cor:norm_from_functionals}, we have
  \begin{align*}
    \norm{\left( \varphi\times \psi \right)\left( t \right)} &= \left\vert \sum_{k=1}^{n}\varphi\left( x_k \right)\psi\left( y_k \right) \right\vert\\
                                                             &\leq \sum_{k=1}^{n} \left\vert \varphi\left( x_k \right) \right\vert\left\vert \psi\left( y_k \right) \right\vert\\
                                                             &\leq \sum_{k=1}^{n}\norm{x_k}\norm{y_k}.
  \end{align*}
  From the definition of the injective norm, we know that the triangle inequality and homogeneity hold, so we only need to focus on positive definiteness.\newline

  Let $\norm{t}_{\vee} = 0$. We express
  \begin{align*}
    t &= \sum_{k=1}^{n}x_k\otimes y_k,
  \end{align*}
  where we allow for $\set{y_1,\dots,y_n}$ to be linearly independent. For all $\varphi\in B_{X^{\ast}}$ and $\psi\in B_{Y^{\ast}}$, we have
  \begin{align*}
    0 &= \left( \varphi\times \psi \right)\left( t \right)\\
      &= \sum_{k=1}^{n}\varphi\left( x_k \right)\psi\left( y_k \right)\\
      &= \psi\left( \sum_{k=1}^{n}\varphi\left( x_k \right)y_k \right).
  \end{align*}
  Since this holds for all $\psi\in B_{Y^{\ast}}$, the Hahn--Banach separation (Theorem \ref{thm:hb_separation}) holds that
  \begin{align*}
    \sum_{k=1}^{n}\varphi\left( x_k \right)y_k &= 0.
  \end{align*}
  Since $\set{y_1,\dots,y_n}$ are linearly independent, then $\varphi\left( x_k \right) = 0$ for all $k$ and all $\varphi\in B_{X^{\ast}}$, so yet again by Hahn--Banach separation, we have $x_k = 0$ for all $k$, so $t = 0$.\newline

  To prove that the injective norm is cross, we know from Corollary \ref{cor:norm_from_functionals} that
  \begin{align*}
    \norm{z} &= \sup_{\varphi\in B_{Z^{\ast}}}\left\vert \varphi\left( z \right) \right\vert.
  \end{align*}
  Thus, we have
  \begin{align*}
    \norm{x\otimes y}_{\vee} &= \sup_{\substack{\varphi\in B_{X^{\ast}}\\\psi\in B_{Y^{\ast}}}}\left\vert \varphi\left( x \right) \psi\left( y \right)\right\vert\\
                             &= \sup_{\varphi\in B_{X^{\ast}}}\left\vert \varphi\left( x \right) \right\vert\sup_{\psi\in B_{Y^{\ast}}}\left\vert \psi\left( y \right) \right\vert\\
                             &= \norm{x}\norm{y}.
  \end{align*}
\end{proof}
Thus, we know that the injective norm is a valid cross norm. Using Proposition \ref{prop:completion_existence}, we may complete $X\otimes Y$ to yield a Banach space.
\begin{definition}
  If $X$ and $Y$ are normed spaces, the norm completion of $X\otimes Y$ with respect to the injective norm is called the \textit{injective tensor product} of $X$ and $Y$, denoted $X\check\otimes Y$.
\end{definition}
The injective tensor product allows us to realize the tensor product as a space of bounded linear maps, just as we are able to realize the algebraic tensor product as a space of finite-rank linear maps.
\begin{proposition}[{\cite[Proposition 3.5.5]{rainone_analysis}}]
  Let $X$ and $Y$ be normed spaces. There is an isometric embedding $X\check\otimes Y \hookrightarrow \B\left( Y^{\ast},X \right)$.
\end{proposition}
\begin{proof}
  We provide an outline of the proof rather than fill in the full details.\newline

  Start by defining the linear map $\theta_{x,y}\colon Y^{\ast}\rightarrow X$ by $\theta_{x,y}\left( \varphi \right) = \varphi\left( y \right)x$. From the Hahn--Banach theorems, we then know that $\norm{\theta_{x,y}}_{\op} = \norm{x}\norm{y}$.\newline

  After showing that the map $X\times Y \rightarrow \B\left( Y^{\ast},X \right)$ given by $\left( x,y \right)\mapsto \theta_{x,y}$ is bilinear, we use the universal property of the tensor product to find the map $u\colon X\otimes Y \rightarrow \B\left( Y^{\ast},X \right)$, where $x\otimes y \mapsto \theta_{x,y}$.\newline

  Then, it is shown via the definition of the injective tensor product and Corollary \ref{cor:norm_from_functionals} that $\norm{u(t)}_{\op} = \norm{t}$ for all $t\in X\otimes Y$.\newline

  Since $u$ is an isometry (hence uniformly continuous), we may extend it to the completion to yield an isometric embedding $U\colon X\check\otimes Y \hookrightarrow \B\left( Y^{\ast},X \right)$.
\end{proof}
\begin{remark}
  A similar process allows us to show that there is an isometric embedding $X\check\otimes Y \hookrightarrow \B\left( X^{\ast},Y \right)$.
\end{remark}
Contrasted with the injective norm's connection between the tensor product and the space of linear maps $\B\left( Y^{\ast},X \right)$, the projective norm draws upon the connection between linear maps and bilinear maps. First, we need to implement a norm on bilinear maps.
\begin{definition}[{\cite[Definition 3.5.8]{rainone_analysis}}]
  Let $b\colon X\times Y \rightarrow Z$ be a bilinear map on normed vector spaces $X,Y,Z$. Then, we say $b$ is \textit{bounded bilinear} if
  \begin{align*}
    \norm{b}_{\op} &\coloneq \sup_{\substack{x\in B_{X}\\y\in B_{Y}}}\norm{b\left( x,y \right)}
  \end{align*}
  is finite.
\end{definition}
Just as how linear maps between normed spaces are continuous if and only if they are bounded (Fact \ref{fact:continuity_of_linear_maps}), bilinear maps on normed spaces are continuous if and only if they are bounded.\newline

We begin by defining the projective norm and proving its properties before showing the connection between the projective tensor product and the space of bilinear maps.
\begin{proposition}[{\cite[Proposition 3.5.10]{rainone_analysis}}]
  Let $X$ and $Y$ be normed spaces. The \textit{projective norm} on $X\otimes Y$ is defined by
  \begin{align*}
    \norm{t}_{\wedge} &= \inf\set{\sum_{k=1}^{n}\norm{x_k}\norm{y_k} | t = \sum_{k=1}^{n}x_k\otimes y_k}.
  \end{align*}
  The projective norm is a cross norm that satisfies $\norm{t}_{\vee}\leq \norm{t}_{\wedge}$.
\end{proposition}
\begin{proof}
  The norm is homogeneous from the definition of the tensor product.\newline

  Now, if $t,t'\in X\otimes Y$ have representations of $t= \sum_{k=1}^{n}x_k\otimes y_k$ and $t' = \sum_{j=1}^{m}u_j\otimes v_j$, then
  \begin{align*}
    t + t' &= \sum_{k=1}^{n}x_k\otimes y_k + \sum_{j=1}^{m}u_j\otimes v_j,
    \intertext{giving}
    \norm{t + t'}_{\wedge} &\leq \sum_{k=1}^{n}\norm{x_k}\norm{y_k} + \sum_{j=1}^{m}\norm{u_j}\norm{v_j}.
  \end{align*}
  Taking the infimum over all representations of $t$, we have
  \begin{align*}
    \norm{t + t'}_{\wedge} &\leq \norm{t} + \sum_{j=1}^{m}\norm{u_j}\norm{v_j},
  \end{align*}
  and taking the infimum over all representations of $t'$, we get
  \begin{align*}
    \norm{t + t'} &\leq \norm{t} + \norm{t'}.
  \end{align*}
  We show that the projective norm satisfies $\norm{t}_{\vee}\leq \norm{t}_{\wedge}$. Letting $t = \sum_{k=1}^{n}x_k\otimes y_k$, we use Corollary \ref{cor:norm_from_functionals} to obtain
  \begin{align*}
    \norm{t}_{\vee} &= \sup_{\substack{\varphi\in B_{X^{\ast}}\\\psi\in B_{Y^{\ast}}}} \left\vert \sum_{k=1}^{n}\varphi\left( x_k \right)\psi\left( y_k \right) \right\vert\\
                    &\leq \sum_{k=1}^{n}\left\vert \varphi\left( x_k \right) \right\vert\left\vert \psi\left( y_k \right) \right\vert\\
                    &\leq \sum_{k=1}^{n}\norm{x_k}\norm{y_k}.
  \end{align*}
  Taking the infimum over all representations, we then obtain $\norm{t}_{\vee}\leq \norm{t}_{\wedge}$.\newline

  Thus, if $\norm{t}_{\wedge} = 0$, then $\norm{t}_{\vee} = 0$, so $t = 0$ as $\norm{\cdot}_{\vee}$ is a norm.\newline

  Finally, for $x\in X$ and $y\in Y$, we have
  \begin{align*}
    \norm{x}\norm{y} &= \norm{x\otimes y}_{\vee}\\
                     &\leq \norm{x\otimes y}_{\wedge}\\
                     &\leq \norm{x}\norm{y}.
  \end{align*}
\end{proof}
The norm completion of $X\otimes Y$ with respect to the projective norm is known as the \textit{projective tensor product}, and is denoted $X\hat\otimes Y$.\newline

Now, we may draw the connection between the projective tensor product and the space of bounded bilinear maps.
\begin{proposition}[{\cite[Proposition 3.5.13]{rainone_analysis}}]
  Let $X,Y,Z$ be normed spaces.\newline

  If $b\in \operatorname{Bil}\left( X,Y;Z \right)$ is bounded bilinear, then there is a unique $T_{b}\in \B\left( X\hat\otimes Y,Z \right)$ such that $T_b\left( x\otimes y \right)= b\left( x,y \right)$, and that $\norm{T_{b}}_{\op} = \norm{b}_{\op}$.\newline

  Furthermore, the map $b\mapsto T_b$ is a linear isometric isomorphism.
\end{proposition}
\begin{proof}
  Since $b$ is bilinear, there is a unique linear map $T_b\colon X\otimes Y \rightarrow Z$ by the universal property, where $T_b\left( x\otimes y \right) = b\left( x,y \right)$. If we let $t = \sum_{k=1}^{n}x_k\otimes y_k$, then
  \begin{align*}
    \norm{T_b(t)} &= \norm{\sum_{k=1}^{n}b\left( x_k,y_k \right)}\\
                  &\leq \sum_{k=1}^{n}\norm{b\left( x_k,y_k \right)}\\
                  &\leq \sum_{k=1}^{n}\norm{b}_{\op}\norm{x_k}\norm{y_k}.
  \end{align*}
  Taking the infimum of both sides, we get
  \begin{align*}
    \norm{T_b\left( t \right)} &\leq \norm{b}_{\op}\norm{t}_{\wedge},
  \end{align*}
  so
  \begin{align*}
    \norm{T_b}_{\op} &\leq \norm{b}_{\op}.
  \end{align*}
  Similarly, for $x\in B_X$ and $y\in B_Y$, we have $\norm{x\otimes y}_{\wedge}\leq 1$, meaning
  \begin{align*}
    \norm{b\left( x,y \right)} &= \norm{T_b\left( x\otimes y \right)}\\
                               &\leq \norm{T_b}_{\op},
  \end{align*}
  so by taking suprema, we get $\norm{b}_{\op} = \norm{T_b}_{\op}$. Since $X\hat\otimes Y$ is the completion of $X\otimes Y$ with the projective norm, there is a norm-preserving continuous extension to $X\hat\otimes Y$.\newline

  Now, if $T\colon X\otimes Y\rightarrow Z$ is any map, then we may define $b\colon X\times Y \rightarrow Z$ by $b\left( x,y \right) = T\left( x\otimes y \right)$. We have that $b$ is bounded, as
  \begin{align*}
    \norm{b\left( x,y \right)} &= \norm{T\left( x\otimes y \right)}\\
                               &\leq \norm{T}_{\op}\norm{x\otimes y}_{\wedge}\\
                               &= \norm{T}_{\op}\norm{x}\norm{y}.
  \end{align*}
  Now, since $T_b\left( x\otimes y \right) = b\left( x,y \right) = T\left( x\otimes y \right)$, $T$ agrees with $T_b$ on $X\otimes Y$, and both $T$ and $T_b$ are bounded with respect to the projective norm, they must agree on $X\hat\otimes Y$.\newline

  The map $b\mapsto T_b$ is automatically linear by definition, so since $\norm{b}_{\op} = \norm{T_b}_{\op}$, the map $b\mapsto T_b$ is an isometric isomorphism.
\end{proof}
We may also draw connections between the tensor product and spaces of linear maps.
\begin{proposition}[{\cite[Proposition 3.5.14]{rainone_analysis}}]
  Let $X$ and $Y$ be normed spaces. There is an isometric isomorphism such that $\left( X\hat\otimes Y \right)^{\ast} \cong B\left( X,Y^{\ast} \right)$.
\end{proposition}
\begin{proof}
  We provide an outline of the proof of this proposition.\newline

  First, define the map $T\colon \left( X\hat\otimes Y \right)^{\ast}\rightarrow \B\left( X,Y^{\ast} \right)$ by $\psi\mapsto T_{\psi}$, where $T_{\psi}\left( x \right)\left( y \right) = \psi\left( x\otimes y \right)$. Then, $T_{\psi}$ is a linear operator on $Y$ such that $\norm{T_{\psi}(x)}_{\op}\leq \norm{\psi}\norm{x}$, meaning $T_{\psi}\in Y^{\ast}$. Furthermore, we also establish that $T_{\psi}$ is a contraction.\newline

  In the other direction, we establish that a map $\eta\colon \B\left( X,Y^{\ast} \right)\rightarrow \left( X\hat\otimes Y \right)^{\ast}$ is also a bounded linear map that is a contraction with $\eta\left( T_{\psi} \right) = \psi$, meaning $T$ is an isometric isomorphism.
\end{proof}
\section{Remarks}%
We will use all these established foundations in later chapters, both implicitly and explicitly, to understand different properties related to groups, amenability, and results in functional analysis and operator algebras that will relate to groups and amenability.\newline

To provide a preview, we use properties of the free group in Chapter \ref{ch:paradoxical_decompositions} to establish an understanding of when a group is \textit{not} amenable. This helps establish that any group that \textsl{is} amenable does not contain a freely generated subgroup.\newline

Meanwhile, the results on free algebras, the group $\ast$-algebra, and tensor products will be used in Chapter \ref{ch:nuclearity} to understand amenability of groups via their $C^{\ast}$-algebras. We will endow the universal $\ast$-algebra(s) with certain norms that, when completed, will yield $C^{\ast}$-algebras, and we will discuss the connection between nuclearity and the tensor product in Chapter \ref{ch:nuclearity}, though we will not directly prove the theorem in \cite{choi_nuclearity} that displays the equivalence between these two definitions of nuclearity.
