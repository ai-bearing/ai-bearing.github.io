In this book, we cover certain structures --- like the free group, free $\ast$-algebra, tensor product, etc. --- that are usually not covered in the undergraduate algebra or analysis curriculum in depth. We discuss these ``free'' constructions\footnote{Hence the name of this chapter.} here, with the general theme that these constructions allow us to, in a ``universal'' manner, convert one type of map (a set-map or a bilinear map) into another type of map (a group homomorphism or a linear map).
\section{Free Groups}%
Given a set $A$, we want to know how exactly we can create a group structure from the elements in $A$ such that they extend from $A$ to a group generated by $A$ in a particularly ``natural'' way. This will be the free group.
\begin{definition}\label{def:generating_sets}
  Let $G$ be a group, and $S\subseteq G$ be a subset. We define the subgroup \textit{generated by} $S$ to be
  \begin{align*}
    \left\langle S \right\rangle_{G} &= \bigcap \set{H | S\subseteq H,~H\text{ a subgroup}}.
  \end{align*}
  We say $S$ generates $G$ if $\left\langle S \right\rangle_{G} = G$.\newline

  We say $\left\langle S \right\rangle_{G}$ is \textit{finitely generated} if $\Card(S) < \infty$.\newline

  If $S$ is such that, for any $x\in S$, we have $x^{-1}\in S$, then we say $S$ is \textit{symmetric}.
\end{definition}
\begin{fact}
  If $S = \set{s_1,\dots,s_n}\subseteq G$, then the picture of $\left\langle S \right\rangle$ is as follows:
  \begin{align*}
    \left\langle S \right\rangle_{G} &= \set{s_1^{a_1}s_2^{a_2}\cdots s_n^{a_n} | n\in\N,~s_1,\dots,s_n\in S,~a_1,\dots,a_n\in \set{-1,1}}.
  \end{align*}
\end{fact}
To construct a free group, we begin by stating its universal property --- that is, its innate nature as an ``extension'' of a set-function into a group structure. Then, we will show that a more constructive definition of the free group satisfies this universal property. The following section draws heavily from \cite{loh_geometric_group_theory}, but we will mostly focus on the construction of the free group rather than the proof of uniqueness.
\begin{definition}\label{def:free_group}
  Let $S$ be a set. A group $F$ containing $S$ is said to be \textit{freely generated} if, for every group $G$, and every map $\phi\colon S\rightarrow G$, there is a unique group homomorphism $\varphi\colon F\rightarrow G$ that extends $\varphi$. The following diagram, where $\iota$ denotes the inclusion of $S$ into $F$, commutes:
    \begin{center}
      \begin{tikzcd}
        S \arrow[d, "\iota"', hook] \arrow[r, "\phi"] & G \\
        F \arrow[ru, "\varphi"']                      &  
      \end{tikzcd}
    \end{center}
  We say $F$ is the \textit{free group} generated by $S$.
\end{definition}
Intuitively, to construct the free group, if we have $a\mapsto \phi(a)$ between $S$ and $G$, then we will define $\varphi\left(a^n\right) = \phi(a)^n$ inside $F(S)$. Uniqueness will follow from the fact that we can take two groups that satisfy the universal property, $F$ and $F'$, and apply the universal property on set-valued functions between $S$ and $F$ and $S$ and $F'$ respectively. 
\begin{theorem}\label{thm:free_group_existence}
  If $S$ is some set, then there is some freely generated group $F(S)$ that satisfies \ref{def:free_group}.
\end{theorem}
\begin{proof}
  We will construct a group consisting of ``words'' made up of elements of $S$ and their inverses. This starts by considering the alphabet $A = S\cup \widehat{S}$, where $\widehat{S}$ is a disjoint copy of $S$ --- every $\hat{s}\in \widehat{S}$ will play the role of an inverse to $s$ in our group.
  \begin{itemize}
    \item Define $A^{\ast}$ to be the set of all words over the alphabet $A$, including the empty word, $\epsilon$. We define the operation $A^{\ast}\times A^{\ast}\rightarrow A^{\ast}$ by concatenating words, which is an associative operation with neutral element $\epsilon$.
    \item Define the equivalence relation $\sim$ generated by the following two relations, where for all $x,y\in A^{\ast}$ and $s\in S$, we have
      \begin{align*}
        xs\hat{s}y &\sim xy\\
        x\hat{s}sy &\sim xy.
      \end{align*}
      The equivalence classes with respect to $\sim$ will be denoted $\left[\cdot\right]$.\newline

      We have a well-defined composition $\left[x\right]\left[y\right] = \left[xy\right]$ mapping $F(S) \times F(S) \rightarrow F(S)$ for all $x,y\in A^{\ast}$.
  \end{itemize}
  We show that $F(S)$ with the concatenation operation is a group. Here, we see that $\left[\epsilon\right]$ is the neutral element for the composition, and associativity is inherited from associativity of concatenation in $A^{\ast}$. To show the existence of inverses, we define the inverse map inductively by taking $I\left(\epsilon\right) = \epsilon$, and
  \begin{align*}
    I\left(sx\right) &= I(x)\hat{s}\\
    I\left(\hat{s}x\right) &= I(x)s
  \end{align*}
  for all $x\in A^{\ast}$  and $s\in S$. Inductively, we can see that $I\left(I\left(x\right)\right) = x$ and
  \begin{align*}
    \left[I(x)\right]\left[x\right] &= \left[I(x)x\right]\\
                                    &= \left[\epsilon\right]\\
    \left[x\right]\left[I(x)\right] &= \left[xI(x)\right]\\
                                    &= \left[\epsilon\right].
  \end{align*}
  Thus, $F(S)$ is a group.\newline

  Now, we show $F(S)$ is freely generated. Let $i\colon S\rightarrow F(S)$ be the map that sends $s\mapsto \left[s\right]$. By our construction, we know that $i(S)\subseteq F(S)$ is a generating set for $F(S)$. We will show the universal property holds for $F(S)$.\newline

  To start, let $\phi\colon S\rightarrow G$ be a set-valued map between $S$ and an arbitrary group $G$. We construct $\phi^{\ast}\colon A^{\ast}\rightarrow G$ by taking
  \begin{align*}
    \epsilon &\mapsto e\\
    sx &\mapsto \phi(s)\phi^{\ast}\left(x\right)\\
    \hat{s}x &\mapsto \left(\phi(s)\right)^{-1}\phi^{\ast}\left(x\right)
  \end{align*}
  for all $x\in A^{\ast}$ and $s\in S$. This definition of $\phi^{\ast}$ is compatible with the equivalence relation on $A^{\ast}$, and we see that $\phi^{\ast}\left(xy\right) = \phi^{\ast}\left(x\right)\phi^{\ast}\left(y\right)$. Thus, we get a well-defined map $\varphi\colon F(S)\rightarrow G$, taking $\left[x\right]\mapsto \left[\phi^{\ast}\left(x\right)\right]$.\newline

  It remains to be shown that the map $i\colon S\rightarrow F(S)$ is injective, which will show that $F(S)$ is freely generated by $S$. Let $s_1,s_2\in S$, and consider the set-function $\phi\colon S\rightarrow \Z$ given by $\phi\left(s_1\right) = 1$ and $\phi\left(s_2\right) = -1$. Then, we must have
  \begin{align*}
    \varphi\left(i\left(s_1\right)\right) &= \phi\left(s_1\right)\\
                                          &= 1\\
                                          &\neq -1\\
                                          &= \phi\left(s_2\right)\\
                                          &= \varphi\left(i\left(s_2\right)\right).
  \end{align*}
  Thus, we have $i\left(s_1\right)\neq i\left(s_2\right)$, so $i$ is injective.
\end{proof}
\begin{remark}
  This establishes that any group is a quotient of its free group when considered as a set.
\end{remark}

Most of the definitions of the free group automatically default to the characterization of $F(S)$ as the set of reduced words in $S\cup S^{-1}$. This is the characterization we will be using in the future, but it is still important to understand where exactly the ``free'' in free group comes from, and how it relates to the particular universal property that actually characterizes $F(S)$ uniquely up to isomorphism.
\section{Free Vector Spaces}%
Given a set $A$, just as we are able to construct a free group, $F(A)$, we can take any set $A$ and construct a ``universal'' vector space out of the set.\newline

The free vector space (as it is known) is the universal object that extends any set-valued function into a linear map, treating elements of the set as its basis (Definition \ref{def:basis}). We are interested in the case of the free vector space over the complex numbers, but note that the following definition of the free vector space applies over any field. 
\begin{theorem}\label{thm:free_vector_space}
  Let $\Gamma$ be a nonempty set. There is a vector space, $\C\left[\Gamma\right]$, with $\Dim\left(\C\left[\Gamma\right]\right) = \Card\left(\Gamma\right)$, and an injective map $\delta\colon \Gamma\rightarrow \C\left[\Gamma\right]$ such that the following universal property holds: if $V$ is a $\C$-vector space, and $\phi\colon \Gamma\rightarrow V$ is a set-valued function, then there is a unique linear map $T_{\phi}\colon \C\left[\Gamma\right]\rightarrow V$ such that $T_{\phi}\circ \delta = \phi$.
  \begin{center}
    % https://tikzcd.yichuanshen.de/#N4Igdg9gJgpgziAXAbVABwnAlgFyxMJZABgBpiBdUkANwEMAbAVxiRAB12BxOgW17ogAvqXSZc+QigCM5KrUYs2nAMLJOPfnQrDRIDNjwEis6fPrNWiEADVh8mFADm8IqABmAJwi8kZEDgQSLIKlsrssAw4giIe3r6IIYFIAEzUDHQARjAMAAriRlIgDDDuOCDUFkrWACoA+sCcaAAWWEK6cT5+1MmIacVZOfmGkmyeWE7N5ZWKVhzsLVj2QkA
\begin{tikzcd}
\Gamma \arrow[r, "\delta"] \arrow[rd, "\phi"'] & {\C[\Gamma]} \arrow[d, "T_{\phi}"] \\
                                               & V                                 
\end{tikzcd}
  \end{center}
\end{theorem}
\begin{proof}
  Consider the linear subspace of finitely supported functions, $\C\left[\Gamma\right]\subseteq \mathcal{F}\left(\Gamma,\C\right)$. For each $t\in \Gamma$, we define
  \begin{align*}
    \delta_t\left(s\right) &= \begin{cases}
      1 & s=t\\
      0 & \text{else}
    \end{cases}.
  \end{align*}
    We see that $\delta_t\neq \delta_s$ whenever $s\neq t$, meaning that the map $\delta\colon \Gamma\rightarrow \C\left[\Gamma\right]$, defined by $s \mapsto \delta_s$, is injective.\newline

    We will show that $\set{\delta_s}_{s\in \Gamma}$ is a linear basis for $\C\left[\Gamma\right]$. If $f\in \C\left[\Gamma\right]$, with $\supp\left(f\right) = \set{s_1,\dots,s_n}\subseteq \Gamma$, we set $\alpha_j = f\left(t_j\right)$, and see that
    \begin{align*}
      f &= \sum_{j=1}^{n}\alpha_j\delta_{s_j},
    \end{align*}
    which shows that $\set{\delta_s}_{s\in\Gamma}$ is a spanning set.\newline

    To show that $\set{\delta_s}_{s\in\Gamma}$ is linearly independent, consider $g = \sum_{j=1}^{n}\alpha_j\delta_{s_j}\in \C\left[\Gamma\right]$ such that $g = 0$. Then, $g(t) = 0$ for all $t\in\Gamma$, and in particular, $g\left(s_i\right) = 0$ for every $1 \leq i \leq n$. Thus, we have
    \begin{align*}
      0 &= g\left(s_j\right)\\
        &= \sum_{j=1}^{n}\alpha_j\delta_{s_j}\left(s_i\right)\\
        &= \alpha_i,
    \end{align*}
    so $\alpha_j = 0$ for each $j$. Thus, $\set{\delta_s}_{s\in \Gamma}$ is linearly independent.\newline

    Turning to the universal property, we define $T_{\phi}\colon \C\left[\Gamma\right]\rightarrow V$ in terms of $\phi$ as follows:
    \begin{align*}
      T_{\phi}\left(\sum_{j=1}^{n}\alpha_j\delta_{s_j}\right) &= \sum_{j=1}^{n}\alpha_j\phi\left(s_j\right).
    \end{align*}
    This yields an expression of $T_{\phi}$ uniquely in terms of $\phi$ and $\delta$.
\end{proof}
\begin{example}
  Let $z$ be an abstract variable, and consider the set of ``formal powers'' of $z$, $\set{z^k}_{k\in\Z_{\geq 0}}$. Then, the free vector space generated by this set, $\C\left[z\right]$, is the set of all polynomials with coefficients in $\C$. By the universal property, we know that every polynomial $p\in \C\left[z\right]$ has a unique expression $p = \sum_{j=0}^{n}a_jz^j$.
\end{example}
One of the primary uses of the free vector space is that, via this construction, we can show that vector spaces are particularly nice algebraic objects. We often use these properties implicitly in linear algebra.
\begin{theorem}\label{thm:injective_projective_objects}
  Let $X$, $Y$, and $Z$ be vector spaces.
  \begin{enumerate}[(a)]
    \item If $\iota\colon Y\hookrightarrow X$ is an injective linear map, and $\varphi\colon Y\rightarrow Z$ is a linear map, then there is a (not necessarily unique) map $T\colon X\rightarrow Y$ such that $T\circ\iota = \varphi$.
      \begin{center}
        % https://tikzcd.yichuanshen.de/#N4Igdg9gJgpgziAXAbVABwnAlgFyxMJZABgBpiBdUkANwEMAbAVxiRGJAF9T1Nd9CKAIzkqtRizYBNLjxAZseAkRFCx9Zq0QgAWrN6KBRAEyjqGydoAaXMTCgBzeEVAAzAE4QAtkhEgcEEgAzOYSWiAAOhH4OHQg1LFYDGwAFhAQANb6IB7evgmBiKYgDHQARjAMAAp8SoIg7lgOKTjx4ppsUfTuaClY2bk+iCH+hcWlFdW1RtoMMK6toR3aACoDnkNko76cFJxAA
\begin{tikzcd}
0 \arrow[r] & Y \arrow[r, "\iota", hook] \arrow[d, "\varphi"'] & X \arrow[ld, "T"] \\
            & Z                                                &                  
\end{tikzcd}
      \end{center}
This shows that vector spaces are injective objects --- any linear map factors through an injective map.
    \item If $\pi\colon X\rightarrow Z$ is a surjective linear map, and $\varphi\colon Y\rightarrow Z$ is a linear map, then there is a (not necessarily unique) map $\delta\colon Y\rightarrow X$ such that $\pi\circ\delta = \varphi$.
      \begin{center}
        % https://tikzcd.yichuanshen.de/#N4Igdg9gJgpgziAXAbVABwnAlgFyxMJZARgBoAGAXVJADcBDAGwFcYkQBNEAX1PU1z5CKMsWp0mrdgC0efEBmx4CRcqTE0GLNohAANOfyVCiAJnXitU3eR7iYUAObwioAGYAnCAFskakDgQSOYgjPQARjCMAAoCysIgHliOABY4IJqSOiAAOjmwjDj0hiCePsE0gUhkoRFRscYqukmp6Zna7HloWCVlvoj+VYg1Vtl5DB5oKT00YZExcSa6jDBu6bzuXv01QwDM3JTcQA
        \begin{tikzcd}
                            & Y \arrow[ld, "\delta"'] \arrow[d, "\varphi"] &   \\
        X \arrow[r, "\pi"'] & Z \arrow[r]                                  & 0
        \end{tikzcd}
      \end{center}
      This shows that vector spaces are projective objects --- any linear map factors through a surjective map.
  \end{enumerate}
\end{theorem}
\begin{proof}\hfill
  \begin{enumerate}[(a)]
    \item Let $\mathcal{A}$ be a basis for $Y$. Then, since $\iota$ is an injective linear map, the set $\set{\iota(y) | y\in \mathcal{A}}$ can be extended to a basis $\mathcal{B}$ for $X$.\newline

      We set $t\colon \mathcal{B}\rightarrow Z$ to be
      \begin{align*}
        t\left(x\right) &= \begin{cases}
          \varphi(x) & x\in \set{\iota(y) | y\in \mathcal{A}}\\
          0 & x\in \mathcal{B}\setminus \set{\iota(y) | y\in \mathcal{A}}
        \end{cases}.
      \end{align*}
      By the universal property of the free vector space, this extends to a linear map $T\colon X\rightarrow Y$. Since $T\circ\iota$ agrees with $\varphi$ on $\mathcal{A}$, the universal property of the free vector space states that $T\circ\iota$ agrees with $\varphi$ on all of $Y$.
    \item Let $\set{y_i}_{i\in I}$ be a basis for $Y$. We define $d\left( y_i \right) = x_i\in  \pi^{-1}\circ \varphi\left( \set{y_i} \right)$ for each $i\in I$.  By the universal property of the free vector space, this extends to a unique linear map $\delta\colon Y\rightarrow X$ that agrees on the basis of $Y$.
  \end{enumerate}
\end{proof}

\section{Free Algebras}%
Later chapters of this thesis will require understanding results from the theory of operator algebras and algebras more generally. Here, we establish a purely algebraic understanding of a free construction, similar to the free vector space and free group. Just as there are free groups and free vector spaces, we can also talk about free algebras. In Chapter \ref{ch:nuclearity}, we will construct special norms on free algebras to elucidate properties of the underlying group.\newline

Similar to a free group, the free algebra (or free $\ast$-algebra) is constructed by taking a certain collection of ``words'' over a set of symbols, and then, if desired, ``modding out'' by the ideal generated by a set of relations. We formalize this in steps.
\begin{definition}\label{def:free_algebra}
  Let $E=\set{x_i}_{i\in I}$ be a collection of symbols that may not commute. The space of all polynomials over $E$ is the free vector space over the set of words formed by symbols in $E$,
  \begin{align*}
    \Gamma_E &= \set{x_{i_1}x_{i_2}\cdots x_{i_n} | n\in\N,i_1,\dots,i_n\in I}.
  \end{align*}
  We denote this space $\C \left\langle E \right\rangle$.\newline

  In the free vector space $\C \left\langle E \right\rangle$, we may define multiplication by concatenation:
  \begin{align*}
    \left(x_{i_1}x_{i_2}\cdots x_{i_n}\right)\left(x_{j_1}x_{j_2}\cdots x_{j_m}\right) &= x_{i_1}x_{i_2}\cdots x_{i_n}x_{j_1}x_{j_2}\cdots x_{j_m},
  \end{align*}
  where $i_1,\dots,i_n,j_1,\dots,j_m\in I$. The space $\C\left\langle E \right\rangle$, equipped with multiplication by concatenation, is known as the \textit{free algebra} on $E$.\newline

  To turn $\C\left\langle E \right\rangle$ into a $\ast$-algebra, we define the formal set $E^{\ast} = \set{x_{i}^{\ast}}_{i\in I}$, and define the involution on $\C\left\langle E\cup E^{\ast} \right\rangle$ by taking
  \begin{align*}
    \left(\alpha x_{i_1}^{\ve_1}x_{i_2}^{\ve_2}\cdots x_{i_n}^{\ve_n}\right)^{\ast} &= \overline{\alpha}x_{i_n}^{\delta_n}x_{i_{n-1}}^{\delta_{n-1}}\cdots x_{i_2}^{\delta_2}x_{i_1}^{\delta_1},
  \end{align*}
  where
  \begin{align*}
    \delta_j &= \begin{cases}
      \ast & \ve_j = 1\\
      1 & \ve_j = \ast
    \end{cases}.
  \end{align*}
  The set $\C\left\langle E\cup E^{\ast} \right\rangle$ with the involution defined above is known as the \textit{free $\ast$-algebra} on $E$, and is usually denoted $\mathbb{A}^{\ast}\left(E\right)$.\newline

  If $R\subseteq \mathbb{A}^{\ast}\left(E\right)$ is a collection of relations, we let $I(R) = \operatorname{ideal}\left(R\right)$. Then, the quotient algebra
  \begin{align*}
    \mathbb{A}^{\ast}\left(E|R\right) &= \mathbb{A}^{\ast}\left(E\right)/I(R)
  \end{align*}
  is known as the \textit{universal $\ast$-algebra on $E$ with relations $R$}.
\end{definition}
Evident from the name, the universal $\ast$-algebra(s) admit universal properties that characterize them as unique.
\begin{theorem}[Universal Properties]\label{thm:universal_property_free_algebra}
  Let $E = \set{x_i}_{i\in I}$ be a set of abstract symbols, and let $B$ be a $\ast$-algebra. Let $\phi\colon E\rightarrow B$ be an injective map, and define $b_i = \phi\left(x_i\right)$.
  \begin{itemize}
    \item There is a unique $\ast$-homomorphism $\varphi\colon \mathbb{A}^{\ast}\left(E\right) \rightarrow B$ such that $x_i \mapsto b_i$. The following diagram commutes.
      \begin{center}
        % https://tikzcd.yichuanshen.de/#N4Igdg9gJgpgziAXAbVABwnAlgFyxMJZABgBpiBdUkANwEMAbAVxiRAFEQBfU9TXfIRQBGclVqMWbAELdeIDNjwEiZYePrNWiEAB1dAWzo4AFgCMzwAIJcAFOwCU3cTCgBzeEVAAzAE4QDJDIQHAgkUQktNn00Eyw5H39AxGDQpAAmagY6MxgGAAV+ZSEQXyw3ExwQak0pHX18HDoEkD8AjOo0xAjs3IKiwTYyiqqayW09XXpfWPiuCi4gA
        \begin{tikzcd}
        E \arrow[r, "\phi"] \arrow[d, "\iota"'] & B \\
        \mathbb{A}^{\ast}(E) \arrow[ru, "\varphi"']    &  
        \end{tikzcd}
      \end{center}
    \item If $R\subseteq \mathbb{A}^{\ast}\left(E\right)$ is a set of relations, and $\set{b_i}_{i\in I}$ satisfies the relations $R$, then there is a unique $\ast$-homomorphism $\mathbb{A}^{\ast}\left(E|R\right) \rightarrow B$ such that $x_i + I(R) \mapsto b_i$. The following diagram commutes.
      \begin{center}
        % https://tikzcd.yichuanshen.de/#N4Igdg9gJgpgziAXAbVABwnAlgFyxMJZABgBpiBdUkANwEMAbAVxiRAFEQBfU9TXfIRQBGclVqMWbAELdeIDNjwEiZYePrNWiEAB1dAWzo4AFgCMzwAIJcAesH104OLgAp2AHwBKASm7iYKABzeCJQADMAJwgDJDIQHAgkUQktNn00Eyw5COjYxHjEpAAmagY6MxgGAAV+ZSEQSKwgkxwQak0pHX18HDockCiYkuoixBTyypq6wTYmlraOyW09XXpIzOyuCi4gA
\begin{tikzcd}
E \arrow[r, "\phi"] \arrow[d, "\iota"']       & B \\
\mathbb{A}^{\ast}(E|R) \arrow[ru, "\varphi"'] &  
\end{tikzcd}
      \end{center}
  \end{itemize}
\end{theorem}
One of the most important $\ast$-algebras we will study is generated from a group by taking the free vector space over the group.
\begin{definition}\label{def:group_star_algebra}
  Let $\Gamma$ be a group with identity element $e$, and let $\C\left[\Gamma\right]$ be the free vector space generated by $\Gamma$. We define a multiplication $f \ast g$, where $f,g\in \C\left[\Gamma\right]$ are finitely supported functions, by convolution:
  \begin{align*}
    f\ast g(s) &= \sum_{t\in\Gamma}f(t)g\left(t^{-1}s\right)\\
               &= \sum_{r\in\Gamma}f\left(sr^{-1}\right)g\left(r\right).
  \end{align*}
  The involution on $\C\left[\Gamma\right]$ is defined by $f^{\ast}\left(t\right) = \overline{f\left(t^{-1}\right)}$. The multiplicative identity is $\delta_e$, and multiplication satisfies $\delta_s\ast \delta_t = \delta_{st}$. Furthermore, this gives $\delta_{s}^{\ast} = \delta_{s^{-1}}$.\newline

  This is known as the \textit{group $\ast$-algebra}.
\end{definition}
\begin{remark}
  In Chapter \ref{ch:nuclearity}, we will endow the group $\ast$-algebra with special norms to create the group $C^{\ast}$-algebra(s).
\end{remark}
\section{Tensor Products}%
Given two vector spaces $V,W$, and a bilinear map $b\colon V\times W \rightarrow Z$ (for some vector space $Z$), it's tempting to use the property of the free vector space to find a linear map on some structure that incorporates both $V$ and $W$ and stays faithful to the bilinear map $b$. Indeed, this is what the tensor product of the vector spaces $V$ and $W$ is --- a universal construction that ``turns'' bilinear maps into linear maps.
\begin{definition}\label{def:bilinear_map}
  Let $V,W,Z$ be vector spaces, and let $b\colon V\times W\rightarrow Z$ be a map such that, for all $\alpha\in \C$, $v,v_1,v_2\in V$, and $w,w_1,w_2\in W$,
  \begin{align*}
    b\left( \alpha v_1 + v_2,w \right) &= \alpha b\left( v_1,w \right) + b\left( v_2,w \right)\\
    b\left( v,\alpha w_1 + w_2 \right) &= b\left( v,w_1 \right) + \alpha b\left( v,w_2 \right).
  \end{align*}
  Then, we say $b$ is \textit{bilinear}. The space of bilinear maps is denoted $\operatorname{Bil}\left( V,W;Z \right)$.
\end{definition}
Just as we defined the free vector space and free group, we define the tensor product through a universal property --- and, just as with the case of the free group, we will focus more on the construction of the tensor product than on showing uniqueness.
\begin{theorem}[Universal Property of Tensor Products]\label{thm:tensor_product_existence}
  Let $V,W,Z$ be vector spaces, and let $b\colon V\times W \rightarrow Z$ be a bilinear map. Then, there exists a vector space, $V\otimes W$ and a linear map $T\colon V\otimes W \rightarrow Z$ such that for any $v\in V$ and $w\in W$, $T\left( v\otimes w \right) = b\left( v,w \right)$. The following diagram, where $\iota\colon V\times W \hookrightarrow V\otimes W$ is defined by $\left( v,w \right)\mapsto v\otimes w$, commutes.
  \begin{center}
      % https://tikzcd.yichuanshen.de/#N4Igdg9gJgpgziAXAbVABwnAlgFyxMJZABgBpiBdUkANwEMAbAVxiRADUAdTvAW3gAEAdRABfUuky58hFAEZyVWoxZsunCH0Ejxk7HgJEFcpfWatEIAFpilMKAHN4RUADMAThF5IyIHBCQAJmoGOgAjGAYABSkDWRB3LAcACxwQajNVSzCxCRAPLx9qfyQFZXM2bnwcOnS-OiwGNkgwVl18z29EMpLEYJBQiOjYmTYGGFc0jJULEAAVW1EgA
    \begin{tikzcd}
    V\times W \arrow[rd, "b"'] \arrow[r, "\iota"] & V\otimes W \arrow[d, "T"] \\
                                                  & Z                        
    \end{tikzcd}
  \end{center}
  The vector space $V\otimes W$ is unique up to linear isomorphism, and is known as the \textit{tensor product} of $V$ and $W$.
\end{theorem}
\begin{proof}
  We focus on showing existence. With $V$ and $W$ as in Theorem \ref{thm:tensor_product_existence}, we consider the free vector space (Theorem \ref{thm:free_vector_space}) on $V\times W$, $\C\left[ V\times W \right]$. Elementary elements of $V\times W$ are of the form $\delta_{(v,w)}$, where
  \begin{align*}
    \delta_{(v,w)} \left( s,t \right) &= \begin{cases}
      1 & v=s,w=t\\
      0 & \text{else}
    \end{cases}.
  \end{align*}
  Intuitively, from the way we have defined the tensor product as a linear map that extends a bilinear map, we would find the following properties of tensors desirable, for any $v,v_1,v_2\in V$, $w,w_1,w_2\in W$, and $\alpha\in \C$
  \begin{align*}
    \left( v_1 + v_2 \right)\otimes w &= v_1\otimes w + v_2\otimes w\label{eq:rel_1}\tag{1}\\
    v\otimes\left( w_1 + w_2 \right) &= v\otimes w_1 + v\otimes w_2\label{eq:rel_2}\tag{2}\\
    \left( \alpha v \right)\otimes w &= \alpha \left( v\otimes w \right)\label{eq:rel_3}\tag{3}\\
    v\otimes \left( \alpha w \right) &= \alpha \left( v\otimes w \right)\label{eq:rel_4}\tag{4}.
  \end{align*}
  With these four desirable properties in mind, we define a certain set of relations on the free vector space that we will ``mod out'' to obtain our desired tensor product. 
  \begin{itemize}
    \item To satisfy \eqref{eq:rel_1}, we define the set $N_1 = \set{\delta_{\left( v_1 + v_2,w \right)} - \delta_{\left( v_1,w \right)} - \delta_{\left( v_2,w \right)} | v_1,v_2\in V,w\in W}$, as this will be equivalent to the statement $\left( v_1 + v_2 \right)\otimes w - v_1\otimes w - v_2\otimes w = 0$.
    \item To satisfy \eqref{eq:rel_2}, we define the set $N_2 = \set{\delta_{\left( v,w_1 + w_2 \right)} - \delta_{\left( v,w_1 \right)} - \delta_{\left( v,w_2 \right)} | v\in V,w_1,w_2\in W}$, as this will be equivalent to the statement $v\otimes \left( w_1 + w_2 \right) - v\otimes w_1 - v\otimes w_2 = 0$.
    \item To satisfy \eqref{eq:rel_3}, we define the set $N_3 = \set{\delta_{\left( \alpha v,w \right)} - \alpha \delta_{\left( v,w \right)} | \alpha\in\C,v\in V,w\in W}$, as this will be equivalent to the statement $\left( \alpha v \right)\otimes w - \alpha \left( v\otimes w \right) = 0$.
    \item To satisfy \eqref{eq:rel_4}, we define the set $N_4 = \set{\delta_{\left(  v,\alpha w \right)} - \alpha \delta_{\left( v,w \right)} | \alpha\in\C,v\in V,w\in W}$, as this will be equivalent to the statement $v\otimes \left( \alpha w \right) - \alpha \left( v\otimes w \right) = 0$.
  \end{itemize}
  We define the ``zero set'' of our tensor product to be
  \begin{align*}
    N &= \Span\left( N_1 \cup N_2\cup N_3\cup N_4 \right),
  \end{align*}
  and consider the quotient space (Definition \ref{def:subspace_quotient_space_direct_sum}) $\C\left[ V\times W \right]/N$. We define
  \begin{align*}
    v\otimes w &\coloneq \delta_{(v,w)} + N.
  \end{align*}
  It can be verified that this definition is faithful to our requirements in \eqref{eq:rel_1}--\eqref{eq:rel_4}. Elements of $V\otimes W$ are of the form $\sum_{i\in I}v_i \otimes w_i$. We call elements of the form $v\otimes w$ \textit{elementary tensors}.\newline

  Define $\iota\colon V\times W \rightarrow V\otimes W$ by $\left( v,w \right) \mapsto v\otimes w$, and set $b = T\circ \iota$.\newline

  We verify that this definition satisfies the universal property of tensor products. We let $v_1,v_2,v\in V$, $w_1,w_2,w\in W$, and $\alpha\in \C$. Then,
  \begin{align*}
    b\left( v_1 + cv_2,w \right) &= T\left( \iota\left( v_1 + cv_2,w \right) \right)\\
                                 &= T\left( \left( v_1 + cv_2 \right)\otimes w \right)\\
                                 &= T\left( v_1\otimes w + c\left( v_2\otimes w \right) \right)\\
                                 &= T\left( v_1\otimes w \right) + cT\left( v_2\otimes w \right)\\
                                 &= b\left( v_1,w \right) + cb\left( v_2,w \right)\\
                                 \\
    b\left( v,w_1 + cw_2 \right) &= T\left( \iota\left( v,w_1 + cw_2 \right) \right)\\
                                 &= T\left( v\otimes \left( w_1 + cw_2 \right) \right)\\
                                 &= T\left( v\otimes w_1 + c\left( v\otimes w_2 \right) \right)\\
                                 &= T\left( v\otimes w_1 \right) + cT\left( v\otimes w_2 \right)\\
                                 &= b\left( v,w_1 \right) + cb\left( v,w_2 \right).
  \end{align*}
  Thus, by the universal property of the free vector space, there is a unique linear map $\tilde{b}\colon \C\left[ V\times W \right]\rightarrow Z$, defined by $\tilde{b}\left( \delta_{(v,w)} \right) = b\left( v,w \right)$.\newline

  Note that $\tilde{b}$ vanishes on $N$, so by the First Isomorphism Theorem there is a unique linear map $T_{b}\colon \C\left[ V\times W \right]/N\rightarrow Z$ that is defined by $T_{b} \circ \pi = \tilde{b}$, where $\pi\colon \C\left[ V\times W \right] \rightarrow \C\left[ V\times W \right]/N$ is the canonical projection.\newline

  Thus, we know that $T = T_{b}$ satisfies the universal property of tensor products.
\end{proof}
\begin{remark}
  Elements of the tensor product $X\otimes Y$ are of the form
  \begin{align*}
    t &= \sum_{k=1}^{n}x_k\otimes y_k,
  \end{align*}
  where $x_k\in X$ and $y_k\in Y$. Elements of the form $x_k\otimes y_k$ are known as \textit{elementary tensors}.\newline

  We note that any such $t$ has a variety of representations as elements of the tensor product.
\end{remark}
In linear algebra, we often use the universal property of tensor products to convert from bilinear maps to linear maps. However, we can also apply tensor products to spaces of linear maps by using the universal property.
\begin{proposition}[{\cite[Proposition E.6.14]{rainone_analysis}}]
  Let $X,Y,V,W$ be $\C$-vector spaces.
  \begin{enumerate}[(1)]
    \item If $T\in \mathcal{L}\left( X,V \right)$ and $S\in \mathcal{L}\left( Y,W \right)$, then there is a unique linear map
      \begin{align*}
        T\bar{\otimes} S \colon X\otimes Y \rightarrow V\otimes W
      \end{align*}
      that satisfies $T\bar{\otimes} S\left( x\otimes y \right) = T\left( x \right)\otimes S\left( y \right)$ for all $x\in X$ and $y\in Y$.
    \item For all $\varphi\in X'$ and $\psi\in Y'$, there is a linear map $\varphi\times\psi \in \left( X\otimes Y \right)'$ such that $\left( \varphi\times\psi \right)\left( x\otimes y \right) = \varphi\left( x \right)\psi\left( y \right)$ for all $x\in X$ and $y\in y$.
  \end{enumerate}
\end{proposition}
\begin{proof}\hfill
  \begin{enumerate}[(1)]
    \item The map $X\times Y \rightarrow V\otimes W$ that sends $\left( x,y \right)\mapsto T\left( x \right)\otimes S\left( y \right)$ is bilinear. Thus, by the universal property of tensor products, there exists a linear map $T \bar{\otimes} S \colon X\otimes Y \rightarrow V\otimes W$.
    \item Similarly, the map $X\times Y \rightarrow \C$ given by $\left( x,y \right)\mapsto \varphi(x)\psi(y)$ is bilinear, so the universal property gives us $\varphi\times\psi\colon X\otimes Y \rightarrow \C$ such that $\left( \varphi\times \psi \right)\left( x\otimes y \right) = \varphi\left( x \right)\psi\left( y \right)$.
  \end{enumerate}
\end{proof}
\begin{remark}
Technically, the map $T\bar{\otimes} S$ is an element of $\mathcal{L}\left( X\otimes Y,V\otimes W \right)$, rather than the vector space $\mathcal{L}\left( X,V \right)\otimes \mathcal{L}\left( Y,W \right)$. The next proposition will show an injection of the latter space into the former.
\end{remark}
\begin{proposition}[{\cite[Proposition E.6.17]{rainone_analysis}}]
  Let $X,Y,V,W$ be $\C$-vector spaces. There is a natural linear embedding
  \begin{align*}
    \iota\colon \mathcal{L}\left( X,V \right)\otimes \mathcal{L}\left( Y,W \right) \hookrightarrow \mathcal{L}\left( X\otimes Y,V\otimes W \right)
  \end{align*}
  such that $\iota\left( T\otimes S \right) = T\bar{\otimes}S$.
\end{proposition}
\begin{proof}
  We see that for any $T,T_1,T_2\in \mathcal{L}\left( X,V \right)$, $S,S_1,S_2\in \mathcal{L} \left( Y,W \right)$, and $\alpha \in \C$, that
  \begin{align*}
    \left( T_1 + \alpha T_2 \right)\bar{\otimes}S &= T_1\bar{\otimes}S + \alpha \left( T_2\bar{\otimes}S \right)\\
    T\bar{\otimes}\left( S_1 + \alpha S_2 \right) &= T\bar{\otimes}S_1 + \alpha \left( T\bar{\otimes}S_2 \right).
  \end{align*}
  Therefore, the map $\mathcal{L}\left( X,V \right)\times \mathcal{L}\left( Y,W \right) \rightarrow \mathcal{L}\left( X\otimes Y,V\otimes W \right)$, sending $\left( T,S \right)\mapsto T\bar{\otimes}S$. Thus, there is a map $\iota\colon \mathcal{L}\left( X,V \right)\otimes \mathcal{L}\left( Y,W \right)\rightarrow \mathcal{L}\left( X\otimes V,Y\otimes W \right)$ such that $\iota\left( T\otimes S \right) = T\bar{\otimes}S$.\newline

  Now, we will show that $\iota$ is injective. Suppose that
  \begin{align*}
    0 &= \iota\left( \sum_{k=1}^{n}T_k\otimes S_k \right)\\
      &= \sum_{k=1}^{n}T_k\bar{\otimes}S_k,
  \end{align*}
  where $T_k,S_k$ are linearly independent. Now, for any $x\in X$ and $y\in Y$, we have
  \begin{align*}
    0 &= \left( \sum_{k=1}^{n}T_k\bar{\otimes}S_k \right)\left( x\otimes y \right)\\
      &= \sum_{k=1}^{n}T_k\left( x \right)\otimes S_k\left( y \right).
  \end{align*}
  Furthermore, for any $\varphi\in V'$ and $\psi\in W'$, we have
  \begin{align*}
    0 &= \left( \varphi\times \psi \right)\left( \sum_{k=1}^{n}T_k\left( x \right)\otimes S_k\left( y \right) \right)\\
      &= \sum_{k=1}^{n}\varphi\left( T_k\left( x \right) \right)\psi\left( S_k\left( y \right) \right)\\
      &= \psi\left( \sum_{k=1}^{n}\varphi\left( T_k\left( x \right) \right)S_k\left( y \right) \right).
  \end{align*}
  Now, since $W'$ separates points, we have that
  \begin{align*}
    0 &= \sum_{k=1}^{n}\varphi\left( T_k\left( x \right) \right)S_k\left( y \right)\\
      &= \left( \sum_{k=1}^{n} T_k\left( x \right)S_k\right)\left( y \right),
  \end{align*}
  meaning $\sum_{k=1}^{n}\varphi\left( T_k\left( x \right) \right)S_k = 0$ in $\mathcal{L}\left( Y,W \right)$. Since we have defined $S_k$ to be linearly independent, we have $\varphi\left( T_k\left( x \right) \right) = 0$ for all $k$, $x\in X$, and $\varphi\in V'$. Since $V'$ separates points, we have $T_k(x) = 0$ for all $k$ and $x\in X$, so $T_k = 0$ for all $k$.\newline

  Thus, 
  \begin{align*}
    \sum_{k=1}^{n}T_k\otimes S_k &= 0,
  \end{align*}
  so $\ker\left( \iota \right) = \set{0}$, and $\iota$ is injective.
\end{proof}
Now that we understand how tensor products play with spaces of linear maps, we may prove some crucial results related to tensor products of algebras. Note that in all of these cases, we use the universal property of tensor products to ensure that our expression is unique.
\begin{proposition}[{\cite[Proposition F.2.24]{rainone_analysis}}]\label{prop:tensor_product_algebras}
  Let $A$ and $B$ be algebras. The vector space $A\otimes B$ admits a multiplication $\left( A\otimes B \right)\times \left( A\otimes B \right)\rightarrow A\otimes B$, given by
  \begin{align*}
    \left( a\otimes b \right)\left( c\otimes d \right) &= ac\otimes bd.
  \end{align*}
  If $A$ and $B$ are unital, then so too is $A\otimes B$. If $A$ and $B$ are $\ast$-algebras, then $A\otimes B$ admits an involution given by
  \begin{align*}
    \left( a\otimes b \right)^{\ast} &= a^{\ast}\otimes b^{\ast}.
  \end{align*}
\end{proposition}
\begin{proof}
  Fixing $a\in A$ and $b\in B$, we define linear maps $L_a\colon A\rightarrow A$ and $L_b\colon B\rightarrow B$  by
  \begin{align*}
    L_a\left( x \right) &= ax\\
    L_b\left( y \right) &= by.
  \end{align*}
  The maps $a\mapsto L_a$ and $b\mapsto L_b$ are linear by the fact that ring multiplication is left-distributive. Therefore, the map $A\times B \rightarrow \mathcal{L}\left( A \right)\otimes \mathcal{L}\left( B \right)$, given by $\left( a,b \right)\mapsto L_a\otimes L_b$ is bilinear.\newline

  By the universal property of tensor products, we have a linear map $L\colon A\otimes B \rightarrow \mathcal{L}\left( A \right)\otimes \mathcal{L}\left( B \right)$, given by $a\otimes b \mapsto L_a\otimes L_b$.\newline

  Now, by above, there is an embedding $\mathcal{L}\left( A \right)\otimes \mathcal{L}\left( B \right) \hookrightarrow \mathcal{L}\left( A\otimes B \right)$, so we may identify elements of $\mathcal{L}\left( A \right)\otimes \mathcal{L}\left( B \right)$ with linear maps on $A\otimes B$.\newline

  We define $\left( A\otimes B \right)\times \left( A\otimes B \right)\rightarrow A\otimes B$ by $\left( t,s \right)\mapsto ts \coloneq L(t)(s)$.\newline

  Since $L$ is linear, and $L(t)$ is linear for all $t\in A\otimes B$, both scalar multiplication and distributivity are preserved.\newline

  For all $a\in A$ and $b\in B$, we have
  \begin{align*}
    \left( a\otimes b \right)\left( c\otimes d \right) &= L\left( a\otimes b \right)\left( c\otimes d \right)\\
                                                       &= L_a\otimes L_b\left( c\otimes d \right)\\
                                                       &= \left( L_a\left( c \right) \right)\otimes \left( L_b\left( d \right) \right)\\
                                                       &= ac\otimes bd.
  \end{align*}
  Since multiplication in $A$ and $B$ is associative, multiplication in $A\otimes B$ is also associative.\newline

  Now, if $A$ and $B$ are unital, then $1_A\otimes 1_B$ is a unit for $A\otimes B$, as
  \begin{align*}
    \left( 1_A\otimes 1_B \right)\left( a\otimes b \right) &= \left( 1_A a \right)\otimes \left( 1_B b \right)\\
                                                           &= a\otimes b.
  \end{align*}
  Now, if $A$ and $B$ are $\ast$-algebras, we write $\overline{A\otimes B}$ to refer to the conjugate space. Regarding the conjugate space, we if $V$ is a vector space, then $\overline{V}$ is defined by
  \begin{align*}
    \overline{v} + \overline{w} &= \overline{v+w}\\
    \alpha\cdot \left( \overline{x} \right) &= \overline{\overline{\alpha}x}.
  \end{align*}
  Thus, if $\overline{A\otimes B}$ is the conjugate space, we can see from the definition of the involution that the map $A\times B \rightarrow \overline{A\otimes B}$, given by $\left( a,b \right)\mapsto \overline{a^{\ast}\otimes b^{\ast}}$ is a bilinear map.\newline

  There is a unique linear map $\psi\colon A\otimes B \rightarrow \overline{A\otimes B}$ such that $\psi\left( a\otimes b \right) = \overline{a^{\ast}\otimes b^{\ast}}$. Additionally, the map $\mu\colon \overline{A\otimes B}\rightarrow A\otimes B$, given by $\mu\left( \overline{t} \right) = t$ is conjugate linear.\newline

  Thus, the map $\nu\colon A\otimes B \rightarrow A\otimes B$, given by $a\otimes b \mapsto a^{\ast}\otimes b^{\ast}$ is conjugate linear, and we may define an involution $A\otimes B \rightarrow A\otimes B$ by $t\mapsto t^{\ast}\coloneq \nu(t)$. We see that
  \begin{align*}
    \left( \left( a\otimes b \right)\left( c\otimes d \right) \right)^{\ast} &= \left( ac\otimes bd \right)^{\ast}\\
                                                                             &= \left( ac \right)^{\ast}\otimes \left( bd \right)^{\ast}\\
                                                                             &= c^{\ast}a^{\ast} \otimes d^{\ast}b^{\ast}\\
                                                                             &= \left( c^{\ast}\otimes d^{\ast} \right)\left( a^{\ast}\otimes b^{\ast} \right)\\
                                                                             &= \left( c\otimes d \right)^{\ast}\left( a\otimes b \right)^{\ast}.
  \end{align*}
  A similar approach gives $t^{\ast\ast} = t$ for all $t\in A\otimes B$, meaning that this is a bona fide involution on $A\otimes B$, universal by definition.
\end{proof}
Now, we turn our attention towards matrix algebras. Recall that if $A$ is an algebra, then the matrix algebra $\Mat_n\left( A \right)$ is the set of $n\times n$ matrices $\left( a_{ij} \right)_{ij}$ such that $a_{ij}\in A$ for each $i,j$. This is also an algebra, but perhaps even more importantly, it is able to be expressed as a tensor product, which is often used in the definition of nuclearity for $C^{\ast}$-algebras. We will discuss more on this in Chapter \ref{ch:nuclearity}.
\begin{theorem}[{\cite[Example E.6.21, Example F.4.11]{rainone_analysis}}]\label{thm:matrix_algebras_tensor_product}
  Let $A$ be a $\ast$-algebra, and let $n\in \N$. Then, there is a $\ast$-isomorphism of $\ast$-algebras, $\varphi\colon \Mat_n\left( A \right)\rightarrow \Mat_n\left( \C \right)\otimes A$, given by
  \begin{align*}
    \varphi\left( \left( a_{ij} \right)_{ij} \right) &= \sum_{i,j=1}^{n}e_{ij}\otimes a_{ij},
  \end{align*}
  where $\set{e_{ij}}_{i,j=1}^{n}$ are the system of matrix units.
\end{theorem}
\begin{proof}
  We start by showing that $\varphi$ is an isomorphism of vector spaces. Note that by the definition of the tensor product, we know that $\varphi$ is a linear map. Now, we start by showing that $\varphi$ is injective. Suppose
  \begin{align*}
    \varphi\left( \left( a_{ij} \right)_{ij} \right) &= \sum_{i,j=1}^{n}e_{ij}a_{ij}\\
                                                     &= 0.
  \end{align*}
  Then, since the system of matrix units is linearly independent in $\Mat_n\left( \C \right)$, we have that $x_{ij} = 0$ for all $i,j$, so $\left( x_{ij} \right)_{ij} = 0$, so $\varphi$ is injective.\newline

  Now, we show that $\varphi$ is surjective. Let $t\in \Mat_n\left( \C \right)\otimes A$ be given by
  \begin{align*}
    t &= \sum_{k=1}^{m}m_k\otimes a_k,
  \end{align*}
  where $m_k\in \Mat_n\left( \C \right)$ and $a_k\in A$. Since every matrix over $\C$ is a linear combination of the matrix units, we write
  \begin{align*}
    m_k &= \sum_{i,j=1}^{n} m_k\left( i,j \right)e_{ij}.
  \end{align*}
  Substituting, we get
  \begin{align*}
    t &= \sum_{k=1}^{m}\left( \sum_{i,j=1}^{n}m_k\left( i,j \right)e_{ij} \right)\otimes a_k\\
      &= \sum_{i,j=1}^{n}e_{ij}\otimes \left( \sum_{k=1}^{m}m_k\left( i,j \right)a_k \right),
      \intertext{and defining $a_{ij}\coloneq \sum_{k=1}^{m}m_k\left( i,j \right)a_k$, we obtain}
      &= \sum_{i,j=1}^{n}e_{ij}\otimes a_{ij}.
  \end{align*}
  Thus, $\varphi\left( \left( a_{ij} \right)_{ij} \right) = t$, and $\varphi$ is surjective, hence a linear isomorphism.\newline

  Now, we show that $\varphi$ is multiplicative and preserves the involution. Let $\left( a_{ij} \right)_{ij},\left( b_{ij} \right)_{ij}\in \Mat_n\left( A \right)$. Then,
  \begin{align*}
    \varphi\left( \left( a_{ik} \right)_{ik} \right)\varphi\left( \left( b_{\ell j} \right)_{\ell j} \right) &= \left( \sum_{i,k=1}^{n}e_{ik}\otimes a_{ik} \right)\left( \sum_{\ell,j=1}^{n}e_{\ell j}\otimes b_{\ell j} \right)\\
                                                                               &= \sum_{i,j,k,\ell=1}^{n}\left( e_{ik}\otimes a_{ik} \right)\left( e_{\ell j}\otimes b_{\ell j} \right)\\
                                                                               &= \sum_{i,j,k,\ell=1}^{n}e_{ik}e_{\ell j}\otimes a_{ik}b_{\ell j}\\
                                                                               &= \sum_{i,j,k=1}^{n}e_{ik}e_{kj}\otimes a_{ik}b_{kj}\\
                                                                               &= \sum_{i,j,k=1}^{n}e_{ij}\otimes a_{ik}b_{kj}\\
                                                                               &= \sum_{i,j=1}^{n}e_{ij}\otimes \left( \sum_{k=1}^{n}a_{ik}b_{kj} \right)\\
                                                                               &= \varphi\left( \left( \sum_{k=1}^{n}a_{ik}b_{kj} \right)_{ij} \right)\\
                                                                               &= \varphi\left( \left( a_{ij} \right)_{ij}\left( b_{ij} \right)_{ij} \right),
  \end{align*}
  meaning $\varphi$ is multiplicative.\newline

  Finally, we have
  \begin{align*}
    \varphi\left( \left( a_{ij} \right)_{ij} \right)^{\ast} &= \left( \sum_{i,j=1}^{n}e_{ij}\otimes a_{ij} \right)^{\ast}\\
                                                            &= \sum_{i,j=1}^{n}\left( e_{ij}\otimes a_{ij} \right)^{\ast}\\
                                                            &= \sum_{i,j=1}^{n}e_{ij}^{\ast}\otimes a_{ij}^{\ast}\\
                                                            &= \sum_{i,j=1}^{n}e_{ji}\otimes a_{ij}^{\ast}\\
                                                            &= \sum_{i,j=1}^{n}e_{ij}\otimes a_{ji}^{\ast}\\
                                                            &= \varphi\left( \left( a_{ji}^{\ast} \right)_{ij} \right)\\
                                                            &= \varphi\left( \left( a_{ij} \right)_{ij}^{\ast} \right),
  \end{align*}
  meaning that $\varphi$ is a $\ast$-isomorphism.
\end{proof}
\section{Remarks and Notes}%
There are a variety of norms that can be placed on tensor products of normed vector spaces and normed algebras. These are dealt with in depth in other definitions and formulations of nuclearity, but we will unfortunately not have the space to expand upon them to the fullest extent in this thesis. There is a little bit of discussion on the topic of norms on tensor products of $C^{\ast}$-algebras in the final section of Chapter \ref{ch:nuclearity}.\newline

We will use all these established foundations, implicitly and explicitly, in later chapters as we understand different formulations of amenability and how they interact with a wide variety of fields of math. We start by discussing the free group in Chapter \ref{ch:paradoxical_decompositions}, and then expanding on free vector spaces, algebras, and tensor products in later chapters.
