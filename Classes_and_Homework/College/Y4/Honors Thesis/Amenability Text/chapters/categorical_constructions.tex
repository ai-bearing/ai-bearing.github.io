We start by introducing some categorical constructions, such as free groups, free vector spaces, free algebras, and the group algebra, as well as understanding their universal properties. We will be using the various properties of these categorical constructions to further understand amenability and its various characterizations.
\section{Free Groups}%
Given a set $A$, we want to know how exactly we can create a group structure from the elements in $A$ such that they ``extend'' the set structure to the group. This will be the free group, an important construction that will appear in later chapters as we understand the properties of linear groups that contain subgroups isomorphic to some free group. 
\begin{definition}\label{def:generating_sets}
  Let $G$ be a group, and $S\subseteq G$ be a subset. We define the subgroup {generated by} $S$ to be
  \begin{align*}
    \left\langle S \right\rangle_{G} &= \bigcap \set{H | S\subseteq H,~H\text{ a subgroup}}.
  \end{align*}
  We say $S$ generates $G$ if $\left\langle S \right\rangle_{G} = G$.\newline

  Generated subgroups can be broadly characterized as follows:
  \begin{align*}
    \left\langle S \right\rangle_{G} &= \set{s_1^{a_1}s_2^{a_2}\cdots s_n^{a_n} | n\in\N,~s_1,\dots,s_n\in S,~a_1,\dots,a_n\in \set{-1,1}}.
  \end{align*}
  We say $\left\langle S \right\rangle_{G}$ is finitely generated if $\Card(S) < \infty$.\newline

  If $S$ is such that, for any $x\in S$, we have $x^{-1}\in S$, then we say $S$ is symmetric.
\end{definition}
To construct a free group, we begin by stating its universal property --- that is, its innate nature as an ``extension'' of a set-function into a group structure. Then, we will show that a more constructive definition of the free group satisfies this universal property. The following section draws heavily from \cite{loh_geometric_group_theory}, but will be slightly abbreviated so as to focus more on existence and the construction of the free group.
%There are two major ways we can conceive of the free group. One way (used in \cite{loh_geometric_group_theory}) characterizes the free group directly through the universal property --- the traditional definition of the free group is then shown to satisfy the universal property.\newline
%
%We will not be using this method, though, instead we will be using the construction in \cite{delaHarpe_topics_in_geometric_group_theory}. To start the construction of the free group, we will understand a more general categorical construction --- a free product of groups --- and then we will define the free group through the free product. 
\begin{definition}\label{def:free_group}
  Let $S$ be a set. A group $F$ containing $S$ is said to be freely generated if, for every group $G$, and every map $\phi\colon S\rightarrow G$, there is a unique group homomorphism $\varphi\colon F\rightarrow G$ that extends $\varphi$. The following diagram, where $\iota$ denotes the inclusion of $S$ into $F$, commutes:
  \begin{center}
\begin{tikzcd}
S \arrow[d, "\iota"', hook] \arrow[r, "\phi"] & G \\
F \arrow[ru, "\varphi"']                      &  
\end{tikzcd}
  \end{center}
We say $F$ is the {free group} generated by $S$.
\end{definition}
Intuitively, to construct the free group, if we have $a\mapsto \phi(a)$ between $S$ and $G$, then we will define $\varphi\left(a^n\right) = \phi(a)^n$ inside $F(S)$. Uniqueness will follow from the fact that we can take two groups that satisfy the universal property, $F$ and $F'$, and apply the universal property on set-valued functions between $S$ and $F$ and $S$ and $F'$ respectively. The formal proof of the construction of the free group is as follows.
\begin{proof}
  We will construct a group consisting of ``words'' made up of elements of $S$ and their inverses. This starts by considering the alphabet $A = S\cup \widehat{S}$, where $\widehat{S}$ is a disjoint copy of $S$ --- every $\hat{s}\in \widehat{S}$ will play the role of an inverse to $s$ in our group.
  \begin{itemize}
    \item Define $A^{\ast}$ to be the set of all words over the alphabet $A$, including the empty word, $\epsilon$. We define the operation $A^{\ast}\times A^{\ast}\rightarrow A^{\ast}$ by concatenating words, which is an associative operation with neutral element $\epsilon$.
    \item Define the equivalence relation $\sim$ generated by the following two relations, where for all $x,y\in A^{\ast}$ and $s\in S$, we have
      \begin{align*}
        xs\hat{s}y &\sim xy\\
        x\hat{s}sy &\sim xy.
      \end{align*}
      The equivalence classes with respect to $\sim$ will be denoted $\left[\cdot\right]$.\newline

      We have a well-defined composition $\left[x\right]\left[y\right] = \left[xy\right]$ mapping $F(S) \times F(S) \rightarrow F(S)$ for all $x,y\in A^{\ast}$.
  \end{itemize}
  We show that $F(S)$ with the concatenation operation is a group. Here, we see that $\left[\epsilon\right]$ is the neutral element for the composition, and associativity is inherited from associativity of concatenation in $A^{\ast}$. To show the existence of inverses, we define the inverse map inductively by taking $I\left(\epsilon\right) = \epsilon$, and
  \begin{align*}
    I\left(sx\right) &= I(x)\hat{s}\\
    I\left(\hat{s}x\right) &= I(x)s
  \end{align*}
  for all $x\in A^{\ast}$  and $s\in S$. Inductively, we can see that $I\left(I\left(x\right)\right) = x$ and
  \begin{align*}
    \left[I(x)\right]\left[x\right] &= \left[I(x)x\right]\\
                                    &= \left[\epsilon\right]\\
    \left[x\right]\left[I(x)\right] &= \left[xI(x)\right]\\
                                    &= \left[\epsilon\right].
  \end{align*}
  Thus, $F(S)$ is a group.\newline

  Now, we show $F(S)$ is freely generated. Let $i\colon S\rightarrow F(S)$ be the map that sends $s\mapsto \left[s\right]$. By our construction, we know that $i(S)\subseteq F(S)$ is a generating set for $F(S)$. We will show the universal property holds for $F(S)$.\newline

  To start, let $\phi\colon S\rightarrow G$ be a set-valued map between $S$ and an arbitrary group $G$. We construct $\phi^{\ast}\colon A^{\ast}\rightarrow G$ by taking
  \begin{align*}
    \epsilon &\mapsto e\\
    sx &\mapsto \phi(s)\phi^{\ast}\left(x\right)\\
    \hat{s}x &\mapsto \left(\phi(s)\right)^{-1}\phi^{\ast}\left(x\right)
  \end{align*}
  for all $x\in A^{\ast}$ and $s\in S$. This definition of $\phi^{\ast}$ is compatible with the equivalence relation on $A^{\ast}$, and we see that $\phi^{\ast}\left(xy\right) = \phi^{\ast}\left(x\right)\phi^{\ast}\left(y\right)$. Thus, we get a well-defined map $\varphi\colon F(S)\rightarrow G$, taking $\left[x\right]\mapsto \left[\phi^{\ast}\left(x\right)\right]$.\newline

  It remains to be shown that the map $i\colon S\rightarrow F(S)$ is injective, which will show that $F(S)$ is freely generated by $S$. Let $s_1,s_2\in S$, and consider the set-function $\phi\colon S\rightarrow \Z$ given by $\phi\left(s_1\right) = 1$ and $\phi\left(s_2\right) = -1$. Then, we must have
  \begin{align*}
    \varphi\left(i\left(s_1\right)\right) &= \phi\left(s_1\right)\\
                                          &= 1\\
                                          &\neq -1\\
                                          &= \phi\left(s_2\right)\\
                                          &= \varphi\left(i\left(s_2\right)\right).
  \end{align*}
  Thus, we have $i\left(s_1\right)\neq i\left(s_2\right)$, so $i$ is injective.
\end{proof}

%\begin{definition}[Free Monoid]
%  A monoid is a set with multiplication that is associative and contains a neutral element.\newline
%
%  Given a set $A$, the free monoid on $A$ is the set $W(A)$ of all finite sequences of elements of $A$. We write an element $W(A)$ as $w = a_1a_2\cdots a_n$, with $a_j\in A$ For each $j$. We identify $A$ with the subset $W(A)$ of words with length $1$.\newline
%
%  The operation on $W(A)$ is concatenation.
%\end{definition}
%
%\begin{definition}\label{def:free_product}
%  Let $\set{\Gamma_i}_{i\in I}$ be a family of groups. Set $A = \coprod_{i\in I}\Gamma_i = \set{\left(g_i,i\right) | g_i\in \Gamma_i,~i\in I}$ to be the coproduct of the family $\set{\Gamma_i}_{i\in I}$.\newline
%
%  Let $\sim$ be the equivalence relation generated by
%  \begin{align*}
%    we_iw' &\sim ww'\\
%    wabw' &\sim wcw',
%  \end{align*}
%  for all $w,w'\in W(A)$, where $e_i\in \Gamma_i$ is the neutral element, and $a,b,c\in \Gamma_i$ with $ab = c$ for some $i\in I$.\newline
%
%  The quotient $W(A) / \sim$ with the operation of concatenation is a group, known as the {free product} of the groups $\set{\Gamma_i}_{i\in I}$. We write it as
%  \begin{align*}
%    \bigstar_{i\in I}\Gamma_i.
%  \end{align*}
%  The inverse of the equivalence class for $w = a_1a_2\cdots a_n$ is $w^{-1} = a_{n}^{-1}a_{n-1}^{-1}\cdots a_{1}^{-1}$. The neutral element is $\epsilon$, denoting the empty word.\newline
%
%  A word $w = a_1a_2\cdots a_n\in W(A)$ with $a_j\in \Gamma_{i_j}$ is said to be {reduced} if $i_{j + 1}\neq i_j$ and $a_j \neq e_{i_j}$ for each $j$.
%\end{definition}
%It is the case that free products exist.
%\begin{proposition}\label{prop:reduced_words}
%  Let $\set{\Gamma_i}_{i\in I}$ be a family of groups, with $A = \coprod_{i\in I}\Gamma_i$, and $\bigstar_{i\in I}\Gamma_i = W(A) / \sim$ as in Definition \ref{def:free_product}.\newline
%
%  Then, any element in $\bigstar_{i\in I}\Gamma_i$ is represented by a unique reduced word in $W(A)$.
%\end{proposition}
%\begin{proof}
%  We start by showing existence. Consider an integer $n \geq 0$ and a reduced word $w = a_1a_2\cdots a_n$ in $W(A)$, an element $a\in A$, and the word $aw \in W(A)$.\newline
%
%  If $k$ is the index for which $a_1\in \Gamma_k$, we set
%  \begin{align*}
%    \mathcal{R}\left(aw\right) &= \begin{cases}
%      w & a = e_i\\
%      aa_1a_2\cdots a_n & a\in \Gamma_i,~a\neq e_i,~i\neq k\\
%      ba_2\cdots a_n & a\in \Gamma_k,aa_1 = b\neq e_k\\
%      a_2\cdots a_n & a\in \Gamma_k, a = a_1^{-1} \in \Gamma_k.
%    \end{cases}
%  \end{align*}
%  Then, $\mathcal{R}\left(aw\right)$ is another reduced word, and $\mathcal{R}\left(aw\right) \sim aw$ by our construction, meaning that any word $w\in W(A)$ is equivalent to some reduced word by inducting on the length of $w$.\newline
%
%  Now, we show uniqueness. For each $a\in A$, let $T\left(a\right) $ be the map $ w\xmapsto{T(a)} \mathcal{R}\left(aw\right)$, which is a self-map on the set of reduced words. For each $w = b_1b_2\cdots b_n$, we set $T(w) = T\left(b_1\right)T\left(b_2\right)\cdots T\left(b_n\right)$. For $a,b,c\in \Gamma_i$ with $ab = c$, we have $T\left(a\right)T\left(b\right) = T\left(c\right)$, and $T\left(e_i\right) = \epsilon$ for all $i\in I$.\newline
%
%  If $w$ is a reduced word, notice that $T\left(w\right)\left(\epsilon\right) = w$.\newline
%
%  Let $w$ be some word in $W(A)$ with $w_1,w_2$ being reduced words equivalent to $w$ under the equivalence relation $\sim$. Since $w_1\sim w_2$, we have $T\left(w_1\right) = T\left(w_2\right)$, and
%  \begin{align*}
%    w_1 &= T\left(w_1\right)\left(\epsilon\right)\\
%        &= T\left(w_2\right)\left(\epsilon\right)\\
%        &= w_2.
%  \end{align*}
%  Since $w_1 = w_2$, it is the case that the reduced representations of any word $w\in W(A)$ are unique.
%\end{proof}
%\begin{corollary}
%  If $\set{\Gamma_i}_{i\in I}$ and $\Gamma = \bigstar_{i\in I}\Gamma_i$ are as in Definition \ref{def:free_product}, then for each $i_0\in I$, the canonical inclusion
%  \begin{align*}
%    \iota\colon \Gamma_{i_0}\hookrightarrow \Gamma,
%  \end{align*}
%  where an element $a\in \Gamma_{i_0}$ maps to its one-letter reduced word representation in $\Gamma$, is injective.
%\end{corollary}
%\begin{proof}
%  For any $a\in \Gamma_{i_0}\setminus \set{e_{i_0}}$, the one-letter reduced word representation $\iota(a)$ is unique, and not equivalent to the empty word, meaning $\ker\left(\iota\right) = \set{e_{i_0}}$, so $\iota$ is injective.
%\end{proof}
%
%We can now define the free group as a special type of free product.
%\begin{definition}\label{def:free_group_as_product}
%  Let $X$ be a set, and for each $a\in X$, let $\left\langle a \right\rangle = \set{a^n}_{n\in \Z}$ be the formal infinite cyclic group generated by $a$, setting $a^0 = e_{\left\langle a \right\rangle}$ and $\left(a^n\right) \left(a^m\right) = a^{n+m}$.\newline
%
%  The free group on $X$ is the free product of the formal infinite cyclic groups generated by each element of $X$:
%  \begin{align*}
%    F(X) &= \bigstar_{a\in X}\left\langle a \right\rangle.
%  \end{align*}
%  As the free product is in one-to-one correspondence with the collection of reduced words over a collection $\set{\Gamma_i}_{i\in I}$, it is also the case that $F(X)$ is the collection of reduced words with the ``alphabet'' in $X\sqcup X^{-1}$.\newline
%
%  Given a free group $F(X)$, its rank is equal to $\left\vert X \right\vert$.
%\end{definition}
%We can now state and prove a universal property for free products of groups, which we will then apply to the case of the free group.
%\begin{theorem}[Universal Property for Free Products]
%  Let $\Gamma$ be a group, and let $\set{\Gamma_{i}}_{i\in I}$ be a family of groups. Let $\set{h_i\colon \Gamma_i\rightarrow \Gamma}_{i\in I}$ be a family of homomorphisms.\newline
%
%  Then, there exists a unique homomorphism $h\colon \bigstar_{i\in I}\Gamma_i \rightarrow \Gamma$ that extends each $h_{i_{0}}$ making the following diagram commute.
%  \begin{center}
%    % https://tikzcd.yichuanshen.de/#N4Igdg9gJgpgziAXAbVABwnAlgFyxMJZABgBpiBdUkANwEMAbAVxiRAB12BxOgW17oB9YFkHEAviHGl0mXPkIoAjOSq1GLNpx786UmSAzY8BImSVr6zVog7sARlgDmcHHQBOwrJyxgABACS4tp8Al6S4mowUE7wRKAAZu4QvEhkIDgQSABM1Ax09jAMAApyJoog7s4AFjgg1Faatj4QbvqJyamI6ZlIKurWbNVeYhEGSSk51L2I-fmFJWUKbFVOtfUDTSDVUhTiQA
%\begin{tikzcd}
%\Gamma_{i_0} \arrow[d, "\iota"'] \arrow[r, "h_{i_0}"] & \Gamma \\
%\bigstar_{i\in I}\Gamma_{i} \arrow[ru, "h"']          &       
%\end{tikzcd}
%  \end{center}
%  In particular, if $\Gamma$ is a group, and $\phi\colon X\rightarrow \Gamma$ is a set map, there exists a unique homomorphism $\Phi\colon F(X)\rightarrow \Gamma$ such that $\Phi(x) = \phi(x)$ for each $x\in X$.
%\end{theorem}
%\begin{proof}
%  For a reduced word $a_1a_2\cdots a_n\in \bigstar_{i\in I}\Gamma_i$, where $a_j\in \Gamma_{i_j}\setminus \set{e_{i_j}}$, and $i_{j+1} \neq i_j$ for each $j$, we set
%  \begin{align*}
%    h\left(w\right) &= h_{i_1}\left(a_1\right)h_{i_2}\left(a_2\right)\cdots h_{i_n}\left(a_n\right),
%  \end{align*}
%  which defines $h$ uniquely in terms of the homomorphisms $h_{i}$.
%\end{proof}
%In particular, the free group admits the following universal property.
%\begin{definition}
%  Let $S$ be a set, $G$ be a group, and let $\phi\colon S\rightarrow G$ be a set-valued function between $S$ and $G$. Then, there is a unique homomorphism $\varphi\colon F(S) \rightarrow G$ such that that the following diagram commutes.
%  \begin{center}
%\begin{tikzcd}
%S \arrow[d, "\iota"', hook] \arrow[r, "\phi"] & G \\
%F(S) \arrow[ru, "\varphi"']                      &  
%\end{tikzcd}
%  \end{center}
%\end{definition}
%Pairing the above universal property with the first isomorphism theorem from group theory, we see that if $G$ is any group with generating set $S$, then $G$ is isomorphic to the quotient $F(S) / N$ for some $N\trianglelefteq F(S)$.
%\subsection{The Ping Pong Lemma}%
%If we are given an arbitrary group, we may be curious as to whether or not the group (or a subgroup of it) is freely generated. The Ping Pong Lemma allows us to ascertain various sufficient conditions that yield a free group.
%\begin{theorem}[Ping Pong Lemma]\label{thm:ping_pong}
%  Let $G$ be a group that acts on a set $X$, and let $\Gamma_1,\Gamma_2$ be subgroups of $G$. Let $\Gamma = \left\langle \Gamma_1,\Gamma_2 \right\rangle$. Assume $\Gamma_1$ contains at least $3$ elements, and $\Gamma_2$ contains at least $2$ elements.\newline
%
%  Suppose there exist nonempty subsets $X_1,X_2\subseteq X$ with $X_1\triangle X_2 \neq \emptyset$ such that for all $\gamma\in \Gamma_1$ with $\gamma \neq e_{G}$,
%  \begin{align*}
%    \gamma\left(X_2\right)\subseteq X_1,
%  \end{align*}
%  and for all $\gamma \in \Gamma_2$ with $\gamma \neq e_G$,
%  \begin{align*}
%    \gamma\left(X_1\right)\subseteq X_2.
%  \end{align*}
%  Then, $\Gamma$ is isomorphic to the free product $\Gamma_1\star \Gamma_2$.
%\end{theorem}
%\begin{proof}
%  Let $w$ be a nonempty reduced word with letters in the disjoint union of $\Gamma_1\setminus \set{e_G}$ and $\Gamma_2\setminus \set{e_G}$. We must show that the element of $\Gamma$ defined by $w$ is not the identity.\newline
%
%  If $w = a_1b_1a_2b_2\cdots a_k$ with $a_1,\dots,a_k\in \Gamma_1\setminus \set{e_G}$ and $b_1,\dots,b_{k-1}\in \Gamma_{2}\setminus \set{e_G}$, then,
%  \begin{align*}
%    w\left(X_2\right) &= a_1b_1\cdots a_{k-1}b_{k-1}a_k\left(X_2\right)\\
%                      &\subseteq a_1b_1\cdots a_{k-1}b_{k-1}\left(X_1\right)\\
%                      &\subseteq a_1b_1\cdots a_{k-1}\left(X_2\right)\\
%                      &\vdots\\
%                      &\subseteq a_1\left(X_2\right)\\
%                      &\subseteq X_1.
%  \end{align*}
%  Seeing as $X_2\nsubseteq X_1$ (by the definition of symmetric difference), it is the case that $w\neq e_{G}$.\newline
%
%  If $w = b_1a_2b_2a_2\cdots b_k$, we select $a\in \Gamma_1\setminus \set{e_G}$, and we find that $awa^{-1}\neq e_G$, meaning $w\neq e_G$. Similarly, if $w = a_1b_1\cdots a_kb_k$, we select $a\in \Gamma_1\setminus \set{e_G,a_{1}^{-1}}$, similarly finding that $awa^{-1}\neq e_{G}$. If $w = b_1a_2b_2\cdots a_k$, then we select $a\in \Gamma_1\setminus \set{1,a_k}$, and find $awa^{-1}\neq e_G$.
%\end{proof}
%
%We can refine Theorem \ref{thm:ping_pong} to the case of ``doubles'' wherein we find a different (yet more readily applicable) sufficient condition for a group that contains a copy of the free group on two generators.
%\begin{corollary}[Ping Pong Lemma for ``Doubles'']\label{corollary:ping_pong_doubles}
%  Let $G$ act on $X$, and let $A_{+}, A_{-},B_{+},B_{-}$ be disjoint subsets of $X$ whose union is not equal to $X$. Then, if
%  \begin{align*}
%    a\cdot \left(X\setminus A_{-}\right) &\subseteq A_{+}\\
%    a^{-1}\cdot \left(X\setminus A_{+}\right) &\subseteq A_{-}\\
%    b\cdot \left(X\setminus B_{-}\right) &\subseteq B_{+}\\
%    b^{-1}\cdot \left(X\setminus B_{+}\right) &\subseteq B_{-},
%  \end{align*}
%  then it is the case that $\left\langle a,b \right\rangle$ is isomorphic to the free group on two generators.
%\end{corollary}
%\begin{proof}
%  We let $A = A_{+}\sqcup A_{-}$, $B = B_{+}\sqcup B_{-}$, $\Gamma_1 = \left\langle a \right\rangle$, and $\Gamma_2 = \left\langle b \right\rangle$. Then, $A,B,\Gamma_1,\Gamma_2$ satisfy the conditions for Theorem \ref{thm:ping_pong}.
%\end{proof}
%\begin{remark}
%Instead of typing out ``the free group on two generators,'' we will henceforth use $F(a,b)$ to refer to the free group on two generators.
%\end{remark}
%
%We can apply Theorem \ref{thm:ping_pong} to show the existence of a set of isometries of $\R^n$ that is isomorphic to the free group on two generators.
%\begin{definition}[Special Orthogonal Group]\label{thm:free_group_so3}
%  For $n\in \N$, we define $\text{SO}(n)$ to be the group of all real $n\times n$ matrices $A$ such that $A^{T} = A^{-1}$ and $\det(A) = 1$.
%\end{definition}
%In terms of an isometry of $\R^3$, the group $\text{SO}(3)$ denotes the set of all rotations about any line through the origin.
%\begin{theorem}
%  There are elements $a,b\in \text{SO}(3)$ such that $\left\langle a,b \right\rangle_{\text{SO}(3)} \cong F(a,b)$.
%\end{theorem}
%\begin{proof}
%  We let
%  \begin{align*}
%    a &= \begin{pmatrix}3/5 & 4/5 & 0 \\ -4/5 & 3/5 & 0 \\ 0 & 0 & 1\end{pmatrix}\\
%    a^{-1} &= \begin{pmatrix}3/5 & -4/5 & 0 \\ 4/5 & 3/5 & 0 \\ 0 & 0 & 1\end{pmatrix}\\
%    b &= \begin{pmatrix}1 & 0 & 0 \\ 0 & 3/5 & -4/5 \\ 0 & 4/5 & 3/5\end{pmatrix}\\
%    b^{-1} &= \begin{pmatrix}1 & 0 & 0 \\ 0 & 3/5 & 4/5 \\ 0 & -4/5 & 3/5\end{pmatrix}.
%  \end{align*}
%  We specify
%  \begin{align*}
%    X &= A_{+} \sqcup A_{-} \sqcup B_{+} \sqcup B_{-} \sqcup \begin{pmatrix}0\\1\\0\end{pmatrix},
%  \end{align*}
%  where
%  \begin{align*}
%    A_{+} &= \set{\frac{1}{5^{k}} \begin{pmatrix}x\\y\\z\end{pmatrix} | k\in \Z, x \equiv 3y\text{ modulo $5$}, z\equiv0\text{ modulo $5$}}\\
%    A_{-} &= \set{\frac{1}{5^{k}} \begin{pmatrix}x\\y\\z\end{pmatrix} | k\in \Z, x \equiv -3y\text{ modulo $5$}, z\equiv 0\text{ modulo $5$}}\\
%    B_{+} &= \set{\frac{1}{5^{k}} \begin{pmatrix}x\\y\\z\end{pmatrix} | k\in \Z, z \equiv 3y\text{ modulo $5$}, x\equiv 0\text{ modulo $5$}}\\
%    B_{-} &= \set{\frac{1}{5^{k}} \begin{pmatrix}x\\y\\z\end{pmatrix} | k\in \Z, z \equiv -3y\text{ modulo $5$}, x\equiv 0\text{ modulo $5$}}.
%  \end{align*}
%  To verify that the conditions of Theorem \ref{thm:ping_pong} hold, we calculate
%  \begin{align*}
%    \begin{pmatrix}3/5 & 4/5 & 0 \\ -4/5 & 3/5 & 0 \\ 0 & 0 & 1\end{pmatrix}\left(\frac{1}{5^k} \begin{pmatrix}x\\y\\z\end{pmatrix}\right) &= \frac{1}{5^{k+1}} \begin{pmatrix}3x + 4y \\ -4x + 3y \\ 5z\end{pmatrix}\tag*{(1)}\\
%    \begin{pmatrix}3/5 & -4/5 & 0 \\ 4/5 & 3/5 & 0 \\ 0 & 0 & 1\end{pmatrix} \left(\frac{1}{5^k} \begin{pmatrix}x\\y\\z\end{pmatrix}\right) &= \frac{1}{5^{k+1}} \begin{pmatrix}3x - 4y \\ 4x + 3y \\ 5z\end{pmatrix}\tag*{(2)}\\
%    \begin{pmatrix}1 & 0 & 0 \\ 0 & 3/5 & -4/5 \\ 0 & 4/5 & 3/5\end{pmatrix}\left(\frac{1}{5^{k}} \begin{pmatrix}x\\y\\z\end{pmatrix}\right) &= \frac{1}{5^{k+1}} \begin{pmatrix}5x \\ 3y- 4z \\ 4y + 3z\end{pmatrix}\tag*{(3)}\\
%    \begin{pmatrix}1 & 0 & 0 \\ 0 & 3/5 & 4/5 \\ 0 & -4/5 & 3/5\end{pmatrix} \left(\frac{1}{5^{k}} \begin{pmatrix}x\\y\\z\end{pmatrix}\right) &= \frac{1}{5^{k+1}} \begin{pmatrix}5x \\ 3y + 4z \\ -4y + 3z\end{pmatrix}.\tag*{(4)}
%  \end{align*}
%  We verify that the conditions for Corollary \ref{corollary:ping_pong_doubles} hold for each of these four conditions.
%  \begin{enumerate}[(1)]
%    \item For any vector
%      \begin{align*}
%        \frac{1}{5^{k}} \begin{pmatrix}x\\y\\z\end{pmatrix} \notin A_{-},
%      \end{align*}
%      we see that $k+1\in \Z$, $x' = 3x + 4y \equiv 3\left(-4x + 3y\right)$  modulo $5$, and that $z' = 5z\equiv 0$ modulo $5$.
%    \item For any vector
%      \begin{align*}
%        \frac{1}{5^{k}} \begin{pmatrix}x\\y\\z\end{pmatrix} \notin A_{+},
%      \end{align*}
%      we see that $k+1\in \Z$, $x' = 3x - 4y\equiv -3\left(4x + 3y\right)$ modulo $5$, and $z' = 5z \equiv 0$ modulo $5$.
%    \item For any vector
%      \begin{align*}
%        \frac{1}{5^{k}} \begin{pmatrix}x\\y\\z\end{pmatrix}\notin B_{-},
%      \end{align*}
%      we see that $k+1\in \Z$, $z' = 4y + 3z \equiv 3\left(3y-4z\right)$ modulo $5$, and $x' = 5x\equiv 0$ modulo $5$.
%    \item For any vector
%      \begin{align*}
%        \frac{1}{5^{k}} \begin{pmatrix}x\\y\\z\end{pmatrix}\notin B_{+},
%      \end{align*}
%      we see that $k+1\in \Z$, $z' = -4y + 3z \equiv -3\left(3y + 4z\right)$ modulo $5$, and $x' = 5x \equiv 0$ modulo $5$.
%  \end{enumerate}
%  Thus, by Theorem \ref{thm:ping_pong} and Corollary \ref{corollary:ping_pong_doubles}, it is the case that $\left\langle a,b \right\rangle\cong F(a,b)$.
%\end{proof}
\section{Free Vector Spaces}%
Given a set $A$, just as we are able to construct a free group, we can take any set $A$ and construct a ``universal'' vector space out of the set. The free vector space (as it is known) is the universal object that extends any set-valued function into a linear map, treating elements of the set as its basis (see Definition \ref{def:basis}). We are interested in the case of the free vector space over the complex numbers, but note that the following definition of the free vector space applies over any field. 
\begin{theorem}
  Let $\Gamma$ be a nonempty set. There is a vector space, $\C\left[\Gamma\right]$, with $\Dim\left(\C\left[\Gamma\right]\right) = \Card\left(\Gamma\right)$, and an injective map $\delta\colon \Gamma\rightarrow \C\left[\Gamma\right]$ such that the following universal property holds: if $V$ is a $\C$-vector space, and $\phi\colon \Gamma\rightarrow V$ is a set-valued function, then there is a unique linear map $T_{\phi}\colon \C\left[\Gamma\right]\rightarrow V$ such that $T_{\phi}\circ \delta = \phi$.
  \begin{center}
    % https://tikzcd.yichuanshen.de/#N4Igdg9gJgpgziAXAbVABwnAlgFyxMJZABgBpiBdUkANwEMAbAVxiRAB12BxOgW17ogAvqXSZc+QigCM5KrUYs2nAMLJOPfnQrDRIDNjwEis6fPrNWiEADVh8mFADm8IqABmAJwi8kZEDgQSLIKlsrssAw4giIe3r6IIYFIAEzUDHQARjAMAAriRlIgDDDuOCDUFkrWACoA+sCcaAAWWEK6cT5+1MmIacVZOfmGkmyeWE7N5ZWKVhzsLVj2QkA
\begin{tikzcd}
\Gamma \arrow[r, "\delta"] \arrow[rd, "\phi"'] & {\C[\Gamma]} \arrow[d, "T_{\phi}"] \\
                                               & V                                 
\end{tikzcd}
  \end{center}
\end{theorem}
\begin{proof}
  Consider the linear subspace of finitely supported functions, $\C\left[\Gamma\right]\subseteq \mathcal{F}\left(\Gamma,\C\right)$. For each $t\in \Gamma$, we define
  \begin{align*}
    \delta_t\left(s\right) &= \begin{cases}
      1 & s=t\\
      0 & \text{else}
    \end{cases}.
  \end{align*}
    We see that $\delta_t\neq \delta_s$ whenever $s\neq t$, meaning that the map $\delta\colon \Gamma\rightarrow \C\left[\Gamma\right]$, defined by $s \mapsto \delta_s$, is injective.\newline

    We will show that $\set{\delta_s}_{s\in \Gamma}$ is a linear basis for $\C\left[\Gamma\right]$. If $f\in \F\left[\Gamma\right]$, with $\supp\left(f\right) = \set{s_1,\dots,s_n}\subseteq \Gamma$, we set $\alpha_j = f\left(t_j\right)$, and see that
    \begin{align*}
      f &= \sum_{j=1}^{n}\alpha_j\delta_{s_j},
    \end{align*}
    which shows that $\set{\delta_s}_{s\in\Gamma}$ is a spanning set.\newline

    To show that $\set{\delta_s}_{s\in\Gamma}$ is linearly independent, consider $g = \sum_{j=1}^{n}\alpha_j\delta_{s_j}\in \F\left[\Gamma\right]$ such that $g = 0$. Then, $g(t) = 0$ for all $t\in\Gamma$, and in particular, $g\left(s_i\right) = 0$ for every $1 \leq i \leq n$. Thus, we have
    \begin{align*}
      0 &= g\left(s_j\right)\\
        &= \sum_{j=1}^{n}\alpha_j\delta_{s_j}\left(s_i\right)\\
        &= \alpha_i,
    \end{align*}
    so $\alpha_j = 0$ for each $j$. Thus, $\set{\delta_s}_{s\in \Gamma}$ is linearly independent.\newline

    Turning to the universal property, we define $T_{\phi}\colon \F\left[\Gamma\right]\rightarrow V$ in terms of $\phi$ as follows:
    \begin{align*}
      T_{\phi}\left(\sum_{j=1}^{n}\alpha_j\delta_{s_j}\right) &= \sum_{j=1}^{n}\alpha_j\phi\left(s_j\right).
    \end{align*}
    This yields an expression of $T_{\phi}$ uniquely in terms of $\phi$ and $\delta$, thereby satisfying the universal property.
\end{proof}
\begin{example}
  Let $z$ be an abstract variable, and consider the set of ``formal powers'' of $z$, $\set{z^k}_{k\in\N}$. Then, the free vector space generated by this set, $\C\left[z\right]$, is the set of all polynomials with coefficients in $\C$. By the universal property, we know that every polynomial $p\in \C\left[z\right]$ has a unique expression $p = \sum_{j=0}^{n}a_jz^j$.
\end{example}
%\subsection{The First Isomorphism Theorem}%
%The universal property of free vector spaces carries nicely into perhaps the most fundamental theorem in all of algebra,\footnote{Not to be confused with the fundamental theorem \textit{of} algebra.} which allows us to characterize linear maps, subspaces, and quotient spaces.
%\begin{definition}
%  Let $X$ and $Y$ be vector spaces.
%  \begin{itemize}
%    \item A subset $W\subseteq X$ is known as a subspace of $X$ if, for any $x,y\in W$, the element $x + \alpha y\in W$ for all $\alpha \in \C$.
%    \item If $W\subseteq X$ is a subspace, we may define the equivalence relation $x \sim_{W} y$ if and only if $y-x \in W$. The collection of equivalence classes under this relation is a subspace of $X$, known as the quotient of $X$ by $W$, and is denoted $X/W$.\newline
%
%      Elements of $X/W$ are usually written as $x + W$. Additionally, the space $X/W$ admits a canonical surjective quotient map $\pi\colon X\rightarrow X/W$ that sends $x\mapsto x + W$.
%    \item If $T\colon X\rightarrow Y$ is a linear map, then the following four are subspaces:
%      \begin{align*}
%        \ker\left(T\right) &= \set{x\in X | T(x) = 0_Y}\\
%        \img\left(T\right) &= \set{y\in Y | T(x) = y\text{ for some }x\in X}\\
%        \coker(T) &= Y/\img(T)\\
%        \coim(T) &= A/\ker(T).
%      \end{align*}
%  \end{itemize}
%\end{definition}
%\begin{theorem}[First Isomorphism Theorem]
%  Let $X$ and $Y$ be vector spaces, and let $T\colon X\rightarrow Y$ be a linear map. If $W$ is a subspace of $X$ such that $W\subseteq \ker(T)$, then there is a unique linear map $\widetilde{T}\colon X/W \rightarrow Y$ such that $\widetilde{T}\circ \pi = T$.\newline
%
%  Moreover, if $W = \ker(T)$, then $\widetilde{T}$ is injective, and $X/\ker(T)\cong \img(T)$.
%\end{theorem}
%\begin{proof}
%  Let $\widetilde{T}\colon X/W\rightarrow Y$ be defined by $\widetilde{T}\left(x + W\right) = T(x)$. Note that if $x + W = y + W$, then $x-y\in \ker(T)$, so $\widetilde{T}\left((x-y) + W\right) = T(x-y) = 0$, so $T(x) = T(y)$, so $\widetilde{T}(x+W) = \widetilde{T}(y+W)$. Thus, $\widetilde{T}$ is well-defined, and satisfies $\widetilde{T} \circ \pi = T$.\newline
%
%  Now, if $W = \ker(T)$, then $\widetilde{T}(x+W) = 0$ if and only if $x\in \ker(T)$, so $x + W = 0_{X/W}$.
%\end{proof}
%\begin{corollary}
%  If $\varphi\colon X\rightarrow \C$ is a linear functional, then $\varphi$ is onto if and only if $\varphi\neq 0$.
%\end{corollary}
\section{Free Algebras and the Group $\ast$-algebra}%
Chapter 8 of this thesis will be focused on understanding the properties of the (reduced) group $C^{\ast}$-algebra. This will require some background in the theory of algebras, so we will understand the purely algebraic properties here before diving into the analytic properties in Chapter 5.
\begin{definition}
  Let $A$ be an algebra over $\C$ (see Definition \ref{def:vector_space_and_algebra}). An involution on $A$ is a unary operation $\ast\colon A\rightarrow A$ that satisfies the following, for all $a,b\in A$ and $\alpha\in\C$:
  \begin{itemize}
    \item $\left(a^{\ast}\right)^{\ast} = a$;
    \item $\left(a+b\right)^{\ast} = a^{\ast} + b^{\ast}$;
    \item $\left(\alpha a\right)^{\ast} = \overline{\alpha} a^{\ast}$;
    \item $\left(ab\right)^{\ast} = b^{\ast}a^{\ast}$.
  \end{itemize}
  If $A$ is equipped with an involution, we say $A$ is a $\ast$-algebra.
\end{definition}
\begin{example}
  Consider the algebra of $n\times n$ matrices over $\C$, $\Mat_n\left(\C\right)$, with element-wise addition and scalar multiplication, as well as traditional matrix multiplication. From linear algebra, we know that if $T\in \Mat_n\left(\C\right)$, then $T$ admits a unique adjoint map (or conjugate transpose), $T^{\ast}$, such that for any $x,y\in \C^n$, $ \iprod{T\left(x\right)}{y} =  \iprod{x}{T^{\ast}\left(y\right)}$, where $ \iprod{\cdot}{\cdot} $ denotes the complex inner product. The map $\ast\colon \Mat_n\left(\C\right)\rightarrow \Mat_n\left(\C\right)$, given by $T\mapsto T^{\ast}$, satisfies the definition of an involution.\newline

  If $x,y\in \C^n$, $\alpha\in\C$, and $T,S\in \Mat_n\left(\C\right)$,
  \begin{align*}
    \iprod{T\left(x\right)}{y} &= \iprod{x}{T^{\ast}\left(y\right)}\\
                               &= \overline{ \iprod{T^{\ast}\left(y\right)}{x} }\\
                               &= \overline{ \iprod{y}{T^{\ast\ast}\left(x\right)} }\\
                               &= \iprod{T^{\ast\ast}\left(x\right)}{y}\\
                               \\
    \iprod{\left(T+S\right)\left(x\right)}{y} &= \iprod{T\left(x\right)}{y} + \iprod{S\left(x\right)}{y}\\
                                              &= \iprod{x}{T^{\ast}\left(y\right)} + \iprod{x}{S^{\ast}\left(y\right)}\\
                                              &= \iprod{x}{\left(T^{\ast} + S^{\ast}\right)\left(y\right)}\\
                                              \\
    \iprod{\alpha T\left(x\right)}{y} &= \iprod{T\left(\alpha x\right)}{y}\\
                                      &= \iprod{\alpha x}{T^{\ast}\left(y\right)}\\
                                      &= \iprod{x}{\overline{\alpha}T^{\ast}\left(y\right)}\\
                                      \\
    \iprod{TS\left(x\right)}{y} &= \iprod{S\left(x\right)}{T^{\ast}\left(y\right)}\\
                                &= \iprod{x}{S^{\ast}T^{\ast}\left(y\right)}.
  \end{align*}
  Thus, we can see that $\Mat_n\left(\C\right)$ is a $\ast$-algebra.
\end{example}
\begin{definition}
  Let $A$ be a $\ast$-algebra, and let $B\subseteq A$.
  \begin{itemize}
    \item We say $B$ is self-adjoint (or $\ast$-closed) if for any $x\in B$, $x^{\ast}\in B$.
    \item We say $B$ is a subalgebra of $A$ if $B\subseteq A$ is a linear subspace and for any $b_1,b_2\in B$, $b_1b_2\in B$. If $B$ is $\ast$-closed, then we say $B$ is a $\ast$-subalgebra.
    \item If $B$ is a subalgebra such that, for any $b\in B$ and $a\in A$, $ab\in B$ and $ba\in B$, then $B$ is an ideal. If $B$ is $\ast$-closed, then we say $B$ is a $\ast$-ideal.
  \end{itemize}
  If $J\subseteq A$ is a $\ast$-ideal, the linear space $A/J$ admits multiplication and involution, defined by
  \begin{align*}
    \left(a+J\right)\left(b+J\right) &= ab + J\\
    \left(a+J\right)^{\ast} &= a^{\ast}+J.
  \end{align*}
  For any $a\in A$, the $\ast$-ideal generated by $a$ is denoted
  \begin{align*}
    \operatorname{ideal}\left(a\right) &= \bigcap\set{J\subseteq A | a\in J\text{ and }J\text{ is a $\ast$-ideal} }.
  \end{align*}
  We say an ideal $J\subseteq A$ is maximal if $J$ is a proper ideal in $A$ and, if $J\subseteq I$ for some ideal $I$, then $I = J$ or $I = A$.
\end{definition}
Just as there are free groups and free vector spaces, we can also talk about free algebras. In Chapter 8, we will construct special norms on free algebras to elucidate properties of the underlying group.\newline

Similar to a free group, the free algebra (or free $\ast$-algebra) is constructed by taking a certain collection of ``words'' over a set of symbols, and then, if desired, ``modding out'' by the ideal generated by a set of relations. We formalize this in steps.
\begin{definition}
  Let $E=\set{x_i}_{i\in I}$ be a collection of symbols that may not commute. The space of all polynomials over $E$ is the free vector space over the set of words formed by symbols in $E$,
  \begin{align*}
    \Gamma_E &= \set{x_{i_1}x_{i_2}\cdots x_{i_n} | n\in\N,i_1,\dots,i_n\in I}.
  \end{align*}
  We denote this space $\C \left\langle E \right\rangle$.\newline

  In the free vector space $\C \left\langle E \right\rangle$, we may define multiplication by concatenation:
  \begin{align*}
    \left(x_{i_1}x_{i_2}\cdots x_{i_n}\right)\left(x_{j_1}x_{j_2}\cdots x_{j_m}\right) &= x_{i_1}x_{i_2}\cdots x_{i_n}x_{j_1}x_{j_2}\cdots x_{j_m},
  \end{align*}
  where $i_1,\dots,i_n,j_1,\dots,j_m\in I$. The space $\C\left\langle E \right\rangle$, equipped with multiplication by concatenation, is known as the free algebra on $E$.\newline

  To turn $\C\left\langle E \right\rangle$ into a $\ast$-algebra, we define the formal set $E^{\ast} = \set{x_{i}^{\ast}}_{i\in I}$, and define the involution on $\C\left\langle E\cup E^{\ast} \right\rangle$ by taking
  \begin{align*}
    \left(\alpha x_{i_1}^{\ve_1}x_{i_2}^{\ve_2}\cdots x_{i_n}^{\ve_n}\right)^{\ast} &= \overline{\alpha}x_{i_n}^{\delta_n}x_{i_{n-1}}^{\delta_{n-1}}\cdots x_{i_2}^{\delta_2}x_{i_1}^{\delta_1},
  \end{align*}
  where
  \begin{align*}
    \delta_j &= \begin{cases}
      \ast & \ve_j = 1\\
      1 & \ve_j = \ast
    \end{cases}.
  \end{align*}
  The set $\C\left\langle E\cup E^{\ast} \right\rangle$ with the involution defined above is known as the free $\ast$-algebra on $E$, and is usually denoted $\mathbb{A}^{\ast}\left(E\right)$.\newline

  If $R\subseteq \mathbb{A}^{\ast}\left(E\right)$ is a collection of relations, we let $I(R) = \operatorname{ideal}\left(R\right)$. Then, the quotient algebra
  \begin{align*}
    \mathbb{A}^{\ast}\left(E|R\right) &= \mathbb{A}^{\ast}\left(E\right)/I(R)
  \end{align*}
  is known as the universal $\ast$-algebra on $E$ with relations $R$.
\end{definition}
One of the most important $\ast$-algebras we will study is generated from a group by taking the free vector space over the group.
\begin{definition}
  Let $\Gamma$ be a group with identity element $e$, and let $\C\left[\Gamma\right]$ be the free vector space generated by $\Gamma$. We define a multiplication $f \ast g$, where $f,g\in \C\left[\Gamma\right]$ are finitely supported functions, by convolution:
  \begin{align*}
    f\ast g(s) &= \sum_{t\in\Gamma}f(t)g\left(t^{-1}s\right)\\
               &= \sum_{r\in\Gamma}f\left(sr^{-1}\right)g\left(r\right).
  \end{align*}
  The involution on $\C\left[\Gamma\right]$ is defined by $f^{\ast}\left(t\right) = \overline{f\left(t^{-1}\right)}$. The multiplicative identity is $\delta_e$, and multiplication satisfies $\delta_s\ast \delta_t = \delta_{st}$.
\end{definition}

