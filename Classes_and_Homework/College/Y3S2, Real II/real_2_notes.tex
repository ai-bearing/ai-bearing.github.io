\documentclass[8pt]{extarticle}
\title{}
\author{}
\date{}
\usepackage[shortlabels]{enumitem}


%paper setup
\usepackage{geometry}
\geometry{letterpaper, portrait, margin=1in}
\usepackage{fancyhdr}
% sans serif font:
\usepackage{cmbright}
%symbols
\usepackage{amsmath}
\usepackage{bigints}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{mathtools}
\usepackage{bbm}
\usepackage{bbold}
\usepackage[hidelinks]{hyperref}
\usepackage{gensymb}
\usepackage{multirow,array}
\usepackage{multicol}

\newtheorem*{remark}{Remark}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}

%chemistry stuff
%\usepackage[version=4]{mhchem}
%\usepackage{chemfig}

%plotting
\usepackage{pgfplots}
\usepackage{tikz}
\tikzset{middleweight/.style={pos = 0.5}}
%\tikzset{weight/.style={pos = 0.5, fill = white}}
%\tikzset{lateweight/.style={pos = 0.75, fill = white}}
%\tikzset{earlyweight/.style={pos = 0.25, fill=white}}

%\usepackage{natbib}

%graphics stuff
\usepackage{graphicx}
\graphicspath{ {./images/} }
\usepackage[style=numeric, backend=biber]{biblatex} % Use the numeric style for Vancouver
\addbibresource{the_bibliography.bib}
%code stuff
%when using minted, make sure to add the -shell-escape flag
%you can use lstlisting if you don't want to use minted
%\usepackage{minted}
%\usemintedstyle{pastie}
%\newminted[javacode]{java}{frame=lines,framesep=2mm,linenos=true,fontsize=\footnotesize,tabsize=3,autogobble,}
%\newminted[cppcode]{cpp}{frame=lines,framesep=2mm,linenos=true,fontsize=\footnotesize,tabsize=3,autogobble,}

%\usepackage{listings}
%\usepackage{color}
%\definecolor{dkgreen}{rgb}{0,0.6,0}
%\definecolor{gray}{rgb}{0.5,0.5,0.5}
%\definecolor{mauve}{rgb}{0.58,0,0.82}
%
%\lstset{frame=tb,
%	language=Java,
%	aboveskip=3mm,
%	belowskip=3mm,
%	showstringspaces=false,
%	columns=flexible,
%	basicstyle={\small\ttfamily},
%	numbers=none,
%	numberstyle=\tiny\color{gray},
%	keywordstyle=\color{blue},
%	commentstyle=\color{dkgreen},
%	stringstyle=\color{mauve},
%	breaklines=true,
%	breakatwhitespace=true,
%	tabsize=3
%}
% text + color boxes
\usepackage[most]{tcolorbox}
\tcbuselibrary{breakable}
\tcbuselibrary{skins}
\newtcolorbox{problem}[1]{colback=white,enhanced,title={\small #1},
          attach boxed title to top center=
{yshift=-\tcboxedtitleheight/2},
boxed title style={size=small,colback=black!60!white}, sharp corners, breakable}
%including PDFs
%\usepackage{pdfpages}
\setlength{\parindent}{0pt}
\usepackage{cancel}
\pagestyle{fancy}
\fancyhf{}
\rhead{Avinash Iyer}
\lhead{Real Analysis II: Class Notes}
\newcommand{\card}{\text{card}}
\newcommand{\ran}{\text{ran}}
\newcommand{\N}{\mathbbm{N}}
\newcommand{\Q}{\mathbbm{Q}}
\newcommand{\Z}{\mathbbm{Z}}
\newcommand{\R}{\mathbbm{R}}
\setcounter{secnumdepth}{0}
\begin{document}
\section{Normed Vector Spaces}%
\subsection{Vector Spaces}%
Throughout, $\mathbbm{F} = \R$ or $\mathbbm{C}$. A \textbf{vector space} over $\mathbbm{F}$ is a nonempty set $V$ equipped with two operations: vector addition and scalar multiplication.
\begin{align*}
  V\times V \xrightarrow{+} V\\
  (v,w)\mapsto v+w \tag*{Vector Addition}\\
  F\times V \rightarrow V\\
  (\alpha,v)\mapsto \alpha v \tag*{Scalar Multiplication}
\end{align*}
The vector space is an Abelian group, where $u,v,w\in V$ and $\alpha,\beta\in \mathbbm{F}$, we have:
\begin{enumerate}[(i)]
  \item $u+(v+w) = (u+v)+w$
  \item $\exists 0_v\in V$ with $\forall v\in V,~0_v + v = v + 0_v = v$
  \item $(\forall v\in V)(\exists w\in V)$ with $v+w = 0_v$
  \item $\forall v,w\in V,~v+w = w+v$
  \item $\alpha(v+w) = \alpha v + \alpha w,~(\alpha + \beta)v = \alpha v + \beta v$
  \item $\alpha(\beta w) = (\alpha\beta)w$
  \item $1\cdot v = v$
\end{enumerate}
\textbf{Remarks:}
\begin{enumerate}[(a)]
  \item $0_v$ is unique and known as the zero vector.
  \item The vector $w$ in (iii) is unique, and denoted $-v$.
  \item $0\cdot v = 0_v$
  \item $(-1)\cdot v = -v$
  \item Property (iv) follows from all the other axioms.
  \item For $n\in\N$, $n\cdot v = \underbrace{v+v+\cdots+v}_{n~\text{times}}$
\end{enumerate}
\subsection{Subspaces}%
Let $V$ be a vector space over $\mathbbm{F}$. A \textbf{subspace} is a nonempty subset $W\subseteq V$ satisfying the following:
\begin{enumerate}[(i)]
  \item $w\in W,\alpha\in \mathbbm{F}\rightarrow \alpha w \in W$.
  \item $w_1,w_2\in W \Rightarrow w_1 + w_2\in W$.
\end{enumerate}
\begin{description}
  \item[Remark:] $0_v$ is always a member of any subspace; a subspace is also a vector space.
\end{description}
\subsubsection{Proposition: Intersection of Subspaces}%
If $\{W_i\}_{i\in I}$ is a family of subspaces of $V$, then, $\bigcap W_i$ is a subspace of $V$.
\subsubsection{Proposition: Union of Subspaces}%
It is not the case that the union of subspaces of $V$ also a subspace. For example, consider $\R^2$ with the traditional vector space operations:
\begin{align*}
  \begin{pmatrix}x\\y\end{pmatrix} + \begin{pmatrix}x'\\y'\end{pmatrix} &= \begin{pmatrix}x+x'\\y+y'\end{pmatrix}\\
  \alpha \begin{pmatrix}x\\y\end{pmatrix} &= \begin{pmatrix}\alpha x\\\alpha y\end{pmatrix}
\end{align*}
If $W_1,W_2\in V$ are subspaces such that $W_1 \cup W_2$ is a subspace, then $W_1\subseteq W_2$ or $W_2\subseteq W_1$.
\subsubsection{Generated Subspaces}%
Let $S\subseteq V$ be any subset of a vector space $V$. Then,
\begin{align*}
  \text{span}(S) &= \left\{\sum_{j=1}^{n}\alpha_jv_j\mid \alpha_1,\dots,\alpha_n\in \mathbbm{F},v_1,\dots,v_n\in S\right\}
\end{align*}
\begin{description}
  \item[Remarks:]\hfill
    \begin{itemize}
      \item $\text{span}(S)\subseteq V$ is a subspace.
      \item $\text{span}(S) = \bigcap W$, where $S\subseteq W$ and $W\subseteq V$ is a subspace. Thus, $\text{span}(S)$ is the ``smallest'' subspace containing $S$, or the subspace generated by $S$.
    \end{itemize}
\end{description}
\subsubsection{Proposition: Quotient Group on Vector Space}%
Let $V$ be a vector space, and let $W\subseteq V$ is a subspace. Define $u\sim_{W} v\leftrightarrow u-v\in W$.
\begin{enumerate}[(1)]
  \item $\sim_W$ is an equivalence relation.
  \item If $[v]_W$ denotes the equivalence class of $v$, then $[v]_W = v+W = \{v+w|w\in W\}$.
  \item $V/W:= \{[v]_W|v\in V\}$ is a vector space with $[v_1]_W + [v_2]_W = [v_1+v_2]_W$ and $\alpha[v]_W = [\alpha v]_W$.
\end{enumerate}
\begin{description}
  \item[Proof of (1):]\hfill
    \begin{itemize}
      \item Reflexive: $u\sim_W u$, since $u-u = 0\in W$.
      \item Transitive: Suppose $u\sim_W v$, and $v\sim_W z$. Then, $u-v\in W$, and $v-z\in W$. So, $(u-v) + (v-z)\in W$, so $u-z\in W$. Whence, $u\sim_W z$.
      \item Symmetric: If $u\sim_W v$, then $u-v\in W$, so $-1\cdot(u-v)\in W$, so $v-u\in W$. Whence, $v\sim_W u$.
    \end{itemize}
  \item[Proof of (2):]
    \begin{align*}
      [v]_W &= \{u\in V\mid u\sim_W v\}\\
            &= \{u\in V\mid u-v\in W\}\\
            &= \{u\in V\mid u = v+w~\text{some $w\in W$}\}\\
            &= \{v+w\mid w\in W\}\\
            &= v+W
    \end{align*}
  \item[Proof of (3):] Prove that the operation is well-defined.
\end{description}
\subsection{Bases}%
Let $V$ be a vector space and $S\subseteq V$ be a subset.
\begin{enumerate}[(1)]
  \item $S$ is said to be spanning for $V$ if $\text{span}(S) = V$.
  \item $S$ is linearly independent if, for $\sum_{j=1}^{n}\alpha_jv_j = 0_v$ with $\alpha_1,\dots,\alpha_n\in \mathbbm{F}$, $v_1,\dots,v_n\in S$, then $\alpha_1=\alpha_2 = \cdots = \alpha_n = 0$.
  \item $S$ is a basis for $V$ if $S$ is linearly independent and spanning for $V$.
\end{enumerate}
\subsubsection{Proposition: Existence of Basis}%
Every vector space admits a basis. If $B_0\subseteq V$ is linearly independent, $\exists B\subseteq V$ such that $B$ is a basis and $B \supseteq B_0$.
\begin{description}
  \item[Background:] A relation on a set $X$ is a subset $R\subseteq X\times X$. If $R$ is reflexive ($x\sim x$), transitive ($x\sim y,y\sim z \rightarrow x\sim z$), and antisymmetric ($x\sim y, y\sim x \rightarrow x=y$), then $R$ is an ordering, and we write $x\leq y$.\\

    If $\leq$ is an ordering of $X$ such that $\forall x,y\in X,~x\leq y$ or $y\leq x$, then $\leq$ is a total (or linear) ordering.\\

    Let $\leq$ be an ordering of $X$, let $Y\subseteq X$. An upper bound for $Y$ is an element $u\in X$ such that $y\leq u$ $\forall y\in Y$. A maximal element in $X$ is an element $m\in X$ such that $x\in X,~x \geq m \rightarrow x=m$.
  \item[Example:] $\N$ under the division ordering defines $a\leq b \Leftrightarrow a|b$. If we want to find the maximal elements of $A = \{2,6,9,12\}$, we would see that they are $9$ and $12$ (since no element of $A$ can be divided by $9$ and $12$). Meanwhile, $\N$ itself has no maximal elements.\\

    This leads us to ask: given an ordered set, $(X,\leq)$, does $X$ admit maximal elements.
  \item[Zorn's Lemma (or Axiom):] Let $(X,\leq)$ be an ordered set. Suppose that every totally ordered subset, $Y\subseteq X$ has an upper bound in $X$. Then, $X$ admits at least one maximal element.\\

    The proof of Zorn's Lemma relies on the Axiom of Choice (and Zorn's Lemma is equivalent to the Axiom of Choice).
  \item[Proof:] Let $X = \{D\mid B_0 \subseteq D \subseteq V\}$ with $D$ linearly independent. Since $B_0\subseteq X$, $X \neq \emptyset$. Define $D,E\in X$, $D\leq E \Leftrightarrow D\subseteq E$. We will show that $X$ has a maximal element.\\

    Consider any totally ordered subset, $Y = \{D_i\}_{i\in I}$. Consider $D = \bigcup D_i$. Clearly, $B_0\subseteq D\subseteq V$. Suppose $\sum \alpha_kv_k = 0_v$ with $v_1,\dots,v_n \in D$. Therefore, $\exists D_j$ with $v_1,\dots,v_n\in D_j$ because $Y$ is totally ordered. However, by definition, $D_j$ is a linearly independent set --- therefore, $\alpha_k = 0$. Thus, $D$ is linearly independent.\\

    Since $D$ is linearly independent, and $B_0\subseteq D$, it must be the case that $D\in X$. $D$ is also an upper bound for $Y$. So, by Zorn's Lemma, $X$ has a maximal element, $B$.\\

    So, $B_0\subseteq B \subseteq V$, $B$ is independent, and $B$ is maximal in $X$. We claim that $B$ is a basis for $V$. Suppose toward contradiction that $\exists v \in V$ such that $v\notin \text{span}(B)$. Consider $B' = B \cup \{v\}$.\\

    Then, $B_0\subseteq B'$, and $B'$ is linearly independent --- if $\sum \alpha_kv_k + \alpha v = 0$, where $v_1,\dots,v_n\in B$, then either:
    \begin{itemize}
      \item If $\alpha = 0$, then $\alpha_kv_k = 0 \Rightarrow \alpha_k = 0$.
      \item If $\alpha \neq 0$, then $\sum\alpha_kv_k = -\alpha v$, which means $v\in \text{span}(B)$. $\bot$
    \end{itemize}
    Thus, we have a linearly independent set, $B'$, with $B\subseteq B'$, and $B_0\subseteq B'$. Therefore, $B'\in X$. However, this contradicts the maximality of $B$. Therefore, $\text{span}(B) = V$, and $B$ is a basis for $V$.
\end{description}
\subsection{Examples: Vector Spaces}%
\begin{enumerate}[(1)]
  \item $n$-Dimensional Vectors:
    \begin{align*}
      \mathbbm{F}^n &= \left\{ \begin{pmatrix}x_1\\\vdots\\x_n\end{pmatrix} \mid x_j\in \mathbbm{F}\right\}\\
      \begin{pmatrix}x_1\\\vdots\\x_n\end{pmatrix} + \begin{pmatrix}y_1\\\vdots\\y+n\end{pmatrix} &= \begin{pmatrix}x_1+y+1\\\vdots\\x_n + y+n\end{pmatrix}\\
      \alpha \begin{pmatrix}x_1\\\vdots\\x_n\end{pmatrix} &= \begin{pmatrix}\alpha x_1\\\vdots\\\alpha x_n\end{pmatrix}\\
      B &= \{e_1,\dots,e_n\}\\
      \shortintertext{where $e_i$ denotes the unit vector at position $i$.}
    \end{align*}
  \item $m\times n$ Matrices:
    \begin{align*}
      \mathbbm{M}_{m,n}(\mathbbm{F}) &= \left\{ \begin{pmatrix}a_{11} & \cdots & a_{1n}\\\vdots & \ddots & \vdots \\ a_{m1} & \cdots & a_{mn}\end{pmatrix}\mid a_{ij}\in \mathbbm{F}\right\}\\
      (a_{ij}) + (b_{ij}) &= (a_{ij} + b_{ij})\\
      \alpha(a_{ij}) &= (\alpha a_{ij})\\
      B &= \{e_{ij}\}\\
      \shortintertext{where $e_{ij}$ denotes a matrix of $0$ everywhere except column $i$ and row $j$.}
    \end{align*}
  \item Functions with domain $\Omega$:
    \begin{align*}
      \mathcal{F}(\Omega,\mathbbm{F}) &= \{f\mid f: \Omega \rightarrow \mathbbm{F}\}\\
      (f+g)(x) &= f(x) + g(x)\\
      (\alpha f)(x) &= \alpha f(x)
    \end{align*}
  \item Bounded functions with domain $\Omega$:
    \begin{align*}
      \ell_{\infty}(\Omega,\mathbbm{F}) &= \{f\in \mathcal{F}(\Omega,\mathbbm{F}) \mid \Vert f\Vert_u \leq \infty\}\\
      \Vert f\Vert_u &= \sup_{x\in\Omega}|f(x)|
    \end{align*}
    Exercises:
    \begin{itemize}
      \item Triangle Inequality: $\Vert f+g\Vert_u \leq \Vert f\Vert_u + \Vert g\Vert_u$
      \item Scalar Multiplication/Absolute Homogeneity: $\Vert \alpha f\Vert_u = |\alpha| \Vert f\Vert_u$
      \item Positive Definite: $\Vert f\Vert_u = 0 \Rightarrow f = \mathbb{0}$
    \end{itemize}
    \begin{description}
      \item[Proof of Triangle Inequality:] Given $x\in\Omega$,
        \begin{align*}
          |(f+g)(x)| &= |f(x) + g(x)|\\
                     &\leq |f(x)| + |g(x)|\\
                     &\leq \Vert f\Vert_u + \Vert g \Vert_u\\
                     \shortintertext{Therefore,}
          \sup|(f+g)(x)| &\leq \Vert f\Vert_u + \Vert g\Vert_u\\
          \Vert f+g\Vert_u &\leq \Vert f\Vert_u + \Vert g\Vert_u
        \end{align*}
    \end{description}
  \item Continuous functions on closed and bounded intervals:
    \begin{align*}
      C([a,b],\mathbbm{F}) &= \{f: [a,b]\rightarrow \mathbbm{F}\mid f~\text{continuous}\}
    \end{align*}
    Check that $C([a,b],\mathbbm{F}) \subseteq \ell_{\infty}([a,b],\mathbbm{F})$ is a subspace.
  \item Let $f:[a,b]\rightarrow \R$ be any function. Let $\mathcal{P}: a = x_0 < x_1< x_2 < \cdots < x_n = b$.
    \begin{align*}
      \text{var}(f;\mathcal{P}) &:= \sum_{k=1}^{n} |f(x_k)-f(x_{k-1})|\\
      \text{var}(f) &= \sup_{\mathcal{P}} \text{var}(f;\mathcal{P})\\
      \text{BV}([a,b]) &= \{f:[a,b]\rightarrow \R\mid \text{var}(f) < \infty\}\\
      \Vert f\Vert_{\text{BV}} &= |f(a)| + \text{var}(f)
    \end{align*}
    $\text{BV}([a,b])$ is a vector space. 
    \begin{description}
      \item[Question:] Is $\mathbbm{1}_{\Q} \in \text{BV}([0,1])$?
    \end{description}
  \item Suppose $K\subseteq V$ is a \textit{convex} subset of a vector space: $v,w\in K,t\in [0,1]\Rightarrow (1-t)v + tw\in K$. Let $\text{Aff}(K) = \{f: K\rightarrow \R\mid f\text{ is affine}\}$, where $f$ is affine if $\forall v,w\in K,t\in[0,1],f((1-t)v + tw) = (1-t)f(v) + tf(w)$.
    \begin{description}
      \item[Exercise:] Show that $\text{Aff}(K)\subseteq \mathcal{F}(K,\R)$ is a subspace.
    \end{description}
  \item Let $S$ be defined as
    \begin{align*}
      S = \{(a_k)_{k=1}^{\infty}\mid a_k\in\mathbbm{F}\}.
    \end{align*}
    Under pointwise operations, $S$ is a vector space.
    \begin{align*}
      (a_k)_k + (b_k)_k &= (a_k + b_k)_k\\
      \alpha(a_k)_k &= (\alpha a_k)_k
    \end{align*}
    \begin{description}
      \item[Note 1:] $S = \mathcal{F}(\N,\mathbbm{F})$.
      \item[Note 2:] $c_{00} \subseteq \ell_{1}\subseteq c_{0} \subseteq c \subseteq \ell_{\infty}\subseteq S$.
        \begin{itemize}
          \item $c_{00} = \left\{(a_k)_k\mid \text{finitely many }a_k\neq 0\right\}$
          \item $c_0 = \left\{(a_k)k\mid (a_k)_k\rightarrow 0\right\}$
          \item $c = \left\{(a_k)_k\mid (a_k)_k\rightarrow a < \infty\right\}$
          \item $\ell_{\infty} = \left\{(a_k)_k\mid \Vert(a_k)_k\Vert_u<\infty\right\}$
          \item $\ell_1 = \left\{(a_k)_k\mid \sum_{k=1}^{\infty}|a_k| = a < \infty\right\}$
        \end{itemize}
    \end{description}
  \item $C_C(\R) \subseteq C_0(\R) \subseteq \ell_{\infty}(\R)$ are all subspaces.
    \begin{itemize}
      \item $C_C(\R) = \left\{f:\R\rightarrow \mathbbm{F}\mid f\text{ compactly supported}\right\}$: $f:\R\rightarrow \mathbbm{F}$ is compactly supported if $\exists [a,b]$ such that $x\notin[a,b]\Rightarrow f(x) = 0$.
      \item $C_0(\R) = \left\{f:\R\rightarrow \mathbbm{F}\mid f\text{ continuous, }\lim_{x\rightarrow \pm\infty} f(x) = 0\right\}$
    \end{itemize}
  \item Let $S$ be any non-empty set.
    \begin{align*}
      \mathbbm{F}(S)&:=\left\{f: S\rightarrow \mathbbm{F}\mid f\text{ finitely supported}\right\}\\
      \text{supp}(f)&=\left\{x\in S\mid f(x)\neq 0\right\}
    \end{align*}
    We claim that $\mathbbm{F}(S)\subseteq \mathcal{F}(S,\mathbbm{F})$ is a subspace. Consider $e_t:S\rightarrow \mathbbm{F}$ defined as follows:
    \begin{align*}
      e_t(s) &= \begin{cases}
        1 & s = t\\
        0 & s\neq t
      \end{cases}.
    \end{align*}
    We claim that $\xi = \{e_t\}_{t\in S}$ is a basis for $\mathbbm{F}(S)$.\\

    Indeed, given $f\in \mathbbm{F}(S)$, we know that $\text{supp}(f) = \{t_1,\dots,t_n\}\subseteq S$. Therefore, $f = \sum_{k=1}^{n}f(t_k)e_{t_k} \in \text{span}(\xi)$. Therefore, $\xi$ is spanning for $\mathbbm{F}(S)$. Suppose $\sum_{k=1}^{n}\alpha_{t_k}e_{t_k} = \mathbb{0}$ for some $\alpha_k\in \mathbbm{F}$, $t_k\in S$.
    \begin{align*}
      \left(\sum_{k=1}^{\alpha_{t_k}}e_{t_k}\right) &= \mathbb{0}(t_1)\\
      \alpha_{t_1} &= 0.
    \end{align*}
    Similarly, $\alpha_{t_j} = 0$ for $j = 1,\dots,n$. Therefore, $\xi$ is linearly independent. Since $\xi$ is linearly independent and spanning, $\xi$ forms a basis for $\mathbbm{F}(S)$.
    \begin{description}
      \item[Note:] The free vector space, $\mathbbm{F}(S)$, displays the universal property.\\

        There are functions $\iota: S\rightarrow \mathbbm{F}(S)$, where $\iota(t) = e_{t}$, and given any map $\varphi: S\rightarrow V$ for $V$ a vector space over $\mathbbm{F}$, $\exists!$ linear map $T_{\varphi}: \mathbbm{F}(S)\rightarrow V$ such that $\iota\circ T_{\varphi} = \varphi$.
      \item[Proof:] Every $f\in \mathbbm{F}(S)$ has a unique expression $f = \sum_{k=1}^{n}f(t_k)e_{t_k}$, where $\text{supp}(f) = \{t_1,\dots,t_n\}$. Therefore,
        \begin{align*}
          T_{\varphi}(f) := \sum_{k=1}^{n}f(t_k)\varphi(t_k)
        \end{align*}
      \item[Exercise:] Show $T_{\varphi}$ is linear and unique.
      \item[Exercise 2:] Suppose $V$ is a vector space over $\mathbbm{F}$ with basis $B$. Show that $\mathbbm{F}(B) \cong V$. Remember that $V\cong W$ if $\exists$ $T:V\rightarrow W$ such that $T$ is bijective and linear.
    \end{description}
\end{enumerate}
\subsection{Normed Spaces}%
To every vector $v\in V$, we want to assign a length to $v$, $\Vert v \Vert$.\\

A \textbf{norm} on a vector space $V$ is a map
\begin{align*}
  \Vert \cdot \Vert: V\rightarrow \R^{+}\\
  v\mapsto \Vert v\Vert \geq 0
\end{align*}
such that
\begin{enumerate}[(i)]
  \item Homogeneity: $\Vert \alpha v \Vert = |\alpha|\Vert v \Vert$
  \item Triangle Inequality: $\Vert v + w\Vert \leq \Vert v \Vert + \Vert w \Vert$
  \item Positive definiteness: $\Vert v \Vert = 0 \Rightarrow v = \mathbb{0}_V$.
\end{enumerate}
If $p: V\rightarrow \R^{+}$ satisfies (i) and (ii), then $p$ is a \textbf{seminorm}.\\

The pair $(V,\Vert \cdot \Vert)$ is called a normed space.\\

Two norms, $\Vert \cdot \Vert$ and $\Vert \cdot \Vert'$ are called \textbf{equivalent} if $\exists c_1,c_2 \geq 0$ with, $\forall v\in V$,
\begin{align*}
  \Vert v \Vert &\leq c_1\Vert v \Vert'\\
  \Vert v \Vert' &\leq c_2\Vert v \Vert
\end{align*}
\begin{description}
  \item[Note:] On $\R^n$, all norms are equivalent.
  \item[Exercise:] If $p$ is any seminorm on $V$, then $|p(v)-p(w)| \leq p(v-w)$.
  \item[Notation:] If $V$ is a normed space, then $B_V = \{v\in V\mid \Vert v \Vert\leq 1\}$, and $U_V = \{v\in V\mid \Vert v \Vert < 1\}$ are the closed and open unit ball respectively.
\end{description}
\subsubsection{Examples of Normed Spaces}%
\begin{enumerate}[(1)]
  \item Given $V = \mathbbm{F}^n$ and $\displaystyle x = \begin{bmatrix}x_1\\x_2\\\vdots\\x_n\end{bmatrix}$, we have different norms:
    \begin{align*}
      \Vert x \Vert_1 &= \sum_{j=1}^{n}|x_j|\\
      \Vert x \Vert_{\infty} &= \max_{1\leq j \leq n}|x_j|\\
      \Vert x \Vert_2 &= \left(\sum_{j=1}^{n}|x_j|^2\right)^{1/2}.
    \end{align*}
    In general, for $1\leq p < \infty$,
    \begin{align*}
      \Vert x\Vert_{p} &= \left(\sum_{j=1}^{\infty}|x_j|^{p}\right)^{1/p}.
    \end{align*}
    \begin{description}
      \tiny
      \item[Exercise:] Show that $\Vert \cdot \Vert_1$ and $\Vert \cdot \Vert_{\infty}$ are norms. Show that $\lim_{p\rightarrow\infty}\Vert x \Vert_p = \Vert x \Vert_{\infty}$.
    \end{description}
    We want to show that $\Vert \cdot \Vert_{p}$ defines a norm for $1\leq p < \infty$. If $ 1\leq p < \infty$, its conjugate index $q\in [1,\infty]$ whereby $\frac{1}{p} + \frac{1}{q} = 1$. For example, if $p = 1$, then $q = \infty$, and if $p = \infty$, then $q = 1$.
    \begin{description}
      \item[Lemma 1:] For $1 < p < \infty$, $p^{-1} + q^{-1} = 1$, $f: [0,\infty)\rightarrow \R$, $f(t) = \frac{1}{p}t^p - t + \frac{1}{q}$. Then, $f(t) \geq 0$ for all $t \geq 0$.
      \item[Proof 1:] We can see that $f'(t) = t^{p-1}-1$. Then, $f'(t) = 0$ at $t = 1$; $f'(t) > 0$ for $t > 1$ and $f'(t) < 0$ for $t \in [0,1)$.\\
        
        So, since $f(t) \geq f(1)$ for all $t \geq 0$, and $f(1) = 0$, $f(t) \geq 0$ for all $t\geq 0$.
      \item[Lemma 2:] For $1 < p < \infty$, $p^{-1} + q^{-1} = 1$, $z,y\geq 0$, $xy \leq \frac{1}{p}x^p + \frac{1}{q}y^q$.
      \item[Proof 2:] We know from Lemma 1, $t \leq \frac{1}{p}t^p + \frac{1}{q}$. Multiply by $y^q$ to get
        \begin{align*}
          ty^{q} \leq \frac{1}{p}t^py^q + \frac{1}{q}y^q.
        \end{align*}
        Set $t = xy^{1-q}$. Then,
        \begin{align*}
          xy^{1-q}y^q &\leq \frac{1}{p}x^py^{p-pq}y^{q} + \frac{1}{q}y^q.
        \end{align*}
        Since $\frac{1}{p} + \frac{1}{q} = 1$, $p-pq = -q$, so
        \begin{align*}
          xy &\leq \frac{1}{p}x^p + \frac{1}{q}y^q.
        \end{align*}
    \end{description}
    With these two lemmas in mind, we get two important inequalities.
    \begin{description}
      \item[Hölder's Inequality:] For $1\leq p \leq \infty$, $p^{-1} + q^{-1} = 1$. Then, for $x,y\in \mathbbm{F}^{n}$,
        \begin{align*}
          \left|\sum_{j=1}^{n}x_jy_j\right| &\leq \Vert x \Vert_{p} \Vert y \Vert_{q}. 
        \end{align*}
      \item[Proof of Hölder's Inequality:] For $p = 1$, the solution is as follows:
        \begin{align*}
          \left|\sum_{j=1}^{n}x_jy_j\right| &\leq \sum_{j=1}^{n}|x_j||y_j|\\
                                            &\leq \sum_{j=1}^{n}|x_j|\Vert y\Vert_{\infty}\\
                                            &= \Vert x \Vert_q \Vert y \Vert_{\infty},
        \end{align*}
        and similarly for $p=\infty, q = 1$.\\

        For $1 < p < \infty$, assume $\Vert x \Vert_p = \Vert y \Vert_q = 1$.
        \begin{align*}
          \left|\sum_{j=1}^{n}x_jy_j\right| &\leq \sum_{j=1}^{\infty}|x_j||y_j|\\
                                            &\leq \sum_{j=1}^{n}\left(\frac{1}{p}|x_j|^p + \frac{1}{q}|y_j|^q\right)\\
                                            &= \frac{1}{p} \left(\sum_{j=1}^{n}|x_j|^p\right) + \frac{1}{q}\left(\sum_{j=1}^{n}|y_j|^q\right)\\
                                            &= \frac{1}{p} + \frac{1}{q}\\
                                            &= 1.
        \end{align*}
        If $\Vert x \Vert_p = 0$ or $\Vert y \Vert_q = 0$, then $x = \mathbb{0}_{\mathbbm{F}}$ or $y = \mathbb{0}_{\mathbbm{F}}$, the inequality still holds.\\

        Assume $\Vert x \Vert_p \neq 0$, $\Vert y \Vert_{p} \neq 0 $. Set
        \begin{align*}
          x' &= \frac{x}{\Vert x \Vert_p}\\
          y' &= \frac{y}{\Vert y \Vert_p}.
        \end{align*}
        It can be verified that $\Vert x'\Vert_p = 1 = \Vert y'\Vert_q$. Therefore,
        \begin{align*}
          \left|\sum_{j=1}^{n}x_j'y_j'\right| &\leq 1\\
          \left|\sum_{j=1}^{n}\frac{x_j}{\Vert x \Vert_p}\frac{y_j}{\Vert y \Vert_q}\right| &\leq 1\\
          \left|\sum_{j=1}^{n}x_jy_j\right| &\leq \Vert x\Vert_p\Vert y\Vert_q
        \end{align*}
      \item[Minkowski's Inequality:] Given $x,y\in\mathbbm{F}^n$, $1\leq p \leq \infty$, $\frac{1}{p} = \frac{1}{q} = 1$,
        \begin{align*}
          \Vert x + y\Vert_p &\leq \Vert x \Vert_p + \Vert y \Vert_p
        \end{align*}
      \item[Proof of Minkowski's Inequality:] We can verify for $p = 1, q = \infty$, and vice versa.\\

        Assume $1 < p < \infty$. Then,
        \begin{align*}
          \Vert x + y\Vert_p^p &= \sum_{j=1}^{n}|x_j + y_j|^p\\
                               &=\sum_{j=1}^{\infty}|x_j + y_j||x_j + y_j|^{p-1}\\
                               &\leq \sum_{j=1}^{\infty}|x_j||x_j + y_j|^{p-1} + \sum_{j=1}^{n}|y_j||x_j + y_j|^{p-1}\\
                               &\leq \left(\sum_{j=1}^{n}|x_j|^p\right)^{1/p}\left(\sum_{j=1}^{n}|x_j + y_j|^{pq-q}\right)^{1/q} + \left(\sum_{j=1}^{n}|y_j|^{p}\right)^{1/p}\left(\sum_{j=1}^{n}|x_j + y_j|^{pq-q}\right)^{1/q}\tag*{Hölder's Inequality}\\
                               &= \Vert x \Vert_p \Vert x+y\Vert_{p}^{p/q} + \Vert y \Vert_p\Vert x+y\Vert_{p}^{p/q}\\
                               &= \left(\Vert x \Vert_p + \Vert y \Vert_p\right) \Vert x + y \Vert_{p}^{p-1}
        \end{align*}
        Divide by $\Vert x  + y \Vert_{p}^{p-1}$ to get desired inequality.
    \end{description}
  \item $\ell_{\infty}(\Omega,\mathbbm{F})$ with $\Vert \cdot \Vert_u$. This includes subspaces that inherit the norm, such as
    \begin{align*}
      C([a,b]) \subseteq \ell_{\infty}(\Omega)\\
      \ell_{\infty}(\R) \supseteq C_0(\R) \supseteq C_{C}(\R)
    \end{align*}
    \begin{description}
      \tiny
      \item[Exercise:] Show that $C_0(\R) \subseteq \ell_{\infty}(\R)$ is a subspace.
    \end{description}
  \item $\Omega = \N$, $\ell_{\infty} = \ell_{\infty}(\N)$ with $\Vert \cdot \Vert_{\infty}$. Subspaces that inherit the norm are
    \begin{align*}
      c_{00}\subseteq c_0 \leq \ell_{\infty}.
    \end{align*}
  \item $\ell_1$ with $\Vert \cdot \Vert_1$,
    \begin{align*}
      \Vert (a_k)_k\Vert_1 &= \sum_{k=1}^{n}|a_k|.
    \end{align*}
  \item $C([a,b])$ with 
    \begin{align*}
      \Vert f \Vert_1 &= \int_{a}^{b}|f(x)|dx.
    \end{align*}
  \item Let $1\leq p < \infty$.
    \begin{align*}
      \ell_{p} &= \left\{(a_k)_{k=1}^{\infty} \mid \sum_{k=1}^{\infty}|a_k|^{p} < \infty\right\}
    \end{align*}
    is a normed space with
    \begin{align*}
      \Vert (a_k)_k\Vert_{p} &= \left(\sum_{k=1}^{\infty}|a_k|^{p}\right)^{1/p}
    \end{align*}
    We will show that the triangle inequality holds for this norm.
    \begin{align*}
      \left(\sum_{k=1}^{n}|a_k + b_k|^{p}\right)^{1/p} &= \left\Vert \begin{bmatrix}a_1 + b_1\\\vdots\\a_n + b_n\end{bmatrix}\right\Vert_{\ell_{p}^{n}}\\
                                                       &= \left\Vert \begin{bmatrix}a_1 \\\vdots\\a_n\end{bmatrix} + \begin{bmatrix}b_1\\\vdots\\b_n\end{bmatrix}\right\Vert_{\ell_{p}^{n}}\\
                                                       &\leq \left\Vert \begin{bmatrix}a_1\\\vdots\\a_n\end{bmatrix}\right\Vert + \left\Vert \begin{bmatrix}b_1\\\vdots\\b_n\end{bmatrix}\right\Vert_{\ell_{p}^{\infty}}\\
                                                       &\leq \Vert (a_k)_k\Vert_p + \Vert(b_k)_k\Vert_{p}.
    \end{align*}
    Taking the limit as $n\rightarrow\infty$ (by the definition of an infinite series), we find that $\Vert (a_k)_k + (b_k)_k\Vert_p \leq \Vert (a_k)_k\Vert_p + \Vert (b_k)_k\Vert_p$.
\end{enumerate}
\end{document}
