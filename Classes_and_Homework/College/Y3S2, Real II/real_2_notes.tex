\documentclass[8pt]{extarticle}
\title{}
\author{}
\date{}
\usepackage[shortlabels]{enumitem}


%paper setup
\usepackage{geometry}
\geometry{letterpaper, portrait, margin=1in}
\usepackage{fancyhdr}
% sans serif font:
\usepackage{cmbright}
%symbols
\usepackage{amsmath}
\usepackage{bigints}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{mathtools}
\usepackage{bbm}
\usepackage{bbold}
\usepackage[hidelinks]{hyperref}
\usepackage{gensymb}
\usepackage{multirow,array}
\usepackage{multicol}

\newtheorem*{remark}{Remark}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}

%chemistry stuff
%\usepackage[version=4]{mhchem}
%\usepackage{chemfig}

%plotting
\usepackage{pgfplots}
\usepackage{tikz}
\tikzset{middleweight/.style={pos = 0.5}}
%\tikzset{weight/.style={pos = 0.5, fill = white}}
%\tikzset{lateweight/.style={pos = 0.75, fill = white}}
%\tikzset{earlyweight/.style={pos = 0.25, fill=white}}

%\usepackage{natbib}

%graphics stuff
\usepackage{graphicx}
\graphicspath{ {./images/} }
\usepackage[style=numeric, backend=biber]{biblatex} % Use the numeric style for Vancouver
\addbibresource{the_bibliography.bib}
%code stuff
%when using minted, make sure to add the -shell-escape flag
%you can use lstlisting if you don't want to use minted
%\usepackage{minted}
%\usemintedstyle{pastie}
%\newminted[javacode]{java}{frame=lines,framesep=2mm,linenos=true,fontsize=\footnotesize,tabsize=3,autogobble,}
%\newminted[cppcode]{cpp}{frame=lines,framesep=2mm,linenos=true,fontsize=\footnotesize,tabsize=3,autogobble,}

%\usepackage{listings}
%\usepackage{color}
%\definecolor{dkgreen}{rgb}{0,0.6,0}
%\definecolor{gray}{rgb}{0.5,0.5,0.5}
%\definecolor{mauve}{rgb}{0.58,0,0.82}
%
%\lstset{frame=tb,
%	language=Java,
%	aboveskip=3mm,
%	belowskip=3mm,
%	showstringspaces=false,
%	columns=flexible,
%	basicstyle={\small\ttfamily},
%	numbers=none,
%	numberstyle=\tiny\color{gray},
%	keywordstyle=\color{blue},
%	commentstyle=\color{dkgreen},
%	stringstyle=\color{mauve},
%	breaklines=true,
%	breakatwhitespace=true,
%	tabsize=3
%}
% text + color boxes
\usepackage[most]{tcolorbox}
\tcbuselibrary{breakable}
\tcbuselibrary{skins}
\newtcolorbox{problem}[1]{colback=white,enhanced,title={\small #1},
          attach boxed title to top center=
{yshift=-\tcboxedtitleheight/2},
boxed title style={size=small,colback=black!60!white}, sharp corners, breakable}
%including PDFs
%\usepackage{pdfpages}
\setlength{\parindent}{0pt}
\usepackage{cancel}
\pagestyle{fancy}
\fancyhf{}
\rhead{Avinash Iyer}
\lhead{Real Analysis II: Class Notes}
\newcommand{\card}{\text{card}}
\newcommand{\ran}{\text{ran}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\iprod}[2]{\left\langle #1,#2\right\rangle}
\newcommand{\norm}[1]{\left\Vert #1 \right\Vert}
\setcounter{secnumdepth}{0}
\begin{document}
\section{Normed Vector Spaces}%
\subsection{Vector Spaces}%
Throughout, $\mathbb{F} = \R$ or $\mathbb{C}$. A \textbf{vector space} over $\mathbb{F}$ is a nonempty set $V$ equipped with two operations: vector addition and scalar multiplication.
\begin{align*}
  V\times V \xrightarrow{+} V\\
  (v,w)\mapsto v+w \tag*{Vector Addition}\\
  F\times V \rightarrow V\\
  (\alpha,v)\mapsto \alpha v \tag*{Scalar Multiplication}
\end{align*}
The vector space is an Abelian group, where $u,v,w\in V$ and $\alpha,\beta\in \mathbb{F}$, we have:
\begin{enumerate}[(i)]
  \item $u+(v+w) = (u+v)+w$
  \item $\exists 0_v\in V$ with $\forall v\in V,~0_v + v = v + 0_v = v$
  \item $(\forall v\in V)(\exists w\in V)$ with $v+w = 0_v$
  \item $\forall v,w\in V,~v+w = w+v$
  \item $\alpha(v+w) = \alpha v + \alpha w,~(\alpha + \beta)v = \alpha v + \beta v$
  \item $\alpha(\beta w) = (\alpha\beta)w$
  \item $1\cdot v = v$
\end{enumerate}
\textbf{Remarks:}
\begin{enumerate}[(a)]
  \item $0_v$ is unique and known as the zero vector.
  \item The vector $w$ in (iii) is unique, and denoted $-v$.
  \item $0\cdot v = 0_v$
  \item $(-1)\cdot v = -v$
  \item Property (iv) follows from all the other axioms.
  \item For $n\in\N$, $n\cdot v = \underbrace{v+v+\cdots+v}_{n~\text{times}}$
\end{enumerate}
\subsection{Subspaces}%
Let $V$ be a vector space over $\mathbb{F}$. A \textbf{subspace} is a nonempty subset $W\subseteq V$ satisfying the following:
\begin{enumerate}[(i)]
  \item $w\in W,\alpha\in \mathbb{F}\rightarrow \alpha w \in W$.
  \item $w_1,w_2\in W \Rightarrow w_1 + w_2\in W$.
\end{enumerate}
\begin{description}
  \item[Remark:] $0_v$ is always a member of any subspace; a subspace is also a vector space.
\end{description}
\subsubsection{Proposition: Intersection of Subspaces}%
If $\{W_i\}_{i\in I}$ is a family of subspaces of $V$, then, $\bigcap W_i$ is a subspace of $V$.
\subsubsection{Proposition: Union of Subspaces}%
It is not the case that the union of subspaces of $V$ also a subspace. For example, consider $\R^2$ with the traditional vector space operations:
\begin{align*}
  \begin{pmatrix}x\\y\end{pmatrix} + \begin{pmatrix}x'\\y'\end{pmatrix} &= \begin{pmatrix}x+x'\\y+y'\end{pmatrix}\\
  \alpha \begin{pmatrix}x\\y\end{pmatrix} &= \begin{pmatrix}\alpha x\\\alpha y\end{pmatrix}
\end{align*}
If $W_1,W_2\in V$ are subspaces such that $W_1 \cup W_2$ is a subspace, then $W_1\subseteq W_2$ or $W_2\subseteq W_1$.
\subsubsection{Generated Subspaces}%
Let $S\subseteq V$ be any subset of a vector space $V$. Then,
\begin{align*}
  \text{span}(S) &= \left\{\sum_{j=1}^{n}\alpha_jv_j\mid \alpha_1,\dots,\alpha_n\in \mathbb{F},v_1,\dots,v_n\in S\right\}
\end{align*}
\begin{description}
  \item[Remarks:]\hfill
    \begin{itemize}
      \item $\text{span}(S)\subseteq V$ is a subspace.
      \item $\text{span}(S) = \bigcap W$, where $S\subseteq W$ and $W\subseteq V$ is a subspace. Thus, $\text{span}(S)$ is the ``smallest'' subspace containing $S$, or the subspace generated by $S$.
    \end{itemize}
\end{description}
\subsubsection{Proposition: Quotient Group on Vector Space}%
Let $V$ be a vector space, and let $W\subseteq V$ is a subspace. Define $u\sim_{W} v\leftrightarrow u-v\in W$.
\begin{enumerate}[(1)]
  \item $\sim_W$ is an equivalence relation.
  \item If $[v]_W$ denotes the equivalence class of $v$, then $[v]_W = v+W = \{v+w|w\in W\}$.
  \item $V/W:= \{[v]_W|v\in V\}$ is a vector space with $[v_1]_W + [v_2]_W = [v_1+v_2]_W$ and $\alpha[v]_W = [\alpha v]_W$.
\end{enumerate}
\begin{description}
  \item[Proof of (1):]\hfill
    \begin{itemize}
      \item Reflexive: $u\sim_W u$, since $u-u = 0\in W$.
      \item Transitive: Suppose $u\sim_W v$, and $v\sim_W z$. Then, $u-v\in W$, and $v-z\in W$. So, $(u-v) + (v-z)\in W$, so $u-z\in W$. Whence, $u\sim_W z$.
      \item Symmetric: If $u\sim_W v$, then $u-v\in W$, so $-1\cdot(u-v)\in W$, so $v-u\in W$. Whence, $v\sim_W u$.
    \end{itemize}
  \item[Proof of (2):]
    \begin{align*}
      [v]_W &= \{u\in V\mid u\sim_W v\}\\
            &= \{u\in V\mid u-v\in W\}\\
            &= \{u\in V\mid u = v+w~\text{some $w\in W$}\}\\
            &= \{v+w\mid w\in W\}\\
            &= v+W
    \end{align*}
  \item[Proof of (3):] Prove that the operation is well-defined.
\end{description}
\subsection{Bases}%
Let $V$ be a vector space and $S\subseteq V$ be a subset.
\begin{enumerate}[(1)]
  \item $S$ is said to be spanning for $V$ if $\text{span}(S) = V$.
  \item $S$ is linearly independent if, for $\sum_{j=1}^{n}\alpha_jv_j = 0_v$ with $\alpha_1,\dots,\alpha_n\in \mathbb{F}$, $v_1,\dots,v_n\in S$, then $\alpha_1=\alpha_2 = \cdots = \alpha_n = 0$.
  \item $S$ is a basis for $V$ if $S$ is linearly independent and spanning for $V$.
\end{enumerate}
\subsubsection{Proposition: Existence of Basis}%
Every vector space admits a basis. If $B_0\subseteq V$ is linearly independent, $\exists B\subseteq V$ such that $B$ is a basis and $B \supseteq B_0$.
\begin{description}
  \item[Background:] A relation on a set $X$ is a subset $R\subseteq X\times X$. If $R$ is reflexive ($x\sim x$), transitive ($x\sim y,y\sim z \rightarrow x\sim z$), and antisymmetric ($x\sim y, y\sim x \rightarrow x=y$), then $R$ is an ordering, and we write $x\leq y$.\\

    If $\leq$ is an ordering of $X$ such that $\forall x,y\in X,~x\leq y$ or $y\leq x$, then $\leq$ is a total (or linear) ordering.\\

    Let $\leq$ be an ordering of $X$, let $Y\subseteq X$. An upper bound for $Y$ is an element $u\in X$ such that $y\leq u$ $\forall y\in Y$. A maximal element in $X$ is an element $m\in X$ such that $x\in X,~x \geq m \rightarrow x=m$.
  \item[Example:] $\N$ under the division ordering defines $a\leq b \Leftrightarrow a|b$. If we want to find the maximal elements of $A = \{2,6,9,12\}$, we would see that they are $9$ and $12$ (since no element of $A$ can be divided by $9$ and $12$). Meanwhile, $\N$ itself has no maximal elements.\\

    This leads us to ask: given an ordered set, $(X,\leq)$, does $X$ admit maximal elements.
  \item[Zorn's Lemma (or Axiom):] Let $(X,\leq)$ be an ordered set. Suppose that every totally ordered subset, $Y\subseteq X$ has an upper bound in $X$. Then, $X$ admits at least one maximal element.\\

    The proof of Zorn's Lemma relies on the Axiom of Choice (and Zorn's Lemma is equivalent to the Axiom of Choice).
  \item[Proof:] Let $X = \{D\mid B_0 \subseteq D \subseteq V\}$ with $D$ linearly independent. Since $B_0\subseteq X$, $X \neq \emptyset$. Define $D,E\in X$, $D\leq E \Leftrightarrow D\subseteq E$. We will show that $X$ has a maximal element.\\

    Consider any totally ordered subset, $Y = \{D_i\}_{i\in I}$. Consider $D = \bigcup D_i$. Clearly, $B_0\subseteq D\subseteq V$. Suppose $\sum \alpha_kv_k = 0_v$ with $v_1,\dots,v_n \in D$. Therefore, $\exists D_j$ with $v_1,\dots,v_n\in D_j$ because $Y$ is totally ordered. However, by definition, $D_j$ is a linearly independent set --- therefore, $\alpha_k = 0$. Thus, $D$ is linearly independent.\\

    Since $D$ is linearly independent, and $B_0\subseteq D$, it must be the case that $D\in X$. $D$ is also an upper bound for $Y$. So, by Zorn's Lemma, $X$ has a maximal element, $B$.\\

    So, $B_0\subseteq B \subseteq V$, $B$ is independent, and $B$ is maximal in $X$. We claim that $B$ is a basis for $V$. Suppose toward contradiction that $\exists v \in V$ such that $v\notin \text{span}(B)$. Consider $B' = B \cup \{v\}$.\\

    Then, $B_0\subseteq B'$, and $B'$ is linearly independent --- if $\sum \alpha_kv_k + \alpha v = 0$, where $v_1,\dots,v_n\in B$, then either:
    \begin{itemize}
      \item If $\alpha = 0$, then $\alpha_kv_k = 0 \Rightarrow \alpha_k = 0$.
      \item If $\alpha \neq 0$, then $\sum\alpha_kv_k = -\alpha v$, which means $v\in \text{span}(B)$. $\bot$
    \end{itemize}
    Thus, we have a linearly independent set, $B'$, with $B\subseteq B'$, and $B_0\subseteq B'$. Therefore, $B'\in X$. However, this contradicts the maximality of $B$. Therefore, $\text{span}(B) = V$, and $B$ is a basis for $V$.
\end{description}
\subsection{Examples: Vector Spaces}%
\begin{enumerate}[(1)]
  \item $n$-Dimensional Vectors:
    \begin{align*}
      \mathbb{F}^n &= \left\{ \begin{pmatrix}x_1\\\vdots\\x_n\end{pmatrix} \mid x_j\in \mathbb{F}\right\}\\
      \begin{pmatrix}x_1\\\vdots\\x_n\end{pmatrix} + \begin{pmatrix}y_1\\\vdots\\y+n\end{pmatrix} &= \begin{pmatrix}x_1+y+1\\\vdots\\x_n + y+n\end{pmatrix}\\
      \alpha \begin{pmatrix}x_1\\\vdots\\x_n\end{pmatrix} &= \begin{pmatrix}\alpha x_1\\\vdots\\\alpha x_n\end{pmatrix}\\
      B &= \{e_1,\dots,e_n\}\\
      \shortintertext{where $e_i$ denotes the unit vector at position $i$.}
    \end{align*}
  \item $m\times n$ Matrices:
    \begin{align*}
      \mathbb{M}_{m,n}(\mathbb{F}) &= \left\{ \begin{pmatrix}a_{11} & \cdots & a_{1n}\\\vdots & \ddots & \vdots \\ a_{m1} & \cdots & a_{mn}\end{pmatrix}\mid a_{ij}\in \mathbb{F}\right\}\\
      (a_{ij}) + (b_{ij}) &= (a_{ij} + b_{ij})\\
      \alpha(a_{ij}) &= (\alpha a_{ij})\\
      B &= \{e_{ij}\}\\
      \shortintertext{where $e_{ij}$ denotes a matrix of $0$ everywhere except column $i$ and row $j$.}
    \end{align*}
  \item Functions with domain $\Omega$:
    \begin{align*}
      \mathcal{F}(\Omega,\mathbb{F}) &= \{f\mid f: \Omega \rightarrow \mathbb{F}\}\\
      (f+g)(x) &= f(x) + g(x)\\
      (\alpha f)(x) &= \alpha f(x)
    \end{align*}
  \item Bounded functions with domain $\Omega$:
    \begin{align*}
      \ell_{\infty}(\Omega,\mathbb{F}) &= \{f\in \mathcal{F}(\Omega,\mathbb{F}) \mid \Vert f\Vert_u \leq \infty\}\\
      \Vert f\Vert_u &= \sup_{x\in\Omega}|f(x)|
    \end{align*}
    Exercises:
    \begin{itemize}
      \item Triangle Inequality: $\Vert f+g\Vert_u \leq \Vert f\Vert_u + \Vert g\Vert_u$
      \item Scalar Multiplication/Absolute Homogeneity: $\Vert \alpha f\Vert_u = |\alpha| \Vert f\Vert_u$
      \item Positive Definite: $\Vert f\Vert_u = 0 \Rightarrow f = \mathbb{0}$
    \end{itemize}
    \begin{description}
      \item[Proof of Triangle Inequality:] Given $x\in\Omega$,
        \begin{align*}
          |(f+g)(x)| &= |f(x) + g(x)|\\
                     &\leq |f(x)| + |g(x)|\\
                     &\leq \Vert f\Vert_u + \Vert g \Vert_u\\
                     \shortintertext{Therefore,}
          \sup|(f+g)(x)| &\leq \Vert f\Vert_u + \Vert g\Vert_u\\
          \Vert f+g\Vert_u &\leq \Vert f\Vert_u + \Vert g\Vert_u
        \end{align*}
    \end{description}
  \item Continuous functions on closed and bounded intervals:
    \begin{align*}
      C([a,b],\mathbb{F}) &= \{f: [a,b]\rightarrow \mathbb{F}\mid f~\text{continuous}\}
    \end{align*}
    Check that $C([a,b],\mathbb{F}) \subseteq \ell_{\infty}([a,b],\mathbb{F})$ is a subspace.
  \item Let $f:[a,b]\rightarrow \R$ be any function. Let $\mathcal{P}: a = x_0 < x_1< x_2 < \cdots < x_n = b$.
    \begin{align*}
      \text{var}(f;\mathcal{P}) &:= \sum_{k=1}^{n} |f(x_k)-f(x_{k-1})|\\
      \text{var}(f) &= \sup_{\mathcal{P}} \text{var}(f;\mathcal{P})\\
      \text{BV}([a,b]) &= \{f:[a,b]\rightarrow \R\mid \text{var}(f) < \infty\}\\
      \Vert f\Vert_{\text{BV}} &= |f(a)| + \text{var}(f)
    \end{align*}
    $\text{BV}([a,b])$ is a vector space. 
    \begin{description}
      \item[Question:] Is $\mathbb{1}_{\Q} \in \text{BV}([0,1])$?
    \end{description}
  \item Suppose $K\subseteq V$ is a \textit{convex} subset of a vector space: $v,w\in K,t\in [0,1]\Rightarrow (1-t)v + tw\in K$. Let $\text{Aff}(K) = \{f: K\rightarrow \R\mid f\text{ is affine}\}$, where $f$ is affine if $\forall v,w\in K,t\in[0,1],f((1-t)v + tw) = (1-t)f(v) + tf(w)$.
    \begin{description}
      \item[Exercise:] Show that $\text{Aff}(K)\subseteq \mathcal{F}(K,\R)$ is a subspace.
    \end{description}
  \item Let $S$ be defined as
    \begin{align*}
      S = \{(a_k)_{k=1}^{\infty}\mid a_k\in\mathbb{F}\}.
    \end{align*}
    Under pointwise operations, $S$ is a vector space.
    \begin{align*}
      (a_k)_k + (b_k)_k &= (a_k + b_k)_k\\
      \alpha(a_k)_k &= (\alpha a_k)_k
    \end{align*}
    \begin{description}
      \item[Note 1:] $S = \mathcal{F}(\N,\mathbb{F})$.
      \item[Note 2:] $c_{00} \subseteq \ell_{1}\subseteq c_{0} \subseteq c \subseteq \ell_{\infty}\subseteq S$.
        \begin{itemize}
          \item $c_{00} = \left\{(a_k)_k\mid \text{finitely many }a_k\neq 0\right\}$
          \item $c_0 = \left\{(a_k)k\mid (a_k)_k\rightarrow 0\right\}$
          \item $c = \left\{(a_k)_k\mid (a_k)_k\rightarrow a < \infty\right\}$
          \item $\ell_{\infty} = \left\{(a_k)_k\mid \Vert(a_k)_k\Vert_u<\infty\right\}$
          \item $\ell_1 = \left\{(a_k)_k\mid \sum_{k=1}^{\infty}|a_k| = a < \infty\right\}$
        \end{itemize}
    \end{description}
  \item $C_C(\R) \subseteq C_0(\R) \subseteq \ell_{\infty}(\R)$ are all subspaces.
    \begin{itemize}
      \item $C_C(\R) = \left\{f:\R\rightarrow \mathbb{F}\mid f\text{ compactly supported}\right\}$: $f:\R\rightarrow \mathbb{F}$ is compactly supported if $\exists [a,b]$ such that $x\notin[a,b]\Rightarrow f(x) = 0$.
      \item $C_0(\R) = \left\{f:\R\rightarrow \mathbb{F}\mid f\text{ continuous, }\lim_{x\rightarrow \pm\infty} f(x) = 0\right\}$
    \end{itemize}
  \item Let $S$ be any non-empty set.
    \begin{align*}
      \mathbb{F}(S)&:=\left\{f: S\rightarrow \mathbb{F}\mid f\text{ finitely supported}\right\}\\
      \text{supp}(f)&=\left\{x\in S\mid f(x)\neq 0\right\}
    \end{align*}
    We claim that $\mathbb{F}(S)\subseteq \mathcal{F}(S,\mathbb{F})$ is a subspace. Consider $e_t:S\rightarrow \mathbb{F}$ defined as follows:
    \begin{align*}
      e_t(s) &= \begin{cases}
        1 & s = t\\
        0 & s\neq t
      \end{cases}.
    \end{align*}
    We claim that $\xi = \{e_t\}_{t\in S}$ is a basis for $\mathbb{F}(S)$.\\

    Indeed, given $f\in \mathbb{F}(S)$, we know that $\text{supp}(f) = \{t_1,\dots,t_n\}\subseteq S$. Therefore, $f = \sum_{k=1}^{n}f(t_k)e_{t_k} \in \text{span}(\xi)$. Therefore, $\xi$ is spanning for $\mathbb{F}(S)$. Suppose $\sum_{k=1}^{n}\alpha_{t_k}e_{t_k} = \mathbb{0}$ for some $\alpha_k\in \mathbb{F}$, $t_k\in S$.
    \begin{align*}
      \left(\sum_{k=1}^{\alpha_{t_k}}e_{t_k}\right) &= \mathbb{0}(t_1)\\
      \alpha_{t_1} &= 0.
    \end{align*}
    Similarly, $\alpha_{t_j} = 0$ for $j = 1,\dots,n$. Therefore, $\xi$ is linearly independent. Since $\xi$ is linearly independent and spanning, $\xi$ forms a basis for $\mathbb{F}(S)$.
    \begin{description}
      \item[Note:] The free vector space, $\mathbb{F}(S)$, displays the universal property.\\

        There are functions $\iota: S\rightarrow \mathbb{F}(S)$, where $\iota(t) = e_{t}$, and given any map $\varphi: S\rightarrow V$ for $V$ a vector space over $\mathbb{F}$, $\exists!$ linear map $T_{\varphi}: \mathbb{F}(S)\rightarrow V$ such that $\iota\circ T_{\varphi} = \varphi$.
      \item[Proof:] Every $f\in \mathbb{F}(S)$ has a unique expression $f = \sum_{k=1}^{n}f(t_k)e_{t_k}$, where $\text{supp}(f) = \{t_1,\dots,t_n\}$. Therefore,
        \begin{align*}
          T_{\varphi}(f) := \sum_{k=1}^{n}f(t_k)\varphi(t_k)
        \end{align*}
      \item[Exercise:] Show $T_{\varphi}$ is linear and unique.
      \item[Exercise 2:] Suppose $V$ is a vector space over $\mathbb{F}$ with basis $B$. Show that $\mathbb{F}(B) \cong V$. Remember that $V\cong W$ if $\exists$ $T:V\rightarrow W$ such that $T$ is bijective and linear.
    \end{description}
\end{enumerate}
\subsection{Normed Spaces}%
To every vector $v\in V$, we want to assign a length to $v$, $\Vert v \Vert$.\\

A \textbf{norm} on a vector space $V$ is a map
\begin{align*}
  \Vert \cdot \Vert: V\rightarrow \R^{+}\\
  v\mapsto \Vert v\Vert \geq 0
\end{align*}
such that
\begin{enumerate}[(i)]
  \item Homogeneity: $\Vert \alpha v \Vert = |\alpha|\Vert v \Vert$
  \item Triangle Inequality: $\Vert v + w\Vert \leq \Vert v \Vert + \Vert w \Vert$
  \item Positive definiteness: $\Vert v \Vert = 0 \Rightarrow v = \mathbb{0}_V$.
\end{enumerate}
If $p: V\rightarrow \R^{+}$ satisfies (i) and (ii), then $p$ is a \textbf{seminorm}.\\

The pair $(V,\Vert \cdot \Vert)$ is called a normed space.\\

Two norms, $\Vert \cdot \Vert$ and $\Vert \cdot \Vert'$ are called \textbf{equivalent} if $\exists c_1,c_2 \geq 0$ with, $\forall v\in V$,
\begin{align*}
  \Vert v \Vert &\leq c_1\Vert v \Vert'\\
  \Vert v \Vert' &\leq c_2\Vert v \Vert
\end{align*}
\begin{description}
  \item[Note:] On $\R^n$, all norms are equivalent.
  \item[Exercise:] If $p$ is any seminorm on $V$, then $|p(v)-p(w)| \leq p(v-w)$.
  \item[Notation:] If $V$ is a normed space, then $B_V = \{v\in V\mid \Vert v \Vert\leq 1\}$, and $U_V = \{v\in V\mid \Vert v \Vert < 1\}$ are the closed and open unit ball respectively.
\end{description}
\subsubsection{Examples of Normed Spaces}%
\begin{enumerate}[(1)]
  \item Given $V = \mathbb{F}^n$ and $\displaystyle x = \begin{bmatrix}x_1\\x_2\\\vdots\\x_n\end{bmatrix}$, we have different norms:
    \begin{align*}
      \Vert x \Vert_1 &= \sum_{j=1}^{n}|x_j|\\
      \Vert x \Vert_{\infty} &= \max_{1\leq j \leq n}|x_j|\\
      \Vert x \Vert_2 &= \left(\sum_{j=1}^{n}|x_j|^2\right)^{1/2}.
    \end{align*}
    In general, for $1\leq p < \infty$,
    \begin{align*}
      \Vert x\Vert_{p} &= \left(\sum_{j=1}^{\infty}|x_j|^{p}\right)^{1/p}.
    \end{align*}
    \begin{description}
      \tiny
      \item[Exercise:] Show that $\Vert \cdot \Vert_1$ and $\Vert \cdot \Vert_{\infty}$ are norms. Show that $\lim_{p\rightarrow\infty}\Vert x \Vert_p = \Vert x \Vert_{\infty}$.
    \end{description}
    We want to show that $\Vert \cdot \Vert_{p}$ defines a norm for $1\leq p < \infty$. If $ 1\leq p < \infty$, its conjugate index $q\in [1,\infty]$ whereby $\frac{1}{p} + \frac{1}{q} = 1$. For example, if $p = 1$, then $q = \infty$, and if $p = \infty$, then $q = 1$.
    \begin{description}
      \item[Lemma 1:] For $1 < p < \infty$, $p^{-1} + q^{-1} = 1$, $f: [0,\infty)\rightarrow \R$, $f(t) = \frac{1}{p}t^p - t + \frac{1}{q}$. Then, $f(t) \geq 0$ for all $t \geq 0$.
      \item[Proof 1:] We can see that $f'(t) = t^{p-1}-1$. Then, $f'(t) = 0$ at $t = 1$; $f'(t) > 0$ for $t > 1$ and $f'(t) < 0$ for $t \in [0,1)$.\\
        
        So, since $f(t) \geq f(1)$ for all $t \geq 0$, and $f(1) = 0$, $f(t) \geq 0$ for all $t\geq 0$.
      \item[Lemma 2:] For $1 < p < \infty$, $p^{-1} + q^{-1} = 1$, $z,y\geq 0$, $xy \leq \frac{1}{p}x^p + \frac{1}{q}y^q$.
      \item[Proof 2:] We know from Lemma 1, $t \leq \frac{1}{p}t^p + \frac{1}{q}$. Multiply by $y^q$ to get
        \begin{align*}
          ty^{q} \leq \frac{1}{p}t^py^q + \frac{1}{q}y^q.
        \end{align*}
        Set $t = xy^{1-q}$. Then,
        \begin{align*}
          xy^{1-q}y^q &\leq \frac{1}{p}x^py^{p-pq}y^{q} + \frac{1}{q}y^q.
        \end{align*}
        Since $\frac{1}{p} + \frac{1}{q} = 1$, $p-pq = -q$, so
        \begin{align*}
          xy &\leq \frac{1}{p}x^p + \frac{1}{q}y^q.
        \end{align*}
    \end{description}
    With these two lemmas in mind, we get two important inequalities.
    \begin{description}
      \item[Hölder's Inequality:] For $1\leq p \leq \infty$, $p^{-1} + q^{-1} = 1$. Then, for $x,y\in \mathbb{F}^{n}$,
        \begin{align*}
          \left|\sum_{j=1}^{n}x_jy_j\right| &\leq \Vert x \Vert_{p} \Vert y \Vert_{q}. 
        \end{align*}
      \item[Proof of Hölder's Inequality:] For $p = 1$, the solution is as follows:
        \begin{align*}
          \left|\sum_{j=1}^{n}x_jy_j\right| &\leq \sum_{j=1}^{n}|x_j||y_j|\\
                                            &\leq \sum_{j=1}^{n}|x_j|\Vert y\Vert_{\infty}\\
                                            &= \Vert x \Vert_q \Vert y \Vert_{\infty},
        \end{align*}
        and similarly for $p=\infty, q = 1$.\\

        For $1 < p < \infty$, assume $\Vert x \Vert_p = \Vert y \Vert_q = 1$.
        \begin{align*}
          \left|\sum_{j=1}^{n}x_jy_j\right| &\leq \sum_{j=1}^{\infty}|x_j||y_j|\\
                                            &\leq \sum_{j=1}^{n}\left(\frac{1}{p}|x_j|^p + \frac{1}{q}|y_j|^q\right)\\
                                            &= \frac{1}{p} \left(\sum_{j=1}^{n}|x_j|^p\right) + \frac{1}{q}\left(\sum_{j=1}^{n}|y_j|^q\right)\\
                                            &= \frac{1}{p} + \frac{1}{q}\\
                                            &= 1.
        \end{align*}
        If $\Vert x \Vert_p = 0$ or $\Vert y \Vert_q = 0$, then $x = \mathbb{0}_{\mathbb{F}}$ or $y = \mathbb{0}_{\mathbb{F}}$, the inequality still holds.\\

        Assume $\Vert x \Vert_p \neq 0$, $\Vert y \Vert_{p} \neq 0 $. Set
        \begin{align*}
          x' &= \frac{x}{\Vert x \Vert_p}\\
          y' &= \frac{y}{\Vert y \Vert_p}.
        \end{align*}
        It can be verified that $\Vert x'\Vert_p = 1 = \Vert y'\Vert_q$. Therefore,
        \begin{align*}
          \left|\sum_{j=1}^{n}x_j'y_j'\right| &\leq 1\\
          \left|\sum_{j=1}^{n}\frac{x_j}{\Vert x \Vert_p}\frac{y_j}{\Vert y \Vert_q}\right| &\leq 1\\
          \left|\sum_{j=1}^{n}x_jy_j\right| &\leq \Vert x\Vert_p\Vert y\Vert_q
        \end{align*}
      \item[Minkowski's Inequality:] Given $x,y\in\mathbb{F}^n$, $1\leq p \leq \infty$, $\frac{1}{p} = \frac{1}{q} = 1$,
        \begin{align*}
          \Vert x + y\Vert_p &\leq \Vert x \Vert_p + \Vert y \Vert_p
        \end{align*}
      \item[Proof of Minkowski's Inequality:] We can verify for $p = 1, q = \infty$, and vice versa.\\

        Assume $1 < p < \infty$. Then,
        \begin{align*}
          \Vert x + y\Vert_p^p &= \sum_{j=1}^{n}|x_j + y_j|^p\\
                               &=\sum_{j=1}^{\infty}|x_j + y_j||x_j + y_j|^{p-1}\\
                               &\leq \sum_{j=1}^{\infty}|x_j||x_j + y_j|^{p-1} + \sum_{j=1}^{n}|y_j||x_j + y_j|^{p-1}\\
                               &\leq \left(\sum_{j=1}^{n}|x_j|^p\right)^{1/p}\left(\sum_{j=1}^{n}|x_j + y_j|^{pq-q}\right)^{1/q} + \left(\sum_{j=1}^{n}|y_j|^{p}\right)^{1/p}\left(\sum_{j=1}^{n}|x_j + y_j|^{pq-q}\right)^{1/q}\tag*{Hölder's Inequality}\\
                               &= \Vert x \Vert_p \Vert x+y\Vert_{p}^{p/q} + \Vert y \Vert_p\Vert x+y\Vert_{p}^{p/q}\\
                               &= \left(\Vert x \Vert_p + \Vert y \Vert_p\right) \Vert x + y \Vert_{p}^{p-1}
        \end{align*}
        Divide by $\Vert x  + y \Vert_{p}^{p-1}$ to get desired inequality.
    \end{description}
  \item $\ell_{\infty}(\Omega,\mathbb{F})$ with $\Vert \cdot \Vert_u$. This includes subspaces that inherit the norm, such as
    \begin{align*}
      C([a,b]) \subseteq \ell_{\infty}(\Omega)\\
      \ell_{\infty}(\R) \supseteq C_0(\R) \supseteq C_{C}(\R)
    \end{align*}
    \begin{description}
      \tiny
      \item[Exercise:] Show that $C_0(\R) \subseteq \ell_{\infty}(\R)$ is a subspace.
    \end{description}
  \item $\Omega = \N$, $\ell_{\infty} = \ell_{\infty}(\N)$ with $\Vert \cdot \Vert_{\infty}$. Subspaces that inherit the norm are
    \begin{align*}
      c_{00}\subseteq c_0 \leq \ell_{\infty}.
    \end{align*}
  \item $\ell_1$ with $\Vert \cdot \Vert_1$,
    \begin{align*}
      \Vert (a_k)_k\Vert_1 &= \sum_{k=1}^{n}|a_k|.
    \end{align*}
  \item $C([a,b])$ with 
    \begin{align*}
      \Vert f \Vert_1 &= \int_{a}^{b}|f(x)|dx.
    \end{align*}
  \item Let $1\leq p < \infty$.
    \begin{align*}
      \ell_{p} &= \left\{(a_k)_{k=1}^{\infty} \mid \sum_{k=1}^{\infty}|a_k|^{p} < \infty\right\}
    \end{align*}
    is a normed space with
    \begin{align*}
      \Vert (a_k)_k\Vert_{p} &= \left(\sum_{k=1}^{\infty}|a_k|^{p}\right)^{1/p}
    \end{align*}
    We will show that the triangle inequality holds for this norm.
    \begin{align*}
      \left(\sum_{k=1}^{n}|a_k + b_k|^{p}\right)^{1/p} &= \left\Vert \begin{bmatrix}a_1 + b_1\\\vdots\\a_n + b_n\end{bmatrix}\right\Vert_{\ell_{p}^{n}}\\
                                                       &= \left\Vert \begin{bmatrix}a_1 \\\vdots\\a_n\end{bmatrix} + \begin{bmatrix}b_1\\\vdots\\b_n\end{bmatrix}\right\Vert_{\ell_{p}^{n}}\\
                                                       &\leq \left\Vert \begin{bmatrix}a_1\\\vdots\\a_n\end{bmatrix}\right\Vert + \left\Vert \begin{bmatrix}b_1\\\vdots\\b_n\end{bmatrix}\right\Vert_{\ell_{p}^{\infty}}\\
                                                       &\leq \Vert (a_k)_k\Vert_p + \Vert(b_k)_k\Vert_{p}.
    \end{align*}
    Taking the limit as $n\rightarrow\infty$ (by the definition of an infinite series), we find that $\Vert (a_k)_k + (b_k)_k\Vert_p \leq \Vert (a_k)_k\Vert_p + \Vert (b_k)_k\Vert_p$.
  \item $\text{BV}([a,b]) = \{f: [a,b]\rightarrow \R\mid \text{Var}(f) < \infty\}$ with the norm $\Vert f \Vert_{\text{BV}} = |f(a)| + \text{Var}(f)$ is a normed space:
    \begin{align*}
      \Vert f \Vert_{\text{BV}} &= 0\\
      |f(a)| &= 0\\
      \text{Var}(f) &= 0\\
      \shortintertext{given $t\in (a,b]$, look at the partition $a < t \leq b$. Then,}
      \text{Var}(f) &\geq |f(t)-f(a)| + |f(b)-f(t)|\\
      f(t) &= 0\\
      f &= \mathbb{0}_f.
    \end{align*}
  \item $\mathbb{M}_{m,n}(\mathbb{F})$ with
    \begin{align*}
      \Vert a \Vert_{\text{op}} &= \sup_{\Vert \xi \Vert_{\ell_{2}^{n}} \leq 1} \Vert a\xi \Vert_{\ell_{2}^{m}}
    \end{align*}
    is a normed vector space. If $\Vert a \Vert_{\text{op}} = 0$, then
    \begin{align*}
      ae_j &= 0 \tag*{$\forall j \in \{1,\dots,n\}$.}\\
      \shortintertext{take the dot product with $i\neq j$}
      ae_{j}\cdot e_{i} &= a_{ij}\\
                        &= 0\\
                        \shortintertext{so $a_{ij} = 0$ for all $a_{ij}$, so $a$ is the $\mathbb{0}$ matrix.}
    \end{align*}
  \item Let $V,W$ be vector spaces over $\mathbb{F}$. Then, $\mathcal{L}(V,W) = \{T\mid T:V\rightarrow W\text{ linear}\}$, where $T(\alpha v_1 + \beta v_2) = \alpha T(v_1) + \beta T(v_2)$.\\

    $\mathcal{L}(V,W)$ is a vector space with operations
    \begin{align*}
      (T+S)(v) &= T(v) + S(v)\\
      (\alpha T)(v) &= \alpha T(v).
    \end{align*}
    \begin{description}
      \item[Notation:] $\mathcal{L}(V) := \mathcal{L}(V,V)$ is all linear operators on $V$. $\mathcal{L}(V,\mathbb{F}) = V'$ is all linear functionals.
    \end{description}
    Suppose $V$ and $W$ are normed vector spaces. If $T: V\rightarrow W$, set
    \begin{align*}
      \Vert T\Vert_{\text{op}} &:= \sup_{\Vert v \Vert_{v}\leq 1}\Vert T(v)\Vert_{W},\\
      \mathbb{B}(V,W) &= \{T\in \mathcal{L}(V,W) \mid \Vert T \Vert_{op}\leq \infty\},
    \end{align*}
    where $\mathbb{B}(V,W)$ is referred to as the set of all bounded linear maps from $V$ to $W$. $\mathbb{B}(V,W)$ with $\Vert \cdot \Vert_{\text{op}}$ is a normed space.
    \begin{itemize}
      \item Homogeneity:
        \begin{align*}
          \Vert \alpha T \Vert_{\text[op]} &= \sup_{\Vert v \Vert_{V} \leq 1} \Vert \alpha T(v)\Vert_{W}\\
                                           &= \sup_{\Vert v \Vert_{V}\leq 1} |\alpha|\Vert T(v)\Vert_{W}\\
                                           &= |\alpha|\sup_{\Vert v \Vert_{V}\leq 1}\Vert T(v)\Vert_{W}\\
                                           &= |\alpha|\Vert T\Vert_{\text{op}}.
        \end{align*}
      \item Triangle Inequality: for $\Vert v \Vert_{V}\leq 1$,
        \begin{align*}
          \Vert \left(T + S\right)(v)\Vert_{W} &= \Vert T(v) + S(v)\Vert_{W}\\
                                               &\leq \Vert T(v)\Vert_{W} + \Vert S(v)\Vert_{W}\\
                                               &\leq \Vert T \Vert_{\text{op}} + \Vert S \Vert_{\text{op}}\\
                                               \shortintertext{so}
          \Vert T+S\Vert_{\text{op}} &= \sup_{\Vert v \Vert\leq 1}\Vert T+S(v)\Vert\\
                                     &\leq \Vert T \Vert_{\text{op}} + \Vert S \Vert_{\text{op}}
        \end{align*}
      \item Positive Definite: If $\Vert T \Vert_{\text{op}} = 0$, then $T(v) = 0$ for all $v\in V$, $\Vert v \Vert\leq 1$.\\

        Let $v\in V$, $v\neq 0$. Then, $\frac{v}{\Vert v \Vert}\in B_V.$
        \begin{align*}
          T\left(\frac{v}{\Vert v\Vert}\right) &= 0\\
          \frac{1}{\Vert v \Vert}T(v) &= 0\\
          T(v) &= 0
        \end{align*}
    \end{itemize}
    \begin{description}
      \item[Special Cases:] $\mathbb{B}(V) = \mathbb{B}(V,V)$, $V^{\ast} = \mathbb{B}(V,\mathbb{F})$.
      \item[Exercise:] $\mathcal{L}(\mathbb{F}^n,\mathbb{F}^m) = \mathbb{B}(\ell_{2}^{n},\ell_{2}^{m}).$
    \end{description}
    \item Inner Product Spaces (expanded upon below).
\end{enumerate}
  \subsubsection{Inner Product Spaces}%
  An inner product on a vector space $V$ is a pairing 
  \begin{align*}
    V \times V \xrightarrow{\langle\cdot,\cdot\rangle} \mathbb{F}
  \end{align*}
  that satisfies
  \begin{enumerate}[(i)]
    \item $\displaystyle \langle v_1+v_2,w\rangle = \langle v_1,w\rangle + \langle v_2,w\rangle$, $\langle \alpha v,w\rangle = \alpha \langle v,w\rangle$.
    \item $\langle v,w\rangle = \overline{\langle w,v\rangle}$
    \item $\langle v,v\rangle \geq 0$.
    \item If $\langle v,v\rangle = 0$, then $v = 0$.
  \end{enumerate}
  The pair $(V,\langle\cdot,\cdot\rangle)$ is known as an inner product space.
  \begin{description}
    \item[Remarks:] $\langle v,w_1+w_2\rangle = \langle v,w_1\rangle + \langle v,w_2\rangle$, $\langle v,\alpha w \rangle = \overline{\alpha}\langle v,w\rangle$.
  \end{description}
  If $\langle\cdot,\cdot\rangle$ is an inner product on a linear space $V$, then set 
  \begin{align*}
    \Vert v\Vert_{2} &:= \langle v,v\rangle^{1/2}.
  \end{align*}
  \begin{description}
    \item[Exercise:] $\Vert \alpha v \Vert_{2} = |\alpha|\Vert v_2\Vert$, $\Vert v \Vert_2 = 0 \Rightarrow v = 0$.
  \end{description}
  $v,w\in (V,\langle,\cdot,\cdot\rangle)$ are \textit{orthogonal} if $\langle v,w\rangle = 0$.\\

  The Pythagoran theorem states that for $v_1,\dots,v_n\in V$ mutually orthogonal, then
  \begin{align*}
    \left\Vert\sum_{i=1}^{n}v_i\right\Vert^{2} &= \sum_{j=1}^{n}\Vert v_j\Vert^2.
  \end{align*}
  For two vectors $v,w\in V$, $P_{w}(v) = \frac{\langle v,w\rangle}{\langle w,w\rangle}w$.
  \begin{description}
    \item[Exercise:] Check that $\iprod{P_{w}(v)}{v-P_{w}(v)}$, meaning
      \begin{align*}
        \Vert v \Vert^2 &= \Vert P_w(v)\Vert^2 + \Vert v-P_{w}(v)\Vert ^2
      \end{align*}
    \item[Cauchy-Schwarz Inequality:] In any inner product space,
      \begin{align*}
        |\iprod{v}{w}| &\leq \Vert v \Vert \cdot \Vert w \Vert.
      \end{align*}
    \item[Proof of Cauchy-Schwarz:] From the exercise,
      \begin{align*}
        \Vert v \Vert &\geq \Vert P_w(v)\Vert\\
        \Vert v \Vert &\geq \left\Vert \frac{\iprod{v}{w}}{\iprod{w}{w}}w\right\Vert\\
                      &= \frac{|\iprod{v}{w}|}{\Vert w \Vert^2}\Vert w \Vert\\
                      \shortintertext{therefore,}
        \Vert v \Vert \Vert w \Vert &\geq |\iprod{v}{w}|
      \end{align*}
  \end{description}
  The triangle inequality follows from the Cauchy-Schwarz inequality.
  \begin{description}
    \item[Proof of Triangle Inequality:]
      \begin{align*}
        \Vert v + w \Vert_2^2 &= \iprod{v+w}{v+w}\\
                              &= \iprod{v}{v} + \iprod{v}{w} + \iprod{w}{v} + \vert{w}{w}\\
                              &= \Vert v \Vert^2 + \Vert w \Vert^2 + \iprod{v}{w} + \overline{\iprod{v}{w}}\\
                              &= \Vert v \Vert^2 + \Vert w \Vert^2 + 2\text{Re}\iprod{v}{w}\\
                              &\leq \Vert v\Vert^2 + \Vert w \Vert^2 + 2|\iprod{v}{w}|\\
                              &\leq \Vert v \Vert^2 + \Vert w \Vert^2 + 2\Vert v \Vert\Vert w \Vert\tag*{Cauchy-Schwarz Inequality}\\
                              &= \left(\Vert v \Vert + \Vert w \Vert\right)^2.
      \end{align*}
      Take square roots on both sides.
  \end{description}
  \begin{enumerate}[(1)]
    \item $\ell_{2}^{n}=\mathbb{F}^n$ with
      \begin{align*}
        \iprod{ \begin{bmatrix}x_1\\\vdots\\x_n\end{bmatrix} }{ \begin{bmatrix}y_1\\\vdots\\y_n\end{bmatrix} } &= \sum_{i=1}^{n}x_i\overline{y_i}.
      \end{align*}
      Cauchy-Schwarz is found as
      \begin{align*}
        \left|\sum_{j=1}^{n}x_j\overline{y_j}\right| &\leq \left(\sum_{j=1}^{n}|x_j|^2\right)^{1/2}\left(\sum_{j=1}^{n}|y_j|^2\right)^{1/2}.
      \end{align*}
    \item $\ell_2$ with
      \begin{align*}
        \iprod{(a_j)_j}{(b_j)_{j}} &= \sum_{j=1}^{\infty}a_j\overline{b}_j.
      \end{align*}
      We can see that for any finite $n$, the Cauchy-Schwarz inequality in $\ell_{2}^{n}$ states
      \begin{align*}
        \left|\sum_{j=1}^{n} a_j\overline{b_j}\right| &\leq \left(\sum_{j=1}^{n}|a_j|^2\right)^{1/2} \left(\sum_{j=1}^{n}|b_j|^2\right)^{1/2}\\
                                                      &\leq \left(\sum_{j=1}^{\infty}|a_j|^2\right)^{1/2}\left(\sum_{j=1}^{\infty}|b_j|^2\right)^{1/2}.
      \end{align*}
    Taking the limit as $n\rightarrow\infty$, we see that $\iprod{(a_j)_j}{(b_j)_j}$ is convergent.
    \item $C([a,b])$ with
      \begin{align*}
        \iprod{f}{g} &= \int_{a}^{b}f(x)\overline{g(x)}dx.
      \end{align*}
    \item Let $V = \mathbb{M}_{n}(\mathbb{C})$.\\

      Recall that if
      \begin{align*}
        a &= (a_{ij})_{i,j},
      \end{align*}
      then
      \begin{align*}
        a^{\ast} &= (\overline{a_{ji}})_{i,j}.
      \end{align*}
      Let $\text{Tr}:\mathbb{M}_{n}(\mathbb{C}) \rightarrow \mathbb{C}$, $\text{Tr}((a_{ij})) = \sum_{i=1}^{n}a_{ii}$.
      \begin{itemize}
        \item $\text{Tr}(I_{n}) = n$
        \item $\text{Tr}(a + \alpha b) = \text{Tr}(a) + \alpha\text{Tr}(b)$
        \item $\text{Tr}(ab) = \text{Tr}(ba)$
      \end{itemize}
      Then, if $\text{Tr}(a^{\ast}a) = 0$, then $a = \mathbb{0}_{\mathbb{M}_n}$.
      \begin{align*}
        a^{\ast}a &= (\overline{a_{ji}})_{i,j}(a_{ij})_{i,j}\\
                  &= \left(\sum_{k=1}^{n}\overline{ki}a_{kj}\right)_{i,j}\\
        \text{Tr}(a^{\ast}a) &= \sum_{i=1}^{n}\sum_{k=1}^{n}\overline{a_{ki}}a_{ki}\\
                             &= \sum_{i,k=1}^{n}|a_{ki}|^{2}\\
                             &= \sum_{i,j=1}^{n}|a_{ij}|^{2}.
      \end{align*}
      If $\text{Tr}(a^{\ast}a) = 0$, then $a_{ij} = 0$ for all $i,j$.\\

      We define
      \begin{align*}
        \iprod{a}{b}_{\text{HS}} &= \text{Tr}(b^{\ast}a).
      \end{align*}
      \begin{enumerate}[(i)]
        \item $(b_1 + b_2)^{\ast} = b_1^{\ast} + b_2^{\ast}$
        \item $(\alpha b)^{\ast} = \overline{\alpha}b^{\ast}$
        \item $(b_1b_2)^{\ast} = b_2^{\ast}b_1^{\ast}$
        \item $b^{\ast\ast} = b$
      \end{enumerate}
      The norm is defined as
      \begin{align*}
        \norm{a}_{\text{HS}} &= \iprod{a}{a}^{1/2}\\
                             &= \text{Tr}(a^{\ast}a)^{1/2}\\
                             &= \left(\sum_{i,j=1}^{n}|a_{ij}|^2\right)^{1/2}
      \end{align*}
  \end{enumerate}
  \section{Metric Spaces}%
  We looked at normed spaces, where we attach a length $\norm{v}$ to very vector $v$. We can also speak of the distance between two vectors, defined as $d(v,w) = \norm{v-w}$.\\

  Notice that the following hold:
  \begin{itemize}
    \item $d(v,w) \geq 0$
    \item 
      \begin{align*}
        d(v,w) &= \norm{v-w}\\
               &= \norm{(-1)(w-v)}\\
               &= |-1|\norm{w-v}\\
               &= \norm{w-v}
      \end{align*}
    \item 
      \begin{align*}
        d(u,w) &= \norm{u-w}\\
               &= \norm{u-v+v-w}\\
               &\leq \norm{u-v} + \norm{v-w}\\
               &= d(u,v) + d(v,w).
      \end{align*}
    \item $d(v,v) = \norm{v-v} = 0$. If $d(v,w) = 0$, then $\norm{v-w} = 0$, so $v-w = \mathbb{0}$, so $v = w$.
  \end{itemize}
  In Real Analysis I, we studied the properties (such as convergence, limits, and continuity) of a particular normed vector space, namely $(\R,|\cdot|)$. We will expand these concepts to all metric spaces.\\

  \subsection{Definition of a Metric Space}%
  Let $X$ be a non-empty set. A \textbf{metric} on $X$ is a map
  \begin{align*}
    d: X\times X \rightarrow \R^{+}\\
    (x,y)\mapsto d(x,y)\geq 0
  \end{align*}
  such that
  \begin{enumerate}[(i)]
    \item Symmetry: $d(x,y) = d(y,x)$ for all $x,y\in X$.
    \item Triangle Inequality: $d(x,z) \leq d(x,y) + d(y,z)$ for all $x,y,z\in X$.
    \item Zero Distance: $d(x,x) = 0$
    \item Definite: $d(x,y) = 0 \Rightarrow x = y$
  \end{enumerate}
  If $d$ satisfies (i), (ii), and (iii), then $d$ is called a semi-metric. If $d$ satisfies (iv) as well, then $d$ is a metric.\\

  If $d$ is a (semi-)metric on $X$, the pair $(X,d)$ is called a (semi-)metric space.\\

  Two metrics, $d$ and $\rho$, on $X$, are equivalent if $\exists c_1,c_2 \geq 0$ such that $d(x,y) \leq c_1\rho(x,y)$ and $\rho(x,y) \leq c_2 d(x,y)$ for all $x,y$.
  \subsection{Examples of Metric Spaces}%
  \begin{enumerate}[(1)]
    \item Discrete Metric:
      \begin{align*}
        d(x,y) &= \begin{cases}
          1 & x\neq y\\
          0 & x=y
        \end{cases}
      \end{align*}
      for $X$ any set.
    \item Hamming distance: between two bit strings of equal length. Let
      \begin{align*}
        X &= \{0,1\}^{n}\\
          &= \{0,1\} \underbrace{\times \cdots \times }_{\text{$n$ times}}\{0,1\}\\
        d_{H}((x_j)_{1}^{n},(y_j)_{1}^{n}) &= \left|\{j\mid x_j\neq y_j\}\right|.
      \end{align*}
    \item Any normed space $(V,\norm{\cdot})$ is a metric space.
      \begin{align*}
        d(v,w) &= \norm{v-w}.
      \end{align*}
      \begin{description}
        \item[Exercise:] Show that if two norms are equivalent, their induced metrics are equivalent.
      \end{description}
    \item Subset of Metric Space: If $(X,d)$ is a metric space, and $Y\subseteq X$ is non-empty. Then, $(Y,d)$ is a metric space.
    \item Paris metric: let $(X,\rho)$ be a metric space. Let $p\in X$ be a fixed point.
      \begin{align*}
        \rho(x,y) &:= \begin{cases}
          0 & x=y\\
          \rho(x,p) + \rho(p,y) & x\neq y
        \end{cases}
      \end{align*}
    \item Bounded metric: Let $\rho$ be a (semi-)metric on $X$. Set
      \begin{align*}
        d(x,y) &= \frac{\rho(x,y)}{1 + \rho(x,y)}.
      \end{align*}
      We claim that $d$ is a (semi-)metric. Notice that $0\leq d(x,y) \leq 1$.
      \begin{description}
        \item[Proof:] Clearly, $d(x,y) = d(y,x)$. Additionally, $d(x,x) = 0$. If $d(x,y) = 0$ and $\rho$ is a metric, then $\rho(x,y) = 0$, so $x = y$.\\

          To show the triangle inequality, we examine the function
          \begin{align*}
            f(t) &= \frac{t}{1+t}\\
            f'(t) &= \frac{1}{(1+t)^2} > 0.
          \end{align*}
          Since $\rho$ satisfies the triangle inequality, $\rho(x,z) \leq \rho(x,y) + \rho(y,z)$. Apply $f$ on both sides. Then,
          \begin{align*}
            \underbrace{\frac{\rho(x,z)}{1 + \rho(x,z)}}_{d(x,z)} &\leq \frac{\rho(x,y) + \rho(y,z)}{1 + (\rho(x,y) + \rho(y,z))}\\
                                            &= \frac{\rho(x,y)}{1+\rho(x,y) + \rho(y,z)} + \frac{\rho(y,z)}{1+\rho(x,y) + \rho(y,z)}\\
                                            &\leq \underbrace{\frac{\rho(x,y)}{1 + \rho(x,y)}}_{d(x,y)} + \underbrace{\frac{\rho(y,z)}{1 + \rho(y,z)}}_{d(y,z)}.
          \end{align*}
      \end{description}
    \item If $d_1,\dots,d_n$ are metrics on $X$, $c_1,\dots,c_n \geq 0$. Then, 
      \begin{align*}
        d(x,y) &= \sum_{k=1}^{n}c_kd_k(x,y)
      \end{align*}
       is a metric.
     \item Let $\{\rho_k\}_{k=1}^{\infty}$ be a family of semi-metrics. Assume the family is separating --- for all $x\neq y$, there exists $k$ such that $\rho_k(x,y) \neq 0$.\\

       Let $d_k$ be defined as
       \begin{align*}
         d_k(x,y) &= \frac{\rho_k(x,y)}{1 + \rho_k(x,y)}.
       \end{align*}
       Note that $\{d_k\}_{k=1}^{\infty}$ is also separating.\\

       Then, 
       \begin{align*}
         d(x,y) &= \sum_{k=1}^{\infty}2^{-k}d_k(x,y)
       \end{align*}
      is a metric.
    \item Frechet Metric: Let $X = C(\R)$. For each $k = 1,2,3,\dots$, set $p_k(f) = \sup_{x\in[-k,k]}|f(x)|$.\\

      We can verify that $p_k$ defines a seminorm. We can then check $\rho_k(f,g) = p_k(f-g)$ is a semi-metric. \\

      We claim that $\{\rho_k\}$ is separating: if $f\neq g$, then there exists $x_0\in \R$ with $f(x_0)\neq g(x_0)$. Since $f$ and $g$ are continuous, there is a neighborhood $[x_0-\delta,x_0+\delta]$ such that $f(x)\neq g(x)$ for all $x\in [x_0-\delta,x_0+\delta]$. Find $k$ such that $[x_0-\delta,x_0+\delta]\subseteq [-k,k]$. Then, $\rho_k(f-g) > 0$.\\

      Construct $d_k$ as above, and then $d$ as follows:
      \begin{align*}
        d_{\text{F}} &= \sum \frac{2^{-k}p_k(f-g)}{1 + p_k(f-g)}
      \end{align*}
  \end{enumerate}
\end{document}
