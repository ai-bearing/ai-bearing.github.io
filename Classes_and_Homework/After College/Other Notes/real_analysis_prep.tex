\documentclass[10pt]{mypackage}

% sans serif font:
%\usepackage{cmbright,sfmath,bbold}
%\renewcommand{\mathcal}{\mathtt}

%Euler:
\usepackage{newpxtext,eulerpx,eucal,eufrak}
\renewcommand*{\mathbb}[1]{\varmathbb{#1}}
\renewcommand*{\hbar}{\hslash}

%\renewcommand{\mathbb}{\mathds}
\usepackage{homework}
%\usepackage{exposition}

\pagestyle{fancy} %better headers
\fancyhf{}
\DeclareMathOperator{\sinc}{sinc}
\rhead{Avinash Iyer}
\lhead{Real Analysis Qualifier Preparation}

\setcounter{secnumdepth}{0}

\begin{document}
\RaggedRight
This is a collection of old real analysis qualifier exam solutions, as well as some notes on useful results and proofs.
\section{Useful Results and Proofs}%
\subsection{Borel--Cantelli Lemma}%
\begin{theorem}
  If $\set{E_j}_j\subseteq \mathcal{M}$ is a family of measurable sets, with
  \begin{align*}
    \sum_{j=1}^{\infty}\mu\left( E_j \right) &< \infty,
  \end{align*}
  then
  \begin{align*}
    \mu\left( \limsup_{j\rightarrow\infty}E_j \right) &= 0.
  \end{align*}
\end{theorem}
\begin{proof}
  Recall the definition of the limit superior of a collection of sets $\set{E_j}_j$ is defined by
  \begin{align*}
    \limsup\left( E_j \right) &= \bigcap_{k=1}^{\infty}\bigcup_{j=k}^{\infty} E_j.
  \end{align*}
  Defining
  \begin{align*}
    F_k &= \bigcup_{j=k}^{\infty} E_j,
  \end{align*}
  we see that $F_k \supseteq F_{k+1}\supseteq \cdots$. Furthermore, note that
  \begin{align*}
    \mu\left( F_k \right) &\leq \sum_{j=k}^{\infty} \mu\left( E_j \right),
  \end{align*}
  and
  \begin{align*}
    \mu\left( F_1 \right) &\leq \sum_{j=k}^{\infty}\mu\left( E_j \right)\\
                          &< \infty.
  \end{align*}
  Thus, by continuity from above, we see that
  \begin{align*}
    \mu\left( \limsup_{j\rightarrow\infty} E_j \right) &= \mu\left( \bigcap_{k=1}^{\infty}F_k \right)\\
                                                       &= \lim_{k\rightarrow\infty}\mu\left( F_k \right)\\
                                                       &\leq \lim_{k\rightarrow\infty}\sum_{j=k}^{\infty} \mu\left( E_j \right)\\
                                                       &= 0,
  \end{align*}
  as the series converges.
\end{proof}
\subsection{Functions Defined as Integrals}%
\begin{theorem}
  Let $f\colon X\times [a,b]\rightarrow \C$, where $-\infty < a < b < \infty$, suppose and $f\left( \cdot,t \right)\colon X\rightarrow \C$ is integrable for each $t\in [a,b]$. Let $F(t) = \int_{X}^{} f(x,t)\:d\mu(x)$.
  \begin{enumerate}[(a)]
    \item If there exists $g\in L_1\left( \mu \right)$ such that $\left\vert f(x,t) \right\vert < g(x)$ for all $x,t$, and $\lim_{t\rightarrow t_0} f\left( x,t \right) = f\left( x,t_0 \right)$ for every $x$, then $\lim_{t\rightarrow t_0}F\left( t \right) = F\left( t_0 \right)$. In particular, if $f\left( x,\cdot \right)$ is continuous for every $x$, then $F$ is continuous.
    \item If $\pd{f}{t}$ exists, and there is $g\in L_1\left( \mu \right)$ such that $\left\vert \pd{f}{t} \left( x,t \right)\right\vert\leq g(x)$ for all $x,t$. Then, $F$ is differentiable, and $F'(t) = \int_{X}^{} \pd{f}{t}\left( x,t \right)\:d\mu(x)$.
  \end{enumerate}
\end{theorem}
\begin{proof}\hfill
  \begin{enumerate}[(a)]
    \item If $\left( t_n \right)_n\rightarrow t_0$, we may define
      \begin{align*}
        f_n\left( x \right) &= f\left( x,t_n \right),
      \end{align*}
      and use the Dominated Convergence Theorem to find that.
      \begin{align*}
        \lim_{n\rightarrow\infty} F\left( t_n \right) &= \lim_{n\rightarrow\infty}\int_{X}^{} f\left( x,t_n \right)\:d\mu(x)\\
                                                      &= \int_{X}^{} \lim_{n\rightarrow\infty}f\left( x,t_n \right)\:d\mu(x)\\
                                                      &= \int_{X}^{} f\left( x,t \right)\:d\mu(x)\\
                                                      &= F\left( t \right),
      \end{align*}
      so $F\left( t \right)$ is continuous.
    \item Observe that
      \begin{align*}
        \pd{f}{t} \left( x,t_0 \right) &= \lim_{n\rightarrow\infty} \frac{f\left( x,t_n \right)-f\left( x,t_0 \right)}{t_n-t_0},
      \end{align*}
      where $\left( t_n \right)_n\rightarrow t_0$. It follows that $\pd{f}{t}$ is measurable, and by mean value theorem,
      \begin{align*}
        \left\vert \frac{f\left( x,t_n \right)-f\left( x,t_0 \right)}{t_n-t_0} \right\vert &\leq \sup_{t\in [a,b]} \left\vert \pd{f}{t}\left( x,t \right) \right\vert \leq g(x),
      \end{align*}
      so by Dominated Convergence,
      \begin{align*}
        F'\left( t_0 \right) &= \lim_{n\rightarrow\infty} \frac{F\left( t_n \right) - F\left( t_0 \right)}{t_n-t_0}\\
                             &= \lim_{n\rightarrow\infty} \int_{X}^{} \frac{f\left( x,t_n \right)-f\left( x,t_0 \right)}{t_n-t_0}\:d\mu(x)\\
                             &= \int_{X}^{} \pd{f}{t}\left( x,t \right)\:d\mu(x).
      \end{align*}
  \end{enumerate}
\end{proof}

\subsection{Completeness of $L_p$}%
\begin{theorem}
  If $\left( X,\mathcal{M},\mu \right)$ is a measure space, then $L_p\left( \mu \right)$ is complete.
\end{theorem}
\begin{proof}
  Let $\left( f_n \right)_n\subseteq L_p\left( X,\mathcal{M},\mu \right)$ be $L_p$-Cauchy. Then, we may extract a subsequence $\left( f_{n_{k}} \right)_k$ such that
  \begin{align*}
    \norm{f_{n_{k+1}}-f_{n_{k}}} &< 2^{-k},
  \end{align*}
  by recursively selecting $n_{k+1} > n_{k}$ and using the fact that $\left( f_n \right)_n$ is Cauchy.\newline

  Consider now the functions
  \begin{align*}
    s_n &= \sum_{k=1}^{n} \left\vert f_{n_{k+1}} -f_{n_{k}} \right\vert\\
    s &= \sum_{k=1}^{\infty} \left\vert f_{n_{k+1}}-f_{n_{k}} \right\vert.
  \end{align*}
  We see from Minkowski's Inequality that
  \begin{align*}
    \norm{s_{n}} &\leq \sum_{k=1}^{n} \norm{f_{n_{k+1}}-f_{n_{k}}},
  \end{align*}
  and so by using Fatou's Lemma, that
  \begin{align*}
    \norm{s} &\leq \liminf_{n\rightarrow\infty} \norm{s_{n}}\\
             &\leq \liminf_{n\rightarrow\infty}\sum_{k=1}^{n} \norm{f_{n_{k+1}}-f_{n_{k}}}\\
             &\leq \sum_{k=1}^{\infty} 2^{-k}\\
             &= 1,
  \end{align*}
  meaning that in particular, $s(x)< \infty$ for a.e. $x\in X$. Thus, the series
  \begin{align*}
    s &= \sum_{k=1}^{\infty} \left\vert f_{n_{k+1}}-f_{n_{k}} \right\vert
  \end{align*}
  converges absolutely for almost every $x$. Define now the function
  \begin{align*}
    f(x) &= f_{n_{1}}(x) + \sum_{k=1}^{\infty} \left( f_{n_{k+1}}-f_{n_{k}} \right)(x)
  \end{align*}
  where $s$ converges, and $0$ otherwise. Notice that
  \begin{align*}
    f_{n_{k}}(x) &= f_{n_{1}}(x) + \sum_{k=1}^{n-1}f_{n_{k+1}}(x) - f_{n_{k}}(x),
  \end{align*}
  so by telescoping, we see that
  \begin{align*}
    f(x) &= \lim_{k\rightarrow\infty}f_{n_{k}}(x)
  \end{align*}
  for almost every $x$.
  \begin{remark}
    This is part of how we show that if a sequence $\left( f_{n} \right)_n\rightarrow f$ in $L_p$, then $\left( f_{n} \right)_{n}$ admits a sequence converging pointwise a.e. to $f$.
  \end{remark}
  Now, we show that $f$ is the $L_p$ limit of $\left( f_n \right)_n$. To see this, let $\ve > 0$, and let $N$ be such that for all $m,n \geq N$, $\norm{f_m - f_n} < \ve$. Then, we see that for all $m\geq N$,
  \begin{align*}
    \int_{X}^{} \left\vert f-f_m \right\vert^{p}\:d\mu &= \int_{X}^{} \liminf_{k\rightarrow\infty} \left\vert f_{n_{k}} - f_m \right\vert\:d\mu\\
                                                       &\leq \liminf_{k\rightarrow\infty} \int_{X}^{} \left\vert f_{n_{k}}-f_m \right\vert\:d\mu\\
                                                       &\leq \ve^{p},
  \end{align*}
  so that $\norm{f-f_m} \leq \ve$. Since Cauchy sequences are bounded, and for all $m\geq N$,
  \begin{align*}
    \norm{f} &= \norm{f-f_m + f_m}\\
             &\leq \norm{f-f_m} + \norm{f_m}\\
             &\leq \ve + \norm{f_m}\\
             &< \infty,
  \end{align*}
  we see that $f\in L_p$, and we are done.
\end{proof}
\subsection{Modes of Convergence}%
\begin{definition}
  Let $\left( f_n \right)_n$ be a sequence of measurable, complex-valued functions on $\left( X,\mathcal{M},\mu \right)$. 
  \begin{enumerate}[(i)]
    \item We say that $\left( f_n \right)_n$ is Cauchy in measure if, for all $\ve > 0$, we have
      \begin{align*}
        \mu\left( \set{x | \left\vert f_m(x)-f_n(x) \right\vert\geq \ve} \right) &\rightarrow 0
      \end{align*}
      as $m,n\rightarrow\infty$.
    \item We say that $\left( f_n \right)_n\rightarrow f$ in measure if, for all $\ve > 0$, the sequence
      \begin{align*}
        \mu\left( \set{x | \left\vert f_n(x)-f(x) \right\vert \geq \ve} \right) \rightarrow 0.
      \end{align*}
    \item We say $\left( f_n \right)_n\rightarrow f$ in $L_1$ if the sequence
      \begin{align*}
        \int_{X}^{} \left\vert f_n-f \right\vert\:d\mu &\rightarrow 0.
      \end{align*}
  \end{enumerate}
\end{definition}
\begin{proposition}
  If $\left( f_n \right)_n\rightarrow f$ in $L_1$, then $\left( f_n \right)_n\rightarrow f$ in measure.
\end{proposition}
\begin{proof}
  Let
  \begin{align*}
    E_{n,\ve} &= \set{x | \left\vert f_n(x) - f(x) \right\vert \geq \ve}.
  \end{align*}
  Then,
  \begin{align*}
    \int_{X}^{} \left\vert f_n-f \right\vert\:d\mu &\geq \int_{E_{n,\ve}}^{} \left\vert f_n-f \right\vert\:d\mu\\
                                                   &\geq \ve \mu\left( E_{n,\ve} \right),
  \end{align*}
  so
  \begin{align*}
    \mu\left( E_{n,\ve} \right) &\leq \frac{1}{\ve} \int_{X}^{} \left\vert f_n-f \right\vert\:d\mu.
  \end{align*}
\end{proof}
\begin{remark}
  We may have proven this by using Chebyshev's inequality, which is proved in effectively the same way. We will prove Chebyshev's inequality below.
\end{remark}
\begin{theorem}
  If $\left( f_n \right)_n$ is Cauchy in measure, then there is a measurable function $f$ such that $\left( f_n \right)_n\rightarrow f$ in measure, and $\left( f_{n_{j}} \right)_j\rightarrow f$ almost everywhere. Furthermore, these limits are essentially unique (i.e., any two such limits are equal almost everywhere).
\end{theorem}
\begin{proof}
  We may choose a subsequence $\left( f_{n_{j}} \right)_j$ such that if we define
  \begin{align*}
    E_j &= \set{x | \left\vert f_{n_{j+1}}(x) -f_{n_{j}}(x) \right\vert\geq 2^{-j}},
  \end{align*}
  then
  \begin{align*}
    \mu\left( E_j \right) &\leq 2^{-j}.
  \end{align*}
  Note that this means
  \begin{align*}
    \sum_{j=1}^{\infty}\mu\left( E_j \right) &\leq 1\\
                                             &< \infty,
  \end{align*}
  so $\mu\left( \limsup_{j\rightarrow\infty}E_j \right) = 0$ by the Borel--Cantelli Lemma. In particular, for all $x\notin \limsup_{j\rightarrow\infty} E_j$, $\left( f_{n_{j}} \right)_{j}$ is pointwise Cauchy, so we may set $f(x) = \lim_{j\rightarrow\infty}f_{n_{j}}(x)$, and we set $f(x) = 0$ for all $x\in \limsup_{j\rightarrow\infty}E_j$.\newline

  This means that $\left( f_{n_{j}} \right)_j\rightarrow f$ almost everywhere, and $\left\vert f_{n_{j}}(x) - f(x) \right\vert\leq 2^{1-j}$ for all $x\notin \bigcup_{j=k}^{\infty}E_j$ and $j\geq k$. It follows that $\left( f_{n_{j}} \right)_j\rightarrow f$ in measure.\newline

  Furthermore, since
  \begin{align*}
    \set{x | \left\vert f_n(x)-f(x) \right\vert\geq \ve} &\subseteq \set{x | \left\vert f_{n}(x) -f_{n_{j}}(x) \right\vert \geq \frac{1}{2}\ve} \cup \set{x | \left\vert f_{n_{j}}(x)-f(x) \right\vert \geq \frac{1}{2}\ve},
  \end{align*}
  and the latter two sets have small measure with sufficiently large $n$ and $j$, it follows that $\left( f_{n} \right)_n\rightarrow f$ in measure.
\end{proof}
\begin{theorem}[Egorov's Theorem]
  If $\mu\left( X \right) < \infty$, and $\left( f_{n} \right)_n\rightarrow f$ pointwise a.e., then for any $\ve > 0$, there is $E\subseteq X$ such that $\mu\left( E \right) < \ve$ and $f_n\rightarrow f$ uniformly on $E^{c}$.
\end{theorem}
\begin{proof}
  We may assume that $\left( f_n \right)_n\rightarrow f$ everywhere on $X$. For $k,n\in\N$, define
  \begin{align*}
    E_{n,k} &= \bigcup_{m=n}^{\infty} \set{x | \left\vert f_m(x) - f(x) \right\vert \geq \frac{1}{k}}.
  \end{align*}
  For fixed $k$, $E_{n,k}$ reduces as $n\rightarrow\infty$, and $\bigcap_{n=1}^{\infty} E_{n,k} = \emptyset$. Since $\mu\left( X \right) < \infty$, we may assume that $\mu\left( E_{n,k} \right)\rightarrow 0$ for fixed $k$ as $n\rightarrow\infty$. Thus, we may choose $n_k$ such that $\mu\left( E_{n_k,k} \right) < \ve 2^{-k}$, and define $E = \bigcup_{k=1}^{\infty}E_{n_k,k}$. Then, $\mu\left( E \right) < \ve$, and $\left\vert f_n(x)-f(x) \right\vert < \frac{1}{k}$ for all $n\geq n_k$ and $x\notin E$. Thus, $\left( f_n \right)_n\rightarrow f$ uniformly on $E^{c}$.
\end{proof}
\subsection{Signed Measures and Radon--Nikodym}%
\begin{definition}
  A \textit{signed measure} on a measurable space $\left( X,\mathcal{M} \right)$ is a function $\nu\colon \mathcal{M}\rightarrow [-\infty,\infty]$ such that
  \begin{itemize}
    \item $\nu\left( \emptyset \right) = 0$;
    \item $\nu$ does \textit{not} attain at least one of $+\infty$ or $-\infty$;
    \item if $\set{E_j}_{j=1}^{\infty}$ is a sequence of disjoint sets in $\mathcal{M}$, then
      \begin{align*}
        \nu\left( \bigsqcup_{j=1}^{\infty}E_j \right) &= \sum_{j=1}^{\infty}\nu\left( E_j \right),
      \end{align*}
      where the latter sum converges absolutely when the former value is finite.
  \end{itemize}
\end{definition}
\begin{definition}
  If $\nu$ is a signed measure, then we say $E\in \mathcal{M}$ is
  \begin{itemize}
    \item \textit{positive} for $\nu$ if for all $F\in \mathcal{M}$ with $F\subseteq E$, $\nu\left( F \right) \geq 0$;
    \item \textit{negative} for $\nu$ if for all $F\in \mathcal{M}$ with $F\subseteq E$, $\nu\left( F \right) \leq 0$;
    \item \textit{null} for $\nu$ if for all $F\in \mathcal{M}$ with $F\subseteq E$, $\nu\left( F \right) = 0$.
  \end{itemize}
\end{definition}
\begin{theorem}[Hahn and Jordan Decomposition]
  If $\nu$ is a signed measure on $\left( X,\mathcal{M} \right)$, there exist measurable subsets $P$ and $N$ such that $P\cap N = \emptyset$, $P\cup N = X$, $P$ is positive for $\nu$, and $N$ is negative for $\nu$.
\end{theorem}
\begin{proof}
  Without loss of generality, we may assume that for all $E\in \mathcal{M}$, $-\infty < \mu\left( E \right) \leq \infty$.\newline

  We note that the difference of two negative sets is negative, and the disjoint, countable union of negative sets is negative, so every countable union of negative sets is negative. We let $\beta = \inf\left( \mu\left( B \right) \right)$ for all negative $B\in \mathcal{M}$. We let $\left( B_j \right)_j\subseteq \mathcal{M}$ be a sequence of measurable negative sets such that $\lim_{j\rightarrow\infty}\mu\left( B_j \right) = \beta$, and set $B = \bigcup_{j=1}^{\infty}B_j$. We see then that $B$ is a negative set for which $\mu\left( B \right)$ is minimal.\newline

  We now prove that $A = X\setminus B$ is a positive set. Suppose toward contradiction that there is $E_0\subseteq A$ such that $\mu\left( E_0 \right) < 0$. The set $E_0$ cannot be a negative set, or else $B \cup E_0$ would be a negative set with a smaller measure than $\mu\left( B \right)$, which is not possible.\newline

  Let $k_1$ be the smallest natural number such that there is $E_1\subseteq E_0$ with $\mu\left( E_1 \right) \geq \frac{1}{k_1}$. Since
  \begin{align*}
    \mu\left( E_0\setminus E_1 \right) &= \mu\left( E_0 \right) - \mu\left( E_1 \right)\\
                                       &\leq \mu\left( E_0 \right) - \frac{1}{k_1}\\
                                       &< 0.
  \end{align*}
  The argument applied to $E_0$ is now applicable to $E_0\setminus E_1$. Letting $k_2$ be the smallest natural number such that $E_0\setminus E_1$ contains $E_2\subseteq E_0\setminus E_1$ with $\mu\left( E_2 \right) \geq \frac{1}{k_2}$, and proceeding ad infinitum, we see that since $\mu$ is finitely valued for measurable subsets of $E_0$, we have $\lim_{n\rightarrow\infty}\frac{1}{k_n} = 0$.\newline

  It follows that for every measurable subset $F$ of
  \begin{align*}
    F_0 &= E_0\setminus \left( \bigcup_{j=1}^{\infty}E_j \right),
  \end{align*}
  we have $\mu\left( F \right) \leq 0$ --- i.e., $F_0$ is a measurable negative set. Since $F_0$ is disjoint from $B$, and
  \begin{align*}
    \mu\left( F_0 \right) &= \mu\left( E_0 \right) - \sum_{j=1}^{\infty}\mu\left( E_j \right)\\
                          &\leq \mu\left( E_0 \right)\\
                          &< 0,
  \end{align*}
  this contradicts the minimality of $B$. Therefore, the hypothesis $\mu\left( E_0 \right) < 0$ is untenable.\newline

  If $A_1\sqcup B_1$ and $A_2\sqcup B_2$ are two Hahn decompositions for $X$, then $A_1\setminus A_2 \subseteq B_2$ and $A_1\setminus A_2 \subseteq A_1$, meaning that $A_1\setminus A_2$ is both positive and negative, hence null; similarly for $A_2\setminus A_1$, so that $A_1\triangle A_2$ is $\mu$-null, and similarly for $B_1\triangle B_2$.
\end{proof}
\begin{definition}
  We say two signed measures $\mu$ and $\nu$ are \textit{mutually singular} on $X$ if there exist $E,F\in \mathcal{M}$ such that $E\cap F = \emptyset$, $E\cup F = X$, $E$ is null for $\mu$, and $F$ is null for $\nu$. We write $\nu\perp\mu$
\end{definition}
\begin{theorem}[Jordan Decomposition]
  If $\nu$ is a signed measure, there are positive measures $\nu^{+}$ and $\nu^{-}$ such that $\nu = \nu^{+} - \nu^{-}$.
\end{theorem}
\begin{proof}
  If $P\cup N$ is a Hahn Decomposition for $\nu$, we may define
  \begin{align*}
    \nu^{+}(E) &= \nu\left( E\cap P \right)\\
    \nu^{-}(E) &= -\nu\left( E\cap N \right).
  \end{align*}
  This yields the Jordan decomposition.
\end{proof}
\begin{definition}
  If $\nu = \nu^{+} - \nu^{-}$ is a Jordan decomposition for a signed measure, then the \textit{total variation} of $\nu$ is defined to be
  \begin{align*}
    \left\vert \nu \right\vert &= \nu^{+} + \nu^{-}.
  \end{align*}
\end{definition}
\begin{definition}
  If $\nu$ is a signed measure on $\left( X,\mathcal{M} \right)$, and $\mu$ is a positive measure, then we say that $\nu$ is \textit{absolutely continuous} with respect to $\mu$, written $\nu\ll\mu$, if $\mu(E) = 0$ implies that $\nu(E) = 0$.
\end{definition}
\begin{proposition}
  If $\nu$ is a signed measure on $\left( X,\mathcal{M} \right)$, $\mu$ is a positive measure, then $\nu\ll\mu$ if and only if for all $\ve > 0$, there is $\delta > 0$ such that whenever $\mu\left( E \right) < \delta$, $\left\vert \nu(E) \right\vert < \ve$.
\end{proposition}
\begin{proof}
  Absolute continuity clearly implies the $\ve$-$\delta$ condition. To see the reverse direction, suppose there were some $\ve_0 > 0$ such that for all $n\in \N$, we may find $E_n\in \mathcal{M}$ with $\mu\left( E_n \right) < 2^{-n}$ and $\nu\left( E_n \right) \geq \ve_0$. Then, since
  \begin{align*}
    \sum_{n=1}^{\infty}\mu\left( E_n \right) &< \infty,
  \end{align*}
  the Borel--Cantelli Lemma provides that $\mu\left( \limsup_{n\rightarrow\infty}E_n \right) = 0$. Yet, we must also have that
  \begin{align*}
    \nu\left( \limsup_{n\rightarrow\infty}E_n \right) &= \lim_{k\rightarrow\infty}\nu\left( \bigcup_{j=k}^{\infty}E_j \right)\\
                                                      &\geq \ve_0,
  \end{align*}
  so $\nu\nll\mu$.
\end{proof}
\begin{theorem}[Lebesgue--Radon--Nikodym Theorem]
  If $\nu$ is a signed measure, and $\mu$ is a positive measure, then there exists a measure $\lambda$ and a measurable function $f\colon X\rightarrow \R$ such that $\lambda\perp\rho$, and
  \begin{align*}
    \nu\left( E \right) &= \lambda\left( E \right) + \int_{E}^{} f\:d\mu.
  \end{align*}
  If $\nu\ll\mu$, we say the particular function $f$ is the \textit{Radon--Nikodym derivative} of $\nu$ with respect to $\mu$, and write $\diff{\nu}{\mu} = f$.
\end{theorem}
\subsection{Differentiation}%
\begin{definition}
  A measurable function $f\colon \R^n\rightarrow \C$ is called locally integrable if $f\1_{B}$ is integrable for every closed ball $B\subseteq \R^n$.
\end{definition}
\begin{theorem}[Vitali Covering Lemma]
  If $\set{B_1,\dots,B_N}$ are a finite collection of open balls in $\R^n$, then there exists a disjoint subset $\set{B_{n_1},\dots,B_{n_k}}$ such that
  \begin{align*}
    m\left( \bigcup_{j=1}^{N} B_j \right) &\leq 3^{n} \sum_{j=1}^{k} m\left( B_{n_j} \right).
  \end{align*}
\end{theorem}
\begin{definition}[Hardy--Littlewood Maximal Function]
Let $f\colon \R^n\rightarrow \C$ be a locally integrable function. The Hardy--Littlewood Maximal Function $f^{\ast}\colon \R^n\rightarrow \C$ is defined by
\begin{align*}
  f^{\ast}\left( x \right) &= \sup_{x\in B} \frac{1}{m(B)} \int_{B}^{} \left\vert f(y) \right\vert\:dy,
\end{align*}
where the supremum is taken over all balls $B$ that contain $x\in \R^n$.
\end{definition}
\begin{theorem}[Maximal Theorem]
  If $f\colon \R^n\rightarrow \C$ is locally integrable, then
  \begin{enumerate}[(i)]
    \item $f^{\ast}$ is measurable;
    \item $f^{\ast}$ is finite a.e.;
    \item $f^{\ast}\left( x \right) \geq \left\vert f(x) \right\vert$ a.e.;
    \item if $f$ is integrable, then $f^{\ast}$ satisfies
      \begin{align*}
        m\left( \set{x\in \R^n | f^{\ast}\left( x \right) > \alpha} \right) \leq \frac{3^{n}}{\alpha} \int_{\R^n}^{} \left\vert f(x) \right\vert\:dx.
      \end{align*}
  \end{enumerate}
\end{theorem}
\begin{definition}
  A family of subsets $\set{E_r}_{r > 0}$ is said to \textit{shrink nicely} to $x$ if
  \begin{itemize}
    \item $E_r\subseteq U\left( x,r \right)$ for each $r$;
    \item there is $\alpha > 0$ independent of $r$ such that $m\left( E_r \right) > \alpha m\left( U\left( x,r \right) \right)$.
  \end{itemize}
\end{definition}
\begin{theorem}[Lebesgue Differentiation Theorem]
  If $f\colon \R^n\rightarrow \C$ is locally integrable, then for a.e. $x\in \R^n$, we have
  \begin{align*}
    \lim_{r\rightarrow 0} \frac{1}{m\left(E_r\right)} \int_{B}^{} f(y)\:dy &= f(x)
  \end{align*}
  for every family $\set{E_r}_{r > 0}$ that shrinks nicely to $x$.
\end{theorem}
\begin{corollary}
  If $\nu$ is a regular complex Borel measure on $\R^n$, with Lebesgue--Radon--Nikodym decomposition $d\nu = d\lambda + f\:dm$, then for a.e. $x\in \R^n$,
  \begin{align*}
    \lim_{r\rightarrow 0} \frac{\nu\left( E_r \right)}{m\left( E_r \right)} &= f(x)
  \end{align*}
  for every family $\set{E_r}_{r > 0}$ that shrinks nicely to $x$.
\end{corollary}
\subsection{Cavalieri's Principle}%
\begin{theorem}
  Let $ \left(X, \mathcal{M}, \mu\right) $ be a measure space, $f\colon X\rightarrow [0,\infty]$ a nonnegative measurable function. Then, the function $g\colon [0,\infty)\rightarrow [0,\infty]$ given by $\alpha \mapsto \mu\left(\set{x\in X | f(x) > \alpha}\right)$ is a measurable function, and
  \begin{align*}
    \int_{X}^{} f(x)\:d\mu(x) &= \int_{0}^{\infty} \mu\left(\set{x | f(x) > \alpha}\right)\:d\alpha.
  \end{align*}
\end{theorem}
\begin{proof}
  Since $g$ is a decreasing function, we may set $b = \sup g^{-1}\left([0,a)\right)$, so $g^{-1}\left([0,a)\right)$ is either $[0,b]$ or $[0,b)$, both of which are Borel sets.\newline

  To show the integral identity, let $f = \sum_{k=1}^{K}a_k\1_{A_k}$, where the $a_k$ are distinct and $A_k$ are disjoint, so $f(x) = 0$ if $x\in X \setminus \bigcup_{k=1}^{K}A_k$. From linearity, we have
  \begin{align*}
    \int_{X}^{} \sum_{k=1}^{K}a_k\1_{A_k}\:d\mu(x) &= \sum_{k=1}^{K} a_k\mu\left(A_k\right).
  \end{align*}
  Meanwhile,
  \begin{align*}
    \mu\left(\set{x | \sum_{k=1}^{K}a_k\1_{A_k} > \alpha}\right) &= \sum_{k=1}^{K} \mu\left(A_k\right)\1_{[0,a_k)}(x),
  \end{align*}
  so
  \begin{align*}
    \int_{0}^{\infty} \mu\left(\set{x | \sum_{k=1}^{K}a_k\1_{A_k}(x)}\right)\:d\alpha &= \sum_{k=1}^{K}a_k\mu\left(A_k\right)\\
                                                                                      &= \int_{X}^{} f(x)\:d\mu(x).
  \end{align*}
  Finally, if $f$ is a nonnegative $\mathcal{M}$-measurable function, there exists a pointwise increasing sequence of simple functions $\left(\varphi_m\right)_m$ that converge pointwise to $f$, meaning that by monotone convergence,
  \begin{align*}
    \int_{X}^{} f(x)\:d\mu(x) &= \lim_{m\rightarrow\infty} \int_{X}^{} \varphi_m(x)\:d\mu(x)\\
                              &= \lim_{m\rightarrow\infty} \int_{0}^{\infty} \mu\left(\set{x | \varphi_m(x) > \alpha}\right)\:d\alpha\\
                              &= \int_{0}^{\infty} \mu\left(\set{x | f(x) > \alpha}\right)\:d\alpha.
  \end{align*}
\end{proof}
\subsection{Chebyshev's Inequality}%
\begin{theorem}
  If $f\in L_p\left(X,\mathcal{M},\mu\right)$, then for any $\alpha > 0$, we have
  \begin{align*}
    \mu\left(\set{x | \left\vert f(x)\right\vert \geq \alpha}\right) &\leq \frac{1}{\alpha^{p}} \int_{X}^{} \left\vert f \right\vert^{p}\:d\mu.
  \end{align*}
\end{theorem}
\begin{proof}
  Let $E_{\alpha} = \set{x | \left\vert f(x) \right\vert \geq \alpha}$. Then,
  \begin{align*}
    \int_{X}^{} \left\vert f \right\vert^{p}\:d\mu &\geq \int_{E_{\alpha}}^{} \left\vert f \right\vert^{p}\:d\mu\\
                                                   &\geq \alpha^{p} \int_{X}^{} \1_{E_{\alpha}}\:d\mu\\
                                                   &= \alpha^{p} \mu\left( \set{x | \left\vert f(x) \right\vert > \alpha} \right).
  \end{align*}
\end{proof}
\section{\href{https://math.virginia.edu/graduate/exams/analysis/2019Aug_real.pdf}{August 2019}}%
\subsection{Problem 1}%
\begin{problem}
  Let $\mathcal{C}$ be the Cantor set on $[0,1]$.
  \begin{enumerate}[(a)]
    \item Show that $\mathcal{C} + \mathcal{C} = [0,2]$.
    \item Find two sets $A,B\subseteq \R$ that are closed and have Lebesgue measure zero such that $A+B = \R$.
  \end{enumerate}
\end{problem}
\begin{enumerate}[(a)]
  \item Recall that the Cantor set $\mathcal{C}$ is defined to consist of all $x\in [0,1]$ such that $x$ only contains $0$ and $2$ in the ternary expansion of $x$. Writing $a\in [0,2]$ as
    \begin{align*}
      a &= \sum_{k=0}^{\infty}\frac{a_k}{3^{k}},
    \end{align*}
    where $a_k\in\set{0,1,2}$, we may then find $a_k$ at each ternary expansion slot for $k$ as follows:
    \begin{itemize}
      \item if $a_k = 0$, we may find $b_k,c_k\in \mathcal{C}$ such that $b_k = c_k = 0$
      \item if $a_k = 2$, we may find $b_k,c_k\in \mathcal{C}$ such that $b_k = 2$ and $c_k = 0$ or vice versa.
      \item if $a_k = 1$, we may find $b_k,c_k\in \mathcal{C}$ such that $b_{k+1} = c_{k+1} = 2$.
    \end{itemize}
    Therefore, since every digit of every ternary expansion in $[0,2]$ can be obtained from $\mathcal{C}$, we see that $\mathcal{C} + \mathcal{C} = [0,2]$.
  \item We may set $B$ to be the union of all integer translates of $\mathcal{C}$, and set $A = \mathcal{C}$. This yields closed subsets of $\R$ with Lebesgue measure zero that sum to $\R$.
\end{enumerate}
\subsection{Problem 2}%
\begin{problem}
  Does there exist a finite measure space $\left( X,\mathcal{F},\mu \right)$ and a sequence $\left( f_n \right)_n$ of $\mu$-measurable functions such that
  \begin{itemize}
    \item $f_n(x) \geq 0$;
    \item $f_n(x)\rightarrow 0$ for all $x$;
    \item $ \int_{X}^{} f_n(x)\:d\mu(x) \rightarrow 0 $ as $n\rightarrow \infty$;
    \item $\Phi(x) = \sup_{n}f_n(x)$ has infinite integral?
  \end{itemize}
\end{problem}
Consider the sequence of functions
\begin{align*}
  f_n(x) &= n\1_{\left[ \frac{1}{n+1},\frac{1}{n} \right]},
\end{align*}
defined on $\left[ 0,1 \right]$. This sequence is pointwise convergent everywhere to zero, as $f_n(0) = 0$ and the Archimedean property give that for any $x\in (0,1]$, there is some $n$ large enough that gives $\frac{1}{n} < x$. Furthermore, we see that
\begin{align*}
  \int_{}^{} f_n\:d\mu &= n\left( \frac{1}{n}- \frac{1}{n+1} \right)\\
                       &= \frac{1}{n+1}\\
                       &\rightarrow 0.
\end{align*}
Finally, we see that by taking suprema, we have the integral
\begin{align*}
  \int_{}^{} \Phi\:d\mu &= \sum_{n=1}^{\infty}\frac{1}{n+1}\\
                        &\rightarrow \infty.
\end{align*}
\subsection{Problem 3}%
\begin{problem}
  Let $\mu$ be a signed measure in $\R^n$ that is bounded on bounded sets. Suppose that
  \begin{align*}
    \int_{\R^n}^{} f\:d\mu &= 0
  \end{align*}
  for all continuous functions $f$ with bounded support. Show that $\mu = 0$.
\end{problem}
Fix $r > 0$, and consider the family of continuous functions $f_n$ defined by
\begin{align*}
  f_n &= \begin{cases}
    1 & x\in B\left( 0,r \right)\\
    0\leq f_n(x) \leq 1 & x\in B\left( 0,r+1/n \right)\setminus B\left( 0,r \right)\\
    0 & x\in B\left( 0,r+1/n \right)^{c}
  \end{cases}
\end{align*}
Since each $f_n$ is continuous with bounded support, we see that
\begin{align*}
  \int_{\R^n}^{} f_n\:d\mu &= 0\\
                           &= \int_{B\left( 0,r \right)}^{} f_n\:d\mu + \int_{B\left( 0,r+1/n \right)\setminus B\left( 0,r \right)}^{} f_n\:d\mu.
\end{align*}
We may define $K_n = B\left( 0,r+1/n \right)\setminus B\left( 0,r \right)$. Therefore, 
\begin{align*}
  \left\vert \mu\left( B\left( 0,r \right) \right) \right\vert &= \left\vert \int_{B\left( 0,r \right)}^{} f_n\:d\mu \right\vert\\
                                                               &= \left\vert \int_{K_n}^{} f_n\:d\mu \right\vert\\
                                                               &\leq \int_{K_n}^{} f_n\:d\left\vert \mu \right\vert\\
                                                               &\leq \int_{K_n}^{} \:d\left\vert \mu \right\vert\\
                                                               &= \mu^{+}\left( K_n \right) + \mu^{-}\left( K_n \right).
\end{align*}
Now, since $K_n$ is bounded, we see that $\mu^{+}$ and $\mu^{-}$ are both finite. Thus, since $\bigcap_{n\geq 1}K_n = \emptyset$, we see that $ \left\vert \mu\left( B\left( 0,r \right) \right) \right\vert \leq \lim_{n\rightarrow\infty} \left( \mu^{+}\left( K_n \right) + \mu^{-}\left( K_n \right) \right) = 0 $, so $\mu\left( B\left( 0,r \right) \right)$. Since the Borel $\sigma$-algebra is generated by the closed balls, $\mu = 0$ for all Borel sets.
\subsection{Problem 4}%
\begin{problem}
  Let $L_1(\R)$ be the space of Lebesgue integrable functions on $\R$. Suppose $f\in L_1\left( \R \right)$ is positive. Show that $\frac{1}{f(x)}\notin L_1\left( \R \right)$.
\end{problem}
Suppose toward contradiction that both $f$ and $1/f$ are in $L_1\left( \R \right)$. Then, from Hölder's Inequality, we have
\begin{align*}
  \infty &= \int_{}^{} 1\:d\mu\\
         &\leq \left( \int_{}^{} f\:d\mu \right)^{1/2} \left( \int_{}^{} \frac{1}{f}\:d\mu \right)^{1/2}\\
         &< \infty,
\end{align*}
which is a contradiction.
\subsection{Problem 5}%
\begin{problem}
  Applying the Gram--Schmidt orthogonalization to $\set{1,x,x^2,\dots}$ in the Hilbert space $L_2\left( [-1,1] \right)$ with Lebesgue measure, one gets the Legendre polynomials $L_n(x)$.
  \begin{enumerate}[(a)]
    \item Show that the Legendre polynomials form a basis (complete orthogonal system) in the Hilbert space $L_2\left( [-1,1] \right)$.
    \item Show that the Legendre polynomials are given by the formula $L_n(x) = c_n \diff{^{n}}{x^{n}} \left( x^2-1 \right)^{n}$.
  \end{enumerate}
\end{problem}
\begin{enumerate}[(a)]
  \item Let $f\in L_2\left( [-1,1] \right)$. We may find $g\in C\left( [-1,1] \right)$ such that $\norm{f-g}_{L_2} < \ve/2$. Similarly, we may find a polynomial $p$ such that $\norm{g-p}_{u} < \ve/4$, meaning that $\left\vert p(x)-g(x) \right\vert < \ve/4$ for all $x\in [-1,1]$. This yields
    \begin{align*}
      \norm{p-g}_{L_2} &= \left( \int_{-1}^{1} \left\vert p(x)-g(x) \right\vert^2\:dx \right)^{1/2}\\
                       &< \left( \int_{-1}^{1} \left( \frac{\ve}{4} \right)^2\:dx \right)^{1/2}\\
                       &= \left( \frac{\ve^2}{8} \right)^{1/2}\\
                       &< \frac{\ve}{2},
    \end{align*}
    so $\norm{f-p}_{L_2} < \ve$, meaning that the closed linear span of the monomials is dense in $L_2$, and the Legendre polynomials form an orthonormal system.
  \item We see that at every step in evaluating the expression
    \begin{align*}
      L_n(x) &= c_n \diff{^{n}}{x^{n}}\left( x^2-1 \right)^{n},\label{eq:legendre_expression}\tag{$\ast$}
    \end{align*}
    the degree of the polynomial increases by $1$, so each $L_n(x)$ has degree $n$. To verify that the polynomials generated from \eqref{eq:legendre_expression} are orthogonal to each other, we let $n > m$ without loss of generality, and use integration by parts to obtain
    \begin{align*}
      \iprod{L_n}{L_m} &= \int_{-1}^{1} \left( \diff{^{n}}{x^{n}}\left( x^2-1 \right)^{n} \right) \left( \diff{^{m}}{x^{m}}\left( x^2-1 \right)^{m} \right)\:dx\\
                       &= \diff{^{n-1}}{x^{n-1}}\left( x^2-1 \right)^{n}\diff{^{m}}{x^{m}}\left( x^2-1 \right)^{m}\biggr\vert_{-1}^{1} - \int_{-1}^{1} \diff{^{n-1}}{x^{n-1}}\left( x^2-1 \right)^{n}\diff{^{m+1}}{x^{m+1}}\left( x^2-1 \right)^{m} \:dx\\
                       &\vdots\\
                       &= \left( -1 \right)^{n} \int_{-1}^{1} \diff{^{m+n}}{x^{m+n}}\left( x^2-1 \right)^{m}\:dx\\
                       &= \left( -1 \right)^{n} \int_{-1}^{1} \diff{^{n}}{x^{n}}\left( \diff{^{m}}{x^{m}}\left( x^2-1 \right)^{m} \right)\:dx\\
                       &= \left( -1 \right)^{n} \int_{}^{} \diff{^{n}}{x^{n}}L_m(x)\:dx\\
                       &= 0,
    \end{align*}
    seeing as we are taking $n$ derivatives of a degree $m < n$ polynomial.
\end{enumerate}
\section{\href{https://math.virginia.edu/graduate/exams/analysis/2020Jan_real.pdf}{January 2020}}%
\subsection{Problem 1}%
\begin{problem}
  Let $\mu$ be the Lebesgue measure on $\R$, and let $A\subseteq [0,1]$ be Lebesgue-measurable.
  \begin{enumerate}[(a)]
    \item Prove or show a counterexample to the assertion that
      \begin{align*}
        \mu(A) &= \sup_{\substack{U\subseteq A\\U\text{ open}}} \mu\left( U \right).
      \end{align*}
    \item Prove or show a counterexample to the assertion that
      \begin{align*}
        \mu(A) &= \inf_{\substack{A\subseteq U\\U\text{ open}}} \mu\left( U \right).
      \end{align*}
  \end{enumerate}
\end{problem}
\begin{enumerate}[(a)]
  \item This is false. If $A\subseteq [0,1]$ is the ``fat Cantor set'' constructed similar to the traditional Cantor, but obtained by deleting the middle fourth of each subinterval rather than the middle third, then $\mu(A) = \frac{1}{2}$, but $A$ is nowhere dense, meaning that if $U\subseteq A$ is open, then $U = \emptyset$.\newline

    To see that $A$ is nowhere dense, we see that $A$ is closed, so if $x\in A\subseteq [0,1]$, and $\ve > 0$, we may show that the interval $\left( x-\ve,x+\ve \right)$ is not contained in $A$. In the recursive construction of $A$, we may see that there is some step $n_1$ such that $\frac{1}{4^{n_1}} < 2\ve$, implying that $\left( x-\ve,x+\ve \right)$ is not contained in the recursive construction at $n_1$. Therefore $A^{\circ} = \emptyset$.
  \item This is true. By the definition of the Lebesgue outer measure, for any $\ve > 0$, there are $\set{\left( a_k,b_k \right)}_{k=1}^{\infty}$ such that
    \begin{align*}
      \mu(A) + \ve &< \mu\left( \bigcup_{k=1}^{\infty}\left( a_k,b_k \right) \right),
    \end{align*}
    so by setting
    \begin{align*}
      U &= \bigcup_{k=1}^{\infty}\left( a_k,b_k \right),
    \end{align*}
    we have that $U$ is open, meaning that by the definition of infimum, we get 
    \begin{align*}
      \mu(A) &= \inf\set{U | A\subseteq U,U\text{ open}}.
    \end{align*}
\end{enumerate}
\begin{remark}
  Part (a) can be solved by selecting $A = \R\setminus \Q\cap [0,1]$.
\end{remark}

\subsection{Problem 3}%
\begin{problem}
  Let $X$ be a compact metric space, $C(X)$ the space of real-valued continuous functions on $X$ with the supremum norm. Assume that $\mathcal{A}\subseteq C(X)$ satisfies
  \begin{itemize}
    \item (algebra) for all $f,g\in \mathcal{A}$, $\alpha,\beta\in \R$, we have $\alpha f + \beta g \in \mathcal{A}$ and $fg\in \mathcal{A}$;
    \item (separates points) for any $x\neq y$ in $X$, there exists $f\in \mathcal{A}$ such that $f(x)\neq f(y)$.
  \end{itemize}
  \begin{enumerate}[(a)]
    \item Show by example that $\mathcal{A}$ need not be dense in $C(X)$.
    \item In order to conclude that $\mathcal{A}$ is dense by the Stone--Weierstrass Theorem, what additional condition(s) should be added.
  \end{enumerate}
\end{problem}
\begin{enumerate}[(a)]
  \item Consider the algebra of polynomials on $[0,1]$ without a constant term. Then, since linear combinations and multiplications still yield polynomials without constant term, and $f(x) = x$ separates points in $[0,1]$, this algebra satisfies the requirements of the question. Yet, since all elements of this algebra are equal to zero at $x= 0$, the uniform closure of the algebra yields all the continuous functions on $[0,1]$ with $f(0) = 0$.
  \item In order to satisfy the requirements of the Stone--Weierstrass theorem, we need the algebra $\mathcal{A}$ to include the constant functions.
\end{enumerate}
\subsection{Problem 4}%
\begin{problem}
  Let $\mu$ be a measure on $\left( \R,\mathcal{B} \right)$, where $\mathcal{B}$ is the Borel $\sigma$-algebra. Let $\mu\left( \R \right) = 1$. Next, let $\mathcal{F}\subseteq \mathcal{B}$ be the sub-$\sigma$-algebra generated by symmetric intervals.\newline

  Let $f\in L_1\left( \R,\mathcal{B},\mu \right)$. Find a function $g$ such that:
  \begin{itemize}
    \item $g\in L_1\left( \R,\mathcal{F},\mu \right)$ (in particular, $g$ is $\mathcal{F}$-measurable);
    \item for all $E\in \mathcal{F}$, $ \int_{E}^{} g\:d\mu = \int_{E}^{} f\:d\mu $.
  \end{itemize}
\end{problem}
We consider the signed measure on $ \mathcal{F} $ defined by
\begin{align*}
  \nu(E) &= \int_{E}^{} f\:d\mu,
\end{align*}
meaning that $\nu\ll \mu$, so the function $g \coloneq \diff{\nu}{\mu}$, where $\diff{\nu}{\mu}$ denotes the Radon--Nikodym derivative of $\nu$ with respect to $\mu$ (where we restrict $\mu$ to $\mathcal{F}$), is $\mathcal{F}$-measurable (by Radon--Nikodym) and in $L_1\left( \R,\mathcal{F},\mu \right)$. This gives, for all $E\in \mathcal{F}$,
\begin{align*}
  \int_{E}^{} g\:d\mu &= \int_{E}^{} \diff{\nu}{\mu}\:d\mu\\
                      &= \int_{E}^{} \:d\nu\\
                      &= \nu\left( E \right)\\
                      &= \int_{E}^{} f\:d\mu.
\end{align*}
\subsection{Problem 5}%
\begin{problem}
  Let $\mu$ be a finite measure on $\left( X,\mathcal{F} \right)$. Show that a sequence of $\mathcal{F}$-measurable functions $\left( f_n \right)_n$ converges to $f$ in measure if and only if
  \begin{align*}
    \int_{X}^{} \min\set{1,\left\vert f_n-f \right\vert}\:d\mu(x) &\rightarrow 0.
  \end{align*}
\end{problem}

Let $M = \mu(X)$.\newline

Let $\left( f_n \right)_n\rightarrow f$ in measure, and let $\ve > 0$. If we let
\begin{align*}
  A &= \set{x | \left\vert f_n(x)-f(x) \right\vert > \ve/2M}\\
  B &= \set{x | \left\vert f_n(x)-f(x) \right\vert \leq \ve/2M},
\end{align*}
we have
\begin{align*}
  \int_{X}^{} \min\left( 1,\left\vert f_n-f \right\vert \right)\:d\mu &= \int_{A}^{} \min\left( 1,\left\vert f_n-f \right\vert \right) \:d\mu + \int_{B}^{} \min\left( 1,\left\vert f_n-f \right\vert \right) \:d\mu\\
                                                                      &\leq \mu\left( A \right) + \ve/2\\
                                                                      &< \ve/2 + \ve/2\\
                                                                      &= \ve.
\end{align*}
Meanwhile, if
\begin{align*}
  \int_{X}^{} \min\left( 1,\left\vert f_n-f \right\vert \right)\:d\mu &\rightarrow 0,
\end{align*}
then by Chebyshev's Inequality, we have, for a fixed $0 < \ve \leq 1$,
\begin{align*}
  \mu\left( \set{x | \left\vert f_n-f \right\vert \geq \ve} \right) &= \mu \left( \set{x | \min\left( 1,\left\vert f_n-f \right\vert \right) \geq \ve} \right)\\
                                                                    &\leq \frac{1}{\ve} \int_{X}^{} \min\left( 1,\left\vert f_n-f \right\vert \right)\:d\mu\\
                                                                    &\rightarrow 0,
\end{align*}
so $\left( f_n \right)_n\rightarrow f$ in measure.
\section{\href{https://math.virginia.edu/graduate/exams/analysis/2020Aug_real.pdf}{August 2020}}%
\subsection{Problem 1}%
\begin{problem}
  Let $f\colon \R\rightarrow \R$ be continuous and almost everywhere differentiable such that $f'(x) = 1$ almost everywhere. Does this imply that $f(2)-f(1) = 1$?
\end{problem}
This is false. To see this, let $ \mathfrak{C}(x) $ denote the Cantor--Lebesgue function, and let
\begin{align*}
  h(x) &= \sum_{n=-\infty}^{\infty} \mathfrak{C}\left( x - n \right) + n.
\end{align*}
Then, since $\mathfrak{C}(x)$ has derivative zero almost everywhere, the sum of a number of translates of $\mathfrak{C}(x)$ still has derivative zero almost everywhere. Then, setting
\begin{align*}
  f(x) &= h(x) + x,
\end{align*}
we get that $f(x)$ has derivative equal to $1$ almost everywhere. However, at the same time, $f(2) - f(1) = 2$.
\subsection{Problem 2}%
\begin{problem}
  Prove or provide a counterexample to the assertion that every open set in $\R^2$ is a countable union of closed sets.
\end{problem}
We show the inverse problem, which is that every closed set in $\R^2$ is $G_{\delta}$. To do this, we let $A\subseteq \R^2$ be closed, nonempty, and proper (if $A = \emptyset$ or $A = \R^2$ the answer is trivial).\newline

Then, there is some $x\in A^{c}$, and specifically there is $x\in A^{c}$ with rational coordinates (else, select $y\in \Q^2$ within the ball of radius $\ve$ that allows $A^{c}$ to be open). Furthermore, since $\R^2$ is a metric space, $\R^2$ is regular, so there are open $U_{x}$ and $V_x$ such that $A\subseteq U_x$, $x\in V_x$, and $U_x\cap V_x = \emptyset$.\newline

Therefore, we get
\begin{align*}
  A &= \bigcap \set{U_x | x\in \Q^2\setminus A},
\end{align*}
meaning that $A$ is $G_{\delta}$. Taking complements, we thus get that every open set is $F_{\sigma}$.
\subsection{Problem 3}%
\begin{problem}
  Let $\mathcal{H}$ be a separable complex Hilbert space with basis $\left( f_n \right)_n$. Define $P\left( f_n \right) = f_{n+1}$.
  \begin{enumerate}[(a)]
    \item Find $P^{\ast}$, the adjoint to $P$.
    \item Find $PP^{\ast}$ and $P^{\ast}P$.
  \end{enumerate}
\end{problem}
\begin{enumerate}[(a)]
  \item We see that
    \begin{align*}
      \iprod{Pf_i}{f_j} &= \delta_{i+1,j}\\
                        &= \delta_{i,j-1}\\
                        &= \iprod{f_i}{f_{j-1}}\\
                        &= \iprod{f_i}{P^{\ast}f_j},
    \end{align*}
    so that $Pf_n = f_{n-1}$ if $n > 1$. Else, if $n = 1$, then $P^{\ast}f_n = 0$.
  \item We see that, acting on the orthonormal basis $\left( f_n \right)_n$, $P^{\ast}P\left( f_n \right) = f_n$, and
    \begin{align*}
      PP^{\ast}\left( f_n \right) &= \begin{cases}
        0 & n = 1\\
        1 & \text{else},
      \end{cases}
    \end{align*}
    so that $P^{\ast}P = I$ and $PP^{\ast}$ is as above.
\end{enumerate}
\subsection{Problem 4}%
\begin{problem}
  Let $\left( X,\mathcal{F},\mu \right)$ be a measure space with $\mu\left( X \right) = 1$. Let $f_n\colon X\rightarrow \R$ be measurable functions such that
  \begin{align*}
    \lim_{n\rightarrow\infty} \mu\left( \set{x | f_n(x) \leq t} \right) &= \begin{cases}
      0 & t < 0\\
      1 & t\geq 0
    \end{cases}.
  \end{align*}
  Show that $f_n\rightarrow 0$ in measure.
\end{problem}

We see that
\begin{align*}
  \mu\left( \set{x | f_n(x) > t} \right) &= \mu\left( X \right) - \mu\left( \set{x | f_n(x) \leq t} \right),
\end{align*}
so by taking limits, we find that
\begin{align*}
  \lim_{n\rightarrow\infty} \mu\left( \set{x | f_n(x) > t} \right) &= \begin{cases}
    1 & t < 0\\
    0 & t\geq 0
  \end{cases}.
\end{align*}
So, if $\ve > 0$, then
\begin{align*}
  \mu\left( \set{x | \left\vert f_n(x) \right\vert > \ve} \right) &= \mu\left( \set{x | f_n(x) < -\ve} \right) + \mu\left( \set{x | f_n(x) > \ve} \right)\\
                                                                  &\leq \mu\left( \set{x | f_n(x)\leq -\ve} \right) + \mu\left( \set{x | f_n(x) > \ve} \right)\\
                                                                  &\rightarrow 0.
\end{align*}
\section{\href{https://math.virginia.edu/graduate/exams/analysis/2021Jan_real.pdf}{January 2021}}%
\subsection{Problem 1}%
\begin{problem}
  Let $\left( f_n \right)_n$, $f$ be measurable functions on $\left( \Omega,\mathcal{F},\mu \right)$ such that $f_n\rightarrow f$ in measure. Does this imply that there exists a measurable set $A\subseteq \Omega$ with $\mu\left( \Omega\setminus A \right) = 0$ such that $f_n(x)\rightarrow f(x)$ for all $x\in A$.
\end{problem}

This is not true. To see this, consider the family of functions defined by
\begin{align*}
  f_1 &= \1_{[0,1]}\\
  f_2 &= \1_{[0,1/2]}\\
  f_3 &= \1_{[1/2,1]}\\
      &\vdots
\end{align*}
where $f_n$ is of width $\frac{1}{2^{k}}$ when $2^{k} \leq n < 2^{k+1}$, moving along $[0,1]$. Then, since $\mu\left( \set{x | \left\vert f_n(x) \right\vert > 0} \right) = \frac{1}{2^{k}}$, we have that for any $\ve > 0$, $\left( \mu\left( \set{x | \left\vert f_n(x) \right\vert > \ve} \right) \right)_n \leq \left( \mu\left( A_n \right) \right)_n$, where we have defined $A_n$ to be the particular set with width $\frac{1}{2^{k}}$ when $2^{k}\leq n\leq 2^{k+1}$. Yet, since for any $x\in [0,1]$ there are infinitely many such $n$ such that $f_n(x) = 1$, the family $\left( f_n \right)_n$ does not converge to $0$ pointwise anywhere on $[0,1]$.
\subsection{Problem 2}%
\begin{problem}
  Let $B$ be a measurable subset of the two-dimensional plane such that the intersection of $B$ with every vertical line is either finite or countable. Find $\mu\left( B \right)$, where $\mu$ is the two-dimensional Lebesgue measure.
\end{problem}
Note that the two-dimensional Lebesgue measure is the completion of $m\times m$, where $m\times m$ is the product measure on the product $\sigma$-algebra $\mathcal{L}\left( \R \right)\otimes \mathcal{L}\left( \R \right)$. If $B\in \mathcal{L}\left( \R^2 \right)$, then $B = C\cup N$, where $N$ is a $\mu$-null set and $C\in \mathcal{L}\left( \R \right)\otimes \mathcal{L}\left( \R \right)$. Therefore, if we show that $\left( m\times m \right)\left( C \right) = 0$, we then show that $\mu\left( B \right) = 0$.\newline

To see that $\left( m\times m \right)\left( \C \right) = 0$, note that by our assumption, $B^{x} = \set{y \in \R | \left( x,y \right)\in B}$ is either finite or countable, so since $C^{x}\subseteq B^{x}$, we must have that $C^{x}$ is either finite or countable. By Tonelli's Theorem, since $\1_{C}$ is positive, we have
\begin{align*}
  \int_{\R^{2}}^{} \1_{C}\:d\left( m\times m \right) &= \int_{\R}^{} \int_{\R}^{} \1_{C^{x}}\:dy\:dx\\
                                                     &= \int_{\R}^{} m\left( C^{x} \right)\:dx\\
                                                     &= 0,
\end{align*}
so $\left( m\times m \right)\left( C^{x} \right) = 0$, meaning
\begin{align*}
  \mu\left( B \right) &= \mu\left( C \right) + \mu\left( N \right)\\
                      &= \left( m\times m \right)\left( C \right) + \mu\left( N \right)\\
                      &= 0.
\end{align*}
\subsection{Problem 3}%
\begin{problem}
  Let $\left( \Omega,\mathcal{F} \right)$ be a measurable space, $\mu,\nu,\rho$ finite positive measures with $\mu\ll\nu$. Show that there exists a measurable function $f$ on $\Omega$ such that for all $E\in \mathcal{F}$,
  \begin{align*}
    \mu\left( E \right) &= \int_{E}^{} f\:d\nu + \int_{E}^{} \left( f-1 \right)\:d\rho.
  \end{align*}
\end{problem}

Since $\mu\ll\nu$, and $\rho\ll\rho$, we have $\mu + \rho \ll \nu + \rho$, as $\left( \nu + \rho \right)(E) = 0$ if and only if $\nu(E) = 0$ and $\rho(E) = 0$, meaning that $\mu(E) = 0$ and $\rho(E) = 0$, so by Radon--Nikodym, there is some measurable $f$ such that
\begin{align*}
  \mu\left( E \right) + \rho\left( E \right) &= \int_{E}^{} f\:d\left( \nu + \rho \right),
\end{align*}
so by rearranging, we get
\begin{align*}
  \mu\left( E \right) &= \int_{E}^{} f\:d\nu + \int_{E}^{} \left( f-1 \right)\:d\rho.
\end{align*}
\subsection{Problem 4}%
\begin{problem}
  Let $f,g$ be nonnegative measurable functions on $[0,1]$, and let $a,b,c,d\geq 0$ be arbitrary nonnegative numbers. Show that
  \begin{align*}
    \left( ac + bd + \int_{0}^{1} f(x)g(x)\:dx \right)^3 &\leq \left( a^3 + b^3 + \int_{0}^{1} \left( f(x) \right)^3\:dx \right)\left( c^{3/2} + d^{3/2} + \int_{0}^{1} \left( g(x) \right)^{3/2}\:dx \right)^2.
  \end{align*}
\end{problem}
Since all of $f,g,a,b,c,d$ are positive, we may show
\begin{align*}
  ac + bd + \int_{0}^{1} f(x)g(x)\:dx &\leq \left( a^3 + b^3 + \int_{0}^{1} \left( f(x) \right)^3\:dx \right)^{1/3}\left( c^{3/2} + d^{3/2} + \int_{0}^{1} \left( g(x) \right)^{3/2}\:dx \right)^{2/3}.
\end{align*}
To do this, we use Hölder's Inequality three times:
\begin{align*}
  ac + bd + \int_{0}^{1} f(x)g(x)\:dx &\leq \left( a^3 + b^3 \right)^{1/3}\left( c^{3/2} + d^{3/2} \right)^{2/3} + \int_{0}^{1} f(x)g(x)\:dx\\
                                      &\leq \left( a^3 + b^3 \right)^{1/3}\left( c^{3/2} + d^{3/2} \right)^{2/3} + \left( \int_{0}^{1} \left( f(x) \right)^{3}\:dx \right)^{1/3}\left( \int_{0}^{1} \left( g(x) \right)^{3/2}\:dx \right)^{2/3}\\
                                      &\leq \left( a^3 + b^3 + \int_{0}^{1} \left( f(x) \right)^{3}\:dx \right)^{1/3}\left( c^{3/2} + d^{3/2} + \int_{0}^{1} \left( g(x) \right)^{3/2}\:dx \right)^{2/3}.
\end{align*}
\subsection{Problem 5}%
\begin{problem}
  Let $f(x)$ be a continuous function on $[0,1]$. Show that for every $\ve > 0$ there exists $n\in \Z_{\geq 0}$ and $a_0,a_1,\dots,a_n\in \R$ such that for
  \begin{align*}
    D &\coloneq \sum_{k=0}^{n} a_k\left( \diff{}{x} \right)^{k},
  \end{align*}
  we have
  \begin{align*}
    \left\vert f(x)-e^{x^2}\left( De^{-x^2} \right) \right\vert &< \ve
  \end{align*}
  for all $x\in [0,1]$.
\end{problem}
We note that for each $n$,
\begin{align*}
  \left( \diff{}{x} \right)^{n}\left( e^{-x^2} \right) &= P_n(x)e^{-x^2}
\end{align*}
where $P_n(x)$ is a degree $n$ polynomial. To see this, using induction on $n$, we get
\begin{align*}
  \left( \diff{}{x} \right)^{0}\left( e^{-x^2} \right) &= \left( 1 \right)e^{-x^2}\\
                                                       &\eqcolon P_0(x)e^{-x^2}\\
  \diff{}{x}\left( P_n(x)e^{-x^2} \right) &= P_n'(x)e^{-x^2} - 2xP_n(x)e^{-x^2}\\
                                          &\eqcolon P_{n+1}(x)e^{-x^2}.
\end{align*}
Therefore,
\begin{align*}
  e^{x^2}\left( \diff{}{x} \right)^{n}\left( e^{-x^2} \right) &= P_n(x).
\end{align*}
Since each $P_n(x)$ is linearly independent (as they have different degrees of polynomials), and consist of polynomials of each degree for all $n\geq 0$, they span $\C\left[ x \right]$. Then, for any $\ve > 0$, by Stone--Weierstrass, there is some polynomial $p(x)$ such that
\begin{align*}
  \sup_{x\in [0,1]}\left\vert f(x) - p(x) \right\vert < \ve.
\end{align*}
Since $\set{P_n(x)}_{n\geq 0}$ forms a basis for $\C\left[ x \right]$, there are $a_0,\dots,a_n$ such that $p(x) = \sum_{k=0}^{n}a_kP_k\left( x \right)$. Setting
\begin{align*}
  D &= \sum_{k=0}^{n}a_k \left( \diff{}{x} \right)^{k},
\end{align*}
we obtain that
\begin{align*}
  \left\vert f(x)-e^{x^2}\left( De^{-x^2} \right) \right\vert < \ve.
\end{align*}
\section{\href{https://math.virginia.edu/graduate/exams/analysis/2022Jan_real.pdf}{January 2022}}%
\subsection{Problem 1}%
\begin{problem}
  Let $\left( f_n \right)_n,f\subseteq L_1\left( X,\mu \right)$ be nonnegative functions, and let $\left( f_n \right)_n\rightarrow f$ pointwise, as well as
  \begin{align*}
    \left( \int_{X}^{} f_n\:d\mu \right)_n \rightarrow \int_{X}^{} f\:d\mu.
  \end{align*}
  Show that $\left( f_n \right)_n\rightarrow f$ in $L_1$.
\end{problem}
Consider the function $g_n(x) = \min\left( f_n,f \right)$, also written as
\begin{align*}
  g_n &= \frac{1}{2}\left( f_n + f - \left\vert f_n-f \right\vert \right).
\end{align*}
Note that $\left\vert g_n \right\vert\leq f$, and $\left( g_n \right)_n\rightarrow f$ pointwise, so by dominated convergence, we have 
\begin{align*}
  \int_{X}^{} f\:d\mu &= \lim_{n\rightarrow\infty} \int_{X}^{} g_n\:d\mu\\
                      &= \frac{1}{2}\lim_{n\rightarrow\infty} \left( \int_{X}^{} f_n\:d\mu + \int_{X}^{} f\:d\mu - \int_{X}^{} \left\vert f_n-f \right\vert\:d\mu \right)\\
                      &= \int_{X}^{} f\:d\mu - \frac{1}{2}\lim_{n\rightarrow\infty} \int_{X}^{} \left\vert f_n-f \right\vert\:d\mu,
\end{align*}
so
\begin{align*}
  \lim_{n\rightarrow\infty} \int_{X}^{} \left\vert f_n-f \right\vert\:d\mu &= 0,
\end{align*}
and $\left( f_n \right)_n\rightarrow f$ in $L_1$.
\subsection{Problem 2}%
\begin{problem}
  Let $p\in [1,\infty)$.
  \begin{enumerate}[(a)]
    \item Show that if $\left( f_n \right)_n\rightarrow f$ in $L_p$, then there is $\left( f_{n_k} \right)_k$ such that for $\mu$-a.e. $x\in X$, $\left( f_{n_k} \right)_k\rightarrow f$ pointwise.
    \item Let $h$ be a measurable function, and let $D$ be defined such that
      \begin{align*}
        D &= \set{f\in L_p\left( X,\mu \right) | hf\in L_p\left( X,\mu \right)}.
      \end{align*}
      Suppose $\left( f_n \right)_n\rightarrow f$ in $L_p$, and $\left( hf_n \right)_n\rightarrow g$ in $L_p$. Show that $f\in D$ and $g = hf$.
  \end{enumerate}
\end{problem}
\begin{enumerate}[(a)]
  \item Since $\left( f_n \right)_n\rightarrow f$ in $L_p$, the sequence $\left( f_n \right)_n$ is $L_p$-Cauchy, so we may find a subsequence $\left( f_{n_k} \right)_k$ such that
    \begin{align*}
      \norm{f_{n_{k+1}} - f_{n_k}} &< \frac{1}{2^{k}}.
    \end{align*}
    Defining
    \begin{align*}
      s_n &= \sum_{k=1}^{n} \left\vert f_{n_{k+1}} - f_{n_k} \right\vert\\
      s = \sum_{k=1}^{n} \left\vert f_{n_{k+1}} -f_{n_{k}} \right\vert,
    \end{align*}
    we see that by Minkowski's Inequality,
    \begin{align*}
      \norm{s_n} &\leq \sum_{k=1}^{n} \norm{f_{n_{k+1}} - f_{n_k}}\\
                 &\leq 1.
    \end{align*}
    So, by applying Fatou's Lemma to $s_{n}^p$, we see that
    \begin{align*}
      \norm{s} &\leq 1,
    \end{align*}
    meaning that in particular, $s(x) < \infty$ almost everywhere, and $\left( s_n \right)_n$ converges absolutely almost everywhere. Defining
    \begin{align*}
      g(x) &= f_{n_1}(x) + \sum_{k=1}^{\infty} \left( f_{n_{k+1}} - f_{n_{k}} \right)(x)
    \end{align*}
    for all $x$ where $s(x)$ is defined, and $0$ otherwise, we see that by telescoping, $g(x) = \lim_{k\rightarrow\infty}f_{n_{k}}(x)$. Now, we show that $\norm{g-f} = 0$, meaning that $g = f$ under the $\mu$-a.e. equivalence relation. Computing, we have
    \begin{align*}
      \int_{X}^{} \left\vert g-f \right\vert^{p}\:d\mu &= \int_{X}^{} \liminf_{k\rightarrow\infty}\left\vert f_{n_{k}} - f \right\vert^{p}\:d\mu\\
                                                       &\leq \liminf_{k\rightarrow\infty} \int_{X}^{} \left\vert f_{n_{k}} - f \right\vert^{p}\:d\mu\\
                                                       &= \liminf_{k\rightarrow\infty}\norm{f_{n_{k}} - f}^{p}\\
                                                       &= 0,
    \end{align*}
    as for any subsequence $\left( f_{n_{k}} \right)_{k}$, $\left( f_{n_{k}} \right)_k\rightarrow f$ in $L_p$. Thus, $\left( f_{n_{k}} \right)_{k}\rightarrow f$ for $\mu$-almost every $x$.
  \item Since $\left( f_n \right)_n\rightarrow f$ in $L_p$, there is a subsequence $\left( f_{n_{k}} \right)_k\rightarrow f$ pointwise almost everywhere. Thus, by multiplying $h(x)$, we see that $\left( hf_{n_{k}} \right)_k\rightarrow hf$ pointwise almost everywhere.\newline

    Now, since $\left( hf_n \right)_n\rightarrow g$ in $L_p$, this applies for every subsequence of $\left( hf_n \right)_n$; in particular, it applies to $\left( hf_{n_{k}} \right)_k$, meaning that $\left( hf_{n_{k}} \right)_k\rightarrow g$ in $L_p$, and admits a subsequence $\left( hf_{n_{k_{j}}} \right)_j\rightarrow g$ pointwise almost everywhere.\newline

    Returning to the convergence $\left( hf_{n_{k}} \right)_k\rightarrow hf$ pointwise almost everywhere, this applies for every subsequence, so in particular, it applies to $\left( hf_{n_{k_{j}}} \right)_j$.\newline

    Set
    \begin{align*}
      E_1 &= \set{x | \left( \left( hf_{n_{k_{j}}} \right)(x) \right)_j\not\rightarrow g(x)}\\
      E_2 &= \set{x | \left( \left( hf_{n_{k_{j}}} \right)(x) \right)_{j}\not\rightarrow (hf)(x)}.
    \end{align*}
    Then, $\mu\left( E_1 \right) = \mu\left( E_2 \right) = 0$, so $\mu\left( E_1\cup E_2 \right) \leq \mu\left( E_1 \right) + \mu\left( E_2 \right) = 0$, and so $g(x) = \left( hf \right)(x)$ for almost every $x$ (as $\C$ is Hausdorff). In particular, this means that $\left[ g \right] = \left[ hf \right]$ under the almost everywhere equivalence relation. Since $L_p$ is complete, and $\left( hf_n \right)_n\rightarrow g$ in $L_p$, we have $g\in L_p$, so $hf\in L_p$, and $f\in D$.
\end{enumerate}
\subsection{Problem 3}%
\begin{problem}
  Let $\mu$ be a Borel probability measure on $\R$, and define
  \begin{align*}
    \hat{\mu}\left( t \right) &= \int_{\R}^{} e^{itx}\:d\mu(x).
  \end{align*}
  \begin{enumerate}[(a)]
    \item Show that $\hat{\mu}(t)$ is bounded and continuous.
    \item If $\delta > 0$, show that
      \begin{align*}
        \frac{1}{2\delta} \int_{-\delta}^{\delta} 1-\re\left( \hat{\mu}\left( t \right) \right)\:dt &= \int_{\R}^{} 1-\sinc\left(\delta x\right)\:d\mu(x).
      \end{align*}
    \item Show that
      \begin{align*}
        1-\sinc(u) &\geq \frac{1}{2}\1_{\left( -\infty,2 \right)\cup \left( 2,\infty \right)}(u),
      \end{align*}
      and deduce that
      \begin{align*}
        \mu\left( \set{x | \left\vert x \right\vert > 2/\delta} \right) &\leq \frac{1}{\delta}\int_{-\delta}^{\delta} 1-\re\left( \hat{\mu}(t) \right)\:dt.
      \end{align*}
    \item Let $\left(\mu_n\right)_n$ be a sequence of Borel probability measures on $\R$. Suppose that for all $t$, $\Phi(t) = \lim_{n\rightarrow\infty}\widehat{\mu_n}(t)$ exists, and $\Phi(t)$ is continuous at $t=0$. Show that for all $\ve > 0$, there is a compact $K$ such that for all $n$, $\mu_n(K)\geq 1-\ve$.
  \end{enumerate}
\end{problem}
\begin{enumerate}[(a)]
  \item We see that $\hat{\mu}$ is bounded, as
    \begin{align*}
      \left\vert \hat{\mu}(t) \right\vert &= \left\vert \int_{\R}^{} e^{itx}\:d\mu(x) \right\vert\\
                                          &\leq \int_{\R}^{} \left\vert e^{itx} \right\vert\:d\mu(x)\\
                                          &\leq 1,
    \end{align*}
    since $\mu$ is a probability measure. Furthermore, using dominated convergence with $g(t) = 1$, we see that if $\left( t_n \right)_n\rightarrow t$, then $e^{it_n x}\rightarrow e^{itx}$ as the exponential function is continuous, so $\hat{\mu}\left( t_n \right) \rightarrow \hat{\mu}(t)$, and $\hat{\mu}$ is continuous.
  \item We note that $\re\left( \hat{\mu}(t) \right) = \int_{\R}^{} \cos\left( tx \right)\:d\mu(x)\leq 1$ for all $t$, meaning that $1-\re\left( \hat{\mu}(t) \right)\geq 0$ for all $t$. Writing our integral, we then get
    \begin{align*}
      \frac{1}{2\delta} \int_{-\delta}^{\delta} 1-\re\left( \hat{\mu}(t) \right)\:dt &= \frac{1}{2\delta} \int_{-\delta}^{\delta} 1- \re\int_{\R}^{} e^{itx}\:d\mu(x)\:dt
      \intertext{and using the fact that $\mu\left( \R \right) = 1$,}
                                                                                     &= \frac{1}{2\delta} \int_{-\delta}^{\delta} \int_{\R}^{} 1-\cos\left( tx \right)\:d\mu(x)\:dt.
                                                                                     \intertext{By Tonelli's Theorem, we may switch the order of integration, so}
                                                                                     &= \frac{1}{2\delta} \int_{\R}^{} \int_{-\delta}^{\delta} 1-\cos\left( tx \right)\:dt\:d\mu(x)\\
                                                                                     &= \int_{\R}^{} 1- \int_{-\delta}^{\delta} \frac{1}{2\delta}\cos\left( tx \right)\:dt\:d\mu(x).
                                                                                     \intertext{Now, evaluating the inner integral, we see that}
      \int_{-\delta}^{\delta} \frac{1}{2\delta}\cos\left( tx \right)\:dt &= \begin{cases}
        1 & x = 0\\
        \frac{\sin\left( \delta x \right)}{\delta x} & x\neq 0
      \end{cases},
      \intertext{so}
                                                                         &= \int_{\R}^{} 1-\sinc\left( \delta x \right)\:d\mu(x).
    \end{align*}
  \item We see that $1-\sinc(u) \geq 0$ for all $u$, so when $\left\vert u \right\vert \leq 2$, the inequality is satisfied. Similarly, if $\left\vert u \right\vert > 2$, then
    \begin{align*}
      1-\sinc\left( u \right) &= 1- \frac{\sin(u)}{u}\\
                              &\geq 1-\frac{1}{2}\\
                              &= \frac{1}{2},
    \end{align*}
    so the inequality is satisfied when $\left\vert u \right\vert > 2$. Thus, we see that
    \begin{align*}
      \frac{1}{\delta} \int_{-\delta}^{\delta} 1-\re\left( \hat{\mu}\left( t \right) \right)\:dt &= 2 \int_{\R}^{} 1-\sinc\left( \delta x \right)\:d\mu(x)\\
                                                                                                 &\geq \int_{\R}^{} \1_{\left( -\infty,2 \right)\cup \left( 2,\infty \right)}\left( \delta x \right)\:d\mu(x)\\
                                                                                                 &= \int_{\R}^{} \1_{\left( \infty,2/\delta \right)\cup \left( 2/\delta,\infty \right)}(x)\:d\mu(x)\\
                                                                                                 &= \mu\left( \set{x | \left\vert x \right\vert > 2/\delta} \right).
    \end{align*}
  \item Let $\ve > 0$. Since $\Phi(t)$ is continuous at $0$, and $\Phi(0) = \lim_{n\rightarrow\infty}\widehat{\mu_n}(0) = 1$, there is $\delta$ such that whenever $\left\vert t \right\vert < \delta$, $\left\vert 1-\Phi(t) \right\vert < \ve/2$. Note that this implies that $1-\re\left( \Phi(t) \right) < \ve/2$ for all $t$ with $\left\vert t \right\vert < \delta$.\newline

    Next, we see that $1-\re\left( \widehat{\mu}_n(t) \right)\rightarrow 1-\re\left( \Phi(t) \right)$, so by using the dominating function $g(t) = 2$, the dominated convergence theorem implies that
    \begin{align*}
      \frac{1}{2\delta} \int_{-\delta}^{\delta} 1-\re\left( \widehat{\mu_n}(t) \right)\:dt &\rightarrow \frac{1}{2\delta}\int_{-\delta}^{\delta} 1-\re\left( \Phi(t) \right)\:dt\\
                                                                                           &< \ve/2,
    \end{align*}
    meaning that there is $N$ such that for all $n\geq N$,
    \begin{align*}
      \frac{1}{2\delta} \int_{-\delta}^{\delta} 1-\re\left( \widehat{\mu_n}(t) \right)\:dt &< \ve/2.
    \end{align*}
    
    Thus, by using part (c), we see that
    \begin{align*}
      \mu_n\left( \set{x | \left\vert x \right\vert > 2/\delta} \right) &< \ve,
    \end{align*}
    so for all $n\geq N$,
    \begin{align*}
      \mu_n\left( \left[ -2/\delta,2/\delta \right] \right) &\geq 1-\ve.
    \end{align*}
    Next, for each $n\leq N$, we find $k_n\in \N$ such that $\mu\left( \left[ -k_n,k_n \right] \right) \geq 1-\ve$; the existence of such a $k_n$ follows from continuity from below, as for each $n$,
    \begin{align*}
      1 &= \mu_n\left( \R \right)\\
        &= \mu_n\left( \bigcup_{k\geq 1}\left[ -k,k \right] \right)\\
        &= \sup_{k\geq 1} \mu_n\left( \left[-k,k\right] \right).
    \end{align*}
    Set $K_N = \max\left( \set{k_n}_{n=1}^{N} \right)$, and let $K = \left[ -K_N,K_N \right]\cup \left[ -2/\delta,2/\delta \right]$. Then, for all $n$, we find that
    \begin{align*}
      \mu_n\left( K \right) &\geq 1-\ve.
    \end{align*}
\end{enumerate}
\section{\href{https://math.virginia.edu/graduate/exams/analysis/2022Aug_real.pdf}{August 2022}}%
\subsection{Problem 1}%
\begin{problem}
  Compute
  \begin{align*}
    \lim_{n\rightarrow\infty} \int_{0}^{\infty} \frac{n\sin\left( x/n \right)}{x\left( 1+x^2 \right)}\:dx.
  \end{align*}
\end{problem}
We note that
\begin{align*}
  \left\vert \frac{n\sin\left( x/n \right)}{x\left( 1+x^2 \right)}  \right\vert &\leq \left\vert \frac{n\left( x/n \right)}{x\left( 1+x^2 \right)} \right\vert\\
                                                                                &= \frac{1}{1+x^2},
\end{align*}
and since $\frac{1}{1+x^2}$ is integrable, we may use Dominated Convergence to switch limit and integral, giving
\begin{align*}
  \lim_{n\rightarrow\infty} \int_{0}^{\infty} \frac{n\sin\left( x/n \right)}{x\left( 1+x^2 \right)}\:dx &= \int_{0}^{\infty} \lim_{n\rightarrow\infty}\frac{n\sin\left( x/n \right)}{x\left( 1+x^2 \right)}\:dx\\
                                                                                                        &= \int_{0}^{\infty} \lim_{h\rightarrow 0} \frac{\frac{1}{h}\sin\left( hx \right)}{x\left( 1+x^2 \right)}\:dx\\
                                                                                                        &= \int_{0}^{\infty} \frac{x}{x\left( 1+x^2 \right)}\:dx\\
                                                                                                        &= \frac{\pi}{2}.
\end{align*}
\subsection{Problem 2}%
\begin{problem}
  Fix $a < b$ in $\R$. For a Lipschitz function $g\colon [a,b]\rightarrow \C$, set
  \begin{align*}
    \norm{g}_{\text{Lip}} &= \sup_{x\neq y\in[a,b]} \frac{\left\vert g(x)-g(y) \right\vert}{\left\vert x-y \right\vert}.
  \end{align*}
  \begin{enumerate}[(a)]
    \item Show that $f\colon [a,b]\rightarrow \C$ is Lipschitz if and only if $f$ is absolutely continuous and $f'\in L_{\infty}\left( [a,b] \right)$.
    \item If $f\colon [a,b]\rightarrow \C$ is Lipschitz, show that $\norm{f}_{\text{Lip}} = \norm{f'}_{L_{\infty}}$.
  \end{enumerate}
\end{problem}
\begin{enumerate}[(a)]
  \item Let $f$ be Lipschitz, and let $M$ denote the Lipschitz constant --- i.e., $\left\vert f(x)-f(y) \right\vert\leq \left\vert x-y \right\vert$ for all $x,y\in [a,b]$. Set $\delta = \frac{\ve}{M}$. Then, if $\set{\left( a_j,b_j \right)}_{j=1}^{k}$ is a partition such that $\sum_{j=1}^{k}\left\vert b_j-a_j \right\vert < \delta$, we have
    \begin{align*}
      \sum_{j=1}^{k} \left\vert f\left(b_j\right)-f\left( a_j \right) \right\vert &\leq M\sum_{j=1}^{k} \left\vert b_j-a_j \right\vert\\
                                                                                  &< \ve.
    \end{align*}
    Thus, $f$ is absolutely continuous. Now, if $x,x+h\in [a,b]$, we have that
    \begin{align*}
      \left\vert \frac{f\left( x+h \right)-f\left( x \right)}{h} \right\vert &\leq M,
    \end{align*}
    meaning that
    \begin{align*}
      \left\vert f'(x) \right\vert &= \lim_{h\rightarrow 0} \left\vert \frac{f\left( x+h \right)-f(x)}{h} \right\vert\\
                                   &\leq M,
    \end{align*}
    and since $f'(x)$ exists for a.e. $x\in [a,b]$, we have that $\esssup_{x\in [a,b]} \left\vert f'(x) \right\vert \leq M$, so $f'\in L_{\infty}\left( [a,b] \right)$.\newline

    Let $f$ be absolutely continuous with bounded derivative. Then, if $M$ is the essential supremum of the $f'$, the fundamental theorem of calculus gives
    \begin{align*}
      \left\vert f(y)-f(x) \right\vert &= \left\vert \int_{x}^{y} f'(t)\:dt \right\vert\\
                                       &\leq \int_{x}^{y} \left\vert f'(t) \right\vert\:dt\\
                                       &\leq \int_{x}^{y} M\:dx\\
                                       &= M\left\vert y-x \right\vert,
    \end{align*}
    so $f$ is Lipschitz.
  \item If $f$ is such that $f'(x)$ exists, then for $x,x+h\in [a,b]$, we have
    \begin{align*}
      \left\vert \frac{f\left( x+h \right)-f(x)}{h} \right\vert &\leq \norm{f}_{\text{Lip}},
    \end{align*}
    so by taking limits, we have
    \begin{align*}
      \left\vert f'(x) \right\vert &\leq \norm{f}_{\text{Lip}}.
    \end{align*}
    Thus, this ordering must respect essential suprema, meaning
    \begin{align*}
      \norm{f'}_{L_{\infty}} &\leq \norm{f}_{\text{Lip}}.
    \end{align*}
    Furthermore, if $\ve > 0$, there are $x,y\in [a,b]$ with $x < y$  such that
    \begin{align*}
      \norm{f}_{\text{Lip}} - \ve &< \left\vert \frac{f(y)-f(x)}{y-x} \right\vert\\
                                  &= \frac{1}{\left\vert y-x \right\vert} \left\vert \int_{x}^{y} f'(t)\:dt \right\vert\\
                                  &\leq \frac{1}{\left\vert y-x \right\vert} \int_{x}^{y} \left\vert f'(t) \right\vert\:dt\\
                                  &\leq \frac{1}{\left\vert y-x \right\vert} \int_{x}^{y} \norm{f'}_{L_{\infty}}\:dt\\
                                  &= \norm{f'}_{L_{\infty}},
    \end{align*}
    and since $\ve$ is arbitrary, we have $\norm{f}_{\text{Lip}}\leq \norm{f'}_{L_{\infty}}$.
\end{enumerate}
\subsection{Problem 3}%
\begin{problem}
  Let $\left( X,\mu \right)$ be a $\sigma$-finite measure space. Show that if $f,g\in L_1\left( X,\mu \right)$ with $0\leq f,g$ almost everywhere, then
  \begin{align*}
    \norm{f-g}_{L_1} &= \int_{0}^{\infty} \mu\left( \set{x | f(x) > t} \triangle \set{x | g(x) > t} \right)\:dt.
  \end{align*}
\end{problem}
We start by showing that
\begin{align*}
  \left\vert a-b \right\vert &= \int_{0}^{\infty} \left\vert \1_{\left( t,\infty \right)}(a) - \1_{\left( t,\infty \right)}(b) \right\vert\:dt
\end{align*}
for all $a,b\in [0,\infty)$. Without loss of generality, $a \leq b$. To see this, note that there are three cases:
\begin{align*}
  \left\vert 1_{\left( t,\infty \right)}(a) - \1_{\left( t,\infty \right)}(b) \right\vert &= \begin{cases}
    0 & t<a,b\\
    1 & a\leq t < b\\
    0 & a,b\leq t
  \end{cases},
\end{align*}
giving
\begin{align*}
  \int_{0}^{\infty} \1_{[a,b)}\:dt &= \mu\left( [a,b) \right)\\
                                   &= b-a\\
                                   &= \left\vert a-b \right\vert.
\end{align*}
Now, we have
\begin{align*}
  \norm{f-g}_{L_1} &= \int_{X}^{} \left\vert f(x)-g(x) \right\vert\:d\mu(x)\\
                   &= \int_{X}^{} \int_{0}^{\infty} \left\vert \1_{(t,\infty)}\left(f(x)\right) - \1_{\left( t,\infty \right)}\left( g(x) \right) \right\vert\:dt\:d\mu(x),
                   \intertext{and by Tonelli's Theorem, we have}
                   &= \int_{0}^{\infty} \int_{X}^{} \left\vert \1_{f^{-1}\left( \left( t,\infty \right) \right)} - \1_{g^{-1}\left( \left( t,\infty \right) \right)} \right\vert\:d\mu(x)\:dt\\
                   &= \int_{0}^{\infty} \int_{X}^{} \1_{f^{-1}\left( \left( t,\infty \right) \right)\triangle g^{-1}\left( \left( t,\infty \right) \right)}\:d\mu(x)\:dt\\
                   &= \int_{0}^{\infty} \mu\left( f^{-1}\left( \left( t,\infty \right) \right)\triangle g^{-1}\left( \left( t,\infty \right) \right) \right)\:dt.
\end{align*}
\subsection{Problem 4}%
\begin{problem}
  Let $\left( X,\Sigma \right)$ be a measurable space. Suppose that $\mu,\nu$ are signed measures on $\Sigma$ such that $\norm{\mu}_{TV},\norm{\nu}_{TV} < \infty$, and $\left\vert \mu \right\vert\perp \left\vert \mu \right\vert$.
  \begin{enumerate}[(a)]
    \item If $\mu = \mu_1-\mu_2$ and $\nu = \nu_1 - \nu_2$ with $\mu_1\perp \mu_2$ and $\nu_1\perp \nu_2$, show that $\mu_i \perp \nu_j$ for all $i,j\in \set{1,2}$.
    \item Show that
      \begin{align*}
        \norm{\mu + \nu}_{\text{TV}} &= \norm{\mu}_{\text{TV}} + \norm{\nu}_{\text{TV}}.
      \end{align*}
  \end{enumerate}
\end{problem}

\begin{enumerate}[(a)]
  \item Since $\left\vert \mu \right\vert\perp \left\vert \nu \right\vert$, there are $U,V\subseteq X$ such that $\left\vert \mu \right\vert$ is concentrated on $U$ and $\left\vert \nu \right\vert$ is concentrated on $V$, with $U\cap V = \emptyset$.\newline

    Note that by the Jordan decompositions, we have $\left\vert \mu \right\vert = \mu_1 + \mu_2 \geq \mu_{1,2}$ so $\mu_{1,2}$ are concentrated on $U$, and similarly $\nu_{1,2}$ are concentrated on $V$, so $\mu_{i}\perp \nu_{j}$.
  \item We show that the measures $\mu_1 + \nu_1$ and $\mu_2 + \nu_2$ are mutually singular. To see this, note the following:
    \begin{itemize}
      \item $\mu_1 = 0$ on $N_{\mu}\cup V$;
      \item $\nu_1 = 0$ on $N_{\nu}\cup U$;
      \item $\mu_2 = 0$ on $P_{\mu}\cup V$;
      \item $\nu_2 = 0$ on $P_{\nu}\cup U$,
    \end{itemize}
    so $\mu_1 + \nu_1 = 0$ on $A = \left( N_{\mu}\cup V \right) \cap \left( N_{\nu}\cup U \right)$, and $\mu_2 + \nu_2 = 0$ on $B = \left( P_{\mu}\cup V \right)\cap \left( P_{\nu}\cup U \right)$. Therefore, since
    \begin{align*}
      A\cup B &= \left( N_{\mu}\cap N_{\nu} \right) \cup \left( N_{\mu}\cap U \right) \cup \left( N_{\nu}\cap V \right)\\
              &\cup \left( P_{\mu}\cap P_{\mu} \right) \cup \left( P_{\mu}\cap U \right) \cup \left( P_{\nu}\cap V \right)\\
              &= X\\
              \\
      A\cap B &= \left( N_{\mu}\cup V \right)\cap \left( N_{\nu}\cup U \right)\\
              &\cap \left( P_{\mu}\cup V \right) \cap \left( P_{\nu}\cup U \right)\\
              &= \emptyset,
    \end{align*}
    the measures $\mu_1 + \nu_1$ and $\mu_2 + \nu_2$ are mutually singular, so $A\sqcup B$ forms a Hahn decomposition for $\mu + \nu$ with corresponding Jordan decomposition of $\left( \mu_1 + \nu_1 \right) - \left( \mu_2 + \nu_2 \right)$. Thus,
    \begin{align*}
      \norm{\mu+\nu}_{\text{TV}} &= \left\vert \mu + \nu \right\vert(X)\\
                                                      &= \left( \mu_1 + \nu_1 \right)(X) + \left( \mu_2 + \nu_2 \right)(X)\\
                                          &= \left( \mu_1 + \mu_2 \right)(X) + \left( \nu_1 + \nu_2 \right)(X)\\
                                          &= \left\vert \mu \right\vert(X) + \left\vert \nu \right\vert(X)\\
                                          &= \norm{\mu}_{\text{TV}} + \norm{\nu}_{\text{TV}}.
    \end{align*}
    
\end{enumerate}
\subsection{Problem 5}%
\begin{problem}\hfill
  \begin{enumerate}[(a)]
    \item For $f\in L_1\left( [0,1] \right)$, let $L_f$ be the set of all $x\in [0,1]$ such that
      \begin{align*}
        \lim_{r\rightarrow 0} \frac{1}{2r} \int_{x-r}^{x+r} \left\vert f(y)-f(x) \right\vert\:dy &= 0.
      \end{align*}
      State the conclusion of the Lebesgue differentiation theorem regarding $L_f$.
    \item For $n\in \N$, $0 \leq j \leq 2^{n}-1$, set $I_{n,j} = \left[ j2^{-n},\left( j+1 \right)2^{-n} \right)$. For $f\in L_1\left( [0,1] \right)$, define
      \begin{align*}
        E_{n}f &= \sum_{j=0}^{2^{n}-1} \left( \frac{1}{m\left( I_{n,j} \right)} \int_{I_{n_j}}^{} f(t)\:dt \right)\1_{I_{n_j}}.
      \end{align*}
      Show that $\lim_{n\rightarrow\infty} \left( E_nf \right)(x) = f(x)$ for a.e. $x\in [0,1]$.
  \end{enumerate}
\end{problem}
\begin{enumerate}[(a)]
  \item The conclusion of the Lebesgue differentiation theorem states that $\mu\left( [0,1]\setminus L_f \right) = 0$.
  \item Let $x\in [0,1]$. We note that $x$ must be in exactly one such interval $\left( j2^{-n},\left( j+1 \right)2^{-n} \right]$ since these intervals are disjoint. If we select $r > 0$ such that $\frac{1}{2^{n}} < r \leq \frac{1}{2^{n-1}}$, then we note the following:
    \begin{itemize}
      \item $I_{n,j}\subseteq U\left( x,r \right)$ for exactly one such $j$;
      \item $m\left( U\left( x,r \right) \right) \leq 4\mu\left( I_{n,j} \right)$.
    \end{itemize}
    If $x\in L_f$, then for any $\ve > 0$, there is some $\delta > 0$ such that when $r < \delta$, then
    \begin{align*}
      \frac{1}{\mu\left( U\left( x,r \right) \right)} \int_{U\left( x,r \right)}^{} \left\vert f(t)-f(x) \right\vert\:dt &< \ve,
    \end{align*}
    by the Lebesgue Differentiation Theorem. If $n$ is such that $\frac{1}{2^{n-1}} < \delta$, then when $\frac{1}{2^{n}} < r \leq \frac{1}{2^{n-1}}$, then for any $x\in L_f$, we have
    \begin{align*}
      \left\vert E_nf\left( x \right) - f(x) \right\vert &= \left\vert \frac{1}{m\left( I_{n,j} \right)}\int_{I_{n,j}}^{} f(t)\:dt - f(x) \right\vert\\
                                                         &\leq \frac{1}{m\left( I_{n,j} \right)} \int_{I_{n,j}}^{} \left\vert f(t)-f(x) \right\vert\:dt\\
                                                         &\leq \frac{1}{m\left( I_{n,j} \right)} \int_{U\left( x,r \right)}^{} \left\vert f(t)-f(x) \right\vert\:dt\\
                                                         &\leq \frac{4}{U\left( x,r \right)} \int_{U\left( x,r \right)}^{} \left\vert f(t)-f(x) \right\vert\:dt\\
                                                         &< 4\ve,
    \end{align*}
    so $\lim_{n\rightarrow\infty}E_nf(x) = f(x)$ for all $x\in L_f$, meaning that it holds for a.e. $x\in [0,1]$.
\end{enumerate}
\section{\href{https://math.virginia.edu/graduate/exams/analysis/2023Jan_real.pdf}{January 2023}}%
\subsection{Problem 1}%
\begin{problem}
  Let $\left( X,\mu \right)$ be a $\sigma$-finite measure space, $p\in [1,\infty)$. Let $\left( f_n \right)_n$ be a sequence in $L_p\left( X,\mu \right)$, and suppose $\norm{f_n}_{L_p}\leq 1$, $\left( f_n \right)_n\rightarrow f$ almost everywhere. Show that $\norm{f}_{p}\leq 1$.
\end{problem}
By using Fatou's Lemma, and assuming WLOG that $\left( f_n \right)_n\rightarrow f$ pointwise everywhere, we get
\begin{align*}
  \int_{X}^{} \left\vert f \right\vert^{p}\:d\mu &= \int_{X}^{} \liminf_{n\rightarrow\infty} \left\vert f_n \right\vert^{p}\:d\mu\\
                                                 &\leq \liminf_{n\rightarrow\infty} \int_{X}^{} \left\vert f_n \right\vert^{p}\:d\mu\\
                                                 &\leq 1,
\end{align*}
so $\norm{f}_{L_p}\leq 1$.
\subsection{Problem 2}%
\begin{problem}
  Let $\mu$ be an atomless Borel probability measure on $\R$. Suppose $E\subseteq \R$ is a Borel set with $\mu\left( E \right) > 0$. Show that there is $t\in \R$ with $\mu\left( E\cap \left( -\infty,t \right) \right) = \frac{1}{2}\mu\left( E \right)$.
\end{problem}
Let
\begin{align*}
  f(t) &= \mu\left( E\cap \left( -\infty,t \right) \right),
\end{align*}
and for any sequence $\left( t_n \right)_n$, define
\begin{align*}
  E_n &= E\cap \left( -\infty,t_n \right).
\end{align*}
We will show that $f$ is left- and right-continuous, hence continuous. To start, if $\left( t_n \right)_n\searrow t$, then
\begin{align*}
  \bigcap_{n\in \N} E_n &= E\cap \left( -\infty,t \right],
\end{align*}
so
\begin{align*}
  f(t) &= \mu\left( \bigcap_{n\in \N} E_n\setminus \set{t} \right)\\
       &= \mu\left( \bigcap_{n\in \N} E_n \right) -\mu\left( \set{t} \right).
\end{align*}
Since $\mu$ is atomless, we see that $\mu\left( \set{t} \right) = 0$, so since $\mu\left( E \right) < \infty$,
\begin{align*}
  f(t) &= \mu\left( \bigcap_{n\in\N} E_n \right)\\
       &= \lim_{n\rightarrow\infty} \mu\left( E_n \right)\\
       &= \lim_{n\rightarrow\infty} f\left( t_n \right).
\end{align*}
Thus, $f$ is right-continuous. Similarly, if $f$ is left-continuous, and $\left( t_n \right)_n \nearrow t$, then
\begin{align*}
  \bigcup_{n\in \N} E_n &= E\cap \left( -\infty,t \right),
\end{align*}
so by continuity from below,
\begin{align*}
  f(t) &= \mu\left( \bigcup_{n\in\N} E_n \right)\\
       &= \lim_{n\rightarrow\infty} \mu\left( E_n \right)\\
       &= \lim_{n\rightarrow\infty} f\left( t_n \right).
\end{align*}
Therefore, $f$ is continuous. Since
\begin{align*}
  \lim_{t\rightarrow -\infty} f(t) &= 0\\
  \lim_{t\rightarrow\infty} f(t) &= \mu\left( E \right)\\
                                 &> 0,
\end{align*}
the intermediate value theorem gives some $t_0\in \R$ such that
\begin{align*}
  f\left(t_0\right) &= \mu\left( E\cap \left( -\infty,t_0 \right) \right)\\
                    &= \frac{1}{2}\mu\left( E \right).
\end{align*}
\subsection{Problem 3}%
\begin{problem}
  Let $X$ be a set equipped with a $\sigma$-algebra $\Sigma$. Suppose $\mu,\nu\colon \Sigma\rightarrow [0,\infty)$ are finite measures with $\lambda = \mu + \nu$. Define $f$ such that
  \begin{align*}
    \nu\left( E \right) &= \int_{E}^{} f\:d\lambda.
  \end{align*}
  \begin{enumerate}[(i)]
    \item Show that $0 \leq f \leq 1$ $\lambda$-a.e.
    \item If $F = \set{x | f(x) = 1}$, show that $\mu(F) = 0$.
    \item If $A\subseteq \set{x | 0 \leq f(x) < 1}$ is such that $\mu(A) = 0$, show that $\nu(A) = 0$.
  \end{enumerate}
\end{problem}
\begin{enumerate}[(i)]
  \item Consider the sets $E_n$, for each $n\in \N$, defined by
    \begin{align*}
      E_n &= \set{x | f(x) < -\frac{1}{n}},
    \end{align*}
    so that $E_n \subseteq E_{n+1}$, and
    \begin{align*}
      E &= \bigcup_{n=1}^{\infty} E_n\\
        &= \set{x | f(x) < 0}.
    \end{align*}
    Then, we see that 
    \begin{align*}
      0 &\geq -\frac{1}{n}\lambda\left( E_n \right)\\
        &= -\frac{1}{n} \int_{E_n}^{} \:d\lambda\\
                                          &> \int_{E_n}^{} f\:d\lambda\\
                                          &= \nu\left( E_n \right)\\
                                          &\geq 0,
    \end{align*}
    meaning that $\lambda\left( E_n \right) = 0$ for each $n$, so by continuity from below, $\lambda\left( E \right) = \lim_{n\rightarrow\infty} \lambda\left( E_n \right) = 0$.\newline

    Now, the set
    \begin{align*}
      F &= \set{x | f(x) > 1}
    \end{align*}
    has
    \begin{align*}
      \lambda(F) &= \int_{F}^{} \:d\lambda\\
                 &< \int_{F}^{} f\:d\lambda\\
                 &= \nu\left( F \right)\\
                 &\leq \nu\left( F \right) + \mu\left( F \right)\\
                 &= \lambda\left( F \right), 
    \end{align*}
    meaning that $\lambda(F) = 0$, and $0 \leq f \leq 1$ $\lambda$-a.e.
  \item If $F = \set{x | f(x) = 1}$, then
    \begin{align*}
      \lambda\left( F \right) &= \int_{F}^{} \:d\lambda\\
                              &= \int_{F}^{} f\:d\lambda\\
                              &= \nu\left( F \right),
    \end{align*}
    so $\mu\left( F \right) = 0$.
  \item Let $A\subseteq \set{x | 0\leq f(x) < 1}$ be such that $\mu(A) =0$. Then, we have
    \begin{align*}
      \nu\left( A \right) &= \int_{A}^{} f\:d\lambda\\
                          &= \int_{A}^{} f\:d\nu + \int_{A}^{} f\:d\mu\\
                          &< \int_{A}^{} f\:d\nu + \int_{A}^{} \:d\mu\\
                          &= \int_{A}^{} f\:d\nu + \mu\left( A \right)\\
                          &= \int_{A}^{} f\:d\nu\\
                          &\leq \int_{A}^{} f\:d\lambda\\
                          &= \nu\left( A \right),
    \end{align*}
    so $\nu\left( A \right) = 0$, else we reach a contradiction.
\end{enumerate}
\subsection{Problem 4}%
\begin{problem}
  Fix $p\in [1,\infty)$. Let $W_{p}\left( [0,1] \right)$ be the space of absolutely continuous functions on $[0,1]$ such that $f'\in L_p\left( [0,1] \right)$. For all $f\in W_p\left( [0,1] \right)$, define
  \begin{align*}
    \norm{f}_{W_p} &= \left\vert f(0) \right\vert + \norm{f'}_{L_p}.
  \end{align*}
  Show that $\norm{\cdot}_{W_p}$ is a norm that makes $W_p\left( [0,1] \right)$ into a Banach space. You are allowed to use the fact that $L_p\left( [0,1] \right)$ is a Banach space.
\end{problem}
We start by showing that $\norm{\cdot}_{W_p}$ is indeed a norm. To see that $\norm{\cdot}_{W_p}$ is positive definite, if
\begin{align*}
  \norm{f}_{W_p} &= 0,
\end{align*}
then $\left\vert f(0) \right\vert = 0$ and $\norm{f'}_{L_p} = 0$. Since $\norm{f'}_{L_p} = 0$, $f' = 0$ a.e. as $L_p$ is a Banach space. Note that, by the fundamental theorem of calculus,
\begin{align*}
  f(x) &= f(0) + \int_{0}^{x} f'(t)\:dt,
\end{align*}
so $f(x) = 0$ almost everywhere, hence $f(x) = 0$ in $L_p$.\newline

Next, to see homogeneity, we have for all $\alpha\in\C$,
\begin{align*}
  \norm{\alpha f}_{W_p} &= \left\vert \alpha f(0) \right\vert + \norm{\left( \alpha f \right)'}_{L_p}\\
                        &= \left\vert \alpha \right\vert\left( \left\vert \alpha \right\vert + \norm{f'}_{L_p} \right)\\
                        &= \left\vert \alpha \right\vert\norm{f}_{W_p},
\end{align*}
as $\norm{\cdot}_{L_p}$ is a norm. Finally, we have
\begin{align*}
  \norm{f + g}_{W_p} &= \left\vert \left( f+g \right)(0) \right\vert + \norm{\left( f+g \right)'}_{L_p}\\
                     &\leq \left\vert f(0) \right\vert + \left\vert g(0) \right\vert + \norm{f'}_{L_p} + \norm{g'}_{L_p}\\
                     &= \norm{f}_{W_p} + \norm{g}_{W_p},
\end{align*}
as $\norm{\cdot}_{L_p}$ is a norm, so the triangle inequality holds. Thus, $\norm{\cdot}_{W_p}$ is a norm.\newline

Let $\left( f_n \right)_n$ be Cauchy in $W_p\left( [0,1] \right)$. Then, for all $\ve > 0$, there is $N\in \N$ such that for all $m,n\geq N$,
\begin{align*}
  \norm{f_n-f_m}_{W_p} &= \left\vert f_n(0)-f_m(0) \right\vert + \norm{f_n' - f_m'}_{L_p}\\
                       &< \ve,
\end{align*}
meaning that both
\begin{align*}
  \left\vert f_n(0)-f_m(0) \right\vert &< \ve\\
  \norm{f_n'-f_m'}_{L_p} &<\ve.
\end{align*}
Since $\C$ and $L_p\left( [0,1] \right)$ are complete, there is $c\in \C$ and $g\in L_p\left( [0,1] \right)$ such that
\begin{align*}
  f_n(0) &\rightarrow c\\
  f_n' &\rightarrow g.
\end{align*}
Define
\begin{align*}
  f(x) &= c + \int_{0}^{x} g(t)\:dt.
\end{align*}
Then, we note that by the Fundamental Theorem of Calculus,
\begin{align*}
  f'(x) &= g(x)\\
        &\in L_p\left( [0,1] \right),
\end{align*}
so $f\in W_p\left( [0,1] \right)$. Finally, we see that
\begin{align*}
  \norm{f_n-f}_{W_p\left( [0,1] \right)} &= \left\vert f_n(0) - f(0) \right\vert + \norm{f_n' - f'}_{L_p}\\
                                         &= \left\vert f_n(0) - c \right\vert + \norm{f_n'-g}_{L_p}\\
                                         &\rightarrow 0,
\end{align*}
so $\left( f_n \right)_n\rightarrow f$ in $W_p$, meaning $W_p$ is complete.
\subsection{Problem 5}%
\begin{problem}
  Let $m$ be Lebesgue measure on $\R$, $\Omega = \set{\1_{E} | E\subseteq \R\text{ Borel, }m(E) < \infty}$ be regarded as a subset of $L_1\left( \R \right)$. We regard $\Omega$ as a metric space with the $L_1$ distance.
  \begin{enumerate}[(i)]
    \item If $a < b$ are real numbers, show that the function $\Omega\rightarrow \R$ given by
      \begin{align*}
        \1_{E} &\mapsto m\left( E\cap [a,b] \right)
      \end{align*}
      is a continuous function.
    \item If $a < b$ are real numbers, let $U_{a,b}$ be the subset of $\Omega$ consisting of all $\1_{E}$ where $E\subseteq \R$ is Borel, and
      \begin{align*}
        0 < m\left( E\cap [a,b] \right) < b-a.
      \end{align*}
      Show that $U_{a,b}$ is open and dense in $\Omega$.
    \item Let $D$ be the set of all $\1_{E}$ where $E\subseteq \R$ is Borel, and for every interval $I$ of positive measure, we have
      \begin{align*}
        0 < m\left( E\cap I \right) < m\left( I \right).
      \end{align*}
      Show that there is a countable collection $\set{U_j}_{j\in J}$ of open and dense subsets of $\Omega$ with $\bigcap_{j\in J}U_j \subseteq D$.
  \end{enumerate}
\end{problem}
\begin{enumerate}[(i)]
  \item Letting $f\colon \Omega\rightarrow \R$ be defined by $f\left( \1_E \right) = m\left( E\cap [a,b] \right)$, we have
    \begin{align*}
      \left\vert m\left( E\cap [a,b] \right) - m\left( F\cap [a,b] \right) \right\vert &= \left\vert \int_{a}^{b} \1_{E} - \1_{F}\:dm \right\vert\\
                                                                                       &\leq \int_{a}^{b} \left\vert \1_{E} - \1_{F} \right\vert\:dm\\
                                                                                       &\leq \int_{\R}^{} \left\vert \1_{E} - \1_{F} \right\vert\:dm\\
                                                                                       &= \norm{\1_{E} - \1_{F}}_{L_1},
    \end{align*}
    meaning that $f$ is Lipschitz, hence continuous.
  \item Let $\1_{F}\in \Omega$. Then, $0 \leq \mu\left( F\cap [a,b] \right)\leq b-a$. If these inequalities are strict, then $F\in U_{a,b}$. Else, we let $\ve > 0$, and see two cases:
    \begin{itemize}
      \item if $\mu\left( F\cap [a,b] \right) = b-a$, then we may set $E = F\setminus \left( \left[a,a+\ve/\right)\cup \left( b-\ve/2,b \right] \right)$, so that $0 < \mu\left( E\cap [a,b] \right) < b-a$, and $\norm{\1_{E} - \1_{F}}_{L_1} = \mu\left( E\triangle F \right) \leq \ve$;
      \item if $\mu\left( F\cap [a,b] \right) = 0$, then we may set $E = F\cup \left( \left[ a,a+\ve/2 \right)\cup \left[ b-\ve/2,b \right) \right)$, meaning that $0 < \mu\left( E\cap [a,b] \right) < b-a$, and $\mu\left( E\triangle F \right) \leq \ve$.
    \end{itemize}
    Therefore, $U_{a,b}$ is dense in $\Omega$. To see that $U_{a,b}$ is open, notice that for any $\1_{E}\in U_{a,b}$, we may find $\ve > 0$ such that $0 < \mu\left( E\cap [a,b] \right) - \ve < \mu\left( E\cap [a,b] \right) < \mu\left( E\cap [a,b] \right) + \ve < b-a$, and for all $F$ with $\norm{\1_{F} - \1_{E}}_{L_1} < \ve$, we have
    \begin{align*}
      \left\vert \mu\left( F\cap [a,b] \right) - \mu\left( E\cap [a,b] \right) \right\vert &\leq \norm{\1_{F}-\1_{E}}_{L_1}\\
                                                                                           &< \ve,
    \end{align*}
    so $0 < \mu\left( F\cap [a,b] \right) < b-a$. Thus, $U_{a,b}$ is also open.
  \item If $\set{\left[ a_k,b_k \right]}$ is an enumeration of rational-endpoint intervals in $\R$, then for any interval $I$, there is some rational-endpoint interval $\left[a_k,b_k\right]\subseteq I$ by density and the characterization of an interval. For any $\1_{E}\in U_{a_k,b_k}$, we have that for an interval $[a,b]\subseteq I$ with $a_k\geq a$ and $b_k \leq b$,
    \begin{align*}
      m\left( E\cap [a,b] \right) &= m\left( E\cap \left[ a,a_k \right] \right) + m\left( E\cap \left[ a_k,b_k \right] \right) + m\left(E\cap  \left[ b_k,b \right] \right)\\
                                  &< a_k-a + b_k-a_k + b-b_k\\
                                  &= b-a,
    \end{align*}
    so $U_{a_k,b_k}\subseteq D$. Thus, since this holds for all intervals of positive measure for each $a_k,b_k$, we get
    \begin{align*}
      \bigcap_{k=1}^{\infty}U_{a_k,b_k} &\subseteq D.
    \end{align*}
\end{enumerate}
\section{August 2023}%
\subsection{Problem 1}%
\begin{problem}
Let $\left( X,\mu \right)$ be a $\sigma$-finite Borel measure space. Let $\left( f_n \right)_n$ be a sequence in $L_2\left( X,\mu \right)$, and $f\in L_2\left( X,\mu \right)$ such that for every $g\in L_2\left( X,\mu \right)$, we have
\begin{align*}
  \lim_{n\rightarrow\infty} \int_{X}^{} f_n(x)g(x)\:d\mu(x) &= \int_{X}^{} f(x)g(x)\:d\mu(x).
\end{align*}
Furthermore, suppose that
\begin{align*}
  \lim_{n\rightarrow\infty}\norm{f_n}_{L_2} &= \norm{f}_{L_2}.
\end{align*}
Prove that there is a subsequence $\left( f_{n_j} \right)_j$ and a subset $E\subseteq X$ with $\mu\left( E \right) = 0$ such that for all $x\in X\setminus E$,
\begin{align*}
  \lim_{j\rightarrow\infty} \left\vert f_{n_j}(x)-f(x) \right\vert = 0.
\end{align*}
\end{problem}
In order to show that $\left( f_{n_j} \right)_j\rightarrow f$ pointwise a.e., we show that $\left( f_{n} \right)_n\rightarrow f$ in measure; it has been well-established that if $\left( f_n \right)_n\rightarrow f$ in measure, then $\left( f_n \right)_n$ admits a subsequence that converges to $f$ pointwise almost everywhere.\newline

By Chebyshev's Inequality, we have that
\begin{align*}
  \mu\left( \set{x | \left\vert f_n(x)-f(x) \right\vert \geq \ve} \right) &\leq \frac{1}{\ve^2}\norm{f_n-f}_{L_2}^2\\
                                                                          &= \frac{1}{\ve^2} \int_{X}^{} \left\vert f_n-f \right\vert^2\:d\mu.
\end{align*}
Focusing on the integral,
\begin{align*}
  \int_{X}^{} \left\vert f_n-f \right\vert^2\:d\mu &= \int_{X}^{} \left( f_n-f \right) \overline{\left( f_n-f \right)}\:d\mu\\
                                                   &= \int_{X}^{} \left\vert f_n \right\vert^2 - f_n \overline{f} - \overline{f_n}f + \left\vert f \right\vert^2\:d\mu\\
                                                   &= \int_{X}^{} \left\vert f_n \right\vert^2\:d\mu - \int_{X}^{} f_n \overline{f}\:d\mu + \int_{X}^{} \left\vert f \right\vert^2\:d\mu - \overline{\int_{X}^{} f_n \overline{f}\:d\mu}.
\end{align*}
Now, we note the following:
\begin{itemize}
  \item $\lim_{n\rightarrow\infty} \int_{X}^{} \left\vert f_n \right\vert^2\:d\mu = \int_{X}^{} \left\vert f \right\vert^2\:d\mu$; and
  \item if $f\in L_2\left( X,\mu \right)$, then so too is $ \overline{f} $.
\end{itemize}
Thus, by taking limits, we have
\begin{align*}
  \lim_{n\rightarrow\infty} \int_{X}^{} \left\vert f_n-f \right\vert^2\:dx &= \lim_{n\rightarrow\infty} \left( \int_{X}^{} \left\vert f_n \right\vert^2\:d\mu - \int_{X}^{} f_n \overline{f}\:d\mu + \int_{X}^{} \left\vert f \right\vert^2\:d\mu - \overline{\int_{X}^{} f_n \overline{f}\:d\mu} \right)\\
                                                                           &= \int_{X}^{} \left\vert f \right\vert^2\:d\mu - \int_{X}^{} \left\vert f \right\vert^2\:d\mu + \int_{X}^{} \left\vert f \right\vert^2\:d\mu - \overline{ \int_{X}^{} \left\vert f \right\vert^2\:d\mu }\\
                                                                           &= 0,
\end{align*}
so $\norm{f_n-f}_{L_2}^2 \rightarrow 0$. Thus, $\left( f_n \right)_n\rightarrow f$ in measure, and thus there is a subsequence $\left( f_{n_j} \right)_j\rightarrow f$ pointwise almost everywhere.
\subsection{Problem 3}%
\begin{problem}
  Let $X$ be a LCH space. Recall that $g\colon X\rightarrow \C$ vanishes at infinity if for every $\ve > 0$, there is a compact $K_{\ve}\subseteq X$ such that for all $x\in X\setminus K_{\ve}$, $\left\vert g(x) \right\vert < \ve$. Show that $C_0\left( X \right)$ is complete with respect to the sup norm.
\end{problem}
Let $\left( f_n \right)_n$ be Cauchy in the sup norm. Then, for all $\ve > 0$, there is $N$ such that for all $m,n\geq N$, $\norm{f_m - f_n} < \ve$. Therefore, for all $x\in X$, we have $\left\vert f_n(x)-f_m(x) \right\vert < \ve$, meaning that the sequence $\left( f_n(x) \right)_n$ is Cauchy in $\C$. Define $f(x) = \lim_{n\rightarrow\infty}f_n(x)$ for each $x$.\newline

We must now show that
\begin{itemize}
  \item $\left( f_n \right)_n\rightarrow f$ in the supremum norm;
  \item $f\in C_0\left( X \right)$.
\end{itemize}
For the first point, we see that for $\ve > 0$, there is $N$ such that for all $n,m \geq N$ and all $x\in X$,
\begin{align*}
  \left\vert f_n(x)-f_m(x) \right\vert < \ve.
\end{align*}
Taking the limit as $m\rightarrow\infty$, we have 
\begin{align*}
  \left\vert f_n(x)-f(x) \right\vert \leq \ve.
\end{align*}
Thus, by taking suprema, we get that
\begin{align*}
  \sup_{x\in X} \left\vert f_n(x)-f(x) \right\vert \leq \ve,
\end{align*}
so $\norm{f_n - f} \leq \ve$, meaning that $\left( f_n \right)_n\rightarrow f$ in the sup norm, implying that $f$ is continuous as it is the uniform limit of continuous functions.\newline

Finally, we let $N_1$ be such that for all $n\geq N_1$, $\norm{f_n - f} < \ve/2$. Note that since $f_{N_1}\in C_0\left( X \right)$, we have a $K_{\ve/2}$ such that for all $x\in X\setminus K_{\ve/2}$, $\left\vert f_N(x) \right\vert < \ve/2$. Therefore, for all $x\in X\setminus K_{\ve/2}$, we have
\begin{align*}
  \left\vert f(x) \right\vert &\leq \left\vert f_{N_1}(x)-f(x) \right\vert + \left\vert f_{N_1}(x) \right\vert\\
                              &\leq \norm{f_{N_1} - f} + \left\vert f_{N_1}(x) \right\vert\\
                              &< \ve/2 + \ve/2\\
                              &= \ve,
\end{align*}
so $f\in C_0\left( X \right)$. Thus, $C_0\left( X \right)$ is complete.
\subsection{Problem 4}%
\begin{problem}
  Let $\left( X,\mathcal{A},\mu \right)$ be a finite measure space. Show that for any $n\geq 1$, and any $A_1,\dots,A_n,B_1,\dots,B_n\in \mathcal{A}$,
  \begin{align*}
    \mu\left( \left( A_1\cup\cdots\cup A_n \right) \triangle \left( B_1\cup\cdots\cup B_n \right) \right) &\leq \sum_{j=1}^{n} \mu\left( A_j\triangle B_j \right).
  \end{align*}
\end{problem}
We start off by noting that the symmetric difference $A\triangle B$ can be written as
\begin{align*}
  A\triangle B &= A\cup B \setminus \left( A\cap B \right).
\end{align*}
This is evident from unwinding the definition $A\triangle B = \left( A\setminus B \right) \cup \left( B\setminus A \right)$. Now, writing the left-hand side of our desired inequality, we get
\begin{align*}
  \mu\left( \left( A_1\cup\cdots\cup A_n \right)\triangle \left( B_1\cup\cdots\cup B_n \right) \right) &= \mu\left( A_1\cup\cdots\cup A_n\cup B_1\cup\cdots\cup B_n \right) - \mu\left( \left( A_1\cup\cdots\cup A_n \right)\cap \left( B_1\cup\cdots\cup B_n \right) \right).
  \intertext{Distributing the second term on the right-hand side and rearranging the first term, we get}
                                                                                                       &= \mu\left( \bigcup_{j=1}^{n} \left( A_j\cup B_j \right) \right) - \mu\left( \bigcup_{j=1}^{n} \left( A_1\cup\cdots\cup A_n \right)\cap B_j \right).
                                                                                                       \intertext{Using subadditivity on the first term, we get}
                                                                                                       &\leq \sum_{j=1}^{n}\mu\left( A_j\cup B_j \right) - \mu\left( \bigcup_{j=1}^{n} \left( A_1\cup\cdots\cup A_n \right)\cap B_j \right).
                                                                                                       \intertext{Finally, using monotonicity and subadditivity on the second term, and exercising the fact that}
  A_j\cap B_j&\subseteq \bigcap_{j=1}^{n}\left( A_1\cup\cdots\cup A_n \right)\cap B_j,
\intertext{we get}
                                                                                                       &\leq \sum_{j=1}^{n} \mu\left( A_j\cup B_j \right) - \sum_{j=1}^{n}\mu\left( A_j\cap B_j \right)\\
                                                                                                       &= \sum_{j=1}^{n}\mu\left( A_j\triangle B_j \right).
\end{align*}
\subsection{Problem 5}%
\begin{problem}
  Let $\left( X,\mu \right)$ be a nonnegative measure space and $f$ a measurable function on $\left( X,\mu \right)$ such that
  \begin{align*}
    \sup_{\lambda > 0} \mu\left( \set{x | \left\vert f(x) \right\vert > \lambda} \right) &< \infty.
  \end{align*}
  Prove that there is a finite constant $C$ such that for every finite measure subset, we have
  \begin{align*}
    \int_{E}^{} \left\vert f(x) \right\vert\:d\mu(x) &\leq C\mu\left( E \right)^{1/2}.
  \end{align*}
\end{problem}
\begin{lemma}[Cavalieri's Principle]
  \begin{align*}
    \int_{X}^{} \left\vert f \right\vert\:d\mu &= \int_{0}^{\infty} \mu\left( \set{x\in X | \left\vert f \right\vert > \lambda} \right)\:d\lambda.
  \end{align*}
\end{lemma}
Using Cavalieri's Principle, we get
\begin{align*}
  \int_{E}^{} \left\vert f \right\vert\:d\mu &\leq \int_{0}^{\alpha} \mu\left( \set{x\in E | \left\vert f \right\vert > \lambda} \right)\:d\lambda + \int_{\alpha}^{\infty} \mu\left( \set{x\in E | \left\vert f \right\vert > \lambda} \right)\:d\lambda\\
                                             &\leq \alpha\mu\left( E \right) + \int_{\alpha}^{\infty} \frac{M}{\lambda^2}\:d\lambda\\
                                             &= \alpha\mu\left( E \right) + \frac{M}{\alpha}\\
                                             &\leq \left( M+1 \right)\mu\left( E \right)^{1/2},
\end{align*}
where we selected $\alpha = \frac{1}{\mu\left( E \right)^{1/2}}$, and $M$ denotes the given supremum.
\section{January 2024}%
\subsection{Problem 1}%
\begin{problem}
  Let $\left( X,\mu \right)$ be a $\sigma$-finite measure space, and suppose $\left( f_n \right)_n$ is a sequence in $L_2\left( X,\mu \right)$ such that $\sup_{n\geq 1}\norm{f_n}_{L_2} < \infty$ and $\left( f_n \right)_n\rightarrow f$ $\mu$-almost everywhere. Prove that $f\in L_2\left( X,\mu \right)$.
\end{problem}
Applying Fatou's Lemma, we find that
\begin{align*}
  \int_{X}^{} \left\vert f \right\vert^2\:d\mu &= \int_{X}^{} \liminf_{n\rightarrow\infty}\left\vert f_n \right\vert^2\:d\mu\\
                                               &\leq \liminf_{n\rightarrow\infty} \int_{X}^{} \left\vert f_n \right\vert^2\:d\mu\\
                                               &\leq \limsup_{n\rightarrow\infty} \int_{X}^{} \left\vert f_n \right\vert^2\:d\mu\\
                                               &\leq \sup_{n\geq 1} \int_{X}^{} \left\vert f_n \right\vert^2\:d\mu\\
                                               &< \infty.
\end{align*}
\subsection{Problem 2}%
\begin{problem}
  Let $\left( X,\mu \right)$ be a measure space, and let $p\in [1,\infty)$. Let $\left( f_n \right)_n\rightarrow f$ in $L_{p}$.
  \begin{enumerate}[(i)]
    \item Prove that there exists a subsequence $\left( f_{n_k} \right)$ such that $\norm{f_{n_{k+1}} - f_{n_{k}}}_{L_p} < 2^{-k}$.
    \item Show that for $\mu$-almost every $x$, we have $\lim_{k\rightarrow\infty} f_{n_{k}}(x) = f(x)$.
  \end{enumerate}
\end{problem}
\begin{enumerate}[(i)]
  \item Since $\left( f_{n} \right)_{n}\rightarrow f$ in $L_{p}$, we see that $\left( f_{n} \right)_{n}$ is $L_{p}$-Cauchy, so we may extract a subsequence as follows. Let $f_{n_{1}} = f_{1}$, and find $f_{n_{2}}$ with $n_2 > 1$ such that
    \begin{align*}
      \norm{f_{n_2} - f_{n_1}} &< \frac{1}{2}.
    \end{align*}
    Inductively, we may use the fact that $\left( f_{n} \right)_n$ is Cauchy to find $n_{k+1} > n_{k}$ such that
    \begin{align*}
      \norm{f_{n_{k+1}} - f_{n_{k}}} &< \frac{1}{2^{k}}.
    \end{align*}
  \item Consider the sequence $\left( s_n \right)_n$ given by
    \begin{align*}
      s_n &= \sum_{k=1}^{n} \left\vert f_{n_{k+1}} - f_{n_{k}} \right\vert.
    \end{align*}
    Then, by Minkowski's Inequality, we find that
    \begin{align*}
      \norm{s_{n}}_{L_p} &\leq \sum_{k=1}^{n}\norm{f_{n_{k+1}} - f_{n_{k}}}_{L_p}.
    \end{align*}
    In particular, $\norm{s_n}_{L_p} \leq 1$ for all $n$, meaning that by dominated convergence, $s = \lim_{n\rightarrow\infty} s_n$ is in $L_p$, and in particular, $s(x) < \infty$ for almost every $x$. Notice that this means that
    \begin{align*}
      h(x) &= f_{n_{1}}(x) + \sum_{k=1}^{\infty} \left( f_{n_{k+1}}(x) - f_{n_{k}}(x) \right)
    \end{align*}
    converges for almost every $x$. Defining $h(x) = 0$ for all $x$ where this sum does not converge absolutely, we notice that
    \begin{align*}
      f_{n_{1}}(x) + \sum_{k=1}^{m}\left( f_{n_{k+1}}(x) - f_{n_{k}}(x) \right) &= f_{n_{m+1}}(x),
    \end{align*}
    meaning that $h$ is the pointwise (almost everywhere) limit of the sequence $\left( f_{n_{k}} \right)_{k}$; by Minkowski's Inequality, and applying Fatou's Lemma, as earlier, we also find that
    \begin{align*}
      \norm{h}_{L_p} &\leq \norm{f_{n_1}}_{L_p} + \sum_{k=1}^{\infty}\norm{f_{n_{k+1}}-f_{n_{k}}}_{L_p}\\
                     &\leq \norm{f_{n_{1}}}_{L_p} + 1\\
                     &< \infty,
    \end{align*}
    meaning $h\in L_{p}\left( X,\mu \right)$. All we need to do now is show that $\norm{f-h}_{L_p} = 0$, meaning that $\left[ f \right] = \left[ h \right]$ under the pointwise almost everywhere equivalence relation. To see this, 
    \begin{align*}
      \int_{X}^{} \left\vert h-f \right\vert^{p}\:d\mu &= \int_{X}^{} \liminf_{k\rightarrow\infty} \left\vert f_{n_{k}} - f \right\vert^{p}\:d\mu\\
                                                       &\leq \liminf_{k\rightarrow\infty} \int_{X}^{} \left\vert f_{n_{k}} - f \right\vert^{p}\:d\mu\\
                                                       &= \liminf_{k\rightarrow\infty} \norm{f_{n_{k}} - f}_{L_p}^{p}\\
                                                       &= 0,
    \end{align*}
    where the last equality is derived from the fact that $\left( f_{n} \right)_n\rightarrow f$ in $L_p$, so every subsequence of $\left( f_{n} \right)_n$ converges to $f$ in $L_p$.
\end{enumerate}
\subsection{Problem 3}%
\begin{problem}
  Let $f$ be Lebesgue-integrable on $\R$, and let $g$ be a bounded continuous function on $\R$. Prove that the convolution 
  \begin{align*}
    \left( f\ast g \right)(x) &= \int_{\R}^{} f(y)g\left( x-y \right)\:dy
  \end{align*}
  is a continuous function on $\R$.
\end{problem}
Let $M = \sup_{x\in \R} \left\vert g(x) \right\vert$. Now, since $f\in L_1$, there is a compactly supported continuous function $h\in C_c\left( \R \right)$ such that $\norm{h-f}_{L_1} < \frac{\ve}{3M}$. If we let $K = \supp\left( h \right)$, then since $h$ is compactly supported, $h$ is uniformly continuous, so there is $\delta > 0$ such that whenever $\left\vert x-y \right\vert < \delta$, we have
\begin{align*}
  \left\vert h(x)-h(y) \right\vert < \frac{\ve}{3M m(K)},
\end{align*}
where $m(K)$ is the Lebesgue measure of $K$ in $\R$. Therefore, if $\left\vert x-y \right\vert < \delta$, we have
\begin{align*}
  \left\vert \left( f\ast g \right)\left( x \right) - \left( f\ast g \right)\left( y \right) \right\vert &= \left\vert \int_{\R}^{} \left( f\left( x-t \right)-f\left( y-t \right) \right)g\left( t \right)\:dt \right\vert\\
                                                                                                         &\leq \int_{\R}^{} \left\vert f\left( x-t \right)-f\left( y-t \right) \right\vert \left\vert g\left( t \right) \right\vert\:dt\\
                                                                                                         &\leq \int_{\R}^{} \left\vert f\left( x-t \right)-h\left( x-t \right) \right\vert\left\vert g\left( t \right) \right\vert\:dt\\
                                                                                                         &+ \int_{\R}^{} \left\vert h\left( x-t \right)-h\left( y-t \right) \right\vert\left\vert g(t) \right\vert\:dt\\
                                                                                                         &+ \int_{\R}^{} \left\vert h\left( y-t \right)- f\left( y-t \right)\right\vert\left\vert g\left( t \right) \right\vert\:dt.
                                                                                                         \intertext{Using Hölder's Inequality on the first and third integrals, we get}
                                                                                                         &\leq M\left( \frac{\ve}{3M} \right) + \int_{\R}^{} \left\vert h\left( x-t \right)-h\left( y-t \right) \right\vert\left\vert g(t) \right\vert\:dt + M\left( \frac{\ve}{3M} \right),
                                                                                                         \intertext{and using the uniform continuity of $h$, we get}
                                                                                                         &\leq \frac{2\ve}{3} + M\left( m(K) \right)\frac{\ve}{3M\left( m(K) \right)}\\
                                                                                                         &= \ve.
\end{align*}
\subsubsection{Alternative Solution}%
We know that $f$ is integrable on $\R$, and $g$ is bounded and continuous. We will show that if $\left( x_n \right)_n\rightarrow x_0$, then $\left( \left( f\ast g \right)\left( x_n \right) \right)_n\rightarrow \left( f\ast g \right)\left( x_0 \right)$.\newline

Now, if $\left( x_n \right)_n\rightarrow x_0$, then $g\left( x_n \right)\rightarrow g\left( x_0 \right)$, since $g$ is continuous. Since $f$ is integrable, $f$ is finite almost everywhere, meaning that $f(y)g\left( x_n-y \right) \rightarrow f(y)g\left( x_0-y \right)$ almost everywhere.\newline

Furthermore, since $g$ is bounded, we have $\left\vert g \right\vert \leq M$ for some $M > 0$. Writing our convolution integrand, we have
\begin{align*}
  \left\vert f(y)g\left( x_n-y \right) \right\vert \leq M\left\vert f(y) \right\vert.
\end{align*}
Since $f$ is integrable, we may use the dominated convergence theorem to find that
\begin{align*}
  \lim_{n\rightarrow\infty} \int_{}^{} f(y)g\left( x_n-y \right)\:dy &= \int_{}^{} f(y)g\left( x_0-y \right)\:dy.
\end{align*}
\subsection{Problem 4}%
\begin{problem}
  Let $\left( a_n \right)_n$ be a sequence of complex numbers such that $\left\vert a_n \right\vert < 1$ for all $n$ and $\lim_{n\rightarrow\infty} a_n = 0$.
  \begin{enumerate}[(i)]
    \item Show that if $\sum_{n\geq 1}\left\vert a_n \right\vert < \infty$, then the sequence $\left( p_n \right)_n$ defined by $p_n = \prod_{i=1}^{n}\left( 1 + a_i \right)$ is convergent.
    \item Does the converse hold? In other words, is it true that if $\left( p_n \right)_n$ is convergent, we must have $\sum_{n\geq 1}\left\vert a_n \right\vert < \infty$? Recall the conditions that $\left\vert a_n \right\vert < 1$ for all $n$ and $\lim_{n\rightarrow \infty}a_n = 0$.
  \end{enumerate}
\end{problem}
\begin{enumerate}[(a)]
  \item Let $\log(z)$ be defined on the branch $-\pi < \arg(z) \leq \pi$, then $\log\left( 1+a_n \right)$ is well-defined for all $n\in\N$, as $\re\left( a_n \right) \leq \left\vert a_n \right\vert < 1$. Since $\log$ is continuous on the branch,
    \begin{align*}
      \log\left( p_n \right) &= \sum_{k=1}^{n} \log\left( 1+a_k \right)\\
      \log\left( \lim_{n\rightarrow\infty} p_n \right) &= \lim_{n\rightarrow\infty} \sum_{k=1}^{\infty} \log\left( 1+a_k \right).
    \end{align*}
    Now, we notice that taking the limit $\lim_{k\rightarrow\infty}a_k = 0$, the limit comparison test (or by seeing that the singularity at $\log(z)/z$ is removable), that $\lim_{k\rightarrow\infty} \frac{\log\left(1+a_k\right)}{a_k} = 1$, and since $\sum_{k=1}^{\infty}a_k$ converges, so too does $\sum_{k=1}^{\infty}\log\left( 1+a_k \right)$, meaning $p_n$ converges.
\end{enumerate}
\section{August 2024}%
\subsection{Problem 1}%
\begin{problem}
  Let $A\subseteq \R$ be a Lebesgue-measurable subset of finite measure. For $r\in\R\setminus \set{0}$, let $rA = \set{x\in \R | r^{-1}x\in A}$, and let $A\triangle rA = \left( A\setminus rA \right) \cup \left( rA\setminus A \right)$. Show that
  \begin{align*}
    \lim_{r\rightarrow 1} m\left( A\triangle rA \right) &= 0.
  \end{align*}
\end{problem}
Rewriting $m\left( A\triangle r A \right)$, we find that
\begin{align*}
  m\left( A\triangle r A\right)&= \int_{\R}^{} \1_{A\triangle r A}\:dm\\
                               &= \int_{\R}^{} \left\vert \1_{A} - \1_{r A} \right\vert\:dm.
\end{align*}
Now, let $\left( r_n \right)_n\rightarrow 1$. Notice that, by the scaling properties the Lebesgue measure,
\begin{align*}
  \int_{\R}^{} \1_{A}\:d\mu &= m\left( A \right)\\
                            &= \lim_{n\rightarrow\infty} \left\vert r_n \right\vert m\left( A \right)\\
                    &= \lim_{n\rightarrow\infty} m\left( \left\vert r_n \right\vert A \right)\\
                    &= \lim_{n\rightarrow\infty} \int_{\R}^{} \1_{r_n A}\:d\mu,
\end{align*}
and $\1_{r_n A}\rightarrow \1_{A}$ pointwise a.e. Now, letting $g_n = \min\set{\1_{r_n A},\1_{A}}$, we see that
\begin{align*}
  g_n &\leq \1_{A}
\end{align*}
for all $n$, so by dominated convergence (since $\mu(A) < \infty$),
\begin{align*}
  \int_{\R}^{} \1_{A}\:d\mu &= \lim_{n\rightarrow\infty} \int_{\R}^{} g_n\:d\mu\\
                            &= \frac{1}{2} \left( \lim_{n\rightarrow\infty}\int_{\R}^{} \1_{r_n A}\:d\mu + \int_{\R}^{} \1_{A}\:d\mu - \int_{\R}^{} \left\vert \1_{r_n A} - \1_{A} \right\vert\:d\mu\right)\\
                            &= \int_{\R}^{} \1_{A}\:d\mu - \frac{1}{2}\lim_{n\rightarrow\infty} \int_{\R}^{} \left\vert \1_{r_n A} - \1_{A} \right\vert\:d\mu,
\end{align*}
so that
\begin{align*}
  \lim_{n\rightarrow\infty} m\left( A\triangle r_n A \right) &= \lim_{n\rightarrow\infty} \int_{\R}^{} \left\vert \1_{r_n A} - \1_{A} \right\vert \:d\mu\\
                                   &= 0.
\end{align*}

\subsection{Problem 2}%
\begin{problem}
  Let $\mu$ be a finite Borel measure on $\R$. For $\xi\in\R$, define
  \begin{align*}
    \widehat{\mu}\left( \xi \right) &= \int_{\R}^{} e^{-2\pi i x\xi}\:d\mu(x).
  \end{align*}
  Suppose
  \begin{align*}
    \lim_{\xi\rightarrow 0} \frac{\widehat{\mu}\left( \xi \right) - \widehat{\mu}(0)}{\xi^2} &= 0.
  \end{align*}
  \begin{enumerate}[(a)]
    \item Show that
      \begin{align*}
        \int_{\R}^{} x^2\:d\mu(x) &= 0.
      \end{align*}
    \item Deduce that for any open interval $\left( a,b \right)\subseteq \R$,
      \begin{align*}
        \mu\left( \left( a,b \right) \right) &= \begin{cases}
          \mu\left( \R \right) & 0\in (a,b)\\
          0 & 0\notin (a,b)
        \end{cases}.
      \end{align*}
  \end{enumerate}
\end{problem}
\begin{enumerate}[(a)]
  \item We note that
    \begin{align*}
      \lim_{\xi\rightarrow 0} \left( \hat{\mu}\left( \xi \right) - \hat{\mu}\left( 0 \right) \right) &= 0,
    \end{align*}
    and
    \begin{align*}
      \lim_{\xi\rightarrow 0} \left( \xi^2 \right) &= 0,
    \end{align*}
    so by L'Hôpital's rule and the Dominated Convergence Theorem, we see that
    \begin{align*}
      0 &= \lim_{\xi\rightarrow 0} \frac{\hat{\mu}\left( \xi \right) - \hat{\mu}\left( 0 \right)}{\xi^2}\\
        &= \lim_{\xi\rightarrow 0} \frac{ \int_{\R}^{} \pd{}{\xi}\left( e^{-2\pi i x \xi} \right)\:d\mu(x) }{2\xi}\\
        &= \lim_{\xi\rightarrow 0} \frac{ \int_{\R}^{} -2\pi i x e^{-2\pi i x \xi}\:d\mu(x) }{2\xi}\\
        &= \int_{\R}^{} \lim_{\xi\rightarrow 0} \frac{-2\pi i x e^{-2\pi i x \xi}}{2\xi}\:d\mu(x)\\
        &= \int_{\R}^{} \left( -2\pi i x \right)\diff{}{\xi}\left( e^{-2\pi i x \xi} \right)\biggr\vert_{\xi = 0}\:d\mu(x)\\
        &= -4\pi^2 \int_{\R}^{} x^2 \:d\mu(x).
    \end{align*}
    Thus, we obtain
    \begin{align*}
      0 &= \int_{\R}^{} x^2\:d\mu(x).
    \end{align*}
  \item We want to evaluate
    \begin{align*}
      \mu\left( (a,b) \right) &= \int_{\R}^{} \1_{(a,b)}\:d\mu(x).
    \end{align*}
    We fix $(a,b)\subseteq \R$, where $0\notin (a,b)$. There are four cases.
    \begin{itemize}
      \item If $0 < a < b$, then we see that
        \begin{align*}
          a^2 \int_{\R}^{} \1_{(a,b)}\:d\mu &\leq \int_{\R}^{} x^2\:d\mu(x),
        \end{align*}
        meaning that $\mu\left( (a,b) \right) = 0$.
      \item If $a < b < 0$, then we see that
        \begin{align*}
          \left\vert b \right\vert^2 \int_{\R}^{} \1_{(a,b)}\:d\mu &\leq \int_{\R}^{} x^2\:d\mu(x),
        \end{align*}
        so $\mu\left( \left( a,b \right) \right) = 0$.
      \item If $0 = a < b$, then by continuity from below, we see that
        \begin{align*}
          \mu\left( \left( a,b \right) \right) &= \lim_{n\rightarrow\infty} \mu\left( (1/n,b) \right)\\
                                               &= 0.
        \end{align*}
      \item Similarly, if $a < b = 0$, then by continuity from below, we see that
        \begin{align*}
          \mu\left( \left( a,b \right) \right) &= \lim_{n\rightarrow\infty} \mu\left( \left( a,-1/n \right) \right)\\
                                               &= 0.
        \end{align*}
    \end{itemize}
    Meanwhile, if $0\in (a,b)$, then we may split
    \begin{align*}
      \int_{\R}^{} \:d\mu(x) &= \int_{\R}^{} \1_{(a,b)}(x)\:d\mu(x) + \int_{\R}^{} \1_{(-\infty,a]}(x)\:d\mu(x) + \int_{}^{} \1_{[b,\infty)}(x)\:d\mu(x)
      \intertext{and, by continuity from above/below,}
                             &= \int_{\R}^{} \1_{(a,b)}(x)\:d\mu(x) + \lim_{n\rightarrow\infty} \mu\left( \left( -\infty,a+1/n \right) \right) + \lim_{n\rightarrow\infty} \mu\left( \left( b-1/n,\infty \right) \right)\\
                             &= \int_{\R}^{} \1_{(a,b)}(x)\:d\mu(x).
    \end{align*}
\end{enumerate}
\subsection{Problem 3}%
\begin{problem}
  Fix $\alpha\in (0,1]$. The space $C^{0,\alpha}$ of Hölder-continuous functions consists of functions $f\colon [0,1]\rightarrow \C$ such that
  \begin{align*}
    \norm{f} &\coloneq \left\vert f(0) \right\vert + \sup_{x\neq y\in [0,1]} \frac{\left\vert f(x)-f(y) \right\vert}{\left\vert x-y \right\vert^{\alpha}}
  \end{align*}
  is finite.
  \begin{enumerate}[(a)]
    \item Show that $\norm{\cdot}$ is a norm on $C^{0,\alpha}\left( [0,1] \right)$.
    \item Show that $\left( C^{0,\alpha}\left( [0,1] \right),\norm{\cdot} \right)$ is a Banach space.
  \end{enumerate}
\end{problem}
\begin{enumerate}[(a)]
  \item Clearly, the value $\norm{f} \geq 0$ for all $f\in C^{0,\alpha}\left( [0,1] \right)$, as $\left\vert f(0) \right\vert \geq 0$ and, for all $x,y\in [0,1]$, $\frac{\left\vert f(x)-f(y) \right\vert}{\left\vert x-y \right\vert^{\alpha}}\geq 0$. The value $\norm{f} = 0$ if and only if $\left\vert f(0) \right\vert = 1$, and for all $x,y\in [0,1]$, we have
    \begin{align*}
      \sup_{x\neq y\in [0,1]} \frac{\left\vert f(x)-f(y) \right\vert}{\left\vert x-y \right\vert^{\alpha}} &= 0,
    \end{align*}
    or that $\left\vert f(x)-f(y) \right\vert = 0$ for all $x\neq y$, implying that $f$ is a constant function. Combined, this means that $f = 0$.\newline

    To see homogeneity, we let $\alpha\in \C$, and see that
    \begin{align*}
      \norm{\alpha f} &= \left\vert (\alpha f)(0) \right\vert + \sup_{x\neq y\in [0,1]} \frac{\left( \alpha f \right)(x) - \left( \alpha f \right)(y)}{\left\vert x-y \right\vert^{\alpha}}\\
                      &= \left\vert \alpha \right\vert\left\vert f(0) \right\vert + \sup_{x\neq y\in [0,1]} \frac{\left\vert \alpha \left( f(x)-f(y) \right) \right\vert}{\left\vert x-y \right\vert^{\alpha}}\\
                      &= \left\vert \alpha \right\vert \left( \left\vert f(0) \right\vert + \sup_{x\neq y\in [0,1]} \frac{\left\vert f(x)-f(y) \right\vert}{\left\vert x-y \right\vert^{\alpha}} \right)\\
                      &= \left\vert \alpha \right\vert\norm{f}.
    \end{align*}
    Finally, if $f$ and $g$ are elements of $C^{0,\alpha}\left( [0,1] \right)$, then
    \begin{align*}
      \norm{f+g} &= \left\vert \left( f+g \right)(0) \right\vert + \sup_{x\neq y\in [0,1]} \frac{\left\vert \left( f+g \right)(x) - \left( f+g \right)(y) \right\vert}{\left\vert x-y \right\vert^{\alpha}}\\
                 &\leq \left\vert f(0) \right\vert + \left\vert g(0) \right\vert + \sup_{x\neq y\in [0,1]} \frac{\left\vert f(x)-f(y) \right\vert + \left\vert g(x)-g(y) \right\vert}{\left\vert x-y \right\vert^{\alpha}}\\
                 &\leq \left\vert f(0) \right\vert + \sup_{x\neq y\in [0,1]} \frac{\left\vert f(x)-f(y) \right\vert}{\left\vert x-y \right\vert^{\alpha}} + \left\vert g(0) \right\vert + \sup_{x\neq y\in [0,1]} \frac{\left\vert g(x)-g(y) \right\vert}{\left\vert x-y \right\vert^{\alpha}}\\
                 &= \norm{f} + \norm{g}.
    \end{align*}
    Thus, $\norm{\cdot}$ is a bona fide norm on $C^{0,\alpha}\left( \left[ 0,1 \right] \right)$.
  \item We will use the absolute convergence criterion for a Banach space. That is, we will show that if
    \begin{align*}
      \sum_{n=1}^{\infty}\norm{f_n} &< \infty,
    \end{align*}
    then $\sum_{n=1}^{\infty}f_n = f$ for some $f\in C^{0,\alpha}\left( [0,1] \right)$. To start, we see that for any $x\in [0,1]$ and any $f\in C^{0,\alpha}\left( [0,1] \right)$,
    \begin{align*}
      \left\vert f(x) \right\vert &\leq \left\vert f(0) \right\vert + \left\vert f(x) - f(0) \right\vert\\
                                  &= \left\vert f(0) \right\vert + \frac{\left\vert f(x)-f(0) \right\vert}{\left\vert x-0 \right\vert^{\alpha}}\left\vert x \right\vert^{\alpha}\\
                                  &\leq \left\vert f(0) \right\vert + \frac{\left\vert f(x)-f(0) \right\vert}{\left\vert x-0 \right\vert^{\alpha}}\\
                                  &\leq \left\vert f(0) \right\vert + \sup_{x\neq y\in [0,1]}\frac{\left\vert f(x)-f(y) \right\vert}{\left\vert x-y \right\vert^{\alpha}},
    \end{align*}
    meaning that $\norm{f}_{u}\leq \norm{f}$.\newline

    Now, let
    \begin{align*}
      \sum_{n=1}^{\infty}\norm{f_n} &< \infty,
    \end{align*}
    so that
    \begin{align*}
      \sum_{n=1}^{\infty}\norm{f_n}_u &< \infty.
    \end{align*}
    Since $C\left( [0,1] \right)$ is complete with respect to the uniform norm, there is some $f\in C\left( [0,1] \right)$ such that $f = \sum_{n=1}^{\infty}f_n$, where the convergence is with respect to the uniform norm. Notice, however, that
    \begin{align*}
      \frac{\left\vert f(x)-f(y) \right\vert}{\left\vert x-y \right\vert^{\alpha}} &= \frac{\left\vert \sum_{n=1}^{\infty}f_n(x) - \sum_{n=1}^{\infty}f_n(y) \right\vert}{\left\vert x-y \right\vert^{\alpha}}\\
                                                                                   &\leq \sum_{n=1}^{\infty}\frac{\left\vert f_n(x)-f_n(y) \right\vert}{\left\vert x-y \right\vert^{\alpha}}\\
                                                                                   &\leq \sum_{n=1}^{\infty}\norm{f_n}\\
                                                                                   &< \infty,
    \end{align*}
    meaning that $f\in C^{0,\alpha}\left( [0,1] \right)$.\newline

    Finally, to see that the convergence is with respect to the $\alpha$-norm, we see that
    \begin{align*}
      \norm{\sum_{n=1}^{N}f_n - f} &= \norm{\sum_{n=N+1}^{\infty}f_n}\\
                                   &\leq \sum_{n=N+1}^{\infty}\norm{f_n}\\
                                   &\rightarrow 0,
    \end{align*}
    by series convergence.
\end{enumerate}
\subsection{Problem 4}%
\begin{problem}
  Let $\left( X,\mathcal{M},\mu \right)$ be a $\sigma$-finite measure space, $p\in [1,\infty)$, and $f\in L_p\left( X,\mathcal{M},\mu \right)$.
  \begin{enumerate}[(a)]
    \item Show that
      \begin{align*}
        \int_{X}^{} \left\vert f(x) \right\vert^{p}\:d\mu(x) &= \int_{0}^{\infty} \alpha^{p-1} \mu\left( \set{x | \left\vert f(x) \right\vert > \alpha} \right)\:d\alpha.
      \end{align*}
    \item Show that, for all $\alpha > 0$,
      \begin{align*}
        \mu\left( \set{x | \left\vert f(x) \right\vert > \alpha} \right) &\leq \frac{\norm{f}_{L_p}^{p}}{\alpha^{p}}.
      \end{align*}
  \end{enumerate}
\end{problem}
\begin{enumerate}[(a)]
  \item We see that
    \begin{align*}
      \int_{X}^{} \left\vert f(x) \right\vert^{p}\:d\mu(x) &= \int_{X}^{} \int_{0}^{\infty} \1_{\left( \left\vert f \right\vert^{p} \right)^{-1}\left( \left( t,\infty \right) \right)}(x)\:dt\:d\mu(x)\\
                                                           &= \int_{0}^{\infty} \int_{X}^{} \1_{\left( \left\vert f \right\vert^{p} \right)^{-1}\left( \left( t,\infty \right) \right)}(x)\:d\mu(x)\:dt\\
                                                           &= \int_{0}^{\infty} \mu\left( \set{x | \left\vert f(x) \right\vert^{p} > t} \right)\:dt\\
                                                           &= \int_{0}^{\infty} \mu\left( \set{x | \left\vert f(x) \right\vert > t^{1/p}} \right)\:dt
    \end{align*}
    which follows by the layer-cake decomposition for a measurable function. By a change of variables, taking $\alpha = t^{1/p}$, we obtain
    \begin{align*}
      \int_{X}^{} \left\vert f(x) \right\vert^{p}\:d\mu(x) &= p \int_{0}^{\infty} \alpha^{p-1}\mu\left( \set{x | \left\vert f(x) \right\vert > \alpha} \right)\:d\alpha.
    \end{align*}
  \item Set $E_{\alpha} = \set{x | \left\vert f(x) \right\vert > \alpha}$. Then,
    \begin{align*}
      \int_{X}^{} \left\vert f \right\vert^{p}\:d\mu &\geq \int_{E_{\alpha}}^{} \left\vert f \right\vert^{p}\:d\mu\\
                                                     &\geq \alpha^{p} \int_{X}^{} \1_{E_{\alpha}}\:d\mu\\
                                                     &= \alpha^{p} \mu\left( E_{\alpha} \right)\\
                                                     &= \alpha^{p} \mu\left( \set{x | \left\vert f(x) \right\vert > \alpha} \right).
    \end{align*}
    By rearranging, we get that
    \begin{align*}
      \mu\left( \set{x | \left\vert f(x) \right\vert > \alpha} \right) &\leq \frac{\norm{f}_{L_p}^{p}}{\alpha^{p}}.
    \end{align*}
\end{enumerate}
\subsection{Problem 5}%
\begin{problem}
  Let $\phi\in \mathcal{S}\left( \R^n \right)$ be a fixed Schwartz function. The Fourier multiplier $M$ acts on functions $f\in L_2\left( \R^n \right)$ by
  \begin{align*}
    \widehat{Mf}\left( \xi \right) &= \phi\left( \xi \right)\hat{f}\left( \xi \right).
  \end{align*}
  That is, $M$ is equal to the operation of taking the Fourier transform of $f$, multiplying by $\phi\left( \xi \right)$, then taking the inverse Fourier transform. Show that $M$ is a bounded linear map from $L_2\left( \R^n \right)$ to $L_2\left( \R^n \right)$.
\end{problem}
Rewriting $M$, we see that
\begin{align*}
  Mf(x) &= \mathcal{F}^{-1}\left( M_{\phi}\mathcal{F}\left( f(x) \right) \right),
\end{align*}
where $M_{\phi}$ is the multiplication operator that multiplies by $\phi$. We see thus that
\begin{align*}
  \norm{M}_{\op} &= \norm{\mathcal{F}^{-1}M_{\phi}\mathcal{F}}_{\op}.
\end{align*}
The norm of a multiplication operator is bounded above by the essential supremum of its symbol, as
\begin{align*}
  \norm{M_{\phi}\left( f \right)}_{L_2} &= \left( \int_{\R^n}^{} \left\vert \phi f \right\vert^2\:dm \right)^{1/2}\\
                                        &\leq \left( \norm{\phi}_{L_{\infty}}^2 \int_{\R^n}^{} \left\vert f \right\vert^2\:dm \right)^{1/2}\\
                                        &= \norm{\phi}_{L_{\infty}}\norm{f}_{L_2}.
\end{align*}
Since $\phi$ is a Schwartz function, all of its derivatives are bounded, and thus so is its zeroth derivative, so $\phi\in L_{\infty}$. Furthermore, by the Plancherel Theorem, the Fourier transform on $L_2$ is unitary, so by applying the properties of the operator norm, we see that
\begin{align*}
  \norm{M}_{\op} &\leq \norm{\mathcal{F}^{-1}}_{\op}\norm{M_{\phi}}_{\op}\norm{\mathcal{F}}_{\op}\\
                 &\leq \norm{\phi}_{L_{\infty}}\\
                 &< \infty,
\end{align*}
so $M$ is a bounded linear operator.
\section{January 2025}%
\subsection{Problem 1}%
\begin{problem}
  Let $\left( X,\mathcal{M},\mu \right)$ be a measure space, $\left( f_n \right)_n$ and $\left( g_n \right)_n$ sequences of functions in $L_1\left( X,\mathcal{M},\mu \right)$ in $L_1\left( X,\mathcal{M},\mu \right)$ that converge pointwise almost everywhere to $f,g\in L_1\left( X,\mathcal{M},\mu \right)$. Suppose $\left\vert f_n \right\vert \leq g_n$ almost everywhere, and
  \begin{align*}
    \lim_{n\rightarrow\infty} \int_{X}^{} g_n\:d\mu &= \int_{X}^{} g\:d\mu.
  \end{align*}
  Show that
  \begin{align*}
    \lim_{n\rightarrow\infty} \int_{X}^{} f_n\:d\mu &= \int_{X}^{} f\:d\mu.
  \end{align*}
\end{problem}
We see that
\begin{align*}
  \int_{X}^{} g + f\:d\mu &= \int_{X}^{} \liminf_{n\rightarrow\infty}\left( g_n + f_n \right)\:d\mu\\
                          &\leq \liminf_{n\rightarrow\infty}\left( \int_{X}^{} g_n\:d\mu + \int_{X}^{} f_n\:d\mu \right)\\
                          &= \int_{X}^{} g\:d\mu + \liminf_{n\rightarrow\infty} \int_{X}^{} f_n\:d\mu,
\end{align*}
so
\begin{align*}
  \int_{X}^{} f\:d\mu &\leq \liminf_{n\rightarrow\infty} \int_{X}^{} f_n\:d\mu.
\end{align*}
Similarly, we also see that
\begin{align*}
  \int_{X}^{} g-f\:d\mu &= \int_{X}^{} \liminf_{n\rightarrow\infty}\left( g_n-f_n \right)\:d\mu\\
                        &\leq \liminf_{n\rightarrow\infty} \left( \int_{X}^{} g_n\:d\mu - \int_{X}^{} f_n\:d\mu \right)\\
                        &= \int_{X}^{} g\:d\mu - \limsup_{n\rightarrow\infty} \int_{X}^{} f_n\:d\mu,
\end{align*}
meaning that
\begin{align*}
  \limsup_{n\rightarrow\infty} \int_{X}^{} f_n\:d\mu &\leq \int_{X}^{} f\:d\mu,
\end{align*}
meaning that
\begin{align*}
  \int_{X}^{} f\:d\mu &= \lim_{n\rightarrow\infty} \int_{X}^{} f_n\:d\mu.
\end{align*}
\subsection{Problem 2}%
\begin{problem}\hfill
  \begin{enumerate}[(a)]
    \item Let $\left( X,\mathcal{M},\mu \right)$ be a finite measure space. Show that if $p,p'\in [1,\infty]$ with $p < p'$, then $L_p\left( X,\mathcal{M},\mu \right) \supseteq L_{p'}\left( X,\mathcal{M},\mu \right)$.
    \item Show that if $p,p'\in [1,\infty]$ are such that $p < p'$, then $L_p\left( \R \right)\setminus L_{p'}\left( \R \right)$ and $L_{p'}\left( \R \right)\setminus L_p\left( \R \right)$ are both nonempty.
  \end{enumerate}
\end{problem}
\begin{enumerate}[(a)]
  \item Let $f\in L_{p'}\left( X,\mathcal{M},\mu \right)$. Then, we use Hölder's inequality on with $\frac{p'}{p}$ and $1-\frac{p'}{p}$ as our Hölder conjugates to obtain
    \begin{align*}
      \int_{X}^{} \left\vert f \right\vert^{p}\:d\mu &= \int_{X}^{} \left\vert f \right\vert^{p}\left( 1 \right)\:d\mu\\
                                                     &\leq \left( \int_{X}^{} \left\vert f \right\vert^{p\left( p'/p \right)}\:d\mu \right)^{p/p'} \left( \int_{X}^{} \:d\mu \right)^{1-p/p'}\\
                                                     &= \left( \int_{X}^{} \left\vert f \right\vert^{p'}\:d\mu \right)^{p/p'}\mu\left( X \right)^{1-p/p'}\\
                                                     &< \infty,
    \end{align*}
    so $f\in L_{p}$.
  \item To see that $L_{p'}\setminus L_{p}$ is nonempty, we consider a function given by
    \begin{align*}
      f &= \sum_{n=1}^{\infty} \frac{1}{n^{1/p}} \1_{[n,n+1)},
    \end{align*}
    where we see that
    \begin{align*}
      \int_{\R}^{} \left\vert f \right\vert^{p}\:d\mu &= \sum_{n=1}^{\infty}\frac{1}{n}\\
                                                      &= \infty\\
      \int_{X}^{} \left\vert f \right\vert^{p'}\:d\mu &= \sum_{n=1}^{\infty} \frac{1}{n^{p'/p}}\\
                                                      &< \infty.
    \end{align*}
    Now, to see that $L_{p}\setminus L_{p'}$ is nonempty, we consider the function
    \begin{align*}
      f &= x^{-1/p'} \1_{(0,1]}.
    \end{align*}
    Then,
    \begin{align*}
      \int_{\R}^{} \left\vert f \right\vert^{p}\:d\mu &= \int_{0}^{1} x^{-(p/p')}\:d\mu\\
                                                      &< \infty,
    \end{align*}
    and
    \begin{align*}
    \int_{\R}^{} \left\vert f \right\vert^{p'}\:d\mu &= \int_{0}^{1} x^{-1}\:d\mu\\
                                                     &= \infty.
    \end{align*}
    Thus, $f\in L_p\setminus L_{p'}$
\end{enumerate}
\subsection{Problem 3}%
\begin{problem}
  Let $\mathcal{H}$ be a separable Hilbert space. A sequence $\left( v_m \right)_m$ is said to converge weakly to $v\in \mathcal{H}$ if
  \begin{align*}
    \lim_{m\rightarrow\infty} \iprod{v_m}{w} &= \iprod{v}{w}
  \end{align*}
  for every $w\in \mathcal{H}$. Show that for any sequence $\left( v_m \right)_m\subseteq \mathcal{H}$ for which $\sup_{m\in\N} \norm{v_m}$ is finite, there exists a subsequence $\left( v_{m_{k}} \right)_k\rightarrow v\in \mathcal{H}$ weakly.
\end{problem}
We see that, since $\mathcal{H}$ is a Hilbert space, $\mathcal{H}\cong \mathcal{H}^{\ast\ast}$, where $\mathcal{H}^{\ast\ast}$ is the double dual of $\mathcal{H}$ (Hilbert spaces are reflexive). This means that, if $\left( v_m \right)_m\subseteq \mathcal{H}$, there is an isometric isomorphism to the sequence $\left( \hat{v}_m \right)_m\subseteq \mathcal{H}^{\ast\ast}$, where $\hat{v}_m$ is the linear functional such that $\hat{v}_m(\varphi) = \varphi\left( v_m \right)$ for all $\varphi\in \mathcal{H}$.\newline

Letting $M = \sup_{m\in \N} \norm{v_m}$, we see that $\frac{1}{M} \left( \hat{v}_m \right)_m\subseteq B_{\mathcal{H}^{\ast\ast}}$. By the Banach--Alaoglu theorem, there is a subsequence $\frac{1}{M}\left( \hat{v}_{m_k} \right)_k\rightarrow \frac{1}{M}\hat{v}$, where the convergence is in the $w^{\ast\ast}$ topology --- i.e., for all $\varphi\in \mathcal{H}^{\ast}$, $\hat{v}_{m_{k}}\left( \varphi \right)\rightarrow \hat{v}\left( \varphi \right)$; rewriting, we then get that $\varphi\left( v_{m_{k}} \right) \rightarrow \varphi\left( v \right)$ for all $\varphi\in \mathcal{H}^{\ast}$.\newline

By the Riesz Representation Theorem, any $\varphi\in \mathcal{H}^{\ast}$ corresponds to an inner product with a unique $w\in \mathcal{H}$, so we have
\begin{align*}
  \iprod{v_{m_{k}}}{w} &\rightarrow \iprod{v}{w}
\end{align*}
for all $w\in \mathcal{H}$, so $\left( v_{m_{k}} \right)_k\rightarrow v$ weakly.
\subsection{Problem 4}%
\begin{problem}
  Let $\delta_0$ be the Dirac measure at $0$, defined by
  \begin{align*}
    \delta_0(A) &= \begin{cases}
      1 & 0\in A\\
      0 & \text{else}
    \end{cases}.
  \end{align*}
  For each $r > 0$, define $\nu_r$ to be the measure defined by
  \begin{align*}
    \nu_r(A) &= \frac{1}{2r} m\left( A\cap \left[ -r,r \right] \right).
  \end{align*}
  Show that for every continuous function $f\colon \R\rightarrow \C$, we have
  \begin{align*}
    \lim_{r\searrow 0} \int_{\R}^{} f(x)\:d\nu_r\left( x \right) &= \int_{\R}^{} f(x)\:d\delta_0(x).
  \end{align*}
\end{problem}
  We consider the family $\set{E_{r}}_{r > 0}$ defined by $E_r = [-r,r]$. We notice that $\frac{1}{2r}m\left( A\cap E_r \right) = \nu\left( E_r \right)$. Furthermore, we also see that $E_r \subseteq (-4/3 r,4/3 r)$, and $E_r\supseteq \frac{3}{8} (-4/3 r,4/3 r)$, so that by a scaling argument, $\set{E_r}_{r > 0}$ is a family that shrinks nicely to $x = 0$.\newline

  Furthermore, we see that
  \begin{align*}
    \int_{\R}^{} f(x)\:d\delta_0(x) &= \int_{\set{0}}^{} f(x)\:d\delta_0(x)\\
                                    &= f(0).
  \end{align*}
  Finally, since $f$ is continuous, for any compact $K\subseteq \R$, $f$ is bounded, so that
  \begin{align*}
    \int_{K}^{} \left\vert f(x) \right\vert\:dx &\leq \int_{K}^{} \sup_{x\in K}\left\vert f(x) \right\vert\:dx\\
                                                &\leq m(K) \sup_{x\in K} \left\vert f(x) \right\vert\\
                                                &< \infty,
  \end{align*}
  as $m$ is regular. Thus, $f$ is locally integrable, meaning that by the Lebesgue Differentiation Theorem,
  \begin{align*}
    \lim_{r\rightarrow 0} \int_{\R}^{} f(x)\:d\nu_r(x) &= \lim_{r\rightarrow 0} \frac{1}{2r} \int_{E_r}^{} f(x)\:dx\\
                                                       &= f(0),
  \end{align*}
  so
  \begin{align*}
    \int_{\R}^{} f(x)\:d\nu_r(x) &= \int_{\R}^{} f(x)\:d\delta_0(x).
  \end{align*}
\subsection{Problem 5}%
\begin{problem}\hfill
  \begin{enumerate}[(a)]
    \item State the Riemann--Lebesgue lemma for the Fourier transform on $\R^n$.
    \item Show that there does not exist a function $g\in L_1\left( \R^n \right)$ such that $f\ast g = f$ for all $f\in L_1\left( \R^n \right)$.
  \end{enumerate}
\end{problem}
\begin{enumerate}[(a)]
  \item The Riemann--Lebesgue Lemma for the Fourier transform on $\R^n$ states that if $f\in L_1\left( \R^n \right)$, then $\hat{f}\in C_0\left( \R^n \right)$.
  \item Suppose toward contradiction that there were such a $g$. Then, it would also be the case that $g\ast g = g$, and since the Fourier transform on $L_1\left( \R^n \right)$ is injective, by the convolution property of the Fourier transform, we have $\hat{g}(k)\hat{g}(k) = \hat{g}(k)$ for all $k\in \R^n$, implying that $\hat{g}(k) = 0$ or $\hat{g}(k) = 1$ for all $k$, depending on if $\hat{g}(k)$ is zero or not.\newline

    However, by the Riemann--Lebesgue Lemma, $\hat{g}$ is continuous and vanishes at infinity, so since $\hat{g}$ takes on either $0$ or $1$ everywhere, we must have $\hat{g}(k) = 0$ for all $k$, implying that $g = 0$; yet, this is absurd, as $f\ast 0 = 0$, yet there are nonzero functions in $L_1\left( \R^n \right)$.
\end{enumerate}
\end{document}
