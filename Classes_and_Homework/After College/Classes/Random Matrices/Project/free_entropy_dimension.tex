\documentclass[10pt]{mypackage}

%\usepackage{mlmodern}
%\usepackage{newpxtext,eulerpx,eucal}
%\renewcommand*{\mathbb}[1]{\varmathbb{#1}}

%\usepackage{homework}
%\usepackage{notes}

\usepackage[ backend=bibtex, style = alphabetic, sorting=ynt ]{biblatex}
\addbibresource{project_references.bib}

\usepackage{parskip}

\fancyhf{}
\fancyhead[R]{Avinash Iyer}
\fancyhead[L]{Free Entropy Dimension}
\fancyfoot[C]{\thepage}

\setcounter{secnumdepth}{0}

\begin{document}
\RaggedRight
\section{Background: Asymptotic Freeness and Large Deviations}%
We start by recalling the basic asymptotic freeness result discussed in class.
\begin{proposition}
  Let $\left( A_1^{N},\dots,A_r^{N} \right)$ be an independent $r$-tuple of GUE $N\times N$ matrices. Then, the family $A_1^N,\dots,A_r^N$ converge in distribution to $r$ independent semicircular elements, $s_1,\dots,s_r\in B\left( \mathcal{F}\left( \C^r \right) \right)$, in the sense that for all $m\geq 1$ and all $1\leq i_1,\dots,i_m \leq r$, we have
  \begin{align*}
    \lim_{N\rightarrow\infty} E\left[ \tr\left( A_{i_1}^N\cdots A_{i_m}^N \right) \right] &= \varphi\left( s_{i_1}\cdots s_{i_m} \right),
  \end{align*}
  where $\varphi$ is the vacuum state, $\varphi\left( T \right) = \iprod{T\Omega}{\Omega}$.
\end{proposition}
In fact, this collection is \textit{almost surely} asymptotically free, in the following sense. Suppose we have two random matrices $A^N$ and $B^N$ defined on probability spaces $\left( X_N,\mu_N \right)$. Define
\begin{align*}
  X &\coloneq \prod_{N\in \N} X_N\\\
  \mu &\coloneq \prod_{N\in \N}\mu_N,
\end{align*}
where the latter is the product measure on $X$. The matrices $A^N$ and $B^N$ are said to be almost surely asymptotically free if there exists a noncommutative probability space $\left( A,\varphi \right)$ and $a,b\in A$, and for almost all $x = \left( x_N \right)_N\in X$, we have $A^N\left(x_N\right),B^N\left(x_N\right)\in \left( \M_N,\tr \right)$ converge in distribution to $a,b$.

Now, from here, we may ask a seemingly simple question: as $N$ grows large, how likely are we to encounter other distributions? To make this sense more precise, we consider a random $N\times N$ self-adjoint matrix $A$, and let
\begin{align*}
  \mu_A &= \frac{1}{N}\sum_{i=1}^{N}\delta_{\lambda_1}
\end{align*}
be its empirical spectral distribution. This is a random probability measure on $\R$, and as $N\rightarrow \infty$, the semicircle law gives that $\mu_A$ converges weakly to the semicircle distribution; this can be strengthened to almost sure convergence by an application of the argument for asymptotic freeness. The question then becomes, how quickly does the deviation between $\mu_A$ and any other probability distribution $\nu$ decrease as $N$ increases? This is where the theory of large deviations starts to take shape.

Much of this exposition related to the classical notions of entropy will be centered around results in \cite[Ch.\,7]{mingo_and_speicher}.
\section{One-Dimensional Free Entropy}%

\section{Microstates Free Entropy}%

\section{Applications: Structural Properties of Free Group Factors}%

\printbibliography
\end{document}
