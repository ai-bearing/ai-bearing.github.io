\documentclass[10pt]{mypackage}

% sans serif font:
%\usepackage{cmbright}
%\usepackage{sfmath}
%\usepackage{bbold} %better blackboard bold

\usepackage{homework}
%\usepackage{notes}
\usepackage{newpxtext,eulerpx,eucal}
\renewcommand*{\mathbb}[1]{\varmathbb{#1}}

\fancyhf{}
\rhead{Avinash Iyer}
\lhead{Assignment 1}

\setcounter{secnumdepth}{0}

\begin{document}
\RaggedRight
\begin{problem}[Problem 1]
  Let $R$ be a ring in which every element $a$ satisfies $a^2 = a$. Show that
  \begin{enumerate}[(a)]
    \item $2a = 0$ for every $a\in R$, so $a = -a$;
    \item $R$ is commutative.
  \end{enumerate}
\end{problem}
\begin{solution}\hfill
  \begin{enumerate}[(a)]
    \item Let $a\in R$. We see that, since $a+a\in R$, $\left( a+a \right)^{2} = a+a$, so that
      \begin{align*}
        a+a &= \left( a+a \right)^2\\
            &= \left( a+a \right)\left( a+a \right)\\
            &= a^2 + a^2 + a^2 + a^2\\
            &= a + a + a + a,
      \end{align*}
      and since $R$ is a ring, we see that $a+a = 0$, or that $a = -a$.
    \item Similarly, if $a,b\in R$, then since $\left( a+b \right)^2 = a+b$, we have
      \begin{align*}
        a+b &= \left( a+b \right)^2\\
            &= \left( a+b \right)\left( a+b \right)\\
            &= a^2 + b^2 + ab + ba\\
            &= a + b + ab + ba,
      \end{align*}
      so $ab = -ba$, but since $-ba = ba$ by the previous part, we have $ab = ba$, and so $R$ is commutative.
  \end{enumerate}
\end{solution}
\begin{problem}[Problem 2]
  Let $R$ be a ring with identity, and let $R^{\times}$ be the set of invertible elements of $R$. Show that $R^{\times}$ is a group under multiplication. What is $\Z\left[ i \right]^{\times}$.
\end{problem}
\begin{solution}
  First, $R^{\times}$ is nonempty, as $R$ contains a multiplicative identity. Next, if $a,b\in R^{\times}$, we see that $ab$ admits the inverse $b^{-1}a^{-1}$, as
  \begin{align*}
    \left( ab \right)\left( b^{-1}a^{-1} \right) &= a\left( bb^{-1} \right)a^{-1}\\
                                                 &= aa^{-1}\\
                                                 &= 1,
  \end{align*}
  and similarly,
  \begin{align*}
    \left( b^{-1}a^{-1} \right)\left( ab \right) &= b^{-1}\left( a^{-1}a \right)b\\
                                                 &= b^{-1}b\\
                                                 &= 1,
  \end{align*}
  so $R^{\times}$ is closed under multiplication. Similarly, since $\left( b^{-1} \right)^{-1} = b$ for any $b\in R^{\times}$, every element of $R^{\times}$ has a multiplicative inverse, so $R^{\times}$ is a group.\newline

  To understand the picture of $\Z\left[ i \right]^{\times}$, we try to understand when, given $a+bi\in \Z\left[ i \right]\subseteq \C$, $\frac{1}{a+bi}\in \Z\left[ i \right]$. Doing the hand calculations, we see that
  \begin{align*}
    \frac{1}{a+bi} &= \frac{1}{a^2+b^2} \left( a-bi \right).
  \end{align*}
  Therefore, we see that this holds if and only if $a=\pm 1$ and $b = 0$, or $b = \pm 1$ and $a = 0$, meaning that $\Z\left[ i \right]^{\times} = \set{1,i,-1,-i}$.
\end{solution}
\begin{problem}[Problem 3]
  Fix an integer $n > 1$. Recall that for $a,b\in \Z$, we write $a \equiv b$ modulo $n$ if $a-b$ is divisible by $n$. Show that this relation is an equivalence relation on $\Z$. Furthermore, show that if $a\equiv b$ modulo $n$, and $c\equiv d$ modulo $n$, then
  \begin{align*}
    a+c \equiv b+d\text{ modulo $n$, and } ac\equiv bd\text{ modulo $n$.}
  \end{align*}
\end{problem}
\begin{solution}
  Since $0$ is divisible by $n$, it is clear that $a\equiv a$ modulo $n$, so the relation is reflexive.\newline

  If $a\equiv b$ modulo $n$, then since $n | \left( a-b \right)$, we must also have $n | \left( b-a \right)$, so $b\equiv a$ modulo $n$, so the relation is symmetric.\newline

  Finally, if $a\equiv b$ modulo $n$ and $b\equiv c$ modulo $n$, then since $n | a-b$ and $n | b-c$, by adding, we see that $n | \left( a-b \right) + \left( b- c\right)$, so $n | a-c$ and $a\equiv c$ modulo $n$, so the relation is transitive.\newline

  Now, if $a\equiv b$ modulo $n$, and $c\equiv d$ modulo $n$, then since $n | \left( a-b \right)$ and $n | \left( c-d \right)$, by adding, we see that $n | \left( a+c \right)-\left( b+d \right)$, so $a+c\equiv b+d$ modulo $n$. To see the last equivalence, we rewrite $a = b + kn$, $c = d + \ell n$, where $k,\ell\in \Z$. Thus, multiplying things out, we see that
  \begin{align*}
    ac &= \left( b+kn \right)\left( d + \ell n \right)\\
       &= bd + nkd + \ell n b + k\ell n^2\\
       &= bd + \left( kd + \ell b + k\ell n \right) n,
  \end{align*}
  and since $kd + \ell b + k\ell n\in \Z$, we have $ac \equiv bd$ modulo $n$.
\end{solution}
\begin{problem}[Problem 4]
  Show that a finite commutative ring with $1$ and without zero divisors is a field.
\end{problem}
\begin{solution}
  Let $a\in R$, and consider the map $\varphi_{a}\colon R\setminus \set{0} \rightarrow R\setminus \set{0}$ given by $b\mapsto ab$. We see that if $ab = ac$, then $a\left( b-c \right) = 0$, and since $a\neq 0$, we see that $b = c$, so $\varphi_{a}$ is injective. Since $\varphi_a$ is an injective self-map of a finite set, $\varphi_a$ is surjective, so $\varphi_{a}$ is bijective, and thus $\varphi_a^{-1}\left( 1 \right)$ is well-defined, so $a\varphi_{a}^{-1}\left( 1 \right) = 1$, meaning $a$ has a right-inverse. Since $R$ is commutative, we have $\varphi_{a}^{-1}\left( 1 \right)a = 1$, so $R$ is a field.
\end{solution}
\begin{problem}[Problem 5]
  Let $ R = \Mat_{n}\left( \R \right) $ be the ring of real $n\times n$ matrices. Show that if $A$ satisfies $\det\left( A \right) = 0$, then there exist nonzero $B,C\in R$ such that $AB = \mathbf{0}_{n}$ and $CA = \mathbf{0}_{n}$.
\end{problem}
\begin{solution}
  If $A$ is the zero matrix, then the problem is trivial, so we assume $A$ is not the zero matrix. By the Cayley--Hamilton theorem, since $0$ is an eigenvalue of $A$, we must have that $c_A(t)$ includes a factor of $t$, which is irreducible, so that the minimal polynomial $m_A(t)$ has a factor of $t$. Thus, we may write $m_A(t) = tp(t)$, where $p(t)$ is some other monic polynomial. Since $\deg p(t) < \deg m_A(t)$, this means that $p(A)\neq \mathbf{0}_n$ (else, it would contradict the minimality of $p$). By setting $B = p(A)$, we find our desired nonzero matrix $B$ such that $AB = BA = \mathbf{0}_n$.
\end{solution}
\begin{problem}[Problem 6]
  An element $x\in R$ is called \textit{nilpotent} if there exists $n > 0$ such that $x^{n} = 0$.\newline

  Assume $R$ is a commutative ring with identity. Show that if $x\in R$ is nilpotent, then
  \begin{enumerate}[(a)]
    \item $rx$ is nilpotent for any $r\in R$;
    \item $1+x$ is invertible.
  \end{enumerate}
\end{problem}
\begin{solution}\hfill
  \begin{enumerate}[(a)]
    \item We see that, since $R$ is commutative,
      \begin{align*}
        \left( rx \right)^{n} &= \left( rx \right)\left( rx \right)\cdots \left( rx \right)\\
                              &= r^{n}x^{n}\\
                              &= 0,
      \end{align*}
      so $rx$ is nilpotent.
    \item We see that if $a$ is nilpotent, then
      \begin{align*}
        1 &= 1-a^{n}\\
          &= \left( 1-a \right)\left( 1 + a + \cdots + a^{n-1} \right),
      \end{align*}
      meaning that $1-a$ is invertible. Furthermore, we note that if $a$ is nilpotent, then so is $-a$, as $-a = \left( -1 \right)a$, allowing us to apply part (a). Thus, $1+x = 1-\left( -x \right)$ is invertible if $x$ is nilpotent.
  \end{enumerate}
\end{solution}
\begin{problem}[Problem 7]
  Let $R = \Mat_{n}\left( \F \right)$, where $\F$ is a field. Show that if $I$ is a nonzero $2$-sided ideal of $R$, then $I = R$.
\end{problem}
\begin{solution}
  We show that if $I$ is a nonzero two-sided ideal in $\Mat_{n}\left( \F \right)$, then $I_{n}\in I$.\newline

  Since $I$ is nonzero, there is some matrix $\left( a_{ij} \right)_{i,j}\in I$ such that at particular indices $i_0$ and $j_0$, $a_{i_0j_0}\neq 0$. Since $a_{ij}\in \F$ for all $i,j$, we have that $a_{i_0j_0}^{-1}$ exists.\newline

  Let $e_{k\ell}$ be the matrix unit with a position $1$ at index $\left( k,\ell \right)$ and zero elsewhere. Then, via some matrix algebra, we see that
  \begin{align*}
    a_{i_0j_0} \left( e_{kk} \right)_{i,j} &= \left( e_{ki_0} \right)_{i,j}\left( a_{ij} \right)_{i,j} \left( e_{j_0 k} \right)_{i,j}
  \end{align*}
  which is necessarily in $I$, as $I$ is a two-sided ideal. Therefore, since $\F$ is a field, we see that $\left( e_{kk} \right)_{i,j}\in I$ for each $k$, so $\sum_{k=1}^{n}\left( e_{kk} \right)_{i,j}\in I$, so $I_{n}\in I$, meaning $I = R$.
\end{solution}
\begin{problem}[Problem 8]
  Let $n\in\N$ and consider $\Z^{n}$ as a ring with component-wise addition and multiplication.
  \begin{enumerate}[(a)]
    \item Prove that $\aut_{\text{group}}\left( \Z^{n} \right) \cong \GL_{n}\left( \Z \right)$.
    \item Prove that $\aut_{\text{ring}} \left( \Z^{n} \right) \cong \Sym\left( n \right)$.
  \end{enumerate}
\end{problem}
\begin{solution}
  Before we start, we first notice that every element of $\Z^{n}$ can be written as
    \begin{align*}
      v &= a_1e_1 + a_2e_2 + \cdots + a_ne_n,
    \end{align*}
    where $e_j$ are the standard basis of $\Z^n$ and $a_j\in \Z$ for each $j$. Therefore, if $\varphi$ is any automorphism as either a group or a ring, we may write $\varphi(v)$ as some integer linear combination of $\varphi\left( e_j \right)$, where the $e_j$ are the standard basis vectors for $\Z^{n}$.
  \begin{enumerate}[(a)]
    \item Let $\varphi\in \aut_{\text{group}}\left( \Z^{n} \right)$. If $v\in \Z^{n}$ is some vector, then
      \begin{align*}
        \varphi\left( v \right) &= \varphi\left( a_1e_1 + a_2e_2 + \cdots + a_ne_n \right)\\
                                &= a_1\varphi\left( e_1 \right) + a_2\varphi\left( e_2 \right) + \cdots + a_n\varphi\left( e_n \right).
      \end{align*}
      Since a linear transformation may be specified uniquely via a basis, we may specify a matrix element $A_{\varphi}\in \Mat_{n}\left( \Z \right)$ by
      \begin{align*}
        A_{\varphi}e_j &= \varphi\left( e_j \right)
      \end{align*}
      for each $j$. Note that since each $\varphi$ is invertible, each $A_{\varphi}$ may have $A_{\varphi}^{-1}$ defined by $A_{\varphi}^{-1}e_j = \varphi^{-1}\left( e_j \right) $, so each $A_{\varphi}\in \GL_n\left( \Z \right)$. Similarly, we see that if $\psi,\varphi\in \aut_{\text{group}}\left( \Z^{n} \right)$, then
      \begin{align*}
        \psi\circ\varphi\left( e_j \right) &= A_{\psi}\left( \varphi\left( e_j \right) \right)\\
                                           &= A_{\psi}\left( A_{\varphi}e_j \right)\\
                                           &= A_{\psi}A_{\varphi}e_j.
      \end{align*}
      Therefore, the map $\varphi\mapsto A_{\varphi}$ is an isomorphism, so $\aut_{\text{group}}\left( \Z^{n} \right) \cong \GL_n\left( \Z \right)$.
    \item Let $\varphi\in \aut_{\text{ring}}$; notice that $\aut_{\text{ring}}\subseteq \aut_{\text{group}}$ meaning that we know already that $\varphi$ can be written as some element of $\GL_n\left( \Z \right)$. Suppose that, for some $e_k$, we may write
      \begin{align*}
        \varphi\left( e_k \right) &= \sum_{k=1}^{n}a_ke_k.
      \end{align*}
      Notice then that, since $e_ie_j = \delta_{ij}$, where $\delta_{ij}$ is the Kronecker delta symbol, we get
      \begin{align*}
        \varphi\left( e_k^2 \right) &= \varphi\left( e_k \right)\varphi\left( e_k \right)\\
                                    &= \sum_{k=1}^{n} a_k^2e_k\\
                                    &= \sum_{k=1}^{n}a_ke_k,
      \end{align*}
      meaning in particular that $a_k = 0$ or $a_k = 1$, seeing as the $a_k$ are elements of $\Z$.\newline

      Now, given a standard basis vector $e_i$, we notice that
      \begin{align*}
        \varphi\left( e_i \right) &= \sum_{m=1}^{k}e_{i_m}.
      \end{align*}
      Yet, since $\varphi$ is a ring automorphism, so too is $\varphi^{-1}$, so that
      \begin{align*}
        e_i &= \sum_{m=1}^{k} \varphi^{-1}\left( e_{i_m} \right).
      \end{align*}
      Now, this means that the sum $\sum_{m=1}^{k}\varphi^{-1}\left( e_{i_m} \right)$ yields a $1$ in position $i$ and zero everywhere else; yet, since $\varphi^{-1}\left( e_{i_m} \right)$ yields another sum of basis vectors, we see that this can only hold if $\varphi^{-1}\left( e_{i_\ell} \right) = e_i$ for exactly one specific $\ell$ (else, we get that $e_i$ either has nonzero entries other than at $i$, or that the entry at $i$ is greater than or equal to $2$).\newline

      Thus, $\varphi\left( e_i \right) = e_k$ for some $e_k$; since $\varphi$ is injective on $\Z^{n}$, $\varphi$ is necessarily injective on $\set{e_1,\dots,e_n}$ as we just established. Therefore, $\varphi$ is some permutation of $\set{e_1,\dots,e_n}$, so $\aut_{\text{ring}}\cong \sym(n)$.
  \end{enumerate}
\end{solution}
\end{document}
