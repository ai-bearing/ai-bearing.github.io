\documentclass[10pt]{mypackage}

% sans serif font:
%\usepackage{cmbright}
%\usepackage{sfmath}
%\usepackage{bbold} %better blackboard bold

%serif font + different blackboard bold for serif font
\usepackage{homework}
\usepackage{newpxtext,eulerpx}
\renewcommand*{\mathbb}[1]{\varmathbb{#1}}

\fancyhf{}
\rhead{Avinash Iyer}
\lhead{Review 1}

\setcounter{secnumdepth}{0}

\begin{document}
\RaggedRight
\begin{problem}[Problem 1]
  Let $T\colon V\rightarrow W$ be a linear transformation between $\F$-vector spaces. Show that $T$ is injective if and only if $T$ maps $\F$-linearly independent subsets of $V$ to $\F$-linearly independent subsets of $W$.
\end{problem}
\begin{solution}
  Let $T$ be injective. We claim that if $\set{v_1,\dots,v_n}$ is linearly independent in $V$, then $\set{Tv_1,\dots,Tv_n}$ is linearly independent in $W$. We see that if
  \begin{align*}
    \sum_{j=1}^{n}a_jTv_j &= 0_{W},
  \end{align*}
  then
  \begin{align*}
    T\left( \sum_{j=1}^{n}a_jv_j \right) &= 0_W,
  \end{align*}
  meaning that
  \begin{align*}
    \sum_{j=1}^{n}a_jv_j &\in \ker\left( T \right).
  \end{align*}
  Now, since $T$ is injective, $\ker\left( T \right) = \set{0_V}$, meaning that $\sum_{j=1}^{n}a_jv_j = 0_V$. Yet, since $\set{v_1,\dots,v_n}$ is linearly independent, this means $a_j = 0$ for each $j$, so $\set{Tv_1,\dots,Tv_n}$ is linearly independent in $W$.\newline

  Now, let $T$ map linearly independent subsets of $V$ to linearly independent subsets of $W$. If $\mathcal{B}_V = \set{v_i}_{i\in I}$ is a basis for $V$, then since $\mathcal{B}_V$ is linearly independent, $\mathcal{C} = \set{Tv_i}_{i\in I}$ is a linearly independent subset of $W$, which can be extended to a basis $\mathcal{B}_W$. Since $\mathcal{C}\subseteq \mathcal{B}_W$, we see that any linear combination in $\mathcal{B}_W$ yields $0$ if and only if every coefficient is zero, meaning that $\ker\left( T \right) = \set{0_V}$, so $T$ is injective.
\end{solution}
\begin{problem}[Problem 2]
  Let $P_{n+1}\left( \R \right)$ be the space of polynomials with real coefficients of degree $\leq n+1$. Prove that for any $n$ points $a_1,\dots,a_n\in \R$, there exists a nonzero polynomial $f\in P_{n+1}\left( \R \right)$ such that $f\left( a_j \right) = 0$ for each $j$, and $\sum_{j=1}^{n}f'\left(a_j\right) = 0$.
\end{problem}
\begin{solution}
  Based on the first condition, we see that the product $\prod_{j=1}^{n}\left( x-a_j \right)$ must divide the polynomial $f$, and since $f$ has degree at most $n+1$, we must have $f(x) = \left( x-L \right)\prod_{j=1}^{n} \left( x-a_j \right)$ for some $a,b\in \R$. Writing $f'(x)$, we see that
  \begin{align*}
    f'(x) &= \prod_{j=1}^{n}\left( x-a_j \right) + \left( x-L \right)\sum_{i=1}^{n} \prod_{j\neq i}\left( x-a_j \right),
  \end{align*}
  implying that
  \begin{align*}
    \sum_{i=1}^{n}f'\left( a_i \right) &= \sum_{i=1}^{n} \left( a_i - L \right) \prod_{j\neq i} \left( a_i - a_j \right). 
  \end{align*}
  By setting
  \begin{align*}
    0 &= \sum_{i=1}^{n} \left( a_i - L \right) \prod_{j\neq i} \left( a_i - a_j \right),
  \end{align*}
  we get
  \begin{align*}
    L &= \frac{1}{\sum_{i=1}^{n}\prod_{j\neq i}\left( a_i - a_j \right)} \sum_{i=1}^{n} a_i \prod_{j\neq i} \left( a_i - a_j \right),
  \end{align*}
  which is well-defined whenever the $a_i$ are distinct.
\end{solution}
\begin{problem}[Problem 3]
  Let $T\colon V\rightarrow W$ be a linear map of finite-dimensional vector spaces, and let $W_0\subseteq W$ be a subspace.
  \begin{enumerate}[(a)]
    \item Show that $T^{-1}\left( W_0 \right) = \set{v\in V | Tv\in W_0}$ is a subspace of $V$.
    \item Assuming $T$ is surjective, express $\dim \left( T^{-1}\left( W_0 \right) \right)$ in terms of $\dim\left( W_0 \right)$ and $\dim\left( \ker\left( T \right) \right)$.
  \end{enumerate}
\end{problem}
\begin{solution}\hfill
  \begin{enumerate}[(a)]
    \item We see that if $v_1,v_2\in T^{-1}\left( W_0 \right)$ and $\alpha\in\R$, then since $Tv_1,\alpha Tv_2\in W_0$, we have $Tv_1 + \alpha Tv_2 \in W_0$, so by linearity, $T\left( v_1 + \alpha v_2 \right)\in W_0$, meaning $v_1 + \alpha v_2\in T^{-1}\left( W_0 \right)$, so $T^{-1}\left( W_0 \right)$ is a subspace of $V$.
    \item First, since $T$ is surjective, $T\left( T^{-1}\left( W_0 \right) \right) = W_0$. Therefore, by restricting the map $T$, we get the surjective map $T'\colon T^{-1}\left( W_0 \right)\rightarrow W_0$, and since $\ker\left( T \right)\subseteq T^{-1}\left( W_0 \right)$, the First Isomorphism Theorem gives $T^{-1}\left( W_0 \right)/\ker\left( T \right)\cong W_0$, so by rank-nullity (as each of $W_0$ and $T^{-1}\left( W_0 \right)$ are finite-dimensional), $\dim\left( T^{-1}\left( W_0 \right) \right) = \dim\left( \ker\left( T \right) \right) + \dim\left( W_0 \right)$.
  \end{enumerate}
\end{solution}
\begin{problem}[Problem 4]\hfill
  \begin{enumerate}[(a)]
    \item Do there exist invertible matrices $A,B\in \Mat_{2}\left( \R \right)$ such that
      \begin{align*}
        ABA^{-1}B^{-1} &= \begin{pmatrix}1 & 0 \\ 0 & 2\end{pmatrix}?
      \end{align*}
    \item Do there exist matrices $A,B\in \Mat_{2}\left( \R \right)$ such that
      \begin{align*}
        AB - BA &= \begin{pmatrix}1 & 0 \\ 0 & 2\end{pmatrix}?
      \end{align*}
  \end{enumerate}
\end{problem}
\begin{solution}\hfill
  \begin{enumerate}[(a)]
    \item There do not. This follows from the fact that $\det\left( ABA^{-1}B^{-1} \right) = 1$, while the determinant of the latter matrix is $2$.
  \end{enumerate}
\end{solution}
\begin{problem}[Problem 5]\hfill
  \begin{enumerate}[(a)]
    \item Find the inverse matrix $A^{-1}$ for the matrix
      \begin{align*}
        A &= \begin{pmatrix}a+1 & a & a \\ a & a+1 & a \\ a & a & a+1\end{pmatrix}.
      \end{align*}
    \item Prove that
      \begin{align*}
        \begin{vmatrix}a + x_1 & a & \cdots & a \\ a & a + x_2 & \cdots & a \\ \vdots & \vdots & \ddots & \vdots \\ a & a & \cdots & a + x_n\end{vmatrix} &= x_1x_2\cdots x_n\left( 1 + \frac{a}{x_1} + \dots + \frac{a}{x_n} \right).
      \end{align*}
  \end{enumerate}
\end{problem}
\begin{solution}\hfill
  \begin{enumerate}[(a)]
    \item We may find $A^{-1}$ by trying to find the sequence of elementary matrices $E_1,\dots,E_n$ such that
      \begin{align*}
        E_nE_{n-1}\cdots E_2E_1 A &= I.
      \end{align*}
      First, we do row reduction on $A$, yielding
      \begin{align*}
        \begin{pmatrix}a+1 & a & a \\ a & a+1 & a \\ a & a & a+1\end{pmatrix} &\xrightarrow{R_1 \leftarrow R_1-R_2} \begin{pmatrix}1 & -1 & 0 \\ a & a+1 & a \\ a & a & a+1\end{pmatrix} \\
                           &\xrightarrow{R_2 \leftarrow R_3-R_2}\begin{pmatrix}1 & -1 & 0 \\ 0 & 1 & -1 \\ a & a & a+1\end{pmatrix}\\
                           &\xrightarrow{R_3 \leftarrow R_3 - aR_1} \begin{pmatrix}1 & -1 & 0 \\ 0 & 1 & -1 \\ 0 & 2a & a+1 \end{pmatrix}\\
                           &\xrightarrow{R_3 \leftarrow R_3 - 2aR_2} \begin{pmatrix}1 & -1 & 0 \\ 0 & 1 & -1 \\ 0 & 0 & 3a+1\end{pmatrix}\\
                           &\xrightarrow{R_3 \leftarrow R_3/(3a+1)} \begin{pmatrix}1 & -1 & 0 \\ 0 & 1 & -1 \\ 0 & 0 & 1\end{pmatrix}\\
                           &\xrightarrow{R_2 \leftarrow R_3 + R_2} \begin{pmatrix}1 & -1 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & 1\end{pmatrix}\\
                           &\xrightarrow{R_1 \leftarrow R_1 + R_2} \begin{pmatrix}1 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & 1\end{pmatrix}.
      \end{align*}
      Thus, the product $E_nE_{n-1}\cdots E_2E_1$ is our desired inverse, which we find by applying the elementary row operations to the identity matrix $I$, yielding
      \begin{align*}
        \begin{pmatrix}1 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & 1\end{pmatrix} &\xrightarrow{R_1 \leftarrow R_1-R_2} \begin{pmatrix}1 & -1 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & 1\end{pmatrix}\\
                         &\xrightarrow{R_2 \leftarrow R_3-R_2} \begin{pmatrix}1 & -1 & 0 \\ 0 & 1 & -1 \\ 0 & 0 & 1\end{pmatrix}\\
                         &\xrightarrow{R_3 \leftarrow R_3 - aR_1} \begin{pmatrix}1 & -1 & 0 \\ 0 & 1 & -1 \\ -a & a & 1\end{pmatrix}\\
                         &\xrightarrow{R_3 \leftarrow R_3 - 2aR_2} \begin{pmatrix}1 & -1 & 0 \\ 0 & 1 & -1 \\ -a & -a & 2a+1\end{pmatrix}\\
                         &\xrightarrow{R_3 \leftarrow R_3/(3a+1)} \begin{pmatrix}1 & -1 & 0 \\ 0 & 1 & -1 \\ -a/(3a+1) & -a/(3a+1) & (2a+1)/(3a+1)\end{pmatrix}\\
                         &\xrightarrow{R_2 \leftarrow R_3 + R_2} \begin{pmatrix}1 & -1 & 0 \\ -a/(3a+1) & 1-\left( a/(3a+1) \right) & -1 + \left( (2a+1)/(3a+1) \right)\\ -\left( a/(3a+1) \right) & -a/(3a+1) & (2a+1)/(3a+1)\end{pmatrix}\\
                         &\xrightarrow{R_1 \leftarrow R_1 + R_2} \begin{pmatrix}1-a/(3a+1) & -a/(3a+1) & -1 + (2a+1)/(3a+1) \\ -a/(3a+1) & 1-\left( a/(3a+1) \right) & -1 + \left( (2a+1)/(3a+1) \right)\\ -a/(3a+1) & -a/(3a+1) & (2a+1)/(3a+1)\end{pmatrix},
      \end{align*}
      which is our desired inverse.
    \item We show the case for $n=2$, then use induction from then on. By raw calculation, we see that
      \begin{align*}
        \begin{vmatrix}a + x_1 & a \\ a & a + x_2\end{vmatrix} &= \left( a+x_1 \right)\left( a+x_2 \right)-a^2\\
                               &= x_1x_2 + ax_1 + ax_2\\
                               &= x_1x_2\left( 1 + \frac{a}{x_1} + \frac{a}{x_2} \right).
      \end{align*}
      Now, for the general $n$ case, we see that since determinants are multilinear,
      \begin{align*}
        \begin{vmatrix}a + x_1 & a & \cdots & a \\ a & a + x_2 & \cdots & a \\ \vdots & \vdots & \ddots & \vdots \\ a & a & \cdots & a + x_n\end{vmatrix} &= \begin{vmatrix}a + x_1 & a & \cdots & a \\ a & a + x_2 & \cdots & a \\ \vdots & \vdots & \ddots & \vdots \\ a & a & \cdots & a\end{vmatrix} + \begin{vmatrix}a + x_1 & a & \cdots & 0 \\ a & a + x_2 & \cdots & 0 \\ \vdots & \vdots & \ddots & \vdots \\ a & a & \cdots & x_n\end{vmatrix}\\
                               &= a\begin{vmatrix}a + x_1 & a & \cdots & 1 \\ a & a + x_2 & \cdots & 1 \\ \vdots & \vdots & \ddots & \vdots \\ a & a & \cdots & 1\end{vmatrix} + \begin{vmatrix}a + x_1 & a & \cdots & 0 \\ a & a + x_2 & \cdots & 0 \\ \vdots & \vdots & \ddots & \vdots \\ a & a & \cdots & x_n\end{vmatrix}
                               \intertext{and since determinants are alternating,}
                               &= a \begin{vmatrix}x_1 & 0 & \cdots & 1 \\ 0 & x_2 & \cdots & 1 \\ \vdots & \vdots & \ddots & \vdots \\ 0 & 0 & \cdots & 1\end{vmatrix} + \begin{vmatrix}a + x_1 & a & \cdots & 0 \\ a & a + x_2 & \cdots & 0 \\ \vdots & \vdots & \ddots & \vdots \\ a & a & \cdots & x_n\end{vmatrix}
                               \intertext{and by the cofactor expansion,}
                               &= a\left( x_1x_2\cdots x_{n-1} \right) + x_n \begin{vmatrix}a + x_1 & a & \cdots & a \\ a & a + x_2 & \cdots & a \\ \vdots & \vdots & \ddots & \vdots \\ a & a & \cdots & x_{n-1}\end{vmatrix}
                               \intertext{and by the induction hypothesis,}
                               &= a\left( x_1x_2\cdots x_{n-1} \right) + x_n\left( x_1x_2\cdots x_{n-1} \right)\left( 1 + \frac{a}{x_1} + \cdots + \frac{a}{x_{n-1}} \right)\\
                               &= x_1x_2\cdots x_{n}\left( 1 + \frac{a}{x_1} + \cdots + \frac{a}{x_{n-1}} + \frac{a}{x_n} \right),
      \end{align*}
      we obtain our desired result.
  \end{enumerate}
\end{solution}
\begin{problem}[Problem 6]
  Let $A\in \Mat_{n}\left( \R \right)$, and $\left( a_{ij} \right)_{ij}$ such that $\left\vert a_{ij} \right\vert < \frac{1}{n}$ for each $i,j$. Show that $\det\left( I_n - A \right) \neq 0$.
\end{problem}
\begin{solution}
  Let $\norm{x} = \max_{i=1}^{n} \left\vert x_i \right\vert$. Let $x_j$ be the component of $x$ such that $\left\vert x_j \right\vert = \norm{x}$. Then, we see that
  \begin{align*}
    \left\vert \left( Ax \right)_j \right\vert &= \left\vert \sum_{i=1}^{n}a_{ij}x_i \right\vert\\
                                               &\leq \sum_{i=1}^{n} \left\vert a_{ij} \right\vert\left\vert x_i \right\vert\\
                                               &< \sum_{i=1}^{n} \frac{1}{n}\left\vert x_i \right\vert\\
                                               &\leq \sum_{i=1}^{n}\frac{1}{n}\norm{x}\\
                                               &= \left\vert x_j \right\vert,
  \end{align*}
  which means that $Ax\neq x$ at the component $x_j$, meaning $\left( I_n - A \right)x \neq 0$.
\end{solution}
\begin{problem}[Problem 7]\hfill
  \begin{enumerate}[(a)]
    \item Let $A\in \Mat_{n}\left( \C \right)$ be a matrix such that $A^2 = I_{n}$. Show that $A$ is diagonalizable.
    \item Give an example of of $A\in \Mat_{2}\left( \C \right)$ satisfying $A^2 = \mathbf{0}_{2}$ (the zero matrix) which is not diagonalizable.
  \end{enumerate}
\end{problem}
\begin{solution}\hfill
  \begin{enumerate}[(a)]
    \item Since $A^2- I_n = \mathbf{0}_{n}$, we see that the minimal polynomial of $A$ is $m_A(t) = t^2 - 1$, which splits over $\C$ to yield $m_A(t) = \left( t-1 \right)\left( t+1 \right)$. In particular, since the minimal polynomial splits into a product of distinct linear factors, $A$ is diagonalizable.
    \item The matrix
      \begin{align*}
        A &= \begin{pmatrix}0 & 1 \\ 0 & 0\end{pmatrix}
      \end{align*}
      satisfies $A^2 = \mathbf{0}_{2}$, but since $A \neq \mathbf{0}_{2}$, we see that $m_{A}(t) = t^2$. Since $m_A(t)$ does not split into distinct linear factors over $\C$, we see that $A$ is necessarily not diagonalizable.
  \end{enumerate}
\end{solution}
\begin{problem}[Problem 8]
  Let $A\in \Mat_{n}\left( \C \right)$ be a matrix such that $A^2$ has $n$ distinct eigenvalues. Show that $A$ is diagonalizable.
\end{problem}
\begin{solution}
  Let $m_{A^2}(t)$ be the minimal polynomial for $A^2$, which since $A^2$ has $n$ distinct eigenvalues, splits as
  \begin{align*}
    m_{A^2}(t) &= \left( t-\lambda_1 \right) \cdots \left( t-\lambda_n  \right).
  \end{align*}
  Observe that, if we set $p = m_{A^2}\left( t^2 \right)$, that $p$ then annihilates $A$. We may factor $p$ as
  \begin{align*}
    p(t) &= \left( t-\sqrt{\lambda_1} \right)\left( t + \sqrt{\lambda_1} \right) \cdots \left( t-\sqrt{\lambda_n} \right)\left( t + \sqrt{\lambda_n} \right).
  \end{align*}
  Each of these factors are distinct, meaning that $m_A(t)$ consists entirely of distinct linear factors, so that $A$ is diagonalizable.
\end{solution}
\begin{problem}
  Let $A\in \Mat_{n}\left( \R \right)$ satisfy $AA^{T} = I_n$, where $A^T$ is the transpose of $A$ and $I_n$ is the identity matrix. Let $f(x) = \det\left( xI_n - A \right)$ be the characteristic polynomial of $A$.
  \begin{enumerate}[(a)]
    \item Show that if $\lambda$ is an eigenvalue of $A$, then $\lambda^{-1}$ is also an eigenvalue of $A$.
    \item Show that if $ \det\left( A \right) = 1$ and $n$ is odd, then $\lambda = 1$ is an eigenvalue of $A$.
  \end{enumerate}
\end{problem}
\begin{solution}\hfill
  \begin{enumerate}[(a)]
    \item Let $\lambda$ be an eigenvalue for $A$ with corresponding eigenvector $v$. Then,
      \begin{align*}
        Av &= \lambda v.
      \end{align*}
      Observe now that $\left( AA^{T} \right)^{T} = A^{T}A = I_n$, meaning that $A^{T} = A^{-1}$. Thus, we see that
      \begin{align*}
        v &= A^{T}\left( Av \right)\\
          &= A^{T}\lambda v,
      \end{align*}
      so
      \begin{align*}
        A^{T}v &= \lambda^{-1}v.
      \end{align*}
      Since $A$ and $A^{T}$ have the same eigenvalues, we thus get that $\lambda^{-1}$ is an eigenvalue for $A$.
    \item We observe that $\det\left( A \right) = \lambda_1\cdots\lambda_n$, where $\lambda_1,\dots,\lambda_n$ are eigenvalues for $A$ (counted with algebraic multiplicity). Since $\det\left( A \right) = 1$, and $n$ is odd, it follows that, by pairing up eigenvalues with their inverses, there is at least one such $\lambda_i$ with $\lambda_i = 1$. Thus, $\lambda = 1$ is an eigenvalue for $A$.
  \end{enumerate}
\end{solution}
\end{document}
