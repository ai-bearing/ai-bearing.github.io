\documentclass[10pt]{mypackage}

% sans serif font:
%\usepackage{cmbright}
%\usepackage{sfmath}
%\usepackage{bbold} %better blackboard bold

%\usepackage{homework}
\usepackage{notes}
\usepackage{newpxtext,eulerpx,eucal}
%\usepackage{mlmodern}
%\renewcommand{\mathbb}[1]{\mathds{#1}}
\renewcommand*{\mathbb}[1]{\varmathbb{#1}}

\fancyhf{}
\rhead{Avinash Iyer}
\lhead{Algebra I: Notes and Review}

\setcounter{secnumdepth}{0}

\begin{document}
\RaggedRight
These are some notes from my Algebra I class. We use the textbook \textit{Abstract Algebra} by Dummit and Foote, and will cover rings, groups, and modules.
\section{PIDs, UFDs and All That}%
We always assume here that $R$ is commutative and unital.
\subsection{Preliminaries}%
\begin{definition}
  If $a_1,\dots,a_n\in R$, then the \textit{ideal generated by} $a_1,\dots,a_n$ is given by
  \begin{align*}
    \left( a_1,\dots,a_n \right) \coloneq \bigcap\set{I | a_1,\dots,a_n\in I,I\text{ is an ideal in }R}.
  \end{align*}
  An ideal is called \textit{principal} if $I = \left( a \right)$ for some $a\in I$. We may write $I = a\cdot R$ in this case. A ring where every ideal is principal is called a \textit{principal ideal domain}.
\end{definition}
\begin{definition}
  If $I$ and $J$ are ideals in $R$, then $IJ$ is given by
  \begin{align*}
    IJ &= \set{\sum_{i=1}^{n}x_iy_i | x_i\in I, y_i\in J,n\in \N}.
  \end{align*}
\end{definition}
\begin{theorem}[Isomorphism Theorems for Rings]\hfill
  \begin{description}
    \item[First Isomorphism Theorem:] Let $\varphi\colon R\rightarrow S$ be a ring homomorphism. Then, $ \overline{\varphi}\colon R/\ker\left( \varphi \right)\rightarrow \img\left( \varphi \right) $ is an isomorphism given by $ \overline{\varphi}\left( a + \ker\left( \varphi \right) \right) = \varphi\left( a \right) $.
    \item[Second Isomorphism Theorem:] Let $R$ be a ring, $S\subseteq R$ a subring, and let $I\subseteq R$ be an ideal. Then,
      \begin{enumerate}[(i)]
        \item $I + S$ is a subring of $R$;
        \item $I$ is an ideal of $I + S$;
        \item $I\cap S$ is an ideal of $S$;
        \item $S/I\cap S \cong I + S/I$.
      \end{enumerate}
    \item[Third Isomorphism Theorem:] Let $R$ be a ring, $I,J$ ideals of $R$ with $I\subseteq J$. Then, $J/I$ is an ideal of $R/I$, and we have $\left( R/I \right)/\left( J/I \right) \cong R/J$.
    \item[Fourth Isomorphism Theorem:] If $R$ is a ring and $I$ is an ideal, then there is a one-to-one correspondence between subrings of $R/I$ and subrings of $R$ containing $I$.
  \end{description}
\end{theorem}
\begin{definition}
  Let $M$ be an ideal in $R$.
  \begin{enumerate}[(i)]
    \item We say $M$ is prime if $M\neq R$ and, for any $ab\in M$, we have either $a\in M$ or $b\in M$.
    \item We say $M$ is maximal if $M\neq R$ and if $M\subseteq I\subseteq R$ where $I$ is an ideal, then either $I = M$ or $I = R$.
  \end{enumerate}
\end{definition}
\begin{theorem}
  Let $M$ be an ideal in $R$.
  \begin{enumerate}[(i)]
    \item $M$ is prime if and only if $R/M$ is an integral domain.
    \item $M$ is maximal if and only if $R/M$ is a field.
  \end{enumerate}
\end{theorem}
\begin{proof}\hfill
  \begin{enumerate}[(i)]
    \item Let $M$ be maximal, with $a + M \in R/M$, $a + M \neq 0 + M$. Then, $a\notin M$, so that the ideal $\left( a \right) + M$ strictly contains $M$. Therefore, $1 + M\in \left( a \right) + M$, meaning there is some $r + M$ such that $ \left( r + M \right)\left( a + M \right) = 1 + M $. Thus, an inverse exists.\newline

      Now, if $R/M$ is a field, and $M \subsetneq I \subseteq R$, then $I/M$ is an ideal of $R/M$, and since $I\supsetneq M$, we have $I/M\neq 0 + M$. Since $R/M$ is a field, its only ideals are either $ 0 + M $ and $R/M$, so $I/M = R/M$, meaning $I = R$.
    \item We have $P\subseteq R$ is prime if and only if $ab\in P$ implies $a\in P$ or $b\in P$. Yet, means that $ab + P = 0 + P$ if and only if $ a = 0 + P $ or $b = 0 + P$.
  \end{enumerate}
\end{proof}
\subsection{Chinese Remainder Theorem}%
\begin{definition}
  We say two ideals $I$ and $J$ are \textit{coprime} if $I + J = R$, or that there exist $x\in I$ and $y\in J$ such that $x + y = 1$.
\end{definition}
\begin{theorem}[Chinese Remainder Theorem]
  Let $I_1,\dots,I_n$ be pairwise coprime ideals of $R$. Then, for any $a_1,\dots,a_n\in R$, there exists $x\in R$ with $x\equiv a_i$ modulo $I_i$ for all $i$. In other words, there a solution to the system of congruences given by
  \begin{align*}
    x + I_1 &= a_1 + I_1\\
    x + I_2 &= a_2 + I_2\\
            &\vdots\\
    x + I_n &= a_n + I_n.
  \end{align*}
\end{theorem}
\begin{proof}
  It suffices to construct elements $y_1,\dots,y_n$ such that $y_i\equiv 1$ modulo $I_i$ and $0$ otherwise. Then, we will be able to set $x = \sum_{i} a_iy_i$ as our desired solution.\newline

  We construct $y_1$ as follows. From our assumption, $I_1 + I_j = R$ for all $j \geq 2$, so for each $j\geq 2$, there exists $u_j\in I_1$ and $v_j\in I_j$ such that $u_j + v_j = 1$. Taking the product, we find that
  \begin{align*}
    \prod_{j=2}^{n} \left( u_j + v_j \right) &= 1\\
                                             &= \underbrace{v_2 \cdots v_n}_{\eqcolon y_1} \underbrace{+ \cdots + u_2\cdots u_n}_{\eqcolon x_1}.
  \end{align*}
  We verify that $y_1$ does the job, which we can see by the fact that $y_1 \equiv 0$ modulo $I_j$ for $j\neq 1$, as $v_2\cdots v_j\in I_2\cdots I_j\subseteq I_j$ for each $j\geq 2$. Similarly, each summand in $x_1$ contains at least one $u_j$, so $x_1\equiv 0$ modulo $I_1$.\newline

  The rest of the $y_i$ follow analogously.
\end{proof}
We can restate the Chinese Remainder Theorem in a variety of ways.
\begin{theorem}[Chinese Remainder Theorem, Alternative Versions]
  Let $I_1,\dots,I_n$ be pairwise coprime ideals.
  \begin{enumerate}[(i)]
    \item There exists a surjective homomorphism 
      \begin{align*}
        \varphi\colon R&\rightarrow  R/I_1\times\cdots\times R/I_n\\
        r &\mapsto \left( r + I_1,\dots, r + I_n \right).
      \end{align*}
      This homomorphism induces an isomorphism
      \begin{align*}
        \overline{\varphi}\colon R/\left( I_1\cap\cdots\cap I_n \right) \rightarrow R/I_1\times\cdots\times R/I_n.
      \end{align*}
    \item If $I_1,\dots,I_n$ are pairwise coprime, then
      \begin{align*}
        R/I_1\cdots I_n &\cong R/I_1\times\cdots\times R/I_n
      \end{align*}
      are isomorphic.
  \end{enumerate}
\end{theorem}
\begin{example}
  We observe that if $R = \Z$, and $p_1,\dots,p_r$ are distinct primes with $\ell_1,\dots,\ell_r$ positive integers, then
  \begin{align*}
    \Z/p_1^{\ell_1}\cdots p_{r}^{\ell_r}\Z &\cong \Z/p_{1}^{\ell_1}\Z \times\cdots\times \Z/p_{r}^{\ell_r}\Z.
  \end{align*}
\end{example}
\begin{example}[Polynomial Interpolation]
  If we let
  \begin{align*}
    p_i(x) &= x-\alpha_i,
  \end{align*}
  where $\alpha_i\in \F$, we observe that there is a surjective evaluation homomorphism
  \begin{align*}
    \operatorname{ev}\colon \frac{\F\left[ x \right]}{\left( p_i(x) \right)} &\rightarrow \F,
  \end{align*}
  given by $f(x) \mapsto f\left( \alpha_i \right)$. In particular, if $\alpha_1,\dots,\alpha_r$ are distinct, then
  \begin{align*}
    \frac{\F\left[ x \right]}{\left( p_1(x),\dots,p_r(x) \right)} &\cong \F\times\cdots\times \F,
  \end{align*}
  so that, for all $\beta_1,\dots,\beta_r\in \F$, there is some $f(x)\in \F\left[ x \right]$ such that $f\left( \alpha_i \right) = \beta_i$ for $ i = 1,\dots,r $.
\end{example}
\subsection{Field of Fractions and Localization}%
Given a ring $R$, how can we find maximal ideals in $R$? More specifically, given a commutative ring $R$ with $1$, and prime ideal $ P\subseteq R $, we want to construct a new ring $R_{\mathfrak{p}}$ with unique maximal ideal $P$.\newline

Toward this end, we start by reviewing a useful construction known as the field of fractions.
\begin{definition}
  Let $R$ be an integral domain. We define the field $K = \operatorname{frac}\left( R \right)$ to be the unique field with an injection
  \begin{align*}
    \iota\colon R&\hookrightarrow K\\
    1_{R} &\mapsto 1_{K},
  \end{align*}
  satisfying the following universal property.\newline

  Given any embedding into a field, $\sigma\colon R\hookrightarrow L$, such that $1_{R}\mapsto 1_{L}$, there is a unique extension $ \widetilde{\sigma}\colon K\rightarrow L $ such that the following diagram commutes.
  \begin{center}
    % https://tikzcd.yichuanshen.de/#N4Igdg9gJgpgziAXAbVABwnAlgFyxMJZABgBpiBdUkANwEMAbAVxiRACUQBfU9TXfIRQAmUsKq1GLNgBluvEBmx4CRUZWr1mrRCADS3CTCgBzeEVAAzAE4QAtkjIgcEJKMna2AHS-4cdEGp-LAY2AAsICABreStbB0QnFyQARmoGOgAjGAYABX4VIRBrLBMwnECPaV0fbBM7AJ44+zcg10Q0kAzsvILBNgYYSwrNKR0QHwB3LFg8BlhgWtKGrkMuIA
\begin{tikzcd}
R \arrow[rr, "\iota", hook] \arrow[rrdd, "\sigma"'] &  & K \arrow[dd, "\widetilde{\sigma}"] \\
                                                    &  &                                    \\
                                                    &  & L                                 
\end{tikzcd}
  \end{center}
\end{definition}
In order to construct $K$, we let $S\subseteq R\times R$ be defined by
\begin{align*}
  S &= \set{\left( a,b \right) | b\neq 0}.
\end{align*}
We impose an equivalence relation on $S$ by saying $\left( a,b \right)\sim \left( c,d \right)$ if and only if $ ad - bc = 0 $. Clearly, this relation is reflexive and symmetric. To see that it is transitive, we let $\left( a,b \right)\sim \left( c,d \right)$, and $ \left( c,d \right)\sim \left( e,f \right) $, meaning $ad-bc=  0$ and $cf-de = 0$. Multiplying the first equation by $f$ and the second equation by $b$, then subtracting, we get $ adf - bde = 0 $, meaning $d\left( af-be  \right)= 0$. Since $R$ admits no zero divisors, this means that $ af-be = 0 $, so the relation is transitive.\newline

We write $ \left[ \left( a,b \right) \right] = \frac{a}{b} $ for $K$, with operations
\begin{align*}
  \frac{a}{b} + \frac{c}{d} &= \frac{ad + bc}{bd}\\
  \frac{a}{b}\cdot \frac{c}{d} &= \frac{ac}{bd}.
\end{align*}
These operations are well-defined and do satisfy the universal property. Verifying this is a pain, but it can be done.\newline

Now, we may extend this to all unital commutative rings, not just integral domains.
\begin{definition}
  Let $R$ be a unital commutative ring, and let $S\subseteq R$. We say $S$ is \textit{multiplicative} if
  \begin{itemize}
    \item $1\in S$;
    \item $0\notin S$;
    \item for any $x,y\in S$, $xy\in S$.
  \end{itemize}
\end{definition}
\begin{example}\hfill
  \begin{enumerate}[(i)]
    \item If $R$ is an integral domain, then $R\setminus \set{0}$ is multiplicative.
    \item If $z\in R$ is such that $z$ is not nilpotent, then $S = \set{z^{n} | n\geq 0}$ is multiplicative.
    \item If $P$ is a prime ideal, then $S = R\setminus P$ is multiplicative.
  \end{enumerate}
\end{example}
We will use (iii) to construct a ring with a unique maximal ideal. First, though, we construct a ring of fractions using multiplicative sets.
\begin{definition}
  Let $R$ be a unital commutative ring, and let $S\subseteq R$ be multiplicative. We construct a ring $S^{-1}R$ by taking an equivalence relation on $R\times S$ as follows:
  \begin{align*}
    \left( a,s \right)\sim \left( b,t \right) &\Leftrightarrow \exists s'\in S\text{ such that }s'\left( at-bs \right) = 0.
  \end{align*}
  We write
  \begin{align*}
    S^{-1}R &= \set{\left[ \left( a,s \right) \right] | a\in R,s\in S},
  \end{align*}
  and denote
  \begin{align*}
    \left[ \left( a,s \right) \right] &= \frac{a}{s}.
  \end{align*}
  This becomes a ring under the operations
  \begin{align*}
    \frac{a}{s} + \frac{b}{t} &= \frac{at + bs}{st}\\
    \frac{a}{s}\cdot \frac{b}{t} &= \frac{ab}{st}.
  \end{align*}
  We call $S^{-1}R$ the \textit{localization of $R$ with respect to $S$}.
\end{definition}
We can see some basic properties of the localization. 
\begin{proposition}
  Let $R$ be a unital commutative ring, $S\subseteq R$ multiplicative, and let $S^{-1}R$ be the corresponding localization.
  \begin{itemize}
    \item The additive identity in $S^{-1}R$ is $\frac{0}{1}$.
    \item The additive inverse of $ \frac{a}{s} $ in $S^{-1}R$ is $\frac{-a}{s}$.
    \item For all $a\in R$ and all $s,s'\in S$, we have $ \frac{as'}{ss'} = \frac{a}{s} $.
    \item Every element of the form $ \frac{s}{t} $ where both $s,t\in S$ is invertible, with corresponding inverse $ \frac{t}{s} $.
    \item The map $\iota_S\colon R\rightarrow S^{-1}R$ given by $ r\mapsto \frac{r}{1} $ is an injective ring homomorphism such that $\iota_S\left( S \right)\subseteq \left( S^{-1}R \right)^{\times}$, where $\left( S^{-1}R \right)^{\times}$ denotes the group of invertible elements in $S^{-1}R$.
  \end{itemize}
\end{proposition}
\subsection{Unique Factorization Domains}%
\begin{definition}
  A ring $R$ is called \textit{Noetherian} if, for any ascending chain of ideals $I_1\subseteq I_2\subseteq\cdots$, there is some index $N$ such that for all $m\geq N$, $I_m = I_N$.
\end{definition}
\begin{proposition}
  The following are equivalent:
  \begin{itemize}
    \item $R$ is Noetherian;
    \item every ideal in $R$ is finitely generated.
  \end{itemize}
\end{proposition}
\begin{proof}
  Let $R$ be Noetherian. Suppose toward contradiction that there exists $I$ that is not finitely generated. Then, $I$ is nonzero, so there is $\alpha_1\in I$ such that $I_1 = \left( \alpha_1 \right)$ is nonzero. Since $I$ is not finitely generated, $I\neq I_1$, so there is $\alpha_2\in I\setminus I_1$, so that $I_2 = \left( \alpha_1,\alpha_2 \right)$ is such that $I_1\subseteq I_2$. Inductively, we generate $I_n = \left( \alpha_1,\dots,\alpha_n \right)$ such that $I_{n-1}\subsetneq I_n$, implying that we have a strictly ascending chain of ideals, which is a contradiction.\newline

  Suppose every ideal in $R$ is finitely generated. Let $I_1\subseteq I_2\subseteq\cdots$ be an ascending chain of ideals, and set $I = \bigcup I_n$ be their union. By assumption, $I$ is finitely generated, so we have $I = \left( \alpha_1,\dots,\alpha_N \right)$ for some $\alpha_1,\dots,\alpha_N\in R$. Yet, since $I$ is the union of all these ideals, there is some $M$ such that $\alpha_1,\dots,\alpha_N\in I_M$, meaning the chain stabilizes.
\end{proof}
\begin{corollary}
  If $R$ is a principal ideal domain, then $R$ is Noetherian.
\end{corollary}
\begin{definition}
  Let $R$ be an integral domain.
  \begin{enumerate}[(i)]
    \item Two elements $a,b\in R$ are called \textit{associated} if $a = bu$ for some unit (invertible) element $u\in R$. Equivalently, $a$ and $b$ are associated if $\left( a \right) = \left( b \right)$
    \item An element $a\in R$ is called \textit{irreducible} if
      \begin{itemize}
        \item $a$ is not a unit element;
        \item whenever $a = bc$ for some $b,c\in R$, then one of $b$ or $c$ is a unit.
      \end{itemize}
    \item An element $a$ is called \textit{prime} if $a\neq 0$, $a\notin R^{\times}$, and $\left( a \right)$ is prime. Equivalently, $a$ is prime if, whenever $a | bc$, it follows that $a | b$ or $a | c$, where divisibility in $R$ is defined traditionally (i.e., there exists $z\in R$ such that $az = b$).
  \end{enumerate}
\end{definition}
\begin{note}
  Prime elements are irreducible, but not necessarily vice versa.
\end{note}
The question then arises: when are irreducibles prime?
\begin{definition}
  We say $a\in R$ with $a\neq 0$, $a\notin R^{\times}$ has a \textit{unique factorization} into irreducibles if
  \begin{enumerate}[(i)]
    \item we may write $a = u p_1\cdots p_r$, where $u$ is a unit and $p_1,\dots,p_r$ are irreducible;
    \item for any other such factorization
      \begin{align*}
        a &= u\prod_{i=1}^{r}p_i\\
          &= v\prod_{j=1}^{s} q_j,
      \end{align*}
      where $p_i,q_j$ are irreducible and $u,v$ are units, we have
      \begin{itemize}
        \item $r = s$;
        \item upon permutation of factors, $p_i$ and $q_i$ are associated.
      \end{itemize}
  \end{enumerate}
  We call $R$ a \textit{unique factorization domain} if, for any $a\in R$ with $a\neq 0$, $a\notin R^{\times}$, $a$ has unique factorization into irreducibles.
\end{definition}
\begin{proposition}
  If $R$ a Noetherian ring, then every $a\in R$ with $a\neq 0$ and $a\notin R^{\times}$ admits a factorization into irreducibles.
\end{proposition}
\begin{proof}
  First, we show that every such $a$ has an irreducible factor or divisor. If $a$ is itself irreducible, then we are done. Else, there are $b,c\in R$ with $a = bc$ and neither $a$ nor $b$ a unit. In particular, this means that $\left( a \right)\subsetneq \left( b \right)$. Inductively, if $b$ is not irreducible, then we may find $b_2,c_2$ such that $b = b_2 c_2$, meaning that $\left( b \right)\subsetneq \left( b_2 \right)$, and so on and so forth.\newline

  This gives a chain of ideals
  \begin{align*}
    \left( a \right)\subsetneq \left( b \right)\subsetneq \left( b_2 \right)\subsetneq \cdots
  \end{align*}
  that eventually stabilizes, meaning that there is some $b_N$ such that $b_N$ is irreducible.\newline

  Now, we may show that $a$ admits a factorization. If $a = bc$ with $b$ irreducible (as we showed previously), then if $c$ is not irreducible, we may take $c = b_1c_1$ and create this same chain of ideals
  \begin{align*}
    \left( c \right)\subsetneq \left( c_1 \right)\subsetneq \left( c_2 \right)\subsetneq\cdots
  \end{align*}
  using the Noetherian condition to end up at an irreducible or a unit.
\end{proof}
The main issue facing general Noetherian rings is that the uniqueness of the factorization may go awry.
\begin{example}
For instance, in the ring $R = \Z\left[ \sqrt{-5} \right]$, there is not unique factorization. For instance, we may write
\begin{align*}
  6 &= \left( 2 \right)\left( 3 \right)\\
    &= \left( 1 + \sqrt{-5} \right)\left( 1 + \sqrt{-5} \right),
\end{align*}
where we may see that all of these are irreducible as follows. Define a norm on $\Z\left[ \sqrt{-5} \right]\subseteq \C$ by $N\left( a + b\sqrt{-5} \right) = a^2 + 5b^2$, where this norm is multiplicative as it is inherited from $\C$.
\begin{lemma}
  If $N$ is a norm on the ring $R = \Z\left[ \sqrt{-D} \right]$, where $D$ is a square-free positive integer, then $u\in R$ is an invertible (or unit) element if and only if $N(u) = 1$.
\end{lemma}
\begin{proof}[Proof of Lemma]
  If $v\in R$ is such that $uv = 1$, then $N(uv) = N(u)N(v) = 1$, meaning that both $N(u)$ and $N(v)$ are $1$.\newline

  Meanwhile, if $N(u) = 1$, then $1 = u \overline{u}$, meaning that $ \overline{u} = u^{-1} $.
\end{proof}
We may show that $2$ is irreducible relatively quickly. Observe that if there were a factorization of $2 = ab$ into irreducibles, then $4 = N(a)N(b)$ would hold, with neither $N(a)$ nor $N(b)$ being equal to $1$. This would mean that $N(a) = 2$ for some $a = x + y\sqrt{-5}$, or that $x^2 + 5y^2 = 2$. Yet, reducing modulo $5$, this implies that $x^2 \equiv 2$ modulo $5$, yet the only squares in $\Z/5\Z$ are $1$ and $4$.
\end{example}
%\begin{proposition}
%  In a unique factorization domain, every irreducible element is prime.
%\end{proposition}
%\begin{proof}
%  Let $p$ be an irreducible element such that $p | ab$, where $a,b\in R$. Writing the factorizations into irreducibles
%  \begin{align*}
%    a &= p_1\cdots p_r\\
%    b &= q_1\cdots q_s,
%  \end{align*}
%  unique up to associates, we then get
%  \begin{align*}
%    pk &= ab\\
%       &= p_1\cdots p_r q_1\cdots q_s.
%  \end{align*}
%  Since the factorization of $ab$ is unique up to associates, it follows that $p$ must be associated to one of $p_1,\dots,p_r$ or $q_1,\dots,q_s$. If it's the former, then $p | a$, and if it's the latter, then $p | b$. Thus, $p$ is prime.
%\end{proof}
Given a factorization, there is a simple way to classify the uniqueness of the factorization.
\begin{proposition}
  Let $a\in R$ be such that $a\neq 0$ and $a\notin R^{\times}$. If $a$ admits a factorization
  \begin{align*}
    a &= u p_1\cdots p_r,
  \end{align*}
  with $p_1,\dots,p_n$ \textit{prime}, then this factorization is unique (up to associates).
\end{proposition}
\begin{proof}
  Suppose $a$ admits another factorization,
  \begin{align*}
    a &= vq_1\cdots q_s,
  \end{align*}
  where $q_1,\dots,q_s$ are irreducible and $v$ is a unit. Then, we have
  \begin{align*}
    up_1\cdots p_r &= vq_1\cdots q_s,
  \end{align*}
  meaning that $p_1$ divides $vq_1\cdots q_s$. Since $p_1$ is prime, $p_1 | q_j$ for some $j$, meaning that $q_j = v_1p_1$ for some $v_1\in R$. Yet, since $q_j$ is irreducible, it follows that $v_1$ is a unit. By permuting elements, we may say that $p_1$ and $q_1$ are associated, so we have
  \begin{align*}
    up_1\cdots p_r &= vv_1p_1q_2\cdots q_s.
  \end{align*}
  Now, since $R$ is a domain, it admits the cancellation property, so we may then write
  \begin{align*}
    up_2\cdots p_r &= vv_1q_2\cdots q_s.
  \end{align*}
  Proceeding in this fashion, we observe first that $r \leq s$, as else, we would have $p_i$ dividing a unit for $R$, which is not allowed. Thus, we find
  \begin{align*}
    u &= vv_1\cdots v_r q_{r+1}\cdots q_s.
  \end{align*}
  Similarly, this means there cannot be any more $q_j$, or else the $q_j$ would be a unit. Thus, these are the same factorizations (up to associates).
\end{proof}
\begin{theorem}
  If a domain $R$ is a principal ideal domain, then $R$ is a unique factorization domain.
\end{theorem}
\begin{proof}
  First, we show that if $a\in R$ is irreducible, then $a$ is prime.\newline

  Observe that $\left( a \right)$ is then contained in a maximal ideal $M$, where $M = \left( p \right)$ for some $p\in R$ with $p$ not a unit. Since $M$ is maximal, $M$ is prime, so that $p$ is prime, and $\left( a \right)\subseteq \left( p \right)$. Observe then that $a = pu$ for some $u\in R$; since $a$ is irreducible and $p$ is not a unit, it must be the case that $u$ is a unit. Thus, $\left( a \right) = \left( p \right)$, so that $a$ is prime.\newline

  Now, since $R$ is a principal ideal domain, every element in $R$ admits a factorization into irreducibles, and all irreducibles are prime. Therefore, the factorization is unique by the above lemma.
\end{proof}
\subsection{Euclidean Domains}%
\begin{definition}
  An integral domain $R$ is called a \textit{Euclidean Domain} if there exists $N\colon R\setminus \set{0}\rightarrow \Z_{\geq 0}$ such that for all $a,b\in R$, with $b\neq 0$, there exist $q,r\in R$ such that
  \begin{itemize}
    \item $a = qb + r$;
    \item either $r = 0$ or $N(r) < N(b)$.
  \end{itemize}
\end{definition}
\begin{example}\hfill
  \begin{itemize}
    \item Any field admits the vacuous norm, $N(k) = 0$ for all $k\in F\setminus \set{0}$.
    \item The ring $R = \Z$ is Euclidean with the norm $N(n) = \left\vert n \right\vert$. 
    \item The ring $R = \F[x]$, where $\F$ is a field, is Euclidean with norm $N\colon \F\left[ x \right]\setminus \set{0}\rightarrow \N$ given by $N(f) = \deg(f)$.
  \end{itemize}
\end{example}
\begin{theorem}
  If $R$ is Euclidean, then $R$ is a principal ideal domain.
\end{theorem}
\begin{proof}
  Let $I\subseteq R$ be an ideal. If $I = \set{0}$, then $I$ is principal and we are done.\newline

  Else, suppose $I\neq 0$. There exists $\alpha\in I$ with $\alpha\neq 0$, so that $N(\alpha)$ is well-defined. Let $b\in I$ be such that $N(b)$ is minimal for all possible elements of $I$.\newline

  We claim that $I = \left( b \right)$. Let $a\in I$ be arbitrary, and perform Euclidean division on $a$ by $b$, yielding
  \begin{align*}
    a &= qb + r,
  \end{align*}
  where $r = 0$ or $N(r) < N(b)$.\newline

  If $r\neq 0$, then $N(r) < N(b)$, but $r = a - bq\in I$, which would contradict minimality of $N(b)$, so that $r = 0$, and thus $a = bq\in \left( b \right)$.
\end{proof}
\begin{theorem}
  The Gaussian integers, $\Z\left[ i \right]$, are Euclidean with norm
  \begin{align*}
    N\left(a + bi\right) &= a^2 + b^2.
  \end{align*}
\end{theorem}
\begin{proof}
  Observe that $N$ is multiplicative. If we let $\alpha = a + bi$ and $\beta = c + di$ with $\alpha,\beta\neq 0$, we want to show that there exist $\gamma$ and $\delta$ such that $\alpha = \beta \gamma + \delta$ and $\delta = 0$ or $N(\delta) < N(\beta)$.\newline

  Consider $\frac{\alpha}{\beta}\in \C$, so that
  \begin{align*}
    \frac{\alpha}{\beta} &= \frac{\left( a + bi \right)\left( c - di \right)}{c^2 + d^2}\\
                         &= \frac{\left( a + bi \right)\left( c -di \right)}{N(\beta)}\\
                         &\eqcolon x + yi,
  \end{align*}
  so that $ \frac{\alpha}{\beta}\in \Q\left[ i \right] $.\newline

  Now, we can find $x_0,y_0\in \Z$ such that $\left\vert x-x_0 \right\vert\leq \frac{1}{2}$ and $\left\vert y-y_0 \right\vert\leq \frac{1}{2}$. Setting $\delta = x_0 + y_0 i$, we have that $\delta = \alpha - \beta\gamma\in \Z\left[ i \right]$. We claim that if $\delta \neq 0$, then $N(\delta) < N(\beta)$.\newline

  Observe that since $N$ is multiplicative, this condition is equivalent to $N\left( \frac{\delta}{\beta} \right) < 1$. We observe that
  \begin{align*}
    N\left( \frac{\delta}{\beta} \right) &= N\left( \frac{\alpha - \beta \gamma}{\beta} \right)\\
                                         &= N\left( \frac{\alpha}{\beta} - \gamma \right)\\
                                         &= \left( x-x_0 \right)^2 + \left( y-y_0 \right)^2\\
                                         &\leq \frac{1}{2}\\
                                         &< 1.
  \end{align*}
\end{proof}
\begin{remark}
  While the remainder in Euclidean division for $\Z$ and $\F\left[ x \right]$ \textit{is} unique, this is not the case for general Euclidean domains. For instance, if we want to divide $a = 1 + i$ by $b = 2$ in $\Z\left[ i \right]$ with our previously specified norm, we find that 
  \begin{align*}
    1 + i &= 2\cdot 0 + \left( 1 + i \right) \\
          &= 2\cdot 1 + \left( -1 + i \right),
  \end{align*}
  both of which satisfy the conditions for Euclidean division.
\end{remark}
Now, in any PID (really, any UFD), we can talk about a greatest common divisor. In a principal ideal domain, the GCD for $a,b\in R$ is given by the unique (up to associates) element $d$ such that
\begin{align*}
  \left( a,b \right) &= \left( d \right).
\end{align*}
Meanwhile, greatest common divisors in a UFD are slightly more complicated. If we have two elements $a,b\in R$ with prime factorizations
\begin{align*}
  a &= up_1^{v_1}p_2^{v_2}\cdots p_n^{v_n}\\
  b &= vp_1^{w_1}p_2^{w_2}\cdots p_n^{w_n},
\end{align*}
then the greatest common divisor is given by
\begin{align*}
  \gcd\left( a,b \right) &= \prod_{i=1}^{n} p_i^{\operatorname{min}\left( v_i,w_i \right)}.
\end{align*}
This is defined up to associates, similar to how the factorization of any element is defined up to associates.
\subsection{Unique Factorization in Polynomial Rings}%
Our goal is to prove that if $R$ is a UFD, then $R[x]$ is a UFD.\newline

We do this by first discussing irreducibility in $R[x]$, including a full characterization of irreducible elements.
\begin{definition}
  Assume $R$ is a unique factorization domain, and let $0\neq f(x)\in R[x]$. Writing
  \begin{align*}
    f(x) &= a_nx^n + a_{n-1}x^{n-1} + \cdots + a_1 x + a_0,
  \end{align*}
  we define the \textit{content} of $f$, written $\operatorname{c}(f)$, to be
  \begin{align*}
    \operatorname{c}(f) &= \operatorname{gcd}\left( a_0,a_1,\dots,a_n \right).
  \end{align*}
\end{definition}
\begin{proposition}[Gauss's Lemma]
  Let $R$ be a UFD, and let $f(x),g(x)\in R[x]$ be nonzero polynomials. Then,
  \begin{align*}
    \operatorname{c}\left( f g \right) &= \operatorname{c}\left( f \right)\operatorname{c}\left( g \right).
  \end{align*}
\end{proposition}
\begin{proof}
  For any nonzero polynomial $h\in R[x]$, we may write
  \begin{align*}
    h(x) &= \operatorname{c}\left( h \right) z(x),
  \end{align*}
  where $\operatorname{c}\left( z \right) = 1$, simply by factoring. Thus, writing
  \begin{align*}
    f(x) &= \operatorname{c}\left( f \right) u(x)\\
    g(x) &= \operatorname{c}\left( g \right) v(x),
  \end{align*}
  where $\operatorname{c}\left( u \right) = \operatorname{c}\left( v \right) = 1$, hence
  \begin{align*}
    \operatorname{c}\left( fg \right) &= \operatorname{c}\left( \operatorname{c}\left( f \right)\operatorname{c}\left( g \right)u v \right)\\
                                      &= \operatorname{c}\left( f \right)\operatorname{c}\left( g \right)\operatorname{c}\left( uv \right).
  \end{align*}
  We want to show that $\operatorname{c}\left( u(x)v(x) \right) = 1$ (up to associates).\newline

  Suppose not. Since $ \operatorname{c}\left( uv \right) $ is nonzero and (assumed to be) not a unit, we may find a prime $p$ such that $ p | \operatorname{c}\left( u v \right) $. That is, we may find $p$ such that $p$ divides all coefficients of $u(x)v(x)$.\newline

  Consider now the reduction homomorphism
  \begin{align*}
    \pi\colon R[x]\rightarrow \left( R/\left( p \right) \right)[x],
  \end{align*}
  where we reduce all coefficients modulo $\left( p \right)$. Since $p$ is prime, $ \left( p \right) $ is prime, so that $R/\left( p \right)$ is an integral domain, meaning that $\left( R/\left( p \right) \right)[x]$ is an integral domain.\newline

  Since $ \operatorname{c}\left( u \right) = \operatorname{c}\left( v \right) = 1 $, it follows that $\pi\left( u(x) \right) \neq 0$ and $\pi\left( v(x) \right) \neq 0$, as at least one coefficient in $u(x)$ or $v(x)$ is not divisible by $p$. Thus, in $\left( R/\left( p \right) \right)[x]$ is a domain, it follows that $\pi\left( u(x) \right)\pi\left( v(x) \right)\neq 0$. Yet, since $\pi$ is a homomorphism, it follows that $0 = \pi\left( u(x)v(x) \right) = \pi\left( u(x) \right)\pi\left( v(x) \right)$, since we assumed that $p$ divides all the coefficients of $u(x)v(x)$.
\end{proof}
\begin{corollary}[Gauss's Lemma, Redux]
  Let $R$ be a UFD, and let $F = \operatorname{frac}\left( R \right)$. Let $f(x)\in R[x]$, and assume $f(x)$ is reducible in $F[x]$. Then, $f(x)$ is reducible in $R[x]$.
\end{corollary}
\begin{proof}
  Let $f(x)$ be reducible in $F[x]$, so that $f(x) = g(x)h(x)$, where $g(x)$ and $h(x)$ are nonconstant polynomials in $F[x]$.\newline

  By factoring, we have
  \begin{align*}
    g(x) &= \frac{a}{b}u(x)\\
    h(x) &= \frac{c}{d}v(x),
  \end{align*}
  where $a,b,c,d\in R\setminus \set{0}$, $u(x),v(x)\in R[x]$, and $ \operatorname{c}\left( u \right) = \operatorname{c}\left( v \right) = 1 $.\newline

  Substituting this information into the expression for $f(x)$, we have
  \begin{align*}
    f(x) &= \frac{ac}{bd}u(x)v(x)\\
    bd f(x) &= ac u(x)v(x),
  \end{align*}
  so that
  \begin{align*}
    bd \operatorname{c}\left( f \right)&= ac \operatorname{c}\left( u \right)\operatorname{c}\left( v \right).
  \end{align*}
  meaning
  \begin{align*}
    bd \operatorname{c}\left( f \right) &= ac.
  \end{align*}
  In particular, this means that $\frac{ac}{bd}$ is a valid representative for $\operatorname{c}\left( f \right)$, so that $ \frac{ac}{bd}\in R $. Therefore,
  \begin{align*}
    f(x) &= \left( \frac{ac}{bd}u(x) \right)v(x),
  \end{align*}
  both nonconstant and in $R[x]$, meaning $f(x)$ has a nontrivial factorization in $R[x]$, and thus $f$ is reducible.
\end{proof}
\begin{corollary}[Classification of Irreducibles]
  Let $R$ be a UFD, let $F = \operatorname{frac}\left( R \right)$, and let $f(x)\neq 0\in R[x]$.
  \begin{enumerate}[(i)]
    \item If $f(x)$ is constant, then $f$ is irreducible in $R[x]$ if and only if $f(x)$ is irreducible in $R$.
    \item If $f(x)$ is not constant, then $f$ is irreducible in $R[x]$ if and only if $\operatorname{c}\left( f \right) = 1$ and $f(x)$ is irreducible in $F[x]$.
  \end{enumerate}
\end{corollary}
\begin{proof}\hfill
  \begin{enumerate}[(i)]
    \item Observe that $R[x]$ and $R$ have the same units (since $R$ is an integral domain, and so admits no nilpotent elements), meaning that the product of two nonzero polynomials is a constant if and only if the polynomials themselves are constant.
    \item Let $f$ be nonconstant. If $f$ is irreducible in $R[x]$, then we may write
      \begin{align*}
        f(x) &= \operatorname{c}\left( f \right)u(x),
      \end{align*}
      where $u(x)$ is nonconstant and has $\operatorname{c}(u) = 1$. Yet, since $f$ is irreducible, it also follows that $\operatorname{c}(f) = 1$. Additionally, $f$ is irreducible in $F[x]$ by the contrapositive of Gauss's Lemma.\newline

      If $f$ is irreducible in $F[x]$, and has content $1$, then for any factorization
      \begin{align*}
        f(x) &= g(x)h(x),
      \end{align*}
      where $g(x),h(x)\in F[x]$, either $g$ or $h$ must be a constant. Now, since $f$ is contained in $R[x]$, we may take a common denominator to yield
      \begin{align*}
        f(x) &= a u(x),
      \end{align*}
      where $u(x)$ is nonconstant and has content $1$, with $a\in R$. Since $f$ has content $1$, it follows that $a$ is a unit element, meaning that any factorization of $f$ must contain a unit, so that $f$ is irreducible in $R[x]$.
  \end{enumerate}
\end{proof}
\begin{theorem}
  If $R$ is a UFD, then $R[x]$ is a UFD.
\end{theorem}
\begin{proof}
  Let $F = \operatorname{frac}(R)$, and let $f(x)\in R[x]$ be a nonzero, non-unit element. If $f(x)\in R$, then $f$ is a product of irreducibles in $R$ by part (i) of the classification, meaning the product is automatically unique up to permutation and associates as $R$ is a UFD.\newline

  Now, if $f$ is nonconstant, then $f(x)\in F[x]$ is nonzero and non-unit, as the units in $F[x]$ are the elements of $F$. Since $F[x]$ is a principal ideal domain (as $F[x]$ is a Euclidean domain, following from the division algorithm), $F[x]$ is a UFD, so we may write
  \begin{align*}
    f(x) &= \prod_{i=1}^{n}g_i(x),
  \end{align*}
  where the $g_i(x)$ are irreducible in $F[x]$. Writing
  \begin{align*}
    g_i(x) &= \frac{a_i}{b_i} u_i(x),
  \end{align*}
  where the $u_i(x)\in R[x]$ with $\operatorname{c}\left( u_i \right) = 1$ for each $i$, we have
  \begin{align*}
    \prod_{i=1}^{n}\frac{a_i}{b_i} &\in R,
  \end{align*}
  as $f(x)\in R[x]$, so we may write
  \begin{align*}
    f(x) &= \prod_{i=1}^{n} \frac{a_i}{b_i} \prod_{i=1}^{n}u_i(x).
  \end{align*}
  Each of the $u_i(x)$ are irreducible in $R[x]$ by the classification, and the product $\prod_{i=1}^{n}\frac{a_i}{b_i}\in R$ is either a unit or a product of irreducibles. This gives the existence of such a factorization for $f$.\newline

  To see uniqueness, if
  \begin{align*}
    f(x) &= \left( \prod_{i=1}^{k}a_i \right)\left( \prod_{i=1}^{m}p_i(x) \right)\\
         &= \left( \prod_{j=1}^{\ell}b_j \right)\left( \prod_{j=1}^{m}q_j(x) \right)
  \end{align*}
  are factorizations where $a_i,b_j$ are irreducible in $R$, and $p_i,q_j$ are nonconstant and irreducible with content $1$, then we may take the content of both sides, yielding
  \begin{align*}
    \operatorname{c}\left( \left( \prod_{i=1}^{k}a_i \right)\left( \prod_{i=1}^{k}p_i(x) \right) \right) &= \prod_{i=1}^{k}a_i\\
    \operatorname{c}\left( \left( \prod_{j=1}^{\ell}b_j \right)\left( \prod_{j=1}^{\ell}q_j(x) \right) \right) &= \prod_{j=1}^{\ell}b_j.
  \end{align*}
  Since contents are only well-defined up to associates, the most we can say is that
  \begin{align*}
    \prod_{i=1}^{k}a_i &= u\prod_{j=1}^{\ell}b_j,
  \end{align*}
  where $u\in R^{\times}$. Since there is at least one $q_j$, we may replace $q_1$ by $uq_1$, then divide, so that we find
  \begin{align*}
    \prod_{i=1}^{k}a_i &= \prod_{j=1}^{\ell}b_j.
  \end{align*}
  Since both of these are products of irreducibles in $R$, it follows that $k = \ell$ and, after permutation of factors, $b_i = u_i a_i$ for some $u_i\in R^{\times}$. Additionally, we also have the equality
  \begin{align*}
    \prod_{i=1}^{m}p_i &= \prod_{j=1}^{n}q_j.
  \end{align*}
  Since all of these factors are irreducible in $F[x]$, and $F[x]$ is a PID, we find that $ n= m $ and, upon permutation of factors, we have $q_i(x) = \gamma_ip_i(x)$ for some $\gamma_i\in F\setminus \set{0}$. Write
  \begin{align*}
    \gamma_i &= \frac{c_i}{d_i},
  \end{align*}
  where $c_i,d_i\in R\setminus \set{0}$, so that
  \begin{align*}
    d_i q_i(x) &= c_ip_i(x).
  \end{align*}
  Taking the content of both sides, we then get that $v_id_i = c_i$ for some $v_i\in R^{\times}$, so that $\gamma_i = v_i\in R^{\times}$, meaning that $p_i$ and $q_i$ are associates in $R[x]$.
\end{proof}
Unique factorization in polynomial rings having the rigidity laid out in the classification theorem makes for very useful criteria to understand irreducibility.
\begin{theorem}[Eisenstein's Criterion]
  Let $R$ be a UFD, and let $p\in R$ be a prime element. If we write $f(x)\in R[x]$ as
  \begin{align*}
    f(x) &= \sum_{i=0}^{n}a_ix^{i},
  \end{align*}
  then if
  \begin{itemize}
    \item $a_0\neq 0$;
    \item $p \nmid a_n$;
    \item $p | a_i$ for $0 \leq i \leq n-1$;
    \item and $p^2 \nmid a_0$,
  \end{itemize}
  then $f(x)$ is irreducible in $F[x]$. If, in addition, $\operatorname{c}(f) = 1$, then $f$ is irreducible in $R[x]$.
\end{theorem}
\begin{remark}
  This is the more general formulation of the case when $R = \Z$ and $f$ is monic that we see in undergrad abstract algebra.
\end{remark}
\begin{proof}
  Suppose toward contradiction that $f$ is reducible in $F[x]$, where we may write
  \begin{align*}
    f(x) &= g(x)h(x)
  \end{align*}
  with $g(x),h(x)\in R[x]$ nonconstant as in the proof of Gauss's Lemma. The reduction map $\pi\colon R[x]\rightarrow \left( R/\left( p \right) \right)[x]$ is a homomorphism, so that
  \begin{align*}
    \overline{f}(x) &= \overline{g}(x) \overline{h}(x).
  \end{align*}
  Thus, by our assumptions, we have
  \begin{align*}
    \overline{f}(x) &= \overline{a_n}x^{n},
  \end{align*}
  with $ \overline{a_n}\neq \overline{0} $. Since the degree of $ \overline{f} $ remains the same upon reduction, it follows that $ \overline{g} $ and $ \overline{h} $ have the same degrees as they had originally.\newline

  Observe that in a domain, the product of the highest-degree terms is the highest-degree term of the product, and similarly for the lowest-degree terms. Therefore, we must have $ \overline{g}(x) $ and $ \overline{h}(x) $ are monomials, as their product is a monomial. Writing
  \begin{align*}
  \overline{g}(x) &= \beta x^{k}\\
  \overline{h}(x) &= \gamma x^{\ell},
  \end{align*}
  with $\gamma,\beta\in R$ and $k = \deg(g)$, $\ell = \deg(h)$, we then get
  \begin{align*}
    g(x) &= bx^{k} + p u(x)\\
    h(x) &= cx^{\ell} + p v(x),
  \end{align*}
  where $k,\ell > 0$ and $u(x),v(x)\in R[x]$. Then,
  \begin{align*}
    f(x) &= \left( bx^{k} + pu(x) \right)\left( cx^{\ell} + pv(x) \right),
  \end{align*}
  whence the constant term of this product is divisible by $p^2$.
\end{proof}
\section{Modules}%
For this section, a ring $R$ may not be commutative nor unital.
\subsection{Basic Definitions}%
\begin{definition}
  Let $R$ be a ring. A \textit{left $R$-module} is a set $M$ with operations
  \begin{align*}
    +\colon M\times M&\rightarrow M\\
    \left( m,n \right) &\mapsto m+n\\
    .\colon R\times M&\rightarrow M\\
    \left( r,m \right) &\mapsto r\cdot m,
  \end{align*}
  satisfying the following axioms:
  \begin{description}[font=\normalfont]
    \item[(M0)] $\left( M,+ \right)$ is an abelian group;
    \item[(M1)] $\left( r+s \right)\cdot m = r\cdot m + s\cdot m$ for all $r,s\in R$ and $m\in M$;
    \item[(M2)] $\left( rs \right)\cdot m = r\cdot \left( s\cdot m \right)$ for all $r,s\in R$ and $m\in M$;
    \item[(M3)] $r\cdot \left( m+n \right) = r\cdot m + r\cdot n$ for all $r\in R$ and $m,n\in M$;
    \item[(M4)] if $R$ is unital, then $1\cdot m = m$ for all $m\in M$.
  \end{description}
  A \textit{submodule} $N\leq M$ of an $R$-module $M$ is an abelian subgroup such that $r\cdot n\in N$ for all $r\in R$ and $n\in N$.
\end{definition}
\begin{definition}
  If $N\leq M$ is a submodule, then the \textit{quotient module} $M/N$ is formed by taking equivalence classes of the form $m + N$, where $m+N = k + N$ if $m-k\in N$.
\end{definition}
\begin{definition}
  An $R$-module homomorphism between $M$ and $N$ is a map $\varphi\colon M\rightarrow N$ such that $\varphi$ is $R$-linear, in the sense that
  \begin{align*}
    \varphi\left( r\cdot m + s\cdot k \right) &= r\cdot\varphi(m) + s\cdot \varphi(k).
  \end{align*}
  The set of all homomorphisms between $R$-modules $M$ and $N$ is denoted $\hom_R(M,N)$, and forms an $R$-module itself under pointwise operations.\newline

  The set of all $R$-module \textit{endomorphisms} is denoted
  \begin{align*}
    \operatorname{end}_R(M) &\coloneq \hom_R\left( M,M \right),
  \end{align*}
  and forms a ring under pointwise operations and composition.\newline

  The space of $R$-module \textit{automorphisms} is denoted
  \begin{align*}
    \aut_R\left( M \right) &\coloneq \left( \operatorname{end}_R\left( M \right) \right)^{\times}.
  \end{align*}
\end{definition}
Modules admit the most ``natural'' form of the isomorphism theorems, as we only need to concern ourselves with submodules, rather than encountering issues like normal subgroups or ideals.
\begin{theorem}[Isomorphism Theorems for Modules]\hfill
  \begin{description}
    \item[First Isomorphism Theorem:] If $\varphi\colon M\rightarrow N$ is a homomorphism of $R$-modules, there is an induced isomorphism
      \begin{align*}
        \overline{\varphi}\colon M/\ker\left( \varphi \right)\rightarrow \img\left( \varphi \right),
      \end{align*}
      given by $ \overline{\varphi}\left( m + \ker\left( \varphi \right) \right) = \varphi(m) $.
    \item[Second Isomorphism Theorem:] If $A$ and $B$ are submodules of $M$, then there is an isomorphism
      \begin{align*}
        \frac{A + B}{A} &\cong \frac{A}{A\cap B},
      \end{align*}
      where 
      \begin{align*}
        A + B &= \set{m + n | m\in A,n\in B}.
      \end{align*}
    \item[Third Isomorphism Theorem:] If $A,B\leq M$ are submodules with $A\subseteq B$, then there is an isomorphism
      \begin{align*}
        M/B &\cong \frac{M/A}{B/A}.
      \end{align*}
    \item[Fourth Isomorphism Theorem:] If $B\leq M$ is a submodule, then there is a one to one correspondence between the set of submodules of $M/B$ and the set of submodules of $M$ containing $B$.
  \end{description}
\end{theorem}
\subsection{Some Special $R$-Modules}%
There are three special cases of $R$-modules that we will discuss here. The first one is pretty straightforward, while the other two are a bit more complex and will enable us to understand some particularly deep results later down the line.
\begin{example}
  If $F$ is a field, then the $F$-modules are precisely the vector spaces over $F$. This is because $F$-vector spaces and $F$-modules have the exact same axioms.
\end{example}
\begin{example}
  We claim that there is a one to one correspondence between $\Z$-modules and abelian groups.\newline

  One direction follows from applying a ``forgetful functor'' on $M$, taking $M\mapsto \left( M,+ \right)$, simply discarding the $\Z$-module structure of $M$. In fact, this can apply to all $R$-modules.\newline

  In the reverse direction, if $\left( M,+ \right)$ is an abelian group, then we can specify a compatible action by $\Z$ onto $M$ by taking
  \begin{align*}
    n\cdot a &= \begin{cases}
      \underbrace{a + \cdots + a}_{n\text{ times}} & n > 0\\
      0 & n = 0\\
      \underbrace{-a-\cdots-a}_{-n\text{ times}} & n < 0
    \end{cases}.
  \end{align*}
\end{example}
The last example is the most intriguing. In fact, as we will see towards the end, it ties directly to the Jordan Canonical Form, as we will see once we discuss the structure of finitely generated ideals over a principal ideal domain.
\begin{example}
  We want to understand the $F[x]$ modules, where $F$ is a field.\newline

  Now, first, observe that since constants are elements of $F[x]$, it immediately follows that if $V$ is a $F[x]$ module, then $V$ admits a compatible structure with respect to $F$, meaning that $V$ is in fact a vector space.\newline

  Now, observe that the action of $p(x)\in F[x]$ on $v\in V$ is fully determined by $x$, as
  \begin{align*}
    x^{n}\cdot v &= x\cdot \left( x\cdot \left( \cdots x\cdot v \right) \right).
  \end{align*}
  If we consider a single linear transformation $T\colon V\rightarrow V$, then by defining $T^{n} = T\circ\cdots\circ T$, we observe that for any $v\in V$, the map
  \begin{align*}
    p(T)(v) &= \left( a_nT^{n} + a_{n-1}T^{n-1} + \cdots a_n T + a_0 \right)v
  \end{align*}
  is an action on $v\in V$; we may then consider the pair $\left( V,T \right)$ to be the corresponding $F[x]$-module. The reverse direction follows from defining $T\colon V\rightarrow V$ by $Tv = x\cdot v$.\newline

  Observe then that the $F[x]$-submodules of a $F[x]$-module $V$ are precisely the $T$-invariant subspaces of $V$.
\end{example}
\subsection{Free Modules and Direct Sums}%
\begin{definition}
  Let $R$ be a ring, $M$ an $R$-module, $X\subseteq M$. Then, we call 
  \begin{align*}
    R\cdot X &= \set{r\cdot x | r\in R, x\in X}
  \end{align*}
  the submodule \textit{generated by} $X$. We also write $ \left\langle X \right\rangle $.
\end{definition}
\begin{definition}\hfill
  \begin{itemize}
    \item We say $X\subseteq M$ is \textit{$R$-linearly independent} if
      \begin{align*}
        a_1\cdot x_1 + \cdots + a_n\cdot x_n &= 0
      \end{align*}
      for any $x_1,\dots,x_n\in X$ and $a_1,\dots,a_n\in R$ implies that $a_1,\dots,a_n = 0$.
    \item A subset $X$ of $M$ is called an \textit{$R$-basis} if $X$ is $R$-linearly independent and $\left\langle X \right\rangle = M$.
    \item We say $M$ is a \textit{free} $R$-module if $M$ admits a basis.
  \end{itemize}
\end{definition}
\begin{theorem}
  Every $\F$-vector space $V$ has a basis. Furthermore, the following hold:
  \begin{itemize}
    \item if $X$ is a generating set for $V$, then $X$ contains a basis;
    \item if $X$ is a linearly independent subset of $V$, then $X$ can be extended to a basis.
  \end{itemize}
\end{theorem}
\begin{example}
  This does not always hold if we are not dealing with vector spaces. For instance, $\Z$ is a free $\Z$-module, but $\set{2}$ is a $\Z$-linearly independent subset that cannot be extended to a basis for $\Z$. This follows from the fact that $\set{2,n}$ for any $n\neq 2$ is $\Z$-dependent.\newline

  Similarly, $\set{2,3}$ is a generating set for $\Z$ as $\operatorname{gcd}\left( 2,3 \right) = 1$, yet $X$ does not contain any $\Z$-bases.
\end{example}
\begin{definition}[External Direct Sum]\hfill
  \begin{enumerate}[(a)]
    \item Let $M_1,\dots,M_r$ be $R$-modules. The \textit{external direct sum} $M_1\oplus\cdots\oplus M_n$ is a module with coordinatewise operations consisting of elements $\left( m_1,\dots,m_r \right)$ with $m_i\in M_i$.
    \item If $\set{M_i}_{i\in I}$ is an indexed family of $R$-modules, then the external direct sum of $\set{M_i}_{i\in I}$ is defined as
      \begin{align*}
        \bigoplus_{i\in I}M_i &\coloneq \set{f\colon I\rightarrow \coprod_{i\in I}M_i | f(i)\in M_i, f\text{ is finitely supported}}.
      \end{align*}
  \end{enumerate}
\end{definition}
\begin{theorem}
  Let $M$ be a free $R$-module, $\Sigma$ a cardinal number. The following are equivalent
  \begin{enumerate}[(i)]
    \item $M$ has a basis with cardinality $\Sigma$;
    \item $M\cong \bigoplus_{i\in \Sigma}R$ as $R$-modules.
  \end{enumerate}
\end{theorem}
\begin{proof}
  Let $M$ have an $R$-basis indexed by $\Sigma$, written $\set{m_i}_{i\in \Sigma}$. Then, for every $y\in M$, we may write
  \begin{align*}
    y &= \sum_{i\in \Sigma} r_i\cdot m_i,
  \end{align*}
  where $r_i = 0$ for all but finitely many such $i\in \Sigma$.\newline

  Now, consider the map
  \begin{align*}
    \varphi\colon M&\rightarrow \bigoplus_{i\in \Sigma}R\\
    \sum_{i\in\Sigma}r_i\cdot m_i &\mapsto \set{f_y\colon \Sigma\rightarrow R | f_y(i) = r_i}.
  \end{align*}
  Since the expression is unique, it follows that $\varphi$ is well-defined, and is an $R$-module homomorphism that is injective by the definition of a basis. Furthermore, we can define an inverse for $\varphi$ by defining
  \begin{align*}
    \psi\colon \bigoplus_{i\in\Sigma}R &\rightarrow M\\
    f &\mapsto \sum_{i\in\Sigma}f(i)\cdot m_i.
  \end{align*}
  Therefore, $M\cong \bigoplus_{i\in \Sigma}R$.\newline

  Now, if $M\cong \bigoplus_{i\in \Sigma}R$, then letting
  \begin{align*}
    X &= \set{e_i | e_i\colon \Sigma\rightarrow R, e_i\left( i \right) = 1, e_i\left( j \right) = 0\text{ for all }j\neq i},
  \end{align*}
  we claim that $X$ is an $R$-basis of $\bigoplus_{i\in \Sigma} R$. Toward this end, we only need to verify that $X$ spans $R$. If $f\in \bigoplus_{i\in \Sigma}R$, then $f$ is a finitely supported function from $\Sigma$ to $R$, so we may write
  \begin{align*}
    f &= \sum_{k=1}^{n} f\left( i_k \right)\cdot e_{i_k}.
  \end{align*}
\end{proof}
\begin{corollary}
  If $M$ and $N$ are free modules with bases of the same cardinality, then $M\cong N$.
\end{corollary}
We now turn our focus towards other ways to build up a large family of modules.
\begin{definition}
  If $\set{M_i}_{i\in I}$ is a collection of $R$-modules, then the \textit{direct product}, 
  \begin{align*}
    M &= \prod_{i\in I}M_i
  \end{align*}
  is the Cartesian product of the $M_i$ with coordinatewise operations.
\end{definition}
\begin{theorem}[Universal Property of Products]
  Let $\set{M_i}_{i\in I}$ be a family of $R$-modules, and let
  \begin{align*}
    M &= \prod_{i\in I}M_i
  \end{align*}
  be the direct product.
  \begin{enumerate}[(i)]
    \item We have that $M$ admits a family of projection homomorphisms
      \begin{align*}
        \pi_j\colon M&\rightarrow M_j\\
        \left( m_i \right)_{i\in I} &\mapsto m_j.
      \end{align*}
    \item Given an $R$-module $N$ with $R$-module homomorphisms $f_j\colon N\rightarrow M_j$, there exists a unique $R$-module homomorphism $f\colon N\rightarrow M$ such that $\pi_j\circ f = f_j$.
      \begin{center}
        % https://q.uiver.app/#q=WzAsMyxbMCwwLCJOIl0sWzEsMCwiXFxwcm9kX3tpXFxpbiBJfU1faSJdLFsxLDEsIk1faiJdLFswLDEsImYiXSxbMSwyLCJcXHBpX2oiXSxbMCwyLCJmX2oiLDJdXQ==
\[\begin{tikzcd}
	N & {\prod_{i\in I}M_i} \\
	& {M_j}
	\arrow["f", from=1-1, to=1-2]
	\arrow["{f_j}"', from=1-1, to=2-2]
	\arrow["{\pi_j}", from=1-2, to=2-2]
\end{tikzcd}\]
      \end{center}
  \end{enumerate}
\end{theorem}
\begin{theorem}[Universal Property of Direct Sum]
  Let $\set{M_i}_{i\in I}$ be a family of $R$-modules, and let $L = \bigoplus_{i\in I}M_i$ be the direct sum.\newline

  Then, for an $R$-module $N$ and a family of $R$-module homomorphisms $g_j\colon M_j\rightarrow N$, there exists a unique $R$-module homomorphism $g\colon L\rightarrow N$ such that $g\circ \iota_j = g_j$, where $\iota_j$ is the inclusion of $M_j$ into $L$, given by $m_j\mapsto \left( 0,0,\dots,m_j,0,0,\dots \right)$.
  \begin{center}
    % https://q.uiver.app/#q=WzAsMyxbMCwwLCJNX2oiXSxbMSwwLCJcXGJpZ29wbHVzX3tpXFxpbiBJfU1faSJdLFsxLDEsIk4iXSxbMCwxLCJmIl0sWzEsMiwiXFxwaV9qIl0sWzAsMiwiZl9qIiwyXV0=
\[\begin{tikzcd}
	{M_j} & {\bigoplus_{i\in I}M_i} \\
	& N
	\arrow["f", from=1-1, to=1-2]
	\arrow["{f_j}"', from=1-1, to=2-2]
	\arrow["{\pi_j}", from=1-2, to=2-2]
\end{tikzcd}\]
  \end{center}
\end{theorem}
\begin{proposition}
  Let $\set{M_i}_{i\in I}$ be a family of $R$-submodules of a fixed $R$-module $M$. The following are equivalent:
  \begin{enumerate}[(i)]
    \item the sum $\sum_{i\in I}M_i$ is a direct sum;
    \item for all $j\in I$ and all $i_1,\dots,i_n\in I\setminus \set{j}$,
      \begin{align*}
        M_j\cap \left( \sum_{k=1}^{n}M_{i_k} \right) &= \set{0}.
      \end{align*}
  \end{enumerate}
\end{proposition}
\begin{theorem}[Universal Property of Free Modules]
  Let $M$ be a free $R$-module with basis $X$. Then, for any $R$-module $N$ and set map $f\colon X\rightarrow N$, there exists a unique $R$-module homomorphism $ \widetilde{f}\colon M\rightarrow N $ such that $\widetilde{f}|_{X} = f$.
  \begin{center}
    % https://tikzcd.yichuanshen.de/#N4Igdg9gJgpgziAXAbVABwnAlgFyxMJZABgBoBGAXVJADcBDAGwFcYkQANEAX1PU1z5CKchWp0mrdgDkefEBmx4CRMsXEMWbRCACyPcTCgBzeEVAAzAE4QAtkjIgcEJKJCN6AIxiMACgOVhECssYwALHBAaTSkdCzlLG3tER2ckACZoyW0QAB1c-Bx6BJBrOwyaNMQ3GJz8gHcsWDxGWGALbgNuIA
\begin{tikzcd}
M \arrow[rd, "\widetilde{f}"]        &   \\
X \arrow[r, "f"'] \arrow[u, "\iota"] & N
\end{tikzcd}
  \end{center}
\end{theorem}
\begin{corollary}
  Every $R$-module is a quotient of a free module.
\end{corollary}
\begin{proof}
  Let $M$ be an $R$-module, and let $F = R[M]$ be the free module generated by the elements of $M$. Then, it follows that $\id\colon M\rightarrow M$ is a bijective set map, which then extends to a surjective module homomorphism $q\colon F\rightarrow M$. By the first isomorphism theorem, it follows that $M\cong F/\ker\left( q \right)$. 
\end{proof}
\begin{definition}
  We call the module $\ker\left( q \right)$ the \textit{module of relations} for $M$. Generally speaking, we seek to understand the minimal such module.
\end{definition}
\subsection{Noetherian Properties}%
For this subsection, we fix a unital, commutative ring $R$. Recall that $R$ is Noetherian if and only if every ascending chain of ideals stabilizes, if and only if every ideal is finitely generated.\newline

We can give a similar description for Noetherian \textit{modules}. We will use this in the proof of a much-celebrated theorem related to polynomial rings.
\begin{proposition}
  Let $M$ be an $R$-module. The following are equivalent:
  \begin{enumerate}[(i)]
    \item Every submodule of $M$ is finitely generated;
    \item every ascending chain of submodules stabilizes;
    \item every nonempty set of submodules has a maximal element.
  \end{enumerate}
\end{proposition}
\begin{proposition}
  Let $M$ be a Noetherian $R$-module, with $N\leq M$. Then, both $N$ and $M/N$ are Noetherian.
\end{proposition}
\begin{proof}
  Let $N'\leq N$; then, $N'\leq M$, whence $N'$ is finitely generated, so $N$ is Noetherian.\newline

  Meanwhile, recall that all $R$-submodules of $M/N$ correspond to modules of the form $N'/N$, where $N\leq N'\leq M$, by the Fourth Isomorphism Theorem. Therefore, $N'$ is finitely generated, so $N'/N$ is finitely generated.
\end{proof}
\begin{proposition}
  Suppose $N\leq M$ and $M/N$ are Noetherian. Then, so too is $M$.
\end{proposition}
\begin{proof}
  Let $K\leq M$ be an $R$-submodule. We will show that $K$ is finitely generated.\newline

  Consider $K\cap N\leq N$. Since $N$ is Noetherian, $K\cap N$ is finitely generated, so it admits generators $x_1,\dots,x_n$. Similarly, since $\frac{K+N}{N}\leq M/N$ is a submodule of the Noetherian module $M/N$, so there are generators $y_1 + N,\dots,y_m + N$ of $\frac{K+N}{N}$.\newline

  In particular, since each of the $y_i$ can be written as $k_i + n_i$, with $y_i + N = k_i + N$, we may say without loss of generality that each of the $y_i$ are elements of $K$.\newline

  We claim now that $\left\langle x_1,\dots,x_n,y_1,\dots,y_m \right\rangle = K$. We call this generating set $X$. In particular, we observe already that $\left\langle X \right\rangle \leq K$, so we only need to show the other inclusion.\newline

  Let $z\in K$. Then, $z\in K + N$, meaning $z + N \in \frac{K+N}{N}$. Therefore, we have $r_1,\dots,r_m$ such that $z + N = r_1\cdot y_1 + N + \cdots + r_m\cdot y_m + N$. In particular, this means that $\left( z - \sum_{i=1}^{m}r_i\cdot y_i \right)\in N\cap K$. Since $\left\langle x_1,\dots,x_n \right\rangle = K\cap N$, we have $s_1,\dots,s_n\in R$ such that
  \begin{align*}
    z - \left( r_1\cdot y_1 + \cdots + r_m\cdot y_m \right) &= s_1\cdot x_1 + \cdots + s_n\cdot x_n.
  \end{align*}
  Thus, $\left\langle X \right\rangle = K$.
\end{proof}
\begin{theorem}
  If $R$ is a Noetherian ring, then any finitely generated $R$-module is Noetherian.
\end{theorem}
\begin{proof}
  We start by proving that every finitely generated free $R$-module is Noetherian. Then, if $M$ is an arbitrary finitely generated module, then $M$ is a quotient of a finitely generated free module, and the Noetherian property is inherited under quotients.\newline

  We prove by induction on the rank. If $F $ is free of rank $n$, then $F\cong R^{n}$. If $n = 1$, then $F\cong R$ as $R$-modules. Since the submodules of $R$ are exactly the ideals, $F$ is Noetherian as an $R$-module as every ideal of $R$ is finitely generated.\newline

  Inductively, if $F \cong R^{n}$, then the submodule $R\cong R\times \set{0}^{n-1}$ is Noetherian, and
  \begin{align*}
    R^{n-1} &\cong \frac{R^{n}}{R\times \set{0}^{n-1}}
  \end{align*}
  is Noetherian by the inductive hypothesis. Thus, $R^{n}$ is Noetherian by the previous proposition.
\end{proof}
\begin{theorem}[Hilbert Basis Theorem]
  If $R$ is a Noetherian ring, then $R[x]$ is Noetherian.
\end{theorem}
\begin{proof}
  Let $I\subseteq R[x]$ be a nonzero ideal. Define the set
  \begin{align*}
    J &= \set{a\in R | \text{there exists }f(x)\in I\text{ with leading coefficient }a}.
  \end{align*}
  We claim that $J$ is an ideal of $R$. Towards this end, let $a\in J$ and $r\in R$, with $a\neq 0$. Then, there exists $f(x)\in I$ with $f(x) = ax^{n} + \text{LOT}$. We observe that $r f(x)\in I$, whence $ra x^{n} + \text{LOT}\in I$, so that $ra\in J$.\newline

  Now, let $a,b\in J$, and let $f(x) = ax^{n} + \text{LOT}$ and $g(x) = bx^{m} + \text{LOT}$, with $f(x),g(x)\in I$. Without loss of generality, $n\geq m$, so we may multiply $x^{n-m}g(x)\in I$ to take $x^{n-m}g(x) = bx^{n} + \text{LOT}$, so that $f(x) - x^{n-m}g(x)\in I$ and thus $a-b\in J$.\newline

  Now, since $R$ is Noetherian, and $J\subseteq R$ is an ideal, we have $J = \left( a_1,\dots,a_n \right)$ for some $a_1,\dots,a_n\in R$. We may find corresponding elements of $I$, which we write $f_i(x) = a_i x^{d_i} + \text{LOT}$. Set $d = \max\set{d_i | 1\leq i \leq r}$. Consider the $R$-module
  \begin{align*}
    M &= \left( R + Rx + \cdots + Rx^{d-1} \right)\cap I\\
      &= \set{\text{polynomials in }I\text{ with degree less than }d-1}\cup \set{0}.
  \end{align*}
  Note that $M$ is finitely generated as an $R$-module, as $M\leq R + Rx + \cdots + Rx^{d-1}$ and the latter is Noetherian as an $R$-module as it is a finitely generated module over a Noetherian ring.\newline

  We may write $M = \left( g_1(x) ,\dots, g_s(x) \right)$ as a result. We claim that
  \begin{align*}
    I &= \left( f_1(x),\dots,f_r(x),g_1(x),\dots,g_s(x) \right).
  \end{align*}
  Write $I_0 = \left( f_1(x),\dots,f_r(x) \right)$. We claim that if $f(x)\in I$ is such that $\deg(f) > d-1$, then there exists $h(x)\in I_0$ such that $\deg\left( f-h \right) < \deg\left( f \right)$. This will allow us to take $p(x)\in I$ and decompose it into constituent parts by repeatedly applying the claim to yield an element $h\in I_0$ with $\deg\left( p-h \right)\leq d-1$, or $p(x) - h(x) = 0$, which yields an element of $I_0$ and an element of $M$.\newline

  Now, let $f(x)\in I$ have degree $n\geq d$. In particular, $n\geq d_i$ for all $i= 1,\dots,r$. Writing
  \begin{align*}
    f(x) = cx^n + \text{LOT},
  \end{align*}
  we then have a leading coefficient $c = \ell_1a_1 + \cdots + \ell_r a_r$ with $\ell_1,\dots,\ell_r\in R$. We take
  \begin{align*}
    h(x) = \ell_1x^{n-d_1}f_1(x) + \cdots + \ell_rx^{n-d_r} f_r(x),
  \end{align*}
  and observe that $h$ has leading term equal to $cx^{n}$. Thus, $\deg\left( f-h \right) < \deg\left( f \right)$. The rest follows from induction.
\end{proof}
The Hilbert Basis Theorem and the theorem on finitely generated modules over Noetherian rings together allow us to create a large family of Noetherian modules. For instance, if $R$ is Noetherian, then
\begin{align*}
  \left( \frac{R\left[ x_1,\dots,x_n \right]}{I} \right)\left[ y_1,\dots,y_m \right]
\end{align*}
is Noetherian.
\subsection{A Taste of Homological Algebra}%
\begin{definition}
  A sequence of $R$-modules homomorphisms 
  \begin{center}
    % https://tikzcd.yichuanshen.de/#N4Igdg9gJgpgziAXAbVABwnAlgFyxMJZABgBpiBdUkANwEMAbAVxiRAEEQBfU9TXfIRQBGclVqMWbAELdeIDNjwEiAJjHV6zVohABhbuJhQA5vCKgAZgCcIAWyRkQOCElETtbS3Ku2HidxckdQ8pXRNDLiA
    \begin{tikzcd}
    A \arrow[r, "f"] & B \arrow[r, "g"] & C
    \end{tikzcd}
  \end{center}
  is called \textit{exact} if $\ker\left( g \right) = \img\left( f \right)$. More generally, a sequence of $R$-module homomorphisms
  \begin{center}
    % https://tikzcd.yichuanshen.de/#N4Igdg9gJgpgziAXAbVABwnAlgFyxMJZABgBpiBdUkANwEMAbAVxiRAEEB9ARhAF9S6TLnyEU3clVqMWbLgCZ+gkBmx4CReZOr1mrRCAA6hgMZQIOBAKFrRRAMzbpeuZ0J8pMKAHN4RUABmAE4QALZIZCA4EEgSzrIGATxKgSHhiHHRSFrx+iBJitb5adnUWYiOuWxJ7hR8QA
    \begin{tikzcd}
    A_1 \arrow[r, "f_1"] & A_2 \arrow[r, "f_2"] & \cdots \arrow[r, "f_n"] & A_n
    \end{tikzcd}
  \end{center}
  is called exact if $\ker\left( f_{i+1} \right) = \img\left( f_i \right)$ for each $i$.
\end{definition}
\begin{definition}
  The special case of an exact sequence is one of the following form.
  \begin{center}
    % https://tikzcd.yichuanshen.de/#N4Igdg9gJgpgziAXAbVABwnAlgFyxMJZABgBpiBdUkANwEMAbAVxiRGJAF9T1Nd9CKAIzkqtRizYBBLjxAZseAkQBMo6vWatEIAEKzeigUQDM68VrYBhA-L5LByACznNknR05iYUAObwiUAAzACcIAFskMhAcCCQhbmCwyMQRGLjENQt3ECDbUIikLNikM2ztEF985NLqEsQnL04gA
    \begin{tikzcd}
    0 \arrow[r] & A \arrow[r, "f"] & B \arrow[r, "g"] & C \arrow[r] & 0
    \end{tikzcd}
  \end{center}
  Here, $f$ is injective, $g$ is surjective, and $\ker\left( g \right) = \img\left( f \right)$. We call such sequences \textit{short exact} sequences.
\end{definition}
\begin{example}\hfill
  \begin{enumerate}[(a)]
    \item The sequence
      \begin{center}
        % https://tikzcd.yichuanshen.de/#N4Igdg9gJgpgziAXAbVABwnAlgFyxMJZABgBpiBdUkANwEMAbAVxiRGJAF9T1Nd9CKAIzkqtRizYA5LjxAZseAkQBMo6vWatEIALKzeigUQDM68Vra6A9DO6H+ylABZzmyTo6cxMKAHN4IlAAMwAnCABbJDIQHAgkIXsQMMiE6jikNQsPZINk8KjELIzEM2ztED88lMKykudvTiA
        \begin{tikzcd}
        0 \arrow[r] & N \arrow[r, "\iota"] & M \arrow[r, "\pi"] & M/N \arrow[r] & 0
        \end{tikzcd}
      \end{center}
      is a short exact sequence.
    \item If $M$ is an $R$-module, then $M$ slots into a short exact sequence of $R$-modules given by the following.
      \begin{center}
        % https://tikzcd.yichuanshen.de/#N4Igdg9gJgpgziAXAbVABwnAlgFyxMJZABgBpiBdUkANwEMAbAVxiRGJAF9T1Nd9CKAIzkqtRizYA5LjxAZseAkQBMo6vWatEIAGKzeigUQDM68VrYBZA-L5LByACznNknR05iYUAObwiUAAzACcIAFskMhAcCCQhbmCwyMQRGLjEFUSQUIikNXSkE2zclLNCxCcvTiA
        \begin{tikzcd}
        0 \arrow[r] & N \arrow[r] & F \arrow[r] & M \arrow[r] & 0
        \end{tikzcd}
      \end{center}
      Here, $F$ is free and $N$ is the module of relations.
  \end{enumerate}
\end{example}
If $f\colon M\rightarrow N$ is an $R$-module homomorphism, and $P$ is a fixed $R$-module, then there is a canonical induced homomorphism
\begin{align*}
  f_{\ast}\colon \hom\left( P,M \right) &\rightarrow \hom\left( P,N \right)\\
  \left[ P\xrightarrow{\varphi}M \right] &\mapsto \left[ P\xrightarrow{\varphi}M\xrightarrow{f}N \right]
\end{align*}
given by $f_{\ast}\left( \varphi \right) = f\circ\varphi$.
\begin{proposition}
  Suppose we start with a short exact sequence of $R$-modules.
  \begin{center}
    % https://tikzcd.yichuanshen.de/#N4Igdg9gJgpgziAXAbVABwnAlgFyxMJZABgBpiBdUkANwEMAbAVxiRGJAF9T1Nd9CKAIzkqtRizYAZLjxAZseAkQBMo6vWatEIALKzeigUQDM68VrYA5A-L5LByACznNknR05iYUAObwiUAAzACcIAFskMhAcCCQhbmCwyMQRGLjENQt3ECDbUIikLNikM2ztEF985NLqEsQnL04gA
    \begin{tikzcd}
    0 \arrow[r] & L \arrow[r, "f"] & M \arrow[r, "g"] & N \arrow[r] & 0
    \end{tikzcd}
  \end{center}
  Then, the sequence
  \begin{center}
    % https://tikzcd.yichuanshen.de/#N4Igdg9gJgpgziAXAbVABwnAlgFyxMJZABgBpiBdUkANwEMAbAVxiRGJAF9T1Nd9CKAIzkqtRizYAdKQAsIAWwAUABVIAZAJRceIDNjwEiAJlHV6zVohAz5ytQFlt3XgYFEAzGfGXpcxaqkAHLOYjBQAObwRKAAZgBOikhkIDgQSEIuIAlJiCKp6YimPpLWsQD6wDJ0cDicOnGJCkjFaUheJVYgEZXVtfWcFJxAA
    \begin{tikzcd}
    0 \arrow[r] & {\hom(P,L)} \arrow[r, "f_{\ast}"] & {\hom(P,M)} \arrow[r, "g_{\ast}"] & {\hom(P,N)}
    \end{tikzcd}
  \end{center}
  is exact for all $R$-modules $P$.
\end{proposition}
\begin{remark}
  The converse also holds.
\end{remark}
\begin{proof}
  Suppose the sequence of $R$-modules is exact. Then, $f$ is injective, $g$ is surjective, and $\img\left( f \right) = \ker\left( g \right)$. We start by showing that $f_{\ast}$ is injective.\newline

  Toward this end, let $\varphi\in \ker\left( f_{\ast} \right)$. Then, for all $x\in P$, we have $f\left( \varphi\left( x \right) \right) = 0$, whence $\varphi\left( x \right) = 0$, so $\varphi$ is zero.\newline

  Next, we observe that $\img\left( f_{\ast} \right)\subseteq \ker\left( g_{\ast} \right)$, as $g_{\ast}\circ f_{\ast} = \left( g\circ f \right)_{\ast} = 0$ as the original sequence is exact. Now, if $\varphi\in \ker\left( g_{\ast} \right)$, then $\varphi\colon P\rightarrow M$ is an $R$-module homomorphism such that $g\circ\varphi = 0$. If $p\in P$, then $g\left( \varphi\left( p \right) \right) = 0$, meaning that $\varphi\left( p \right) \in \ker\left( g \right)$. Since $f$ is injective and $\ker\left( g \right) = \img\left( f \right)$, we have that there is unique $a\in L$ such that $\varphi\left( p \right) = f(a)$. Define $\psi\colon P\rightarrow L$ by $p\mapsto a$. Observe that since $f$ is a homomorphism, so too is $\psi$.
\end{proof}
Note that $g_{\ast}$ may not be surjective. The cases for $P$ where $g_{\ast}$ \textit{is} surjective are special to have their own definition.
\begin{definition}
  An $R$-module $P$ is called \textit{projective} if, for all short exact sequences of $R$-modules
  \begin{center}
    % https://tikzcd.yichuanshen.de/#N4Igdg9gJgpgziAXAbVABwnAlgFyxMJZABgBpiBdUkANwEMAbAVxiRGJAF9T1Nd9CKAIzkqtRizYAZLjxAZseAkQBMo6vWatEIALKzeigUQDM68VrYA5A-L5LByACznNknR05iYUAObwiUAAzACcIAFskMhAcCCQhbmCwyMQRGLjENQt3ECDbUIikLNikM2ztEF985NLqEsQXcrZPCk4gA
    \begin{tikzcd}
    0 \arrow[r] & L \arrow[r, "f"] & M \arrow[r, "g"] & N \arrow[r, "0"] & 0
    \end{tikzcd}
  \end{center}
  the sequence
  \begin{center}
    % https://tikzcd.yichuanshen.de/#N4Igdg9gJgpgziAXAbVABwnAlgFyxMJZABgBpiBdUkANwEMAbAVxiRGJAF9T1Nd9CKAIzkqtRizYAdKQAsIAWwAUABVIAZAJRceIDNjwEiAJlHV6zVohAz5ytQFlt3XgYFEAzGfGXpcxaqkAHLOuvr8RigALN4WktYcnGIwUADm8ESgAGYATopIZCA4EEhCLiC5+YgiRSWIpj7xFQD6wDJ0cDicOtl5CkgNxUhejVYgqa3tnd3llf2II0OIMaNsiRScQA
    \begin{tikzcd}
    0 \arrow[r] & {\hom(P,L)} \arrow[r, "f_{\ast}"] & {\hom(P,M)} \arrow[r, "g_{\ast}"] & {\hom(P,N)} \arrow[r, "0"] & 0
    \end{tikzcd}
  \end{center}
  is also exact.
\end{definition}
Equivalently, this means that for all surjections $M\xrightarrow{\pi}N\rightarrow 0$, and all homomorphisms $\varphi\colon P\rightarrow N$, there is \textit{some} $\widetilde{\varphi}\colon P\rightarrow M$ such that $\pi\circ \widetilde{\varphi} = \varphi$.
\begin{center}
  % https://tikzcd.yichuanshen.de/#N4Igdg9gJgpgziAXAbVABwnAlgFyxMJZABgBoBGAXVJADcBDAGwFcYkQBZEAX1PU1z5CKchWp0mrdgDkefEBmx4CRAExiaDFm0Qhic-kqFFRxcVqm6ACj3EwoAc3hFQAMwBOEALZIAzDRwIJFEJbXYAHXCGdzQACywDEA9vPwCgxDJQyxBIgHcsWDxGWGBI6LisbhAaRnoAIxhGKwFlYRB3LAdYnGqQRiwwHRAoejhY+0Tknwy04M1JIci0BN43T2mQwKRVbkpuIA
    \begin{tikzcd}
                       & P \arrow[d, "\varphi"] \arrow[ld, "\widetilde{\varphi}"', dashed] &   \\
    M \arrow[r, "\pi"] & N \arrow[r]                                                       & 0
    \end{tikzcd}
\end{center}

\end{document}
