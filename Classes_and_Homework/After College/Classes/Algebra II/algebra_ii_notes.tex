\documentclass[10pt]{mypackage}

\usepackage{mlmodern}
%\usepackage{newpxtext,eulerpx,eucal}
%\renewcommand*{\mathbb}[1]{\varmathbb{#1}}

%\usepackage{homework}
\usepackage{notes}

%\usepackage[ backend=bibtex, style = alphabetic, sorting=ynt ]{biblatex}
%\addbibresource{  }

\usepackage{parskip}

\fancyhf{}
\fancyhead[R]{Avinash Iyer}
\fancyhead[L]{Algebra II: Class Notes}
\fancyfoot[C]{\thepage}

\setcounter{secnumdepth}{0}

\begin{document}
\RaggedRight
The primary text for Algebra II is Dummit and Foote's \textit{Abstract Algebra}, and will cover the following topics:
\begin{itemize}
  \item modules and advanced linear algebra;
  \item representation theory of finite groups;
  \item field theory and Galois theory.
\end{itemize}
\tableofcontents
\section{Modules and Advanced Linear Algebra}%
\subsection{Tensor Products of Modules}%
The first major topic in Modules and Advanced Linear Algebra is tensor products.
\subsubsection{Introduction and Basic Definitions}%
To motivate tensor products, we recall a basic fact from linear algebra. If we assume that $R$ is a field, and $M,N$ are finite-dimensional $R$-vector spaces, then the following equation necessarily holds:
\begin{align*}
  \dim\left( M\oplus N \right) &= \dim\left( M \right) + \dim\left( N \right).
\end{align*}
We want to construct a similar operation on vector spaces, $M\otimes N$, that satisfies
\begin{align*}
  \dim\left( M\otimes N \right) &= \dim\left( M \right)\dim\left( N \right).
\end{align*}
For now, we will label this by $M\bar{\otimes}N$, where we use the $\bar{\otimes}$ to refer to the fact that this is a temporary definition. Naively, we might seek to define $M\bar\otimes N$ as follows. If we let $\set{x_1,\dots,x_k}$ be a basis for $M$ and $\set{y_1,\dots,y_{\ell}}$ a basis for $N$, then we will define $M\bar\otimes N$ to be all the formal $R$-linear combinations over the basis
\begin{align*}
  B &= \set{x_i\otimes y_j | 1\leq i \leq k,1\leq j \leq \ell}.
\end{align*}
While this is technically correct --- as in, this does yield a vector space with
\begin{align*}
  \dim\left( M\bar\otimes N \right) &= \dim\left( M \right)\dim\left( N \right),
\end{align*}
the issue is that this definition is not canonical, in that it depends on chosen bases for $M$ and $N$. Furthermore, it is not clear how one may generalize from this definition to modules over arbitrary rings, which do not necessarily have bases. To resolve this issue, we will go about defining a construction that ``extends,'' in a sense, this definition of $M\bar\otimes N$.

To start, we define the simple tensor $m\otimes n$ for any $m\in M$ and $n\in N$. If we let
\begin{align*}
  m &= \sum_{i=1}^{k}\lambda_i x_i\\
  n &= \sum_{j=1}^{\ell}\mu_j y_j,
\end{align*}
then we will define
\begin{align*}
  m\otimes n &= \sum_{i=1}^{k}\sum_{j=1}^{\ell} \lambda_i\mu_j \left( x_i\otimes y_j \right).
\end{align*}
We observe that every element of $M\bar\otimes N$ is a sum (i.e., an \textit{integral} linear combination) of simple tensors, as by regrouping we may take
\begin{align*}
  \sum_{i=1}^{k}\sum_{j=1}^{\ell}\lambda_{ij}\left( x_i\otimes y_j \right) &= \sum_{i=1}^{k}\sum_{j=1}^{\ell} \left( \lambda_{ij}x_i \right)\otimes y_j.
\end{align*}
The simple tensors satisfy the following relations:
\begin{enumerate}[(R1)]
  \item $\left( m_1 + m_2 \right)\otimes n = m_1\otimes n + m_2\otimes n$;
  \item $m\otimes \left( n_1 + n_2 \right) = m\otimes n_1 + m\otimes n_2$;
  \item $\left( \alpha m \right)\otimes n = m\otimes \left( \alpha n \right)$
\end{enumerate}
for $m,m_1,m_2\in M$, $n,n_1,n_2\in N$, and $\alpha\in R$.
\begin{proposition}
  These are the defining relations for $M\bar\otimes N$ in the category of abelian groups.
\end{proposition}
We will simply take this proposition as fact.

Now, let
\begin{align*}
  Q &= M\times N\\
    &= \set{\left( m,n \right) | m\in M,n\in N}
\end{align*}
be the Cartesian product of $M$ and $N$ as sets. We will then take $\Z\left[ Q \right]$ to be the standard free $\Z$-module (i.e., free abelian group) on $Q$. That is, $\Z\left[ Q \right]$ is the set of formal linear combinations
\begin{align*}
  v &= \sum_{q\in Q} \lambda_q q,
\end{align*}
where $\lambda_q\in \Z$ and only finitely many coefficients are nonzero. By the universal property of free abelian groups, the map $\left( m,n \right)\mapsto m\otimes n$ descends to a unique homomorphism $\varphi\colon\Z\left[ Q \right]\rightarrow M\bar\otimes N$. Such a homomorphism is necessarily surjective as every element of $M\bar\otimes N$ is an integral linear combination of simple tensors, meaning that we have
\begin{align*}
  M\bar\otimes N &\cong \Z\left[ Q \right]/\ker\left( \varphi \right)
\end{align*}
as abelian groups.

Now, consider the subgroup of $\Z\left[ Q \right]$, which we denote $ \left\langle K \right\rangle $, that is generated by the following elements:
\begin{enumerate}[(I)]
  \item $\left( m_1 + m_2,n \right) - \left( m_1,n \right) - \left( m_2,n \right)$;
  \item $\left( m,n_1 + n_2 \right) - \left( m,n_1 \right) - \left( m,n_2 \right)$;
  \item $\left( \alpha m,n \right) - \left( m,\alpha n \right)$
\end{enumerate}
for $m_1,m_2,m\in M$, $n_1,n_2,n\in N$, and $\alpha\in R$. Then, from proposition that the relations (R1) through (R3) define $M\bar\otimes N$, it follows that $\left\langle K \right\rangle = \ker\left( \varphi \right)$. Thus, we may define the tensor product canonically as follows.
\begin{definition}
  Letting $M,N,Q,K$ be as above, we define
  \begin{align*}
    M\otimes N &\coloneq \Z\left[ Q \right]/\left\langle K \right\rangle, \label{def:tensor_product_modules}\tag{$\dag$}
  \end{align*}
  and define $m\otimes n = \left( m,n \right) + K$.
\end{definition}
So far, this has only given us an abelian group. We may ask how to define $\Z\left[ Q \right]/\left\langle K \right\rangle$ as an $R$-vector space, which naturally seems to be defined by
\begin{align*}
  r\left( \sum_{i=1}^{n}m_i\otimes n_i \right) &= \sum_{i=1}^{n}\left( rm_i \right)\otimes n_i \label{eq:scalar_multiplication_tensor_product}\tag{$\ast$}
\end{align*}
To show that the right-hand side of \eqref{eq:scalar_multiplication_tensor_product} is well-defined is a very difficult task. We will not do it here.

Now, we can actually quite easily generalize \eqref{def:tensor_product_modules} to modules over non-fields.
\begin{itemize}
  \item If $R$ is a commutative ring with $1$, and $M$ and $N$ are left $R$-modules, the definition in \eqref{def:tensor_product_modules} copies over exactly.
  \item If $R$ is non-commutative with $1$, then the definition in \eqref{def:tensor_product_modules} makes sense, but the scalar multiplication in \eqref{eq:scalar_multiplication_tensor_product} does \textit{not} hold.

    In fact, we need to change the assumptions for $M$ and $N$ as $R$-modules. In particular, we need $M$ to be a \textit{right} $R$-module, and $N$ to be a left $R$-module, and take the generators of type (III) for $K$ to be defined by
    \begin{description}[font=\normalfont]
      \item[(III')] $\left( mr,n \right)-\left( m,rn \right)$
    \end{description}
    for $m\in M$, $n\in N$, and $r\in R$. This gives the tensor product $M\otimes_{R}N$ an abelian group structure, but does not endow it with a $R$-module structure.
\end{itemize}
We may now consider some simple examples computing tensor products.
\begin{example}
  Let $R = \Z$. We will show that $\Z/n\Z\otimes_{R}\Q = 0$.

  As a general strategy, in order to show that a tensor product is the zero module, it suffices to show for every simple tensor. Observe that $0\otimes y = 0$ for any tensor product, since we may take
  \begin{align*}
    0\otimes y &= \left( 0 + 0 \right)\otimes y\\
               &= 0\otimes y + 0\otimes y.
  \end{align*}
  Therefore, we may write
  \begin{align*}
    \left[ a \right]\otimes b &= \left( n\left[ a \right] \right)\otimes \left( \frac{b}{n} \right)\\
                              &= \left[ na \right]\otimes \frac{b}{n}\\
                              &= 0\otimes \frac{b}{n}\\
                              &= 0.
  \end{align*}
\end{example}
\subsubsection{Universal Property}%
We may now work towards understanding one of the defining properties of tensor products in general. This requires a discussion of a weakened version of $R$-bilinear maps.
\begin{definition}
  Let $R$ be a ring, $M$ a right $R$-module, $N$ a left $R$-module, and $L$ an abelian group written additively. A map $\varphi\colon M\times N \rightarrow L$ is called \textit{$R$-balanced} if
  \begin{description}[font=\normalfont]
    \item[(BM1)] $\varphi\left( m_1 + m_2,n \right) = \varphi\left( m_1,n \right) + \varphi\left( m_2,n \right)$
    \item[(BM2)] $\varphi\left( m,n_1 + n_2 \right) = \varphi\left( m,n_1 \right) + \varphi\left( m,n_2 \right)$
    \item[(BM3)] $\varphi\left( mr,n \right) = \varphi\left( m,rn \right)$
  \end{description}
  for all $r\in R$, $m,m_1,m_2\in M$, and $n,n_1,n_2\in N$.
\end{definition}
\begin{theorem}
  Let $R,M,N,L$ be as above. Let
  \begin{align*}
    \Omega &= \set{\Phi\colon M\otimes N\rightarrow L | \Phi\text{ a group homomorphism}}\\
    \Delta &= \set{\varphi\colon M\times N\rightarrow L | \varphi\text{ $R$-balanced}}.
  \end{align*}
  Define the map $J\colon \Omega\rightarrow \Delta$ by
  \begin{align*}
    \left( J\Phi \right)(m,n) &= \Phi(m\otimes n).
  \end{align*}
  Then, $J$ is bijective.
\end{theorem}
\begin{proof}
  We have that $J$ is injective since $J\Phi$ captures the value of $\Phi$ on simple tensors, and $\Phi$ is completely determined by its value on simple tensors since $\Phi$ is a group homomorphism, and elements of $M\otimes N$ are sums of simple tensors.

  To prove surjectivity, we recall that
  \begin{align*}
    M\otimes N &= \Z\left[ M\times N \right]/\left\langle K \right\rangle.
  \end{align*}
  Let $\varphi\colon M\times N\rightarrow L$ be an $R$-balanced map. By the universal property for free modules, there is a homomorphism $ \widetilde{\varphi}\colon \Z\left[ M\times N \right]\rightarrow L $ taking $\left( m,n \right)\mapsto \varphi\left( m,n \right)$.

  We only need to show now that $\widetilde{\varphi}$ kills the elements of $K$ that generate $\left\langle K \right\rangle$, but this follows from the fact that $\varphi$ is $R$-balanced. Therefore, we get an induced map
  \begin{align*}
    \Phi\colon M\otimes N&\rightarrow L\\
    m\otimes n &\mapsto \varphi\left( m,n \right),
  \end{align*}
  so we are done.
\end{proof}
\begin{definition}
	Let $R$ be a commutative ring, $M,N,L$ left $R$-modules. A map $\varphi\colon M\times N\rightarrow L$ is called $R$-bilinear if it satisfies (BM1), (BM2), and
	\begin{description}[font=\normalfont]
		\item[(BM3')] $\varphi \left( m,rn \right) = \varphi \left( rm, n  \right) = r \varphi \left( m,n \right)$
    \end{description}
\end{definition}
\begin{theorem}
    If $R,M,N,L$ are as above, then there exists a natural bijection between $\hom_{R} \left( M\otimes N, L\right)$ and $\hom_{R} \left( M\times N, L \right)$.
\end{theorem}
The proof is the same as the proof in the case of $R$-balanced maps, mutatis mutandis.
\begin{proposition}
	Let $R$ be a commutative ring, and $M,N$ free left $R$-modules with respective bases $X$ and $Y$. Then, $M\otimes N$ is a free module with basis
	\begin{align*}
		Z &= \set{x\otimes y | x\in X,y\in Y}.
	\end{align*}
\end{proposition}
\begin{proof}
    We have that $Z$ generates $M\otimes N$ as a $R$-module, so we only need to show that $Z$ is linearly independent.

    Let
    \begin{align*}
        v &= \sum_{i=1}^{t}r_ix_i\otimes y_i.
    \end{align*}
    Without loss of generality, we assume that $r_1\neq 0$. It is enough to find a homomorphism $\varphi\colon M\otimes N\rightarrow R$ such that $\varphi(v)\neq 0$.

    Toward this end, we construct an $R$-bilinear map, which we only need to specify on the basis. Define
    \begin{align*}
	\alpha\colon M&\rightarrow R\\
	x_i &\mapsto \begin{cases}
		0 & x_i\neq x_1 \\
		1 & x_i = x_1
        \end{cases}\\
    \beta\colon N&\rightarrow R\\
    y_i &\mapsto \begin{cases}
	0 & y_i\neq y_1\\
	1 & y_i = y_1
    \end{cases}.
    \end{align*}
    The map $\varphi\colon M\times N\rightarrow R$ given by $\varphi \left( x_i, y_i \right) = \alpha \left( x_i \right) \beta \left( y_i \right)$ is thus $R$-bilinear and induces a map on the tensor product that is nonzero at $v$. Thus, $v$ is not the zero vector.
\end{proof}
\subsubsection{Module Structure on Tensor Products}%
Thus far, we have only shown that there is a module structure on the tensor product whenever we are considering modules over commutative rings. Else, we only have an abelian group. We will specify the case when there is a module structure on the tensor product.
\begin{definition}
  Let $R$ and $S$ be unital rings. An $\left( S,R \right)$-bimodule is an abelian group $\left( M,+ \right)$ that is both a left $S$-module and right $R$-module satisfying the compatibility condition
  \begin{align*}
    \left( sm \right)r &= s\left( mr \right)
  \end{align*}
  for all $m\in M$, $r\in R$, and $s\in S$.
\end{definition}
\begin{example}\hfill
  \begin{enumerate}[(i)]
    \item If $R$ and $S$ are both subrings of the same ring $T$ with $1_R = 1_S = 1_T$, then $T$ is an $\left( S,R \right)$ bimodule, where $S$ acts by left-multiplication and $R$ acts by right-multiplication.
    \item If $R$ is commutative, $M$ a left $R$-module, then $M$ can be considered as an $\left( R,R \right)$-bimodule by setting $m.r = rm$.
  \end{enumerate}
\end{example}
\begin{proposition}
  Let $R$ and $S$ be rings, $M$ an $\left( S,R \right)$-bimodule, and $N$ a right $R$-module. Then, $M\otimes N$ can be endowed with a unique $S$-module structure by taking $s\left( m\otimes n \right) = sm\otimes n$.
\end{proposition}
\begin{proof}
  Fix $s\in S$. Define the map $\varphi_s\colon M\times N\rightarrow M\otimes_{R}N$ by taking $\varphi_s\left( m,n \right) = sm\otimes n$.

  This map is $R$-balanced; we will verify (BM3) for this purpose:
  \begin{align*}
    \varphi_s\left( mr,n \right) &= s\left( mr \right)\otimes n\\
                                 &= \left( sm \right)r\otimes n\\
                                 &= sm\otimes rn\\
                                 &= \varphi_s\left( m,rn \right).
  \end{align*}
  Thus, by the universal property, there is a homomorphism of abelian groups $ \overline{\varphi_s}\colon M\otimes N\rightarrow M\otimes N $ such that $ \overline{\varphi_s}\left( m\otimes n \right) = sm\otimes n$. We will then define the action of $s$ on $M\otimes N$ by taking $s.u = \overline{\varphi_s}(u)$ for any $u\in M\otimes N$.
\end{proof}
The most useful case for this proposition is the \textit{extension of scalars}. If $R\subseteq S$ is a unital subring, then we may view $S$ as an $\left( S,R \right)$-bimodule; for any left $R$-module $N$, we have that $S\otimes_{R}N$ may be endowed with the structure of an $S$-module. We call this module the extension of scalars of $N$ from $R$ to $S$.
\begin{definition}
  Let $R$ be a commutative ring with $1$. An $R$-algebra is a ring $A$ which is also an $R$-module such that multiplication $\mu\colon A\times A\rightarrow A$, $\mu\left( a,b \right) = ab$ is an $R$-bilinear map.
\end{definition}
\begin{example}[Some $R$-algebras]
  The following are $R$-algebras:
  \begin{enumerate}[(i)]
    \item the polynomial ring $R\left[ x_1,\dots,x_n \right]$ in commuting variables;
    \item the ring of noncommutative polynomials $R \left\langle x_1,\dots,x_n \right\rangle$;
    \item the matrices $\Mat_n\left( R \right)$ of $n\times n$ matrices over $R$.
  \end{enumerate}
\end{example}
\begin{theorem}
  Let $A$ and $B$ be $R$-algebras, where $R$ is commutative. Then, $A\otimes B$ has a unique $R$-algebra structure such that
  \begin{align*}
    \left( a\otimes b \right)\left( c\otimes d \right) &= ac\otimes bd.
  \end{align*}
\end{theorem}
\begin{proof}
  See Proposition 1.4.3 in \href{https://ai.avinash-iyer.com/Classes_and_Homework/College/Y4/Honors\%20Thesis/Amenability\%20Text/amenability.pdf}{this document}.
\end{proof}
\begin{lemma}
  If $R\subseteq S$ is a unital subring, with $S$ commutative, and $M$ is an $R$-algebra, then $S\otimes_{R}M$ is an $S$-algebra.
\end{lemma}
\begin{lemma}
  With the same assumptions as above, we have isomorphisms
  \begin{align*}
    S\otimes_{R}\Mat_n\left( R \right) &\cong \Mat_n\left( S \right)\\
    S\otimes_{R} R\left[ x_1,\dots,x_n \right] &\cong S\left[ x_1,\dots,x_n \right]\\
  S\otimes_{R} R[x]/\left( f(x) \right) &\cong S[x]/\left( f(x) \right).
  \end{align*}
\end{lemma}
The general proof approach for these types of problems is to use the universal properties to construct an isomorphism of abelian groups, then prove that the isomorphism is compatible with the $S$-action and products of elements.
\subsection{Finitely Generated Modules over PIDs}%
We will now turn our focus towards proving the structure theorem for finitely generated modules over a PID. For this, we will use the Smith Normal Form.
\subsubsection{Smith Normal Form}%
\begin{definition}
  Let $R$ be a PID, and $A\in \Mat_n\left( R \right)$. We say $A$ is in Smith normal form if there exists $m\leq \min\left( k,n \right)$ and elements $d_1,\dots,d_m$ such that
  \begin{align*}
    A &= \begin{pmatrix}d_1 & \cdots & 0 & 0 \\ 0 & \ddots & 0 & 0\\
      0 &0 &  d_m & 0 \\
      \vdots & \vdots & \ddots & \vdots\\
    0 & 0 & \cdots & 0\end{pmatrix},
  \end{align*}
  where $d_i\neq 0$ for all $i$ and $ \left( d_1 \right)\supseteq \left( d_2 \right)\supseteq\cdots\supseteq \left( d_m \right) $.
\end{definition}
\begin{theorem}
  If $R$ is a PID with $A\in \Mat_n\left( R \right)$, then there are $U\in \GL_k\left( R \right)$ and $V\in \GL_n\left( R \right)$ such that $UAV$ is in Smith normal form.

  This decomposition is essentially unique, in that if we have two Smith normal forms
  \begin{align*}
    D &= \begin{pmatrix}d_1' & \cdots & 0 & 0 \\ 0 & \ddots & 0 & 0\\
      0 &0 &  d_m & 0 \\
      \vdots & \vdots & \ddots & \vdots\\
    0 & 0 & \cdots & 0\end{pmatrix}\\
    D' &= \begin{pmatrix}d_1' & \cdots & 0 & 0 \\ 0 & \ddots & 0 & 0\\
      0 &0 &  d_s' & 0 \\
      \vdots & \vdots & \ddots & \vdots\\
    0 & 0 & \cdots & 0\end{pmatrix},
  \end{align*}
  then $s = m$ and $d_i$ and $d_i'$ are associates for each $i$.
\end{theorem}
To show existence, we consider the elementary row (and column) operations, viewed as elementary matrices. Given $\lambda\in R$, we consider $E_{ij}(\lambda)$ with $i < j$ to be a square matrix of size to be determined size that has $1$ along the diagonal, $\lambda$ in position $(i,j)$, and $0$ everywhere else. Furthermore, for any $i\neq j$, we let $F_{ij}$ be the matrix obtained from an identity matrix of a certain size by swapping rows $i$ and $j$.\footnote{One may recognize this as the matrix corresponding to the permutation $\tau = \left( i,j \right)$.} Then, we have the following table of correspondences.
\begin{center}
  \renewcommand{\arraystretch}{1.5}
  \begin{tabular}{c|c}
    Elementary Row Operation & Interpretation as Matrix Multiplication\\
    \hline
    $R_i(A) \mapsto R_i(A) + \lambda R_j(A)$ & $A\mapsto A_{ij}(\lambda)A$\\
    $C_i(A) \mapsto C_i(A) + \lambda C_j(A)$ & $A\mapsto AE_{ji}(\lambda)$\\
    $R_i(A) \leftrightarrow R_j(A)$ & $A\mapsto F_{ij}A$\\
    $C_i(A)\leftrightarrow C_j(A)$ & $A\mapsto AF_{ij}$
  \end{tabular}
\end{center}
Thus, it suffices to show that every $A$ can be replaced via these elementary row operations to a matrix in Smith normal form.

We will prove the special case where $R$ is a Euclidean domain, since the primary applications we will be using are for the cases of $\Z$ and $F[x]$ for some field $F$, and both of these rings are Euclidean domains. If $N$ is the Euclidean norm for $R$, then we will let $N(A) = \min_{a_{ij}\neq 0}N\left( a_{ij} \right)$ denote the norm of the matrix.
\begin{proof}[Proof of Existence]
  By induction, we may assume that existence holds for any matrices with smaller values of $k + n$. Starting with an arbitrary matrix with dimensions $k\times n$, we claim that we can reduce any nonzero matrix to either
  \begin{enumerate}[(i)]
    \item a matrix $A'$ with smaller norm
    \item a matrix of the block diagonal form
      \begin{align*}
        \begin{pmatrix}d_1 & 0 \\ 0 & B\end{pmatrix},\label{eq:block_diag_form_snf}\tag{$\dag$}
      \end{align*}
      where $d_1$ divides all the entries of $B$.
  \end{enumerate}
  To see that this suffices to prove existence of Smith normal form, we start by seeing that if case $1$ occurs, we apply the reduction until case $2$ occurs, which necessarily happens by the well-ordering principle. Then, if $A$ is reduced to a matrix of the block diagonal form \eqref{eq:block_diag_form_snf}, then by the induction hypothesis we may reduce $B$ to Smith normal form using the elementary operations. We may then apply these same operations to $A$ to yield $A$ to have $d_2 | d_3 |\cdots | d_m$ and the block $d_1$ on the upper left hand corner, so since these elementary row operations yield $R$-linear combinations of the original element, with $d_1$ dividing all the entries of $B$, we have that $d_1 | d_2$.

  Now, we will show that this is satisfactory. Using column and row flips, we may assume that $N\left( A \right) = N\left( a_{11} \right)$. Write
  \begin{align*}
    a_{1j} &= a_{11}q_{1j} + r_{1j}\\
    a_{i1} &= a_{11}q_{i1} + r_{i1}
  \end{align*}
  for all $2\leq i,j\leq n$. Then, for any $i$ and $j$, we have $N\left( r_{i1} \right) < N\left( a_{11} \right)$ and $N\left( r_{1j} \right)\leq N\left( a_{11} \right)$, or we have $N\left( r_{i1} \right) = 0$ or $N\left( r_{1j} \right) = 0$. By applying the operations $C_j(A) \mapsto C_j(A) - q_{1j}C_1(A)$ and $R_i(A) \mapsto R_i(A) - q_{i1}R_1(A)$, we may perform the replacements $a_{i1}\mapsto r_{i1}$ and $a_{1j}\mapsto r_{1j}$. If there is at least one such nonzero remainder, then we have $N\left( A' \right) < N(A)$, and this shows case (i).

  If all the remainders are $0$, then we have the block diagonal form \eqref{eq:block_diag_form_snf}, and split into two subcases. If we had $a_{11} | b_{ij}$ for all $b_{ij}\in B$, then we would be done. Else, suppose there were some $s,t \geq 2$ with $a_{11}\nmid a_{st}$. In this case, we may first perform the operation $R_1(A')\mapsto R_1(A') + R_s(A')$, write $a_{st} = a_{11}q + r$ with $r\neq 0$, and then perform $C_t(A) = C_t(A) - qC_1(A)$ to find that $N(A')$ is not minimal, so we may perform the process further. This gives existence.
\end{proof}
\end{document}
