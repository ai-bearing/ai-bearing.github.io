\documentclass[10pt]{mypackage}

% sans serif font:
%\usepackage{cmbright}
%\usepackage{sfmath}
%\usepackage{bbold} %better blackboard bold

\usepackage{homework}
%\usepackage{notes}
\usepackage{newpxtext,eulerpx,eucal}
\renewcommand*{\mathbb}[1]{\varmathbb{#1}}

\fancyhf{}
\rhead{Avinash Iyer}
\lhead{Differential Topology: Problem Set 3}

\setcounter{secnumdepth}{0}

\begin{document}
\RaggedRight
\begin{problem}[Problem 1]
  Let $f\colon M\rightarrow N$ be a smooth map of manifolds. Prove that the graph of $f$ is a smooth submanifold of $M\times N$.
\end{problem}
\begin{solution}
  Let $\left( U,\varphi \right)$ be a chart on $M$ with $\varphi\left( U \right)\cong \R^{m}$, and $\left( V,\psi \right)$ a chart on $N$ with $\psi\left( V \right)\cong \R^{n}$ and $f\left( U \right)\subseteq V$.\newline

  Let $U\times V$ be the corresponding open set in $M\times N$, and let $\left( p,q \right)\in U\times V$. We will define a coordinate map on $\rho\colon U\times V\rightarrow \R^{m}\times \R^{n}$ given by $\rho\left( p,q \right) = \left( \varphi(p),\psi(q) - \psi\left( f(p) \right) \right)$. We observe in particular that if $\left( p,q \right) = \left( p,f(p) \right)\in \Gamma(f)\cap \left( U\times V \right)$, then $\rho\left( p,f(p) \right) = \left( \varphi(p),0 \right)$, meaning that $\rho$ is a smooth chart for $\Gamma(f)$.
\end{solution}
\begin{problem}[Problem 2]
  Let $\operatorname{U}(n)$ be the set of unitary complex $n\times N$ matrices. Write $\operatorname{SU}\left( n \right)\leq \operatorname{U}(n)$ for the kernel of the determinant map.
  \begin{enumerate}[(a)]
    \item Show that $\operatorname{U}(1)$ is diffeomorphic to the circle, so that $\operatorname{SU}(1)$ is a point.
    \item Prove that $\operatorname{U}(n)$ is a smooth manifold.
    \item Prove that $\operatorname{SU}(2)$ is diffeomorphic to $S^{3}$, the three-sphere.
    \item Prove that $\operatorname{U}(2)$ is diffeomorphic to $S^{1}\times S^{3}$.
  \end{enumerate}
\end{problem}
\begin{solution}\hfill
  \begin{enumerate}[(a)]
    \item Since complex $1\times 1$ matrices are diffeomorphic to $\C$, we see that $x\in \operatorname{U}(1)$ if and only if $\left\vert x \right\vert^2 = 1$, meaning $\left\vert x \right\vert = 1$, so $x = e^{i\theta}$ for some $\theta$. In particular, this means that the assignment $x\mapsto e^{i\theta}$ gives a diffeomorphism between $S^{1}$ and $\operatorname{U}(1)$.
    \item Consider the self-map $f\colon \Mat_{n}\left( \C \right)\rightarrow \Mat_{n}\left( \C \right)\cong \C^{n^2}$ given by $f(A) = A^{\ast}A$. Note that this maps $\Mat_{n}\left( \C \right)$ to positive semi-definite (Hermitian) matrices $\Mat_{n}\left( \C \right)^{+}\subseteq \Mat_{n}\left( \C \right)_{\operatorname{s.a.}}$.\newline

      Observe that an element of the tangent space to $A\in \Mat_{n}\left( \C \right)$ is given by $ s_B = A + tB $, where $t\in \R$ and $B\in \Mat_{n}\left( \C \right)$. Applying $f$, we get
      \begin{align*}
        f\left( A + tB \right) &= A^{\ast}A + t\left( A^{\ast}B + B^{\ast}A \right) + t^2 B^{\ast}B;
      \end{align*}
      meaning that $D_Af$ applied to $s_B$ yields $A^{\ast}A + t\left( A^{\ast}B + B^{\ast}A \right)$.\newline

      Note that if $A$ is unitary and $B$ is Hermitian, then $\left( AB \right)^{\ast}\left( AB \right) = B^{\ast}B$, and
      \begin{align*}
        A^{\ast}A + t\left( A^{\ast}\left( AB \right) + \left( AB \right)^{\ast}A \right) &= I + 2tB,
      \end{align*}
      meaning that $D_Af$ is surjective onto the tangent space at the identity when $A$ is unitary (after a scaling), so $I$ is a regular value for $f$.
    \item We view $S^{3}$ as a subset of $\C^{2}$, so that $S^{3}$ consists of all $\left( z_1,z_2 \right)$ such that
      \begin{align*}
        \left\vert z_1 \right\vert^2 + \left\vert z_2 \right\vert^2 &= 1.
      \end{align*}
      We claim that the matrix
      \begin{align*}
        A_{z_1,z_2} &= \begin{pmatrix}z_1 & z_2 \\ - \overline{z_2} & \overline{z_1}\end{pmatrix}
      \end{align*}
      is an element of $\operatorname{SU}\left( 2 \right)$. Since it is uniquely determined by $z_1$ and $z_2$ in $S^{3}$, it follows that $\operatorname{SU}(2)$ is diffeomorphic to $S^{3}$.\newline

      To see this, observe that
      \begin{align*}
        \det\left( A \right) &= 1\\
        A^{\ast}A &= \begin{pmatrix} \overline{z_1} & -z_2\\ \overline{z_2} & z_1\end{pmatrix} \begin{pmatrix}z_1 & z_2 \\ - \overline{z_2} & \overline{z_1}\end{pmatrix}\\
                  &= \begin{pmatrix}\left\vert z_1 \right\vert^2 + \left\vert z_2 \right\vert^2 & z_2 \overline{z_1} - z_2 \overline{z_1}\\ z_1 \overline{z_2} - z_1 \overline{z_2} & \left\vert z_1 \right\vert^2 + \left\vert z_2 \right\vert^2\end{pmatrix}\\
                  &= \begin{pmatrix}1 & 0 \\ 0 & 1\end{pmatrix}.
      \end{align*}
      Therefore, $\operatorname{SU}(3)$ is diffeomorphic to $S^{3}$, with the diffeomorphism given by coordinate assignment.
    \item Observe that if $\left( z_1,z_2 \right) = z\in S^{3}\subseteq \C^{2}$, then if $a\in \operatorname{U}(2)$, we have $az\in S^{3}$. In particular, since unitary matrices are invertible, the operation of $a\in \operatorname{U}(2)$ on $z\in S^{3}$ by multiplication is a group action.\newline

      We observe now that the action of $\operatorname{U}(2)$ on $S^{3}\subseteq \C^{2}$ by matrix multiplication is transitive, since for any element $\left( w_1,w_2 \right)\in S^{3}$, the matrix
      \begin{align*}
        \begin{pmatrix}w_1 & - \overline{w_2} \\ w_2 & \overline{w_1}\end{pmatrix} \begin{pmatrix}1\\0\end{pmatrix} &= \begin{pmatrix}w_1\\w_2\end{pmatrix},
      \end{align*}
      and
      \begin{align*}
        \begin{pmatrix} \overline{w_1} & \overline{w_2} \\ -w_2 & w_1\end{pmatrix} \begin{pmatrix}w_1 & - \overline{w_2} \\ w_2 & \overline{w_1}\end{pmatrix} &= \begin{pmatrix}1 & 0 \\ 0 & 1\end{pmatrix}.
      \end{align*}
      Additionally, we observe that for any $\theta$,
      \begin{align*}
        \begin{pmatrix}1 & 0 \\ 0 & e^{i\theta}\end{pmatrix} \begin{pmatrix}1\\0\end{pmatrix} &= \begin{pmatrix}1\\0\end{pmatrix},
      \end{align*}
      meaning 
      \begin{align*}
        S^{3} &\cong \operatorname{U}(2)/ P,
      \end{align*}
      where $P$ consists of all matrices of the form
      \begin{align*}
        Q &= \begin{pmatrix}1 & 0 \\ 0 & e^{i\theta}\end{pmatrix}.
      \end{align*}
      We observe that $P$ is diffeomorphic to $S^{1}$ via a coordinate assignment, so $\operatorname{U}(2)\cong S^{3}\times S^{1}$.
  \end{enumerate}
\end{solution}
\begin{problem}[Problem 3]
  In this exercise, we will prove the Frobenius theorem.\newline

  Let $M$ be a smooth manifold of dimension $n$, and let $D$ be an $r$-dimensional distribution on $M$, where $r\leq n$. That is, $D$ picks out an $r$-dimensional $D_p$ of $T_pM$ for each $p\in M$. In other words, at every point, there are $r$ distinguished, linearly independent vector fields defined in a neighborhood of the point.\newline

  A submanifold $N\subseteq M$ is called an \textit{integral submanifold} for $D$ if $T_pN = D_p$ for each $p\in M$. We say $D$ is \textit{completely integrable} if an integral submanifold exists through every point. Integral curves of a vector field are integral submanifolds of a vector field.\newline

  We call a distribution that is closed under taking Lie brackets involutive. That is, for any vector fields $X,Y\in D$ (i.e., local $1$-distributions that lie in $D$), then $\left[ X,Y \right]\in D$.\newline

  The Frobenius Theorem says that a distribution $D$ on $M$ is completely integrable if and only if it is involutive.
  \begin{enumerate}[(a)]
    \item Show that if $D$ is a completely integrable distribution, then $D$ is involutive.
    \item We say vector fields $X$ and $Y$ commute if $ \left[ X,Y \right] = 0 $. For fixed vector fields $X$ and $Y$, write $\varphi_t$ and $\psi_t$ for the corresponding flows. Show that the following are equivalent:
      \begin{enumerate}[(i)]
        \item $X$ and $Y$ commute;
        \item $Y$ is invariant under $\varphi_t$;
        \item the flows $\varphi_t$ and $\psi_t$ commute, so that $\psi_s\circ \varphi_t = \varphi_t\circ \psi_s$ for all $t$ and $s$ where defined.
      \end{enumerate}
    \item Assume $D$ is $r$-dimensional. Choose local coordinates $\set{x_1,\dots,x_n}$ near a point $p$ and $r$ linearly independent vector fields $Y_1,\dots,Y_r$ near $p$. Write $Y_i$ as
      \begin{align*}
        Y_{i} &= \sum_{j=1}^{n} a_{ij} \pd{}{x_j},
      \end{align*}
      and show that there is some permutation of the coordinates such that the $r\times r$ matrix $\left( a_{ij} \right)_{1\leq i,j\leq r}$ is invertible near $p$.
    \item Let $\left( b_{ij} \right)_{1\leq i,j\leq r}$ be the inverse of the smoothly varying family of matrices $\left( a_{ij} \right)_{1\leq i,j\leq r}$ from the previous part, and let $X_i = \sum_{j}b_{ij}Y_j$. Show that
      \begin{align*}
        X_i &= \pd{}{x_i} + \sum_{j > r} c_{ij} \pd{}{x_j}
      \end{align*}
      for some suitable smooth functions. Show that $X_1,\dots,X_r$ form a basis for $D$ at every point.
    \item Show that $\left[ X_i,X_j \right] = 0$ for $1\leq i,j\leq r$.
    \item Use the flows generated by $\set{X_1,\dots,X_n}$ to define a smooth map $\phi\colon V\rightarrow U$ where $V$ is a neighborhood of $0\in\R^{r}$ and $U$ is a neighborhood of $p\in M$.
    \item Choose coordinates $\set{t_1,\dots,t_r}$ on $\R^{r}$ such that $\phi_{\ast}\left( \pd{}{t_i} \right) = X_i$. Argue by shrinking $V$ and $U$ if necessarily that $V$ is a submanifold of $U$. Use the fact that the flows generated by $X_1,\dots,X_r$ commute to prove that at an arbitrary point $q\in \phi(V)$, we have $D_q = T_q\phi(V)$. Conclude that $\phi(V)$ locally defines an integral submanifold $N$ of the distribution $D$.
  \end{enumerate}
\end{problem}
\begin{solution}\hfill
  \begin{enumerate}[(a)]
    \item Let $\left( U;x_1,\dots,x_r \right)$ be a chart in $N$ for $p$ such that $D_p = \Span\set{ \pd{}{x_1},\dots, \pd{}{x_r} }$. Then,
      \begin{align*}
        \left[ \pd{}{x_i},\pd{}{x_j} \right] &= \delta_{i}^{j} \pd{}{x_i},
      \end{align*}
      meaning that $D_p$ is closed under involution.
    \item Let $X$ and $Y$ be commuting vector fields. Our aim is to show that
      \begin{align*}
        \lim_{t\rightarrow 0} \frac{\left( \varphi_t \right)_{\ast}Y - Y}{t}(f) &= \left[ X,Y \right](f),
      \end{align*}
      where $\left( \varphi_t \right)_{\ast}$ is the pushforward of $\varphi_t$. To this end, observe that at $p$, the pushforward $\left( \left( \varphi_t \right)_{\ast}Y_p \right)(f)$ will map $Y_p$ from $T_pM$ to $T_{\varphi_t(p)}$, meaning that $\left( \left( \varphi_t \right)_{\ast} Y_p \right)(f) = Y_{\varphi_t(p)} \left( f\circ \varphi_{-t} \right)$. In particular, this means that to ``return to'' $p$, we must pre-compose with $\varphi_t$, implying that $\left( \left( \varphi_t \right)_{\ast}Y \right)(f) = \varphi_t^{\ast}Y\left( \varphi_{-t}^{\ast}f \right)$.\newline

      Evaluating the limit, we see that
      \begin{align*}
        \lim_{t\rightarrow 0} \frac{\left( \left( \varphi_t \right)_{\ast}Y \right)(f) - Y(f)}{t} &= \lim_{t\rightarrow 0} \frac{\varphi_t^{\ast}\left( Y\left( \varphi_{-t}^{\ast}f \right) \right) - Y\left( \varphi_{-t}^{\ast}f \right)}{t} + \frac{Y\left( f\circ \varphi_{-t} \right) - Y(f)}{t}\\
                                                                                                  &= X\left( Y(f) \right) + Y\left( \lim_{t\rightarrow 0} \frac{\varphi_{-t}^{\ast}f - f}{t} \right)\\
                                                                                                  &= X\left( Y(f) \right) - Y\left( \lim_{t\rightarrow 0} \frac{\varphi_t^{\ast}f - f}{t} \right)\\
                                                                                                  &= \left[ X,Y \right](f).
      \end{align*}
      In particular, if $ \left[ X,Y \right](f) = 0 $, then we must have that $Y$ is invariant under the pushforward $\left( \varphi_t \right)^{\ast}$.\newline

      Let $Y$ be invariant under the flow $\varphi_t$ (so since $X$ and $Y$ commute, $X$ is invariant under the flow $\psi_s$). For a fixed $s$, define $\gamma_s(t) = \left( \psi_s\circ \varphi_t \right)(p)$, so that $\gamma_s(0) = \psi_s(p)$. Using the chain rule, we compute
      \begin{align*}
        D\gamma_s\left( \pd{}{t} \right) &= D\psi_s\circ D_p\varphi_t\left( \pd{}{t} \right)\\
                                         &= D\psi_s X_{\varphi_t(p)}\\
                                         &= X_{\left( \psi_s\circ \varphi_t \right)(p)}.
      \end{align*}
      Therefore, $\gamma$ is an integral curve for $X$ about $\psi_s(p)$, meaning that $\varphi_t\left( \psi_s(p) \right) = \gamma(t)$. Thus, the flows commute.\newline

      Finally, if the integral curves $\varphi_t$ and $\psi_s$ commute, we write
      \begin{align*}
        Y_{\varphi_t(p)} &= \left( D\psi_s \right)_{\varphi_t(p)}\left( \pd{}{t} \right)\\
                         &= D\left( \varphi_t \right)_{\psi_s(p)}\left( \pd{}{t} \right)\\
                         &= D_{p}\left( \varphi_t\circ \psi_s \right)\left( \pd{}{t} \right)\\
                         &= D_{p}\left( \varphi_t \right)\left( D_{p}\psi_s\left( \pd{}{t} \right) \right)\\
                         &= D_p\left( \varphi_t \right)\left( Y_{p} \right),
      \end{align*}
      so by pushing forward, we find that
      \begin{align*}
        \left( \left( \varphi_t \right)_{\ast}Y \right)_{p} &= Y_p,
      \end{align*}
      meaning that the derivative
      \begin{align*}
        \lim_{t\rightarrow 0} \frac{\left( \left( \varphi_t \right)_{\ast}Y \right) - Y}{t} &= 0\\
                                                                                            &= \left[ X,Y \right],
      \end{align*}
      so that $X$ and $Y$ commute.
    \item At $p$, we write
      \begin{align*}
        \left( Y_i \right)_p &= \sum_{j=1}^{n} a_{ij}\left( p \right) \pd{}{x_j}.
      \end{align*}
      We consider the matrix of all the values $\left( a_{ij}(p) \right)$ such that $ 1\leq i \leq r $ and $1\leq j \leq n$. Notice that this $r\times n$ matrix consists of linearly independent columns, meaning that it is of full rank. In particular, we can put this matrix in row-echelon form, and in particular, this yields a block matrix
      \begin{align*}
        \left( u_{i,j} \right)_{i,j} &= \begin{pmatrix}I & K\end{pmatrix},
      \end{align*}
      where $K$ is some $r\times \left( n-r \right)$ matrix. Since the first $r$ blocks correlate to $Y_1,\dots,Y_r$, this means that the $\left( a_{ij}\left( p \right) \right)_{1\leq i,j\leq r}$ is invertible at $p$, meaning that, since the $a_{ij}$ are smooth, the matrix $\left( a_{ij}\left( \cdot \right) \right)_{1\leq i,j\leq r}$ is invertible in a neighborhood of $p$.
    \item Writing
      \begin{align*}
        Y_{j} &= \sum_{k=1}^{n}a_{jk} \pd{}{x_k},
      \end{align*}
      we find that, by pointwise evaluation, we have
      \begin{align*}
        \left( X_i \right)_p &= \sum_{j=1}^{r} b_{ij}(p) \sum_{k=1}^{n} a_{jk}(p) \pd{}{x_k}\\
            &= \sum_{j=1}^{r} \sum_{k=1}^{n} b_{ij}(p)a_{jk}(p) \pd{}{x_k}\\
            &= \pd{}{x_i} + \sum_{j=1}^{r} \sum_{k=r+1}^{n} b_{ij}(p)a_{jk}(p) \pd{}{x_k}\\
            &= \pd{}{x_i} + \sum_{k=r+1}^{n} \left( \sum_{j=1}^{r} b_{ij}(p)a_{jk}(p) \right) \pd{}{x_k}\\
            &\eqcolon \pd{}{x_i} + \sum_{k=r+1}^{n} c_{ik}(p) \pd{}{x_k}.
      \end{align*}
      We see that, if $X_i\neq X_j$, then
      \begin{align*}
        X_i &= \pd{}{x_i} + \sum_{k > r} c_{ik} \pd{}{x_k}\\
        X_j &= \pd{}{x_j} + \sum_{k > r} c_{ik} \pd{}{x_k},
      \end{align*}
      and since $i \neq j$, we must have that $X_i$ and $X_j$ are independent of each other.
    \item We let
      \begin{align*}
        Q &= \sum_{k > r} c_{ik}\pd{}{x_k}.
      \end{align*}
      We then have
      \begin{align*}
        \left[ X_i,X_j \right] &= \left[ \pd{}{x_i} + Q, \pd{}{x_j} + Q \right]\\
                               &= \left[ \pd{}{x_i},\pd{}{x_j} \right] + \left[ \pd{}{x_i},Q \right] + \left[ \pd{}{x_j},Q \right] + \left[ Q,Q \right]\\
                               &= 0,
      \end{align*}
      as the Lie bracket between any two distinct local basis vectors for $T_pM$ is zero.
    \item Let $\phi_1(t),\dots,\phi_r(t)$ be the flows generated by $X_1,\dots,X_r$. We then define
      \begin{align*}
        \phi\colon \R^{r}\rightarrow M
      \end{align*}
      given by
      \begin{align*}
        \phi\left( t_1,\dots,t_r \right) &= \left( \phi_1\left( t_1 \right),\dots,\phi_r\left( t_r \right) \right),
      \end{align*}
      which is a smooth coordinate map between a neighborhood of $0\in \R^{r}$ and a neighborhood $U\subseteq M$.
  \end{enumerate}
\end{solution}
\begin{problem}
  Let $i,j,k$ be formal symbols that satisfy the relations $i^2 = j^2 = k^2 = ijk = -1$. The $\R$-vector space over $\set{1,i,j,k}$ together with these multiplication rules is called the quarternion algebra $ \mathbb{H} $, which is diffeomorphic to $\R^{4}$. A typical element is $a + bi + cj + dk$, where $a,b,c,d\in \R$. Multiplication is defined by the distributive law, and real scalars commute with everything.
  \begin{enumerate}[(a)]
    \item Show that the multiplicative structure on $ \mathbb{H} $ is completely determined by the rules above.
    \item The conjugate of $q = a + bi + cj + dk$ is $ \overline{q} = a - bi - cj - dk $. A unit quaternion is one where $ \overline{q} q = 1 $. Show that the unit quaternions are diffeomorphic to $S^{3}$.
    \item Find the $ 2\times 2 $ unitary complex matrices representing $i,j,k$ with correct multiplicative structure so that the unit quaternions are explicitly diffeomorphic to $\operatorname{SU}(2)$.
    \item Show that the unit quaternions act on $\R^{3}$, which consists of the vector space spanned by $i,j,k$.
    \item Writing a vector $ v\in \R^{3} $ as $ xi + yj + zk $, show that conjugation by a unit quaternion preserves $x^2 + y^2 + z^2$.
    \item Show that every orthogonal transformation of determinant one, known as $ \operatorname{SO}(3) $, is realized by quaternionic conjugation. Show that the kernel of the map $ \operatorname{SU}(2)\rightarrow \operatorname{SO}(3) $ has order two.
    \item Show that $ \operatorname{SO}(3) $ is diffeomorphic to $ \R \mathbb{P}^{3} $.
  \end{enumerate}
\end{problem}
\begin{solution}\hfill
  \begin{enumerate}[(a)]
    \item We must verify that the multiplication table for $ 1,i,j,k $ is completely determined by the rules shown above. To this end, observe that, if we desire to know the value of $ x = ij $, then $ xk = ijk = -1 $, so that $ xk = -1 $. Then, multiplying on the right by $k$, we then get that $ xk^2 = -k = x\left( -1 \right) $, so $x = k$. Similarly, we then find that $ jk = i $ and $ ki = j $.\newline

      With the cyclic multiplication in mind, we may then compute $ ji = j\left( jk \right) =j^2 k = -k$, and similarly we find that the anti-cyclic multiplication table yields $ ik = -j $ and $ kj = -i $.
    \item Notice that $S^{3}\subseteq \R^{4}$ is given by
      \begin{align*}
        S^{3} &= \set{\left( x_1,x_2,x_3,x_4 \right) | x_1^2 + x_2^2 + x_3^2 + x_4^2 = 1}.
      \end{align*}
      If $q = a + bi + cj + dk$ is a unit quaternion, then by assigning $x_1 = a$, $x_2 = b$, $x_3 = c$, and $x_4 = d$, then we see that
      \begin{align*}
        1 &= \overline{q} q\\
          &= \left( a -bi-cj-dk \right)\left( a + bi + cj + dk \right)\\
          &= a^2 + b^2 + c^2 + d^2,
      \end{align*}
      so that $q$ is uniquely assigned to an element of $S^{3}$. Thus, $S^{3}$ is diffeomorphic to the unit quaternions.
    \item We start by associating $1$ to the identity,
      \begin{align*}
        \1 &= \begin{pmatrix}1 & 0 \\ 0 & 1\end{pmatrix}
      \end{align*}
      We then need to find three matrices $I,J,K$ (note here that $I$ does not denote the identity) subject to the constraints of:
      \begin{itemize}
        \item $I^2 = J^2 = K^2 = IJK = -\1$;
        \item $I^{\ast}I = J^{\ast}J = K^{\ast}K = \1$;
        \item $\det\left( I \right) = \det\left( J \right) = \det\left( K \right) = 1$;
      \end{itemize}
      We start by using the structure of $ \operatorname{SU}(2) $ we determined in Problem 2, and use the coordinates of
      \begin{align*}
        \left( z_1,z_2 \right) &= \left( 1,0 \right)\\
        \left( z_1,z_2 \right) &= \left( i,0 \right)\\
        \left( z_1,z_2 \right) &= \left( 0,1 \right)\\
        \left( z_1,z_2 \right) &= \left( 0,i \right)
      \end{align*}
      in the specification of $ S^{3} $. This yields the matrices of
      \begin{align*}
        \1 &= \begin{pmatrix}1 & 0 \\ 0 & 1\end{pmatrix}\\
        I &= \begin{pmatrix}i & 0 \\ 0 & -i\end{pmatrix}\\
        J &= \begin{pmatrix}0 & 1 \\ -1 & 0\end{pmatrix}\\
        K &= \begin{pmatrix}0 & i \\ i & 0\end{pmatrix}.
      \end{align*}
      Examining these, we find that
      \begin{align*}
        I^2 &= \begin{pmatrix}i & 0 \\ 0 & i\end{pmatrix} \begin{pmatrix}i & 0 \\ 0 & i\end{pmatrix}\\
            &= -\1\\
        J^2 &= \begin{pmatrix}0 & 1 \\ -1 & 0\end{pmatrix} \begin{pmatrix}0 & 1 \\ -1 & 0\end{pmatrix}\\
            &= -\1\\
        K^2 &= \begin{pmatrix}0 & i \\ i & 0\end{pmatrix} \begin{pmatrix}0 & i \\ i & 0\end{pmatrix}\\
            &= -\1\\
        IJK &= \begin{pmatrix}i & 0 \\ 0 & i\end{pmatrix} \begin{pmatrix}0 & 1 \\ -1 & 0\end{pmatrix} \begin{pmatrix}0 & i \\ i & 0\end{pmatrix}\\
            &= -\1.
      \end{align*}
      Furthermore, these matrices are in $ \operatorname{SU}(2) $ by definition, so we have thus written our desired explicit diffeomorphism.
    \item We let $ q $ be a unit quaternion, expressed as an element of $ \operatorname{SU}(2) $ by
      \begin{align*}
        q &= \begin{pmatrix}z_1 & z_2 \\ - \overline{z_2} & \overline{z_1}\end{pmatrix}.
      \end{align*}
      By linearity, we only have to verify that $q$ acts on the basis $ \set{i,j,k} $. This follows from conjugation:
      \begin{align*}
        \begin{pmatrix}z_1 & z_2 \\ - \overline{z_2} & \overline{z_1}\end{pmatrix} \begin{pmatrix} i & 0 \\ 0 & -i \end{pmatrix} \begin{pmatrix} \overline{z_1} & - z_2 \\ \overline{z_2} & z_1\end{pmatrix} &= \begin{pmatrix}z_1 & z_2 \\ - \overline{z_2} & \overline{z_1}\end{pmatrix} \begin{pmatrix} i \overline{z_1} & -iz_2\\ -i \overline{z_2} & -iz_1\end{pmatrix}\\
                           &= \begin{pmatrix} i\left( \left\vert z_1 \right\vert^2 - \left\vert z_2 \right\vert^2 \right) & i\left( -2z_1z_2 \right) \\ i\left( -2z_1z_2 \right) & -i\left( \left\vert z_1 \right\vert^2 - \left\vert z_2 \right\vert^2 \right) \end{pmatrix}\\
                           &= \left( \left\vert z_1 \right\vert^2 - \left\vert z_2 \right\vert^2 \right) \begin{pmatrix}i & 0 \\ 0 & -i\end{pmatrix} + \left( -2z_1z_2 \right) \begin{pmatrix}0 & i \\ i & 0\end{pmatrix},
                           \intertext{and similarly,}
        \begin{pmatrix}z_1 & z_2 \\ - \overline{z_2} & \overline{z_1}\end{pmatrix} \begin{pmatrix} 0 & 1 \\ -1 & 0 \end{pmatrix} \begin{pmatrix} \overline{z_1} & - z_2 \\ \overline{z_2} & z_1\end{pmatrix} &= -i\left( z_1 \overline{z_2} - \overline{z_1}z_2 \right) \begin{pmatrix}i & 0 \\ 0 & -i\end{pmatrix} + \left( z_1^2 + z_2^2 \right) \begin{pmatrix}0 & 1 \\ -1 & 0\end{pmatrix}\\
        \begin{pmatrix}z_1 & z_2 \\ - \overline{z_2} & \overline{z_1}\end{pmatrix} \begin{pmatrix} 0 & i \\ i & 0 \end{pmatrix} \begin{pmatrix} \overline{z_1} & - z_2 \\ \overline{z_2} & z_1\end{pmatrix} &= \left( z_1 \overline{z_2} + \overline{z_1}z_2 \right) \begin{pmatrix}i & 0 \\ 0 & -i\end{pmatrix} + \left( z_1^2 - z_2^2 \right) \begin{pmatrix} 0 & i \\ i & 0\end{pmatrix}.
      \end{align*}
      Thus, we see that conjugation by $q$ yields another basis for $\R^{3}$, so the unit quaternions act on $\R^{3}$.
    \item Writing
      \begin{align*}
        xi + yj + zk &\cong \begin{pmatrix}xi & y + zi \\ -y + zi & -xi\end{pmatrix}\\
                     &\eqcolon V
      \end{align*}
    we notice that the form $x^2 + y^2 + z^2$ is exactly the determinant of this matrix. Therefore, upon acting by $q\in \operatorname{SU}(2)$ , we get
      \begin{align*}
        \det\left( qVq^{\ast} \right) &= \det\left( q \right)\det\left( V \right)\det\left( q^{\ast} \right)\\
                                      &= \det\left( V \right),
      \end{align*}
      so the form is preserved.
  \end{enumerate}
\end{solution}
\end{document}
